[{"id":1,"title":"Deploying YugabyteDB on Google Kubernetes Engine with OpenEBS","author":"OPENEBS","author_info":"No author information","date":"05-04-2021","tags":["OpenEBS"," OpenSource"," Yugabyte"," Cloud Native Gke"],"excerpt":"In this blog post, we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.","content":"\n[OpenEBS](https://www.openebs.io/) is a CNCF project backed by [MayaData](https://mayadata.io/) that provides cloud-native, open source container attached storage (CAS). OpenEBS delivers persistent block storage and other capabilities such as integrated back-up, management of local and cloud disks, and more. For enterprise cloud-native applications, OpenEBS provides storage functionality that is idiomatic with cloud-native development environments, with granular storage policies and isolation that enable cloud developers and architects to optimize storage for specific workloads.\n\nBecause [YugabyteDB](https://www.yugabyte.com/) is a cloud-native, distributed SQL database that runs in Kubernetes environments, it can interoperate with OpenEBS and many other CNCF projects.\n\n***Wait, what is YugabyteDB?** It is an open source, and high-performance distributed SQL database built on a scalable and fault-tolerant design inspired by Google Spanner. Yugabyte’s YSQL API is PostgreSQL wire compatible.*\n\nIn this blog post we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\n\n**Why OpenEBS and YugabyteDB?**  \nBecause YugabyteDB is a transactional database often used as a system of record, it needs to be deployed as a StatefulSet on Kubernetes and requires persistent storage. OpenEBS can be used for backing YugabyteDB local disks, allowing the provisioning of large-scale persistent volumes. \n\nHere are a few of the advantages of using OpenEBS in conjunction with a YugabyteDB database cluster:\n\n- There’s no need to manage the local disks as OpenEBS manages them.\n- OpenEBS and YugabyteDB can provision large size persistent volumes.\n- With OpenEBS persistent volumes, capacity can be thin provisioned, and disks can be added to OpenEBS on the fly without disruption of service. When this capability is combined with YugabyteDB, which already supports multi-TB data density per node, this can prove to be[ massive cost savings on storage.](https://docs.openebs.io/features.html#reduced-storage-tco-upto-50)\n- Both OpenEBS and YugabyteDB support multi-cloud deployments [helping organizations avoid cloud lock-in.](https://docs.openebs.io/docs/next/features.html#truely-cloud-native-storage-for-kubernetes)\n- Both OpenEBS and YugabyteDB integrate with another CNCF project, [Prometheus](https://prometheus.io/). This makes it easy to [monitor both storage and the database](https://docs.openebs.io/docs/next/features.html#prometheus-metrics-for-workload-tuning) from a single system.\n\nAdditionally, OpenEBS can do [synchronous replication](https://docs.openebs.io/docs/next/features.html#synchronous-replication) inside a geographic region. In a scenario where YugabyteDB is deployed across regions, and a node in any one region fails, YugaByteDB would have to rebuild this node with data from another region. This would incur cross-region traffic, which is more expensive and lower in performance. But, with OpenEBS, this rebuilding of a node can be done seamlessly because OpenEBS is replicating locally inside the region. This means YugabyteDB does not end up having to copy data from another region, which ends up being less expensive and higher in performance. In this deployment setup, only if the entire region failed, YugabyteDB would need to do a cross-region node rebuild. Additional detailed descriptions of OpenEBS enabled use cases can be found [here.](https://docs.openebs.io/docs/next/usecases.html)\n\nOk, let’s get started!\n\n**Prerequisites**  \n![](/images/blog/yugabyte-work-flow.png)\n\n\nUsing the latest and greatest versions of the available software (as of this blog’s writing), below is the environment which we’ll use to run a YugabyteDB cluster on top of a Google Kubernetes Engine (GKE) cluster backed by OpenEBS\n\n1. YugabyteDB - [Version 2.5.3.1](https://docs.yugabyte.com/latest/quick-start/install/)\n2. OpenEBS - [Version 2.7.0](https://github.com/openebs/openebs)\n3. A [Google Cloud Platform](https://cloud.google.com/gcp/) account\n\n**Step 1: Setting Up a Cluster on GKE**  \nTo deploy YugabyteDB on the Google Cloud Platform (GCP), we first have to set up a cluster using Ubuntu as our base node image.\n\n***Note**: GKE’s Container-Optimized OS does not come with an iSCSI client pre-installed and does not allow the installation of an iSCSI client. Therefore, we’ll be using the Ubuntu with Docker image type for our nodes.*\n\nFor the purposes of this demo, I used the Google Cloud Console to configure my Kubernetes cluster. Aside from the typical defaults, here’s the options under the *Node Pools > default-pool > Nodes*  I selected\n\n- **Image Type:** Ubuntu with Docker\n- **Series:** N1\n- **Machine Type:** n1-standard-4 (4 vCPU, 15 GB memory)\n\n![](/images/blog/yugabyte-nodes.png)\n\n\nClick *Create* and wait for the Kubernetes cluster to come online.\n\n**Step 2: Configure iSCSI**  \nThe iSCSI client is a prerequisite for provisioning cStor and Jiva volumes. However, it is recommended that the iSCSI client is setup and* iscsid* service is running on worker nodes before proceeding with the OpenEBS installation. In order to set up iSCSI, we’ll first need to determine the names of the nodes in our cluster\n\n    $ kubectl get nodes\n    \n    NAME                                       \tSTATUS   ROLES    \tAGE   \tVERSION\n    gke-cluster-1-default-pool-be95f6dd-5x65  \tReady    <none>   \t18h   \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-rs6c  \tReady    <none>   \t18h \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-t4cp  \tReady    <none> \t18h  \tv1.18.15-gke.1501\n    \n    Now that we have the names of our nodes, we’ll want to log into each node and enable the iSCSI service.\n    \n    $ gcloud compute ssh <node name>\n    $ sudo systemctl enable iscsid && sudo systemctl start iscsid\n    \n    You can check the status of the iSCSI service using the following command:\n    \n    $ systemctl status iscsid\n    \n    iscsid.service - iSCSI initiator daemon (iscsid)\n       Loaded: loaded (/lib/systemd/system/iscsid.service; enabled; vendor preset: enabled)\n       Active: active (running) since Fri 2021-03-26 02:25:42 UTC; 18h ago\n         Docs: man:iscsid(8)\n      Process: 10052 ExecStart=/sbin/iscsid (code=exited, status=0/SUCCESS)\n      Process: 10038 ExecStartPre=/lib/open-iscsi/startup-checks.sh (code=exited, status=0/SUCCESS)\n     Main PID: 10059 (iscsid)\n        Tasks: 2 (limit: 4915)\n       CGroup: /system.slice/iscsid.service\n               ├─10057 /sbin/iscsid\n               └─10059 /sbin/iscsid\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Starting iSCSI initiator daemon (iscsid)...\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 iscsid[10052]: iSCSI logger with pid=10057 started!\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Started iSCSI initiator daemon (iscsid).\n    \n\n**Step 3: Install OpenEBS**  \nNext, let’s install OpenEBS. I’ve found that the OpenEBS Operator is one of the simplest ways to get the software up and running.\n\n    $ kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml\n\nOnce the installation is completed, check and verify the status of the pods. You should something similar to this:\n\n    $ kubectl get pods -n openebs\n    \n    NAME                                            READY   STATUS    \n    maya-apiserver-dd655ff87-rbgmd                  1/1     Running  \n    openebs-admission-server-5965c94767-4h8rc       1/1     Running   \n    openebs-localpv-provisioner-5495669c66-z46lr    1/1     Running   \n    openebs-ndm-dss64                               1/1     Running  \n    openebs-ndm-gnv75                               1/1     Running   \n    openebs-ndm-operator-68949644b9-mqvlx           1/1     Running  \n    openebs-ndm-r5pws                               1/1     Running  \n    openebs-provisioner-544cb85449-w9spl            1/1     Running   \n    openebs-snapshot-operator-6d65b778dd-79zcn      2/2     Running \n\n**Step 4: Create and Attach Disks to Nodes**  \nOur worker nodes need to have disks attached. These disks need to be unmounted and not have a filesystem on them. To accomplish this we’ll need to execute the following commands on each node.\n\n    $ gcloud compute disks create disk1 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-5x65 --disk disk1\n    \n    $ gcloud compute disks create disk2 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-rs6c --disk disk2\n    \n    $ gcloud compute disks create disk3 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-t4cp --disk disk3\n    \n    Next let’s verify that our block devices are indeed attached.\n    \n    $ kubectl get blockdevice -n openebs\n    \n    NAME              NODENAME                           SIZE          CLAIMSTATE   STATUS   \n    blockdevice-03... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    blockdevice-85... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active   \n    blockdevice-b0... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    \n\n**Step 5: Create a Storage Pool Claim**  \nNow that we have the names of our block devices and have verified that they are active, the next step is to create a Storage Pool Claim. We’ll use this to then create a Storage Class, and finally use that for our Persistent Volume Claims. The first step in this chain of steps is to configure our Storage Pool Claim YAML file. In this demo, I’ve named it “cstor-pool1-config.yaml”.\n\n    $ vim cstor-pool1-config.yaml\n    \n    #Use the following YAMLs to create a cStor Storage Pool.\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-disk-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-disk-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n      blockDevices:\n        blockDeviceList:\n    - blockdevice-03e93d010db5169322eb16f3e18e33ed   \n    - blockdevice-22591882979084d0fe580fe229e0d84f   \n    - blockdevice-4d1b4bacbeec1650b337c2cfda7e3a48   \n    ---\n\n    Once you’ve figured out how to exit vim, the next step is to create the resource.\n    $ kubectl create -f cstor-pool1-config.yaml\n    \n    \n\nWe can verify our storage pool with the following command:\n\n    $ kubectl get csp\n    \n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE   \n    cstor-disk-pool-6cmf   1.85M       9.94G   9.94G      Healthy   false      striped\n    cstor-disk-pool-jql6   40.6M       9.90G   9.94G      Healthy   false      striped\n    cstor-disk-pool-vbz5   68.2M       9.87G   9.94G      Healthy   false      striped\n    \n\n**Step 6: Create a Storage Class**  \nNow that we have a storage pool, let’s configure the YAML file for our storage class.  In this demo, I’ve named it “openebs-sc-rep1.yaml”.\n\n    $ vim openebs-sc-rep1.yaml\n    \n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-sc-rep1\n      annotations:\n        openebs.io/cas-type: cstor\n        cas.openebs.io/config: |\n          - name: StoragePoolClaim\n            value: \"cstor-disk-pool\"\n          - name: ReplicaCount\n            value: \"1\"\n    provisioner: openebs.io/provisioner-iscsi\n\nAssuming you have remembered how to exit vim from the previous step, we now need to create the storage class.\n\n    $ kubectl create -f openebs-sc-rep1.yaml\n\nFinally, let’s verify the storage class.\n\n    $ kubectl get sc\n    \n    NAME                  PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE \n    openebs-device        openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-hostpath      openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-jiva-default  openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-sc-rep1       openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-snapshot...   volumesnapshot.external...   Delete          Immediate\n    premium-rwo           pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n    standard (default)    kubernetes.io/gce-pd         Delete          Immediate\n    standard-rwo          pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n\nAt this point, we are now set up for Persistent Volume Claims.\n\n**Step 7: Install YugabyteDB**\n\nIn this final step we’ll install a 3 node YugabyteDB cluster running on top of GKE that will be backed by the OpenEBS deployment we just completed.\n\nThe first step is to create a namespace.\n\n*$ kubectl create namespace yb-demo*\n\nNext, let’s install the cluster using Helm.\n\n    $ helm install yb-demo yugabytedb/yugabyte --set resource.master.requests.cpu=1,resource.master.requests.memory=1Gi,\\\n    resource.tserver.requests.cpu=1,resource.tserver.requests.memory=1Gi,\\\n    enableLoadBalancer=True --namespace yb-demo  --set storage.master.storageClass=openebs-sc-rep1,storage.tserver.storageClass=openebs-sc-rep1 --set persistence.storageClass=openebs-cstor-disk --wait\n    \n\nNote that in the command above we are specifying the following so that YugabyteDB makes explicit use of OpenEBS:\n\n- *storage.master.storageClass=openebs-sc-rep1*\n- *storage.tserver.storageClass=openebs-sc-rep1*\n- *persistence.storageClass=openebs-cstor-disk*\n\nOnce the installation is complete you should be able log into the PostgreSQL compatible YSQL shell on port 5433 with the following command:\n\n    $ kubectl --namespace yb-demo exec -it yb-tserver-0 -- sh -c \"cd /home/yugabyte && ysqlsh -h yb-tserver-0\"\n    \n    ysqlsh (11.2-YB-2.5.3.1-b0)\n    Type \"help\" for help.\n    yugabyte=#\n    \n\nYou can also access the basic YugabyteDB web admin portal at:\n\n*http://<yb-master-ui-endpoint>:7000*\n\n![](/images/blog/yugabyte-master.png)\n\n**Viewing Services and Ingress**\nA quick and visual way to check out all the services and ingress is to go to the “Services and Ingress” view in the Google Cloud Console. If you’ve made it this far you should see something like this:\n\n![](/images/blog/yugabyte-ingress.png)\n\nNote: I have omitted the “Endpoints” column from the screenshot above, but in your view you’ll be able to see the IPs and ports of the various endpoints.\n\nThat’s it! You now have a 3 node YugabyteDB cluster running on GKE with OpenEBS storage.\n\n\n**Next Steps**  \nAs mentioned, MayData is the chief sponsor of the OpenEBS project. It offers an enterprise-grade OpenEBS platform that makes it easier to run stateful applications on Kubernetes by helping get your workloads provisioned, backed-up, monitored, logged, managed, tested, and even migrated across clusters and clouds. You can learn more about MayaData [here.](https://mayadata.io/)\n\n- Learn more about OpenEBS by visiting the [GitHub](https://github.com/openebs/openebs) and [official Docs](https://docs.openebs.io/) pages.\n- Learn more about YugabyteDB by visiting the [GitHub](https://github.com/yugabyte/yugabyte-db) and [official Docs](https://docs.yugabyte.com/) pages.\n\n****About the author:****\n\n![Jimmy Guerrero](/images/blog/authors/jimmy-guerrero.png)\n\nJimmy Guerrero, VP Marketing, and Community at YugaByte.\n","slug":"deploying-yugabytedb-on-google-kubernetes-engine-with-openebs"},{"id":2,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks","author":"OPENEBS","author_info":"No author information","date":"22-03-2021","tags":["Mayastor","OpenEBS"],"excerpt":"Learn about Repeatable OpenEBS Mayastor deployments and benchmarks","content":"\n## Introduction\n\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\n\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\n\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\n\n\n## OpenEBS\n\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\n\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\n\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\n\n\n## OpenEBS Mayastor\n\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\n\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\n\n\n## Introducing: the Automation Playground\n\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\n\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\n\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\n\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\n\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at [https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars](https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars)\n\n\n## Stages\n\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\n\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\n\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\n\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\n\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\n\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\n\n\n#### Stage 1: Provisioning\n\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\n\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\n\nThe nodes provisioned are of three varieties\n\n* Master nodes (for Kubernetes Masters)\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\n\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\n\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\n\n#### Stage 2: Start VPN\n\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\n\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\n\n#### Stage 3: Kubernetes setup\n\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\n\nCurrently two installation types are supported with more planned:\n\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\n\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\n\n#### Stage 4: Node preparation\n\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\n\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\n\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\n\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\n\n## Playbooks\n\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\n\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\n\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\n\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\n\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\n\n## Conclusion\n\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\n\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\n\nPlease visit us at [https://mayadata.io](https://mayadata.io) and give the Demo Playground a spin at [https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).\n\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/).\n\n\n****About the author:****\n\n![Dan Yasny](/images/blog/authors/dan-yasny.png)\n\nDan Yasny is a Principal Field Engineer at MayaData, previously he worked as a Field Engineer at ScyllaDB, an SDET, Technical Product Manager and a Sustaining Engineer at Red Hat, working on such projects as ScyllaDB, Kubernetes, OpenShift, KubeVirt, OpenStack, oVirt/RHV and more.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":3,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"12-03-2021","tags":["Localpv"," OpenEBS"," Flipkart"," TikTok"," Kubernetes"," Mayastor"," MayaData"],"excerpt":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","content":"\n**How to select the right local volume for your workloads?**\n\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\n\n![LocalPv Deployment](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\n\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: [https://github.com/openebs/openebs/blob/master/ADOPTERS.md](https://github.com/openebs/openebs/blob/master/ADOPTERS.md).\n\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\n\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\n\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\n\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\n\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\n\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\n\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\n\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:  \n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\n\n## Limitations of Kubernetes LocalPV\n\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\n\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\n\nWe have seen that cluster administrators are challenged by the following aspects:\n\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\n\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\n* Nodes have 8 to 16 high-performing NVMe SSDs.\n\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\n\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\n\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\n\n* Enforcing Capacity Limits/Thresholds\n* Securing the Volumes\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\n* Encrypting the Volumes\n* Enforce compliance with BCP by taking regular snapshots and full backups\n\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\n\n## Selecting your LocalPV\n\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\n\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\n\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\n\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\n\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\n\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\n\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: [https://github.com/openebs/openebs/blob/master/ADOPTERS.md](https://github.com/openebs/openebs/blob/master/ADOPTERS.md)","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":4,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"13-01-2021","tags":["OpenEBS"],"excerpt":"Read about OpenEBS NDM, the go-to solution for managing Kubernetes Local Storage.","content":"\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\n\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\n\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\n\n## Key Storage Problems solved by NDM\n\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\n* Cluster-wide storage visibility\n* Detect the movement of storage devices across nodes\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\n\n## Getting Started with NDM\n\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\n\nMaster: 2 virtual disks\n\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\n\n![](https://lh3.googleusercontent.com/7r1RKQF4udqvigbryA6XFOxRuoOccQSFqhM5C_e27ArTSXnsXIXZk7b3lwgJm4C2VxxWj4rHoED-pZl4PS_KVkF_SC4D2-NLJzokpg2cqlP2upSNva5PLCaBKtQCBueUhWFYTtS9)\n\n\nWorker 2: 4 physical disks\n\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\n    ```\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml\n    ```\n    (The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\n\n* Once deployed, check the blockdevices present in the cluster using\n    ```\n    kubectl get bd -n openebs -o wide\n    ```\n\n![](https://lh4.googleusercontent.com/v-iVUrfW6v3wSaXmb06pbek7as_RfFTlRJCmsPzhmId460JIsP0LvXVDBkA0FUnBdO3yt203HqHIBYorT-nP6ZtCZTKdRcao0Ws3tlNyvz8yQF9ytQN_UXxbyO9ZFs6-PeLYHQOD)\n\nSome block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\n\n* Deploy a sample application to use the block device\n\nDownload the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\n```\nkubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\n```\nNow check the status of block devices again  \n\n![](https://lh3.googleusercontent.com/A_JL0jXsZhmIPPrRYCSeMHVcPsey6ahFYV1_LVUapmbPLTrcgGEAao_ohbx9zU_SZl-lHmKGYgdMqh4czUCISSezbcOi4rznQNuX0sTAomO4y5HQLVYicTD4s1mPOZfUciacEOU_)\n\nWe can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\n\n* Pool movement across nodes\n\n  NDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\n\n* Reserving storage for workloads\n\n  NDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\n\n## Future Roadmap\n\n* Southbound provisioning\n* Metrics (currently in alpha)\n* API Service to interact with NDM\n* Ability to create partitions or LVM volume groups - preparing storage in general.\n\n## Interested in Contributing to NDM?\n\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":5,"title":"Storage is Evolving!","author":"Nick Connolly","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.","date":"11-12-2020","tags":["OpenEBS"],"excerpt":"Learn how storage has evolved over the years. ","content":"\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\n\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\n\n## The hardware environment is changing!\n\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\n\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\n\n## Application development is changing!\n\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\n\n## A New Era\n\n![](https://lh3.googleusercontent.com/5C8pUrteH4V8JB1li4myidOdIP1xAefDES3ksqG1SaxFX4YHhFZz2gX-tNQV7n4UVuHS-BvZejBVnDnLJiwte6LgGgHN2dzsKDKxC2cd-popha9Ljnw9CWNQ2JUvL_1a2F-w8x0i)\n\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\n\n## Container Attached Storage\n\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\n\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\n\n## Microsoft Windows\n\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not *supported on Windows*’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\n\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\n\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\n\n## Windows Platform Development Kit\n\n![](https://lh4.googleusercontent.com/UDp5t-uCJeM6QlsMpoZCz-oxp2CyYDPS1BMhkdeaXn4asIPhdLzy0GLG74xdceDyWAa8bCrijsMLOZfrwKC7vQyQLNS-uGJbGLXyeDtBljMvMNDQphRtcfgMJ65mhZBTC7v6wFwg)\n\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\n\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\n\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\n\n1. Enable high-performance access to NVMe storage directly from applications.\n2. Native software defined storage stacks, including OpenEBS Mayastor.\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\n\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to [https://wpdk.github.io](https://wpdk.github.io) or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":6,"title":"OpenEBS on DigitalOcean Marketplace","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"3-12-2020","tags":["OpenEBS"],"excerpt":"Learn how to deploy OpenEBS on the DigitalOcean marketplace","content":"\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\n\nWORKFLOW:\n\n![](https://lh3.googleusercontent.com/fQOb_mUG5ebZ4eu2eLCZw4WFIiG_LOUgk2xXj4tBsXokE1oMu5H4SQDcx1jgbpLYBBn4gVpeDOwgU_DhagUjyHi4_kFL3evGUjVTIfkY3Xdf6071c6XWO6AoJ5PruG5f1njtvaJm)\n\nSTEP 1: Getting started  \nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\n\nSTEP 2: Creation of cluster  \nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\n\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\n\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\n\n![](https://lh3.googleusercontent.com/zvcGjrkGegKSp-t29NQf5XPHzCf6LqRn-XFJuRsxNZBfopwNibKiUwBDo9KSFGTWub6tEqLnl_IWKtCTykql315aqUlTqa7U1ORYJ5H4OmIhdVeHArPmRELvKk94GFLIbui9LJTx)\n\nSTEP 3: Connecting your cluster\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\n\n![](https://lh4.googleusercontent.com/5ftx1DgzSOKXRQ_UdiMmakqRMdOMnyes7n0l7kT23t50dSloHosbqAgx7zH2hqaMhE77KIoKINERafGDCyPgZbvnGNQ27oIvpeNm7YqCjGv-6lx9aAgQMSoHiE4j8BrdYABdPg7K)\n\nTo verify, execute the following command:\n\n```\n$ kubectl get ns\n```\n\nOutput:\n```\nNAME     STATUS    AGE\ndefault  Active    13m\nopenebs  Active    13m\n```\nThe output must contain openebs ns in an Active state.\n\nNext, execute:\n\n```\n$ kubectl get pods -n openebs\n```\n\nOutput:\n```\nNAME                                                 READY     STATUS    RESTARTS AGE\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\nopenebs-ndm-74njq                                    1/1       Running   0        13m\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\nopenebs-ndm-spttv                                    1/1       Running   0        13m\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\n```\nAll the pods must be in a running state.\n\nSTEP 4: Attaching BlockDevices  \nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\n\n![](https://lh3.googleusercontent.com/D96l0ASgsYCKEoenZQS7r-i_bdmLMlQ2PxcxYGqYLilrFospNmLmnVwfZAT-VYBHvSP31U70bgjdo0WhUbSuDfM0mU84s3-BopEd0vxuEHlZg64cnzIwO7LlLPc9RjhL5ResDD0-)\n\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\n\n![](https://lh3.googleusercontent.com/i2IkMHV3CmVK8_fgiWMtiXhqlbkWGyCoCXaz4a0hXAR49WEuzXg6s7lbMEZFGr6oXLLFVAsLTfgJTELlrMKTE4mi5aNjDSMKMZn9XCMCGlWLpeUaaC4VsRg2xFPgw0tXLuG2T2uq)\n\nNOTE:\n\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\n\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\n\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\n\n![](https://lh4.googleusercontent.com/i9KOccFfCGjP-Q3E2KpR0YOV3EXDfTin4RbNZbgo9A0PTSYRUj8E989KqnzHYXMigbfE0FZWK1_V0Jg_lAvZKN9iShkxLIyMFGmO9uVEYWhcosL-xUNc-VnrXpYcbu1VDKE-5zOT)\n\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":7,"title":"Atlassian Jira Deployment on OpenEBS","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"20-11-2020","tags":["OpenEBS"],"excerpt":"Learn how to deploy Atlassian Jira on OpenEBS in this short post.","content":"\n***Jira*** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, **Jira** has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\n\n## Requirements\n\n#### Install OpenEBS\n\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\n\n#### Configure cStor Pool\n\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\n\n```\n#Use the following YAMLs to create a cStor Storage Pool.\n# and associated storage class.\napiVersion: openebs.io/v1alpha1\nkind: StoragePoolClaim\nmetadata:\n  name: cstor-disk\nspec:\n  name: cstor-disk\n  type: disk\n  poolSpec:\n    poolType: striped\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\n  #\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\n  # as the disk operator\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\n# Uncomment the below lines after updating the actual disk names.\n  blockDevices:\n    blockDeviceList:\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n---\n```\n\n#### Create Storage Class\n\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: openebs-cstor-disk\n  annotations:\n    openebs.io/cas-type: cstor\n    cas.openebs.io/config: |\n      - name: StoragePoolClaim\n        value: \"cstor-disk\"\n      - name: ReplicaCount\n        value: \"3\"       \nprovisioner: openebs.io/provisioner-iscsi\nreclaimPolicy: Delete\n```\n\n### Deployment of Jira\n\nSample Jira Yaml:\n\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: jira\n      name: jira\n    spec:\n      containers:\n        - name: jira\n          image: \"doriftoshoes/jira:7.3.6\"\n          resources:\n            requests:\n              cpu: \"2\"\n              memory: \"2G\"\n          volumeMounts:\n            - name: \"jira-home\"\n              mountPath: /opt/jira-home\n      volumes:\n        - name: jira-home\n          persistentVolumeClaim:\n            claimName: demo-vol1-claim\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  ports:\n    - port: 8080\n      targetPort: 8080\n  selector:\n    app: jira\n  type: LoadBalancer\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: demo-vol1-claim\nspec:\n  storageClassName: openebs-cstor-disk\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10G\n```\n\nNext, apply both the ***Jira deployment*** and service to your Kubernetes cluster.\n\n```\nkubectl apply -f jira.yaml\n```\n\n#### Verify Jira Pods:\n\n#### Run the following to get the status of Jira pods:\n\n```\nkubectl get pods\n```\n\nFollowing is an example output:\n\n```\nNAME                    READY   STATUS    RESTARTS   AGE\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\n```\n\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":8,"title":"Mayastor NVMe-oF TCP performance","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"19-11-2020","tags":["Mayastor"],"excerpt":"Overview of using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known.","content":"\nFor a while now, we have been saying that OpenEBS Mayastor is “high” performance and community members have written [blogs](https://medium.com/volterra-io/kubernetes-storage-performance-comparison-v2-2020-updated-1c0b69f0dcf4) showing that the performance of OpenEBS Mayastor indeed is much better or on par with others even when running on relatively slow cloud volumes. However, is Mayastor high performance or just “as fast” as the other things out there? \n\nIt used to be the case that CPUs were much faster than the storage systems they served. With modern NVMe, this does not ***have*** to be the case anymore. NVMe is a ***protocol*** that can go fast but does not have to be fast. What this means is that you can use NVMe as your transport protocol for any block device, not just flash. Yes, this is what Mayastor does. It is really useful to keep in mind the distinction between NVMe as a protocol and NVMe devices - you don’t need to use them together but, when you do, additional performance can be unlocked.\n\nIn this blog, we will be using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known. We will show what happens when you marry NVMe as a protocol (embedded within Mayastor) and fast NVMe devices from our friends at Intel.\n\nBefore we get started, you might wonder how we came to this point that a new project like OpenEBS Mayastor was able to deliver amongst the fastest storage available today. Richard Elling of Viking / Sanmina recently wrote an excellent blog on the trends in hardware design that puts NVMe and OpenEBS Mayastor into context:  [https://richardelling.substack.com/p/the-pendulum-swings-hard-towards](https://richardelling.substack.com/p/the-pendulum-swings-hard-towards)\n\n## Hardware setup\n\nLet’s get to it. We will be using three machines that will run kernel version 5.8. The hardware configuration of each host is as follows:\n\n- Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz\n- Intel Corporation NVMe Datacenter SSD [Optane]\n- Mellanox Technologies MT28908 Family [ConnectX-6]\n\n## Baseline performance\n\nTo understand the performance of the device we will be using throughout the test, we run the following Fio workload:\n\n    [global]\n    ioengine=linuxaio\n    thread=1\n    group_reporting=1\n    direct=1\n    norandommap=1\n    bs=4k\n    numjobs=8\n    time_based=1\n    ramp_time=0\n    runtime=300\n    iodepth=64\n    \n    \n    [random-read-QD64]\n    filename=/dev/nvme1n1\n    rw=randread\n    stonewall\n    \n    \n    [random-write-QD64]\n    filename=/dev/nvme1n1\n    rw=randwrite\n    stonewall\n    \n    \n    [random-rw-QD64]\n    filename=/dev/nvme1n1\n    rw=randrw\n    stonewall\n\n![](/images/blog/mayastor-nvme1.png)\nThese numbers are incredibly high and are provided by a ***single*** device. Note that the benchmark itself is rather synthetic in the sense that, in practice, no workload is 100% random.\n\n## High-level overview of the experiments\n\nMy approach in this benchmarking is very much OpenEBS Mayastor “the hard way”.  If you want an easier to use solution that for example automates pool creation and device selection and so on - we call that offering Kubera Propel (also open source btw). You can learn more about Kubera Propel on the [MayaData.io](https://mayadata.io/) website.    \n\nOn two of the nodes, we create a pool (MSP CRD) which we use in the control plane to determine replica placement. To construct pools, we must have what we call a persistence layer. We support several ways to access this persistence layer. To select a particular scheme we use URIs. In this case we will be using today the pcie:/// scheme. This means that Mayastor will directly write into the NVMe devices listed above. The nice thing is that from the user perspective, things do not change that much. We simply replace disks: [‘/dev/nvme0n1’] with disks: [‘pcie:///80:00.0’]. Note that this persistence layer is used to store the replicas of the PVC. Once we have this layer up and running, we will create storage classes and select that we want to use nvmf (NVMe-oF) as the transport layer between the replicas, resulting in NVMe all the way through. \n\nAfter we have deployed mayastor we applied to following two storage classes:\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf\n    parameters:\n      repl: '1'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n    ---\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf-mirror\n    parameters:\n      repl: '2'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n\nNote that `protocol: `nvmf` is just a shorthand for the NVMe-oF format mentioned above. We will be using both storage classes to run a single replica followed by a two way replica AKA mirror.  We use the following YAML to create the volume.\n\n    apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: ms-volume-claim\n    spec:\n      accessModes:\n       - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100G\n      storageClassName: nvmf\n\nAfter creating the PVC, Mayastor’s control plane creates a CRD, “Mayastor Volume” (MSV), that contains additional information about the corresponding volume.  Using kubectl describe msv -n mayastor we get:\n\n    Name:         ba081dc3-46db-445b-969c-7e5245aba146\n    Namespace:    mayastor\n    Labels:       <none>\n    Annotations:  <none>\n    API Version:  openebs.io/v1alpha1\n    Kind:         MayastorVolume\n    Metadata:\n      Creation Timestamp:  2020-09-11T08:49:30Z\n      Generation:          1\n      Managed Fields:\n        API Version:  openebs.io/v1alpha1\n        Fields Type:  FieldsV1\n        fieldsV1:\n          f:spec:\n            .:\n            f:limitBytes:\n            f:preferredNodes:\n            f:replicaCount:\n            f:requiredBytes:\n            f:requiredNodes:\n          f:status:\n            .:\n            f:nexus:\n              .:\n              f:children:\n              f:deviceUri:\n              f:state:\n            f:node:\n            f:reason:\n            f:replicas:\n            f:size:\n            f:state:\n        Manager:         unknown\n        Operation:       Update\n        Time:            2020-09-11T08:51:18Z\n      Resource Version:  56571\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/mayastor/mayastorvolumes/ba081dc3-46db-445b-969c-7e5245aba146\n      UID:               94e11d58-fed9-44c9-9368-95b6f0712ddf\n    Spec:\n      Limit Bytes:  0\n      Preferred Nodes:\n      Replica Count:   1\n      Required Bytes:  100000000000\n      Required Nodes:\n    Status:\n      Nexus:\n        Children:\n          State:     CHILD_ONLINE\n          Uri:       bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n        Device Uri:  nvmf://x.y.z.y:8420/nqn.2019-05.io.openebs:nexus-ba081dc3-46db-445b-969c-7e5245aba146\n        State:       NEXUS_ONLINE\n      Node:          atsnode3\n      Reason:\n      Replicas:\n        Node:     node3\n        Offline:  false\n        Pool:     pool-atsnode3\n        Uri:      bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n      Size:       100000000000\n      State:      healthy\n    Events:       <none>\n\n## Results single replica\n![](/images/blog/mayastor-nvme2.png)![Chart](https://lh5.googleusercontent.com/whpgDl_Id_oo4tUdl7RZDv-C1Uq2ZfvM6Eh7KXbwNkNTu5Mki14meunBgF1PMWMnWLoccSGgHqCfRKXgQpJTfQG42NaS0GkwWRCuNpWGh7znOhqQ94aJXiCODJkzNUs9-G2ucqMJ)\nFrom the results we can see that we are very close to the performance of the local device. To be sure we can put it in the right perspective, the difference between the experiments here is that with the baseline, the workload was local. With repl=1 we use the same NVMe device but export it through our pool layer (and thus provide volume management), but also go over the network.\n\n## Results 2 replicas (mirror)\n\nWe are going to repeat the same test, this time, we will use two replicas. As we now have double the disks bandwidth, we expect to see that the read performance will go up. For writes, however, we actually expect a drop in performance, because we must do each write to both disks before we can acknowledge the IO.  Note that Mayastor does not cache - if you read the blog referenced above from Richard Elling you can learn why caching seems to be falling out of favor for use cases in which millions of IOPS are desired.\n![](/images/blog/mayastor-nvme3.png)![Chart](https://lh4.googleusercontent.com/GJ7c_cZ6vuDxd9-jAnU3XxAc8L0idA9sscz2JB5XVa0taj8v56H6MSIFB56XqPQzQsy_p49-yHlwhCB8SVjZ05YfT0oRdlFt0EMBze1IDrCioqWgtWypidK9fBpb9p3ULI19Dhfa)\n## Wrapup\n\nWith the above experiments, we have demonstrated that with OpenEBS Mayastor we have built a foundational layer that allows us to abstract storage in a way that Kubernetes abstracts compute. While doing so, the user can focus on what's important -- deploying and operating stateful workloads. \n\nIf you’re interested in trying out Mayastor for yourself, instructions for how to setup your own cluster, and run a benchmark like **fio** may be found at [mayastor.gitbook.io/](https://mayastor.gitbook.io/introduction/).\n\nAnd if you are a Kubera Propel user, you’ll find that we’ve productized some of the benchmarking above so that platform teams and other users can programmatically use benchmarks in their decisions about workload placement. We are working with a number of users about operating OpenEBS Mayastor / Kubera Propel at scale. Please get in touch if you have suggestions, feedback, ideas for interesting use cases and so on. Contributions of all kinds are welcome!\n","slug":"mayastor-nvmeof-tcp-performance"},{"id":9,"title":"Mayastor Engine Reaches Beta","author":"Glenn Bullingham","author_info":"Director of Solution Architecture","date":"19-11-2020","tags":["OpenEBS"],"excerpt":"Mayastor, the storage engine by OpenEBS has reached the beta stage. Read the blog to know more.","content":"\ntitle: Mayastor Engine Reaches Beta\nAs I write this, it is early November, and the winds of change are blowing. The United States has a new president. Here in the United Kingdom, Keats' days of mists and mellow fruitfulness are departing, replaced by a low sun and the first morning frosts. And at MayaData, we see the Mayastor project carefully but tenaciously emerging from alpha/pre-release into its beta phase. In fact, Mayastor now undergirds MayaData’s commercial offering for performance sensitive containerized workloads, called [Kubera Propel](https://mayadata.io/product).\n\n> ***“Beta Software: Software considered to be feature complete and substantially free of known major defects”***\n\nSignificant contributions over the past 18 months have seen the project raised from concept to working software. A major requirement of our MVP specification is that it should carry minimal performance overhead; Mayastor is intended to satisfy demands for performance at all levels of scale. At the beginning of Autumn, working in conjunction with Intel’s labs in the UK, we were able to validate that assertion; deployed in conjunction with the latest generation of Optane NVMe devices, the Mayastor data plane was found to introduce less than 6% overhead; you can read more about that benchmarking [here](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/). Having addressed that performance criteria and the other principle MVP requirements, the Mayastor team at MayaData has begun to focus its contributions to the project on QA as we approach Beta and GA releases.\n\nIn particular, we’ve greatly increased end-to-end test coverage on Kubernetes. How MayaData tests Mayastor is something that I’ll elaborate upon in a forthcoming post.  However, suffice it to say customary suspects feature (Jenkins, mocha, nix, cargo test), whilst we’re also collaborating with our colleagues who maintain the [Litmus Chaos](https://litmuschaos.io/) project. By the time that you’re likely reading this, Mayastor-specific chaos tests should be available to all on [ChaosHub](https://hub.litmuschaos.io/).\n\n## Ease of Use, Perf, and Availability\n\nMayastor MVP requirements center on ease of use, performance, and availability. In the Beta phase and subsequent GA release, these will be realized as a CAS platform with full NVMe data path semantics, declarative configuration via CSI compliant dynamic provisioning, and N+1 synchronous mirroring of data at the persistent layer. This closely approaches functional parity with the current OpenEBS storage engines (cStor, Jiva, and Local PV), with snapshot and cloning functionality to be added in Q1 2021. Mayastor will also very soon be the recipient of a streamlined deployment and configuration experience, which is exclusive to this engine.\n\n## Try it Yourself\n\nIf you’re a member of the Kubernetes community looking to implement a platform-native storage solution in the new year, now is an ideal time to start evaluating Mayastor. The other venerable and respected engines of OpenEBS won’t be retiring overnight, but as full feature parity emerges, MayaData’s commercial products and services will on Mayastor as their default storage engine; we do recognize that some users will continue to prefer various flavors of Dynamic Local PV from OpenEBS - as a recent [blog](https://www.percona.com/blog/2020/10/01/deploying-percona-kubernetes-operators-with-openebs-local-storage/) from the CTO of Percona attests as do countless [Adopter.md case studies](https://github.com/openebs/openebs/blob/master/ADOPTERS.md) including that of the SaaS company Optoro, also a CNCF case study. Mayastor’s roadmap includes provisions for the inward migration of existing OpenEBS users. It’s an equally opportune moment to [consider becoming a contributor](https://github.com/openebs/Mayastor/issues/new/choose) to the project yourself.\n\nTo help with Mayastor onboarding as we prepare to go to full steam, we’re putting together a new documentation site over at[ GitBook](https://mayastor.gitbook.io/introduction/), which includes a comprehensive quick-start deployment guide (developer docs will remain, at least for now, with the OpenEBS/Mayastor GitHub repository). We’re also holding [Office Hours at Kubecon NA 2020 this month](https://kccncna20.sched.com/?searchstring=OpenEBS&amp;iframe=no&amp;w=&amp;sidebar=&amp;bg=), and we’d love to see you there.\n\nIf you’d like to try Mayastor from the source - you can do so, of course, from the GitHub repositories. If you’d like to also try out management utilities, including a cool management interface and available 24x7 support - please take a look at [Kubera Propel](https://go.mayadata.io/register-for-kubera-chaos-and-propel-technical-preview). A free forever for individual use tier is available.\n\n## Conclusion\n\nIt is a propitious time for MayaData and Mayastor - and for data on Kubernetes more broadly. If you have always wanted to run workloads on Kubernetes but were put off by the stories of performance challenges, you can now move forward with confidence. Kubernetes enabled storage with the help of Mayastor performs faster than that of traditional shared everything storage while retaining the ease of use, open source community, and Kubernetes semantics for which OpenEBS has become famous.\n","slug":"mayastor-engine-reaches-beta"},{"id":10,"title":"Migrate CSPIs to a different node by moving the disks","author":"Sai Chaithanya","author_info":"A developer who is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate about Data Science. Enjoys playing kabaddi and traveling.","date":"04-11-2020","tags":["OpenEBS"],"excerpt":"Step by step guide to migrate CStorPoolInstances from one node to different nodes by moving the set of underlying disks","content":"\n\nThis blog describes steps to migrate CStorPoolInstances from one node to different nodes by **moving the set of underlying disks to a new node that participates in the pool provisioning**. There were a couple of use cases where this feature can be helpful:\n\n1. Scaling down and scaling up nodes in the cluster(in a cloud environment) by retaining external volumes(for cost savings).\n2. Replacing failed storage nodes with new nodes by attaching the same old disks to the new node.\n\n**Steps to migrate the CSPI to different node:**\n\n1. Detach the disks belonging to the CSPI that you wish to migrate from the node and attach it to the new node. If you are using a cloud platform, check on their documentation, or ask the administrator about the steps to do this.\n2. Change the node selector in the CSPC YAML (next section describes how to do this).\n\n![](https://lh4.googleusercontent.com/XTwKu6lE3lyoZ3cHRO9HNJGUaTOoGfE-OWGuscrmukbxEKJNPSaEqxUPbbNnnc3dcD-Aybc2_AF0y2Scf0QBxSDG_f9QZWRu67sXZjoMKO6nymhgelEWfDzPjfGKi4D9UwLBaN0D)\n\n**Existing setup**:\n\nI have a three-node cluster with CSPC and CSI volumes already provisioned(To create CSPC pools and CSI volume click [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md#quickstart)). Here is detailed information:\n\n**Cluster details**:\n\n    Kubernetes Cluster: AWS\n    Kubernetes Version: v1.15.9\n    OpenEBS Version: 2.2.0 \n\n****Node and BlockDevice details**: **Attached three disks to three nodes(each node has one disk)\n\n    Kubectl get nodes\n    \n    NAME                STATUS   ROLES    AGE   VERSION\n    ip-192-168-29-151   Ready    <none>   16m   v1.15.9\n    ip-192-168-36-89    Ready    <none>   8h    v1.15.9\n    ip-192-168-74-129   Ready    <none>   8h    v1.15.9\n    \n    Kubectl get bd -n openebs\n    NAME                                           NODENAME          SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-36-89  10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-74-129 10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-29-151 10737418240   Claimed      Active\n\n****CSPC Manifest**: **Applied following CSPC manifest to provision cStor pools\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-74-129\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-36-89\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-29-151\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nAfter applying the above CSPC manifest, the following three CStorPoolInstances(CSPI) were created.\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-74-129 24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-36-89  24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-29-151   24100M   24113200k   false     ONLINE   8h\n\nNow everything looks good. After some time, the cluster has been scaled down **0** nodes and scaled back to **3** nodes. So after scaling operations following are new nodes in the cluster.\n\n    Kubectl get nodes\n    \n    NAME               STATUS   ROLES    AGE     VERSION\n    ip-192-168-14-90   Ready    <none>   118s    v1.15.9\n    ip-192-168-49-43   Ready    <none>   5m55s   v1.15.9\n    ip-192-168-94-113  Ready    <none>   4m6s    v1.15.9\n\nAttached old disks that participated in pool creation to new nodes, and the following is blockdevice output.\n\n    Kubectl get bd -n openebs\n    \n    NAME                                           NODENAME            SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-49-43    10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-94-113   10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-14-90    10737418240   Claimed      Active\n\nFrom the above and previous output following are blockdevice mappings with zn old node and new node:\n\n    Blockdevice  Name                                    Old Node            New Node \n    blockdevice-7d311a98255a454a717427b5c2d38426    ip-192-168-36-89        ip-192-168-49-43\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b    ip-192-168-74-129       ip-192-168-94-113\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3    ip-192-168-29-151       ip-192-168-14-90\n\nOpenEBS **NodeDiskManager**(NDM) will automatically update the details in blockdevice CRs when the disks migrate to a new node. Based on the above output, update the CSPC manifest with new **nodeSelector** values.\n\n****Updated CSPC Manifest**:**\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-94-113\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-49-43\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-14-90\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nOnce the CSPC manifest is updated then CSPIs will automatically migrate to the new node (which can be verified using ****kubectl get cspi -n openebs****).\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-94-113   24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-49-43    24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-14-90    24100M   24113200k   false     ONLINE   8h\n\n**Note:** Along with CStorPoolInstance migration, CStorVolumeReplicas belongs to CSPI will also migrate automatically.\n","slug":"migrate-cspis-to-a-different-node-by-moving-the-disks"},{"id":11,"title":"OpenEBS Backup/Restore for ZFS-LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"27-10-2020","tags":["OpenEBS"],"excerpt":"Overview of how to use Velero Backup/Restore plugin for ZFS-LocalPV to protect it against data loss.","content":"\n## Overview: OpenEBS Backup/Restore for ZFS-LocalPV\n\n**Backup** is the process of copying the data to a different/remote location to protect against accidental or corruption or any other type of data loss. Restore is the process of getting back the data from the backup. In this blog, I will discuss how we can use *Velero Backup/Restore* plugin for ***ZFS-LocalPV*** to protect it against data loss.\n\n### Pre-requisites\n\nWe should have installed the ZFS-LocalPV 1.0.0 or later version for Backup and Restore, see my previous[ blog](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d) for the steps to install the ZFS-LocalPV driver.\n\n### Setup\n\n**1.Install Velero CLI**\n\nDownload the 1.5 or later binary for ZFS-LocalPV. For Linux on amd64, we need to download below\n\n    wget\n    https://github.com/vmware-tanzu/velero/releases/download/v1.5.1/velero-v1.5.1-linux-amd64.tar.gz\n\nExtract the tarball:\n\n    tar -xvf velero-v1.5.1-linux-amd64.tar.gz\n\nMove the extracted velero binary to somewhere in your $PATH (/usr/local/bin for most users).\n\nSee the detailed steps[ here](https://velero.io/docs/v1.5/basic-install/).\n\n**2.Deploy Velero**\n\nWe will be using minio for storage purpose in this blog, we need to setup the credential file first\n\n    $ cat /home/pawan/velero/credentials-minio\n    [default]\n    aws_access_key_id = minio\n    aws_secret_access_key = minio123\n\nWe can install Velero by using below command\n\n    $ velero install --provider aws --bucket velero --secret-file /home/pawan/velero/credentials-minio --plugins velero/velero-plugin-for-aws:v1.0.0-beta.1 --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://minio.velero.svc:9000 --use-volume-snapshots=true --use-restic\n\nWe have to install the velero 1.5 or later version of velero for ZFS-LocalPV.\n\n**3.Deploy MinIO**\n\nDeploy the MinIO for storing the backup:-\n\n    $ kubectl apply -f\n    https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/sample/minio.yaml\n\nThe above MinIO uses tmp directory inside the pod to store the data for the demonstration purpose, so when restart happens, the backed up data will be gone. We should change the above YAML to use persistence storage to store the data when deploying it for the production.\n\nCheck the Velero Pods are UP and Running\n\n    $ kubectl get po -n velero\n    NAME                      READY   STATUS      RESTARTS   AGE\n    minio-d787f4bf7-xqmq5     1/1     Running     0          8s\n    minio-setup-prln8         0/1     Completed   0          8s\n    restic-4kx8l              1/1     Running     0          69s\n    restic-g5zq9              1/1     Running     0          69s\n    restic-k7k4s              1/1     Running     0          69s\n    velero-7d9c448bc5-j424s   1/1     Running     3          69s\n\n**4.Setup OpenEBS Plugin**\n\nWe can Install the Velero Plugin for ZFS-LocalPV using the below command\n\n    velero plugin add openebs/velero-plugin:2.2.0\n\nWe have to install the velero-plugin 2.2.0 or later version, which has the support for ZFS-LocalPV. Once the setup is done, we can go ahead and create the backup/restore.\n\n**5.Create the VSL**\n\nThe VSL(Volume Snapshot Location) has information about where the snapshot should be stored. To create the Backup/Restore, we can create the Volume Snapshot Location by applying the below YAML:\n\n    apiVersion: velero.io/v1\n    kind: VolumeSnapshotLocation\n    metadata:\n     name: default\n     namespace: velero\n    spec:\n     provider: openebs.io/zfspv-blockstore\n     config:\n       bucket: velero\n       prefix: zfs\n       namespace: openebs # this is the namespace where ZFS-LocalPV creates all the CRs, passed as OPENEBS_NAMESPACE env in the ZFS-LocalPV deployment\n       provider: aws\n       region: minio\n       s3ForcePathStyle: \"true\"\n       s3Url: http://minio.velero.svc:9000\n\nHere, we have to provide the namespace, which we have used as OPENEBS_NAMESPACE env while deploying the ZFS-LocalPV. The ZFS-LocalPV Operator yamls uses “openebs” as the default value for OPENEBS_NAMESPACE env. Verify the volumesnapshot location:\n\n    kubectl get volumesnapshotlocations.velero.io -n velero\n\n### Create Backup\n\nWe can use the below Velero command to create the backup:\n\n    velero backup create my-backup --snapshot-volumes --include-namespaces=<backup-namespace> --volume-snapshot-locations=default --storage-location=default\n\nwe can add all the namespaces we want to be backed up in a comma-separated format in --include-namespaces parameter. We have to provide the VSL that we have created in --volume-snapshot-locations parameter.\n\nWe can check the backup status using the velero backup get command:\n\n    $ velero backup get\n    NAME        STATUS       CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR\n    my-backup   InProgress   2020-09-14 21:09:06 +0530 IST   29d       default            <none>\n\nThe status InProgress means that the backup is in progress. Wait for it to be Completed.\n\nWe can also create a scheduled backup which will take the backup periodically. For example, to take the full backup at every 5 min, we can create the below schedule :\n\n    velero create schedule schd --schedule=\"*/5 * * * *\" --snapshot-volumes --include-namespaces=<backup-namespace1>,<backup-namespace2> --volume-snapshot-locations=default --storage-location=default\n\n### Restore\n\nIf the application and its PVC has been deployed in a namespace, then we can use the below Velero command to create the backup of the entire namespace:\n\n    velero restore create --from-backup my-backup --restore-volumes=true --namespace-mappings <source-ns>:<dest-ns>\n\nThe above command will create the backup of everything that is there in the namespace provided as --include-namespaces argument. We can provide the namespace mapping if we want to restore in a different namespace as --namespace-mappings parameter. If namespace mappings are not provided, it will restore in the source namespace only where the original pod and pvc was present. Now we can check the restore status:\n\n    $ velero restore get\n    NAME                       BACKUP      STATUS       WARNINGS   ERRORS   CREATED                         SELECTOR\n    my-backup-20200914211331   my-backup   InProgress   0          0        2020-09-14 21:13:31 +0530 IST   <none>\n\nOnce the Status is Completed, we can check the pods in the destination namespace and verify that everything is up and running. We can also verify that the data has been restored.\n\n### Summary\n\nAs demonstrated in this blog, OpenEBS makes it easy to take the backup of the Kubernetes applications, which we can use to Restore as part of disaster recovery. In my next blog, I will talk about how we can take the incremental backup of the volumes, which is space optimized backup for ZFS-LocalPV\n\n## Important links\n\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n[https://velero.io/docs/](https://velero.io/docs/v1.5/basic-install/)\n","slug":"openebs-backuprestore-for-zfslocalpv"},{"id":12,"title":"OpenEBS 2.2.0 - Enhancements And New Storage Capabilities","author":"Ashutosh Kumar","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut","date":"20-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS 2.2.0 is here! Read this post to learn about the new updates.","content":"\n### **OpenEBS 2.2.0 is here**\n\nWe are excited to announce yet another ***OpenEBS*** release that comes with new storage capabilities, control plane enhancements, bug fixes, and new APIs for the world’s fastest storage engine built on RUST, also known as Mayastor.\n\nOpenEBS has seen a wider adoption among the users, thanks to the vibrant and growing community. Like in most of the OpenEBS releases, this release responds to the feedback received in the community. If you want to learn more about the project roadmap, please browse the following link:\n[https://github.com/openebs/openebs/blob/master/ROADMAP.md](https://github.com/openebs/openebs/blob/master/ROADMAP.md)\n\nIncremental Backup and Restore in ZFS local PV and pool and volume migration in cStor are the major release milestones made into the release. The pool migration in cStor solves the use-case of replacing a bad node with a new node or sending a node for maintenance on on-premise clusters. The migration feature provides great value in cloud-managed Kubernetes clusters, too, e.g., GKE, where node reboots or voluntary scale down of nodes can cause the disks to get removed. \n\nThis release is also special due to the [*Hacktoberfest*](https://hacktoberfest.digitalocean.com/) festival and would like to give a shout out to first-time contributors [@didier-durand](https://github.com/didier-durand), [@zlymeda](https://github.com/zlymeda), [@avats-dev](https://github.com/avats-dev), and many more.\n\n### **Key Highlights of OpenEBS 2.2.0 Release:**\n\n- Mayastor aims to be the world’s fastest container attached storage and is currently in alpha. The release introduced block device enumeration feature via the gRPC API and enhancement around storage pool finalizers.\n- ZFS local PV has become a popular storage engine built on local storage design and provides powerful storage features like snapshots and clones, raw block volume, etc. It also supports day two operations like volume resize and backup and restore via the pluggable Velero interface.\nSupport for Incremental Backup and Restore by enhancing the OpenEBS Velero Plugin has been a significant highlight for ZFS local PV release. \nTo learn more about this, please refer to the document [here](https://github.com/openebs/zfs-localpv/blob/master/docs/backup-restore.md).\n- OpenEBS Velero plugin connects the Velero interface to the OpenEBS storage engines to deliver backup/restore functionality. Velero Plugin has been enhanced to restore ZFS Local PV into a different cluster or a different node in the cluster and use custom certificates for S3 object storage.\n- CStor went into beta in 2.0 and has been enhanced to migrate the storage pool from one node to another node. This will help with scenarios where a Kubernetes node can be replaced with a new node but can be attached with the block devices from the old node that contain cStor Pool and the volume data.\n- OpenEBS node disk manager helps in block device discovery and management in a Kubernetes cluster and powers storage engines like cStor. Support to exclude multiple devices that could be mounted as host filesystem directories has been added.\nAn issue where NDM could cause data loss by creating a partition table on an uninitialized iSCSI volume has also been fixed.\n\n### **Useful Links and Summary:**\n\nIf you are interested in knowing more details regarding the changes that made to this release, please visit the release note [link](https://github.com/openebs/openebs/releases/tag/v2.2.0). To try out OpenEBS, you can visit [https://docs.openebs.io/](https://docs.openebs.io/) and follow the user guides.\n\nYou can visit the following link to learn more or experiment with Mayastor\n[https://github.com/openebs/mayastor](https://github.com/openebs/mayastor)\n\nYou can visit the following link to learn more or experiment with ZFS local PV\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n\nTo learn more about the new cStor CSPC API, please visit the following link:\n[https://github.com/openebs/cstor-operators](https://github.com/openebs/cstor-operators)\n\nIf you have any feedback, questions, or suggestions — please reach out to the community on the #openebs channel in the Kubernetes workspace or consider opening a relevant issue at [Github](https://github.com/openebs/openebs).\n","slug":"openebs-220-enhancements-and-new-storage-capabilities"},{"id":13,"title":"Scaling up cStor Volume Replica","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"07-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS provides volume replication through different storage engines. Learn how to scale up cStor Volume Replica.","content":"\nEven if a cluster is reliable, nodes can and do fail. Rebooting a node does not simulate a crash. There can be many reasons, such as catastrophic hardware failure, Operating System failure, or communication failure among the nodes. To overcome this hazardous situation, the Replication of volume becomes necessary.\n\nReplication is the process by which one or more volumes can be copied to maintain the significance of a cluster and to avoid data loss. OpenEBS provides volume replication through different storage engines. One of them is cStor Volume Replication.\n![Synchronous replication of data](https://lh5.googleusercontent.com/ijS24Ywabw-QkWWYbSLoOshGTi2SHZhdEFATaHIYbkNGK8lUq5SJrct6fNHfPjWcPTHGyvByS7uD1vYct2m5D6-HdRC2ZoMpS_c4Crw-9sREhPU-tXE8KAt-nWj7vYw99Ee_s1pE)\n#### Prerequisite for scaling up the replicas of cStor volume:\n\n- A cStor pool should be available, and replicas of this cStor volume should not be present on this cStor pool.\n- The OpenEBS version should be 1.3.0 or more.\n\n### Please follow the below steps for cStor Volume Replication:\n\nGet the StorageClass name using the following command:\n\n    kubectl get sc\n\nExample Output:\n![](https://lh5.googleusercontent.com/lTma7ZqsAavmXEzGG_b4BXDMUEYXjFXf0xxnWgE70znfR_EzP3IorVFp0evkKoLMsBQ0D7gwOQxivB_bZxEcv2vhYZOe17k7mNyDBaPewTgiUdusrd3ow12ClBeQvZVmVzjDrdsI)\nThe storage class for cStor is ***openebs-sc-cstor***. Perform the following command to get the details of the corresponding StorageClass, which is used for creating the cStor volume :\n\n    Kubectl get sc openebs-sc-cstor\n\nWe will get the Yaml file of the corresponding StorageClass ***openebs-sc-cstor***.\n![](https://lh5.googleusercontent.com/81DQJ-DhT3AKseMRfCZ4NpkmOPl2Tckm76jrUxE2eECY7lrejvNz3OjomFWmNiCRwm0L2seAWzmJJhe-8xcqFirBsEUedf2xzPN4NHq2RM2YYEZZv-iKpsE03j06EQi_D5kqnDCi)\nIn the Yaml above, We can see the Replica count Value is 1.\n\nGet the volume name using the following command:\n\n    Kubectl get pvc\n\nGet the VOLUME name and use it in the following command to get the details of corresponding cStor volume. All commands are performed by considering the above PVC.\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=<Vol-name>\n\nExample output:\n![](https://lh4.googleusercontent.com/FIOJchscq3lm7UJLwnk7i1oNne_RxhjIJzI3FMANxxkRhz4yWZAue-Wu1jD03ii2aMjtdDu3zr9C-0ZGaeazkvxb_JkGnxBBDza605w_p-v9BY1ER40f6DityHwimJvhvuAR8FcT)\nGet the details of existing cStor Volume Replica details using the following command:\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nExample output:\n![](https://lh3.googleusercontent.com/68NvgkfD7audTNZN1QLt6SVw4OvN_B3MIlnFnWm8MfgDziiexFX2qeI3tX6H1TCJJgrCA8b-nZQJoM6hx1QoYWOv4q74tKwB7nrZLc9xdluXRCvWTpj-sU6sIv7aJ0AMgL3rr1AR)\nPerform the following command to get complete details of the existing cStor volume replica:\n\n    kubectl get cvr -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nGet the available cStor Pools for creating new cStor volume replica. The following command will get the other associated cStor pools details:\n\n    kubectl get csp -l openebs.io/storage-pool-claim=cstor-disk-pool | grep -v cstor-disk-pool-hgt4\n\nExample Output:\n![](https://lh6.googleusercontent.com/lcbO830nSZgValr-I4ci7FHRa6Qvqf3eG-bycWHHAniRD8mb8dwRHOwxeVObFqj4FqvXbNkb_oZUdWhMgAQuHvU1pYDecvWXhDetYGdJADBQhWfzMuwJm4d9Ywgg6bAKkj-Sd79a)\nFrom the above example output, there are 2 cStor pools available, i.e., ***cstor-disk-pool-2phf*** and ***cstor-disk-pool-zm8l***. So it is possible to scale up the current volume replica count to 3 from 1. If there are no cStor pools available to perform volume replica scale-up, then follow the [steps](https://docs.openebs.io/docs/next/ugcstor.html#expanding-cStor-pool-to-a-new-node) to create a new cStor pool by updating existing SPC configuration.\n\nPerform the following command to get the details of the cStor Pool where new replica will be created:\n\n    kubectl get csp -n openebs cstor-disk-pool-2phf -oyaml\n\nNote down following parameters from the output:\n\n- metadata.labels.cstorpool.openebs.io/name\n- metadata.labels.cstorpool.cstorpool.openebs.io/uid\n- metadata.annotations.cstorpool.openebs.io/hostname\n\nThe sample CVR Yaml is provided below:\n![](https://lh3.googleusercontent.com/JePqVqyIryf396SEkCf9NoS3kmPDXM0huqehkN3kX5f-eE7nX3-mCr42xriJeDKSNRgfVxSeQG_SUHkbqEZS4ktIzzcJ8VKCsFXuz4VhtdXpikLADE3eJdkgwH3zFd5PXRPfYc70)\nApply the updated CVR YAML spec to create the new replica of cStor volume using the following command:\n\n    kubectl apply -f cvr.yaml\n\nExample Output:\n![](https://lh5.googleusercontent.com/JElB0d8zFXHoUh6wM0QpAshOmYbVXOvH5RIR9UjJ_svM67ZR2pq6cQ4ckrq0Qw6ACpRnOqO-6nUbvLUrDhFKvgZxjrh-ke0VHnKW-pR2oyzkgXdQuRATSwy9EVN19G458ZyR_9Xd)\nVerify if new CVR is created successfully using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh4.googleusercontent.com/ql9j6Zcod6DT1vKhJrlJJaxk4YUN8Mf_o7LT3e-fBjjoybINByEwwDS5fln6K5BEJGW6vFfE8h2JA_2tFvQY5PQKo62eJvQfTE5j5JwECIz2oO3u_ypKHWRylL3gmU4KYlo4axtU)\nFrom the above output, a new replica of the cStor volume is created, and STATUS is showing as Offline.\n\nUpdate Desired Replication Factor in cStor volume with a new replica count. This can be updated by editing corresponding cStor volume CR YAML.\n\n    kubectl edit cstorvolume pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8 -n openebs\n\nThe following is the snippet of updated cStor volume CR YAML:\n![](https://lh3.googleusercontent.com/lAisXwgequP2MyeCw1cVuwUYFG9G9L5U88olJ2CjbjIOpHjlMwn-K8p11ktaCjQfxK-u5EL-ebpZofD0W_LOKmfFa-wW3eTLtBpqSt7EPYvz5rQciYeaFdT6_7PCsJkdxPVHZCVg)\n\nIn the above snippet, the desiredReplicationFactor is updated to 2 from 1. Example output:\n![](https://lh6.googleusercontent.com/uBkJft958gfjATk070ZFZOMXaq7Sb1xnd5lBVMa2sKuXo-nxwrRxQS58TPgdpoLjMuMHvT4LwPscxPdT6kgwpaDVSraLmsNwWhfanMUrNVO72K8WgxwT3_or4EdzqQkWBgI-Ka84)\nVerify if the rebuilding has started on the new replica of the cStor volume. Once rebuilding has been completed, it will update its STATUS as Healthy. Get the latest status of the CVRs using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh6.googleusercontent.com/1KjmeLgtvoFcBh0vVmB0iwj_gjo-Tkd3vVTTmaw3OaREY9KbvDUQLqyEu0Hj_aYKDpTIRSDVG2sOrTPMczJAPASlzFitSHDyocPV4Bb6IgajW-ArUpDKhi8StFesnHYZrUc3X9DJ)\n","slug":"scaling-up-cstor-volume-replica"},{"id":14,"title":"\"Hacktoberfest 2020 - Contribute to OpenEBS\"","author":"MayaData Marketing","author_info":"Mayadata Marketing Team","date":"30-09-2020","tags":["OpenEBS"],"excerpt":"Hacktoberfest 2020 is almost here. Contribute to open source project, OpenEBS, to win exciting swag.","content":"\n### Hacktoberfest returns! Contribute to OpenEBS and win exciting swag\n\nThe seventh annual [***Hacktoberfest ***](https://hacktoberfest.digitalocean.com/) celebration is almost here, and we at *OpenEBS* are happy to be participating in the contest once again. In August 2017, the OpenEBS community began growing and building a strong foundation for an open source project.\n\nWe were first introduced to *Hacktoberfest* by friends and peers at the DigitalOcean Bangalore Meetup and were immediately interested in participating. We enlisted OpenEBS as one of the projects participating in Hacktoberfest 2017. We were pleasantly surprised by the participation and enthusiasm that Hacktoberfest attracts from developers around the world. The PRs have been at their peak during Hacktoberfest.\n![](https://lh4.googleusercontent.com/Og_t8KLCiRni_LS66bpJsonSXMjcoAX671c8a2LD7ZjbkVdYZgZCRFq47sDC7hsEZt6qcaoCJPZi_gm2FnKmuzMvlg4UZAQKofU0agH2Z11TRmw6vBCQ8u3ssGfre75BN9OV-vOO)\n### Get started with OpenEBS this Hacktoberfest\n\nFollowing the smashing success we had when we participated in the event last few years, we’re going to do the same this year! MayaData makes it more exciting to participate in **Hacktoberfest **by running multiple Meetups throughout the month and helping contributors to get started with their favorite areas (in any of the programming languages) like website development and documentation enhancements. \n\nTo top it all, there are exciting prizes to be won and every contribution deserves an additional swag from MayaData. Read [this blog](https://blog.mayadata.io/openebs/experience-with-openebs-in-this-hacktoberfest) by Aswath K, one of last year’s weekly winners, who writes about his experience with OpenEBS in Hacktoberfest 2019.\n![](https://lh6.googleusercontent.com/2POqPppb7pyGM0OWwl_LlkHzwz-DSWXMMggxIeNCXvsU6EVVmNHdiIzIoTw23-ceK9R5iBleFMGiK-lw9JLtCP5VVjFGQS1QhIOXbpQhtvku5Gp5aCw4Eul_r6JcM-o0WuVZRZmj)\n### How do I contribute to OpenEBS?\n\nThat is an excellent question! OpenEBS is a Kubernetes native Container Attached Storage (CAS) that simplifies running Stateful workloads on Kubernetes. It is built on Microservices architectural patterns, fully automated development, and build pipelines.\n\nOpenEBS has several components that need your help from simple fixes like adding GitHub issue templates, to enhancing the components. These are developed using Go, Rust, Python, Javascript, Ansible, and many more interesting tools. OpenEBS is also a great way to start your journey into the exciting world of storage, containers, and Kubernetes.\n\nThe [architecture overview document ](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) is a great place to start learning and picking up a component that speaks to your passion. You could start your first contribution by enhancing that document itself for providing more clarity.\n\nThere are many other [good first issues](https://github.com/search?q=org%3Aopenebs+is%3Aissue+label%3A%22good+first+issue%22) to pick from.\n\nContributions can be anything from creating issues, improving user and contributor documents, enhancing build and docker tools, fixing and enhancing code, or unit tests and e2e tests. If you are unsure where to start, begin a discussion with the contributors on [GitHub Discussions](https://github.com/openebs/openebs/discussions) or by joining [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).\n\n### Will there be swag?\n\nYes. A big fat YES!\n\nThe official [Hacktoberfest](https://hacktoberfest.digitalocean.com/) will be giving away free t-shirts to every person making four pull requests to open source repositories during October, as well as limited-edition Hacktoberfest stickers to everyone who participates.\n\nOn top of this, you will also be able to get some exclusive and limited OpenEBS swag. When your PR to any OpenEBS repository is merged, we will contact you to fill out a form to send a special edition swag designed for Hacktoberfest.\n\nNot only this but by becoming a top weekly contributor, you’ll be able to grab even more swag.\n\nPrizes will be sent to quality contributions. The best PR will win a grand prize. Stay tuned to find out more.\n\nSo, what are you waiting for! Go get your git on and start contributing - we can’t wait to receive your PR.\n\nHappy hacking!\n\n### Getting Started:\n\n1. [https://hacktoberfest.digitalocean.com/](https://hacktoberfest.digitalocean.com/)\n2. Join [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F)\n3. Checkout the [OpenEBS Contributing guide](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md)\n4. Learn about the [architecture and components](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) of OpenEBS\n5. Create new issues for your contribution or pick one of the existing issues from [https://github.com/openebs/openebs/issues](https://github.com/openebs/openebs/issues)\n","slug":"hacktoberfest-2020-contribute-to-openebs"},{"id":15,"title":"How to deploy a PostgreSQL Cluster on Kubernetes + OpenEBS","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"02-11-2017","tags":["Crunchy"," Kubectl"," Solutions"," Kubernetes"," Openebs"],"excerpt":"Why Postgres on Kubernetes? Well, the answer is in the question. If you are already running Kubernetes on some form of cloud, you understand the ease-of-use, scalability and monitoring benefits of Kubernetes that you can apply to your database at scale.","content":"\n## Why Postgres on Kubernetes?\n\nWell, the answer is in the question. If you are already running Kubernetes on some form of cloud, you understand the **ease-of-use**, **scalability** and **monitoring** benefits of Kubernetes that you can apply to your database at scale.\n\nPostgreSQL is the **preferred** relational database for most developers around, although setting up a highly available Postgres cluster from scratch is always a challenge, being **cloud-native** adds a bit to the difficulty.\n\nThere are many ways to run **high availability** with PostgreSQL; for a list, see the [PostgreSQL Documentation](https://wiki.postgresql.org/wiki/Replication,_Clustering,_and_Connection_Pooling). To be honest, manually setting it up is quite painful, while there are better ways available. My favorite **cloud-native** Postgres cluster deployment projects are [Crunchy Data](https://www.crunchydata.com/)’s, [Sorint.lab](https://www.sorint.it/)’s [Stolon](https://github.com/sorintlab/stolon) and [Zalando](https://jobs.zalando.com/tech/)’s [Patroni](https://github.com/zalando/patroni)/[Spilo](https://github.com/zalando/spilo).\n\nSince availability requires multi-node Kubernetes deployment instead of local Minikube setup, I’ll deploy crunchy-postgres on my existing K8s cluster on AWS with two worker nodes. If you don’t have a Kubernetes cluster yet, see the [instructions to deploy one using StackPointCloud](http://containerized.me/how-to-install-openebs-on-aws-using-stackpointcloud/). Instructions after that are same in any cloud or on-premises deployment.\n\n## Prerequisites\n\n### Software\n\n- [crunchy-postgres](https://hub.docker.com/r/crunchydata/crunchy-postgres/) (for cluster deployment)\n- [Docker ](https://docs.docker.com/engine/installation/)installed\n- Kubernetes 1.5+ cluster installed\n- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) installed\n- [OpenEBS](https://github.com/openebs/openebs) installed\n\n### Cloud Provider\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) account\n\n### Deploy Crunchy PostgreSQL cluster using kubectl\n\nOnce you have OpenEBS storage classes created on your K8s cluster, you can use the following simple steps to launch a highly available PostgreSQL service with one master and one replica.\n\nDownload the files to your host, which has access to kubectl\n\n     cd $HOME\n     git clone https://github.com/openebs/openebs.git\n     cd openebs/k8s/demo/crunchy-postgres \n\n### Create the Stateful Set\n\nThe deployment will use the default images and credentials defined in the set.json file. To set custom users and passwords:\n\n    vi ~/openebs/k8s/demo/crunchy-postgres/set.json\n\nJSON file should look like below, feel free to edit the number of replicas, credentials and storage capacity. Default uses the **openebs-standard** storage class, and it is 400M.\n\n    {\n      \"apiVersion\": \"apps/v1beta1\",\n      \"kind\": \"StatefulSet\",\n      \"metadata\": {\n        \"name\": \"pgset\"\n      },\n      \"spec\": {\n        \"serviceName\": \"pgset\",\n        \"replicas\": 2,\n        \"template\": {\n          \"metadata\": {\n            \"labels\": {\n              \"app\": \"pgset\"\n            }\n          },\n          \"spec\": {\n            \"containers\": [\n              {\n                \"name\": \"pgset\",\n                \"image\": \"crunchydata/crunchy-postgres:centos7–9.6–1.4.0\",\n                \"ports\": [\n                  {\n                    \"containerPort\": 5432,\n                    \"name\": \"postgres\"\n                  }\n                ],\n                \"env\": [\n                  {\n                    \"name\": \"PG_MASTER_USER\",\n                    \"value\": \"master\"\n                  },\n                  {\n                    \"name\": \"PGHOST\",\n                    \"value\": \"/tmp\"\n                  },\n                  {\n                    \"name\": \"PG_MODE\",\n                    \"value\": \"master\"\n                  },\n                  {\n                    \"name\": \"PG_MASTER_PASSWORD\",\n                    \"value\": \"password\"\n                  },\n                  {\n                    \"name\": \"PG_USER\",\n                    \"value\": \"testuser\"\n                  },\n                  {\n                    \"name\": \"PG_PASSWORD\",\n                    \"value\": \"password\"\n                  },\n                  {\n                    \"name\": \"PG_DATABASE\",\n                    \"value\": \"userdb\"\n                  },\n                  {\n                    \"name\": \"PG_ROOT_PASSWORD\",\n                    \"value\": \"password\"\n                  }\n                ],\n                \"volumeMounts\": [\n                  {\n                    \"name\": \"pgdata\",\n                    \"mountPath\": \"/pgdata\",\n                    \"readOnly\": false\n                  }\n                ]\n              }\n            ]\n          }\n        },\n        \"volumeClaimTemplates\": [\n          {\n            \"metadata\": {\n              \"name\": \"pgdata\"\n            },\n            \"spec\": {\n              \"accessModes\": [\n                \"ReadWriteOnce\"\n              ],\n              \"storageClassName\": \"openebs-standard\",\n              \"resources\": {\n                \"requests\": {\n                  \"storage\": \"400M\"\n                }\n              }\n            }\n          }\n        ]\n      }\n    }\n\nSave the file and run the statefulset:\n\n    ./run.sh\n\nThe above step will automatically create the OpenEBS volumes required for master and replica postgresql containers and few other Kubernetes objects:\n\n- Persistent Volumes (pvc-{UID1}, pvc-{UID2})\n- Persistent Volume Claim (pgdata-pgset-0, pgdata-pgset-1)\n- Replica Sets (pvc-{UID1}-ctrl-{random1},pvc-{UID1}-rep-{random2},pvc-{UID2}-ctrl-{random3},pvc-{UID4}-ctrl-{random4})\n- Service Account (pgset-sa)\n- Services (pgset, pgset-master, pgset-replica)\n- StatefulSet (pgset)\n- Pods (pgset-0, pgset-1)\n\n![](https://cdn-images-1.medium.com/max/800/0*_WTDmIAcGNUGL0zn.gif)\n\nThe volume details can be inspected using the standard kubectl commands. To check **persistent volume claims**:\n\n    kubectl get pvc\n\n![](https://cdn-images-1.medium.com/max/800/0*Jj59F2CWdQqKOkjW.png)\n\nCheck **persistent volumes**:\n\n    kubectl get pv\n\n![](https://cdn-images-1.medium.com/max/800/0*cm0u7Ea_12FvQRC4.png)\n\nList the **services**, and you will see pgset, master and replica created:\n\n    kubectl get service\n\n![](https://cdn-images-1.medium.com/max/800/0*d5PjsFswTOOSBAcq.png)\n\nList the **statefulsets**, and you will see pgset listed with two desired and current sets:\n\n![](https://cdn-images-1.medium.com/max/800/0*F3eKWl181xp3yKLJ.png)\n\nIf you use the **Kubernetes Dashboard**, you can see the same under **Workloads > Stateful Sets** and quickly scale up as well.\n\n![](https://cdn-images-1.medium.com/max/800/0*fQO6h-cj00rbePIi.png)\n\n### Test your Database\n\nIf it is not installed previously, install psql client:\n\n    sudo apt-get install postgresql-client\n\nTest the master as follows (default password is “password”, unless you changed it):\n\n    psql -h pgset-master -U testuser password -c ‘table pg_stat_replication’\n\nAbove command should return output indicating that a single replica is connecting to the master.\n\nNow, test the replica as follows:\n\n    psql -h pgset-replica -U testuser password -c ‘create table foo (id int)’\n\nThis command should fail as the replica is read-only within a PostgreSQL cluster.\n\n---\n\n*Originally published at [Containerized Me](http://containerized.me/how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs/)*.\n","slug":"how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs"},{"id":16,"title":"How to Install OpenEBS on AWS using StackPointCloud?","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"23-10-2017","tags":["Kubernetes"," Solutions"," Stackpointcloud"," Ubuntu"," Openebs"],"excerpt":"What is StackPointCloud? StackPointCloud is a managed Kubernetes control plane to build cloud-native stacks on AWS, Google Cloud (GKE & GCE), Azure & DigitalOcean. ","content":"\n## What is StackPointCloud?\n\nStackPointCloud is a managed Kubernetes control plane to build cloud-native stacks on AWS, Google Cloud (GKE & GCE), Azure & DigitalOcean. StackPointCloud simplifies installation and aggregation of multiple Kubernetes clusters pretty much on any platform. Even if you are an expert, provisioning your own Kubernetes stack their easy to use interface and capabilities to centralize all your deployments in one place is compelling. StackPointCloud is free for the first 30 days and $49.95 month after for any number of Kubernetes clusters.\n\n## Prerequisites\n\nMinimum requirements for deploying your Kubernetes clusters on StackPointCloud:\n\n### Hardware\n\n- None\n\n### Software\n\n- [OpenEBS](https://github.com/openebs/openebs)\n\n### Cloud Provider\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) account (Other major providers supported by StackPoint, but not covered in this article)\n\n## Start your StackPoint Trial\n\nFirst, go to [stackpoint.io](https://stackpoint.io/) and click on **Launch a Cluster** button to start your free trial.\n\n![](https://cdn-images-1.medium.com/max/800/0*3Iro4mlPVlQolQfh.png)\n\nThen choose your cloud provider. In this example, I will use **AWS**.\n\n![](https://cdn-images-1.medium.com/max/800/0*s0vkUYR7sJXoR6IU.png)\n\n#### Configure Access to AWS\n\nOn the next screen, we need to configure our provider. You need to provide AWS Access Key ID and Secret Access Key and optionally your SSH Key.\n\n![](https://cdn-images-1.medium.com/max/800/0*_2SUsICymTDtGlwK.png)\n\nIf you don’t know where to find them, follow the instructions [here](https://stackpointcloud.com/community/tutorial/how-to-create-auth-credentials-on-amazon-web-services-aws) to create your user.\n\nClick on **Add Credentials** button.\n\n![](https://cdn-images-1.medium.com/max/800/0*5LX2XDbBqhnm1au8.png)\n\nAfter you add your credentials, click on **Submit**.\n\n## Configure K8s Cluster\n\nOn “Configure your cluster” page click the edit button on **Distribution** and choose **Ubuntu 16.04 LTS**.\n\n![](https://cdn-images-1.medium.com/max/800/0*ty0IA_1uuDxaCQoX.png)\n\nChange the **Cluster Name** something meaningful like **OpenEBS Demo**.\n\n![](https://cdn-images-1.medium.com/max/800/0*50cyzQI-2DZIX-AG.png)\n\nI could separate my etcd into 3 nodes dedicated cluster, but for a functional demo hosting it on the same cluster works perfectly fine. You can leave all other option as default. Now click on **Submit** to create your cluster. This should take around 5–8 minutes to bring up one Master and two Workers Kubernetes Cluster.\n\n## Import OpenEBS Helm Charts\n\nClick on **Solutions** tab on the top of the screen and select **Import Charts** from the upper left.\n\n![](https://cdn-images-1.medium.com/max/800/0*vZr9hqN35SCCsx-a.png)\n\nAdd the chart repo with the following details:  \n — **name :** openebs-charts  \n — **type :** packaged-charts  \n — **repo url : **[https://openebs.github.io/charts/](https://openebs.github.io/charts/)\n\nClick on **Review Repository**.\n\n![](https://cdn-images-1.medium.com/max/800/0*lkT38CLmsESK2i1T.png)\n\nMake sure **Access Verified** shows ok and click on **Save Repository** button to finish adding chart repo.\n\n![](https://cdn-images-1.medium.com/max/800/0*tS9uArAROjoOLc05.png)\n\n## Adding OpenEBS to Your Kubernetes Cluster\n\nFirst, make sure your cluster and all nodes are up.\n\nOn the **Control Plane** tab click on your cluster name **OpenEBS Demo**.\n\n![](https://cdn-images-1.medium.com/max/800/0*0wxTlbbO_yPMJZ8F.png)\n\nOnce the Kubernetes cluster is up on AWS with functional Helm, click on the **Solutions** tab and **Add Solution** button.\n\n![](https://cdn-images-1.medium.com/max/800/0*QofakUAHAb_DRYWp.png)\n\nAdd the solution with the following details:\n\n– **namespace :** default  \n– **values -> rbacEnabled :** false  \n\n![](https://cdn-images-1.medium.com/max/800/0*JiSAsRHf5SND0Cbp.png)\n\nClick on **Install** to finally add OpenEBS into your cluster.\n\nState field should be green after OpenEBS is successfully added.\n\n![](https://cdn-images-1.medium.com/max/800/0*1nY357dtw3PNOfAi.png)\n\nNow your cluster is ready; you can run your workloads on openebs-standard storage class.\n\nTo confirm, click on **K8s Dashboard**. This will bring up your Kubernetes Dashboard UI in a new window. You should be able to find the **openebs-standard** option under **Storage Classes**.\n\n![](https://cdn-images-1.medium.com/max/800/0*E5eYS81HcguHaG1r.png)\n\nI’ll cover some workload examples such as MongoDB, Percona, Cassandra and [Postgres](http://containerized.me/how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs/) running OpenEBS on my next blogs (stay tuned).\n\n---\n\n*Originally published at [Containerized Me](http://containerized.me/how-to-install-openebs-on-aws-using-stackpointcloud/)*.\n","slug":"how-to-install-openebs-on-aws-using-stackpointcloud"},{"id":17,"title":"How to Install OpenEBS with Kubernetes using MiniKube","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"22-10-2017","tags":["Container"," Docker"," Minikube"," Kubernetes"," Solutions"," Openebs"],"excerpt":"Whether you are a newbie to Kubernetes looking for a small setup to start or a developer who uses Kubernetes on a daily basis, Minikube is the tool that helps you quickly set up and run a Kubernetes environment locally. ","content":"\n## What is MiniKube?\n\nWhether you are a newbie to Kubernetes looking for a small setup to start or a developer who uses Kubernetes on a daily basis, Minikube is the tool that helps you quickly set up and run a Kubernetes environment locally. Minikube runs a single-node Kubernetes cluster inside a VM on your laptop for users looking to try out Kubernetes or develop with it day-to-day.\n\nThere are several options available for developers to install Minikube based on an operating system. You can read the detailed instructions for the three most popular operating systems in [Minikube Setup](https://github.com/kubernetes/minikube).\n\nHowever, if you are already an experienced Minikube user, skip the Minikube setup instructions and jump directly to the **Setup OpenEBS** section.\n\nIn this post, I will explain how to set up Kubernetes using Minikube directly on Ubuntu 16.04 (without using any VM drivers) and how to configure OpenEBS in hyper-converged mode or, more accurately, create your Container-Converged Infrastructure using OpenEBS Container Attached Storage (CAS).\n\n## Prerequisites\n\nMinimum requirements for Minikube:\n\n### Hardware\n\n- Machine Type — minimum 4 vCPUs.\n- RAM — minimum 4 GB.\n- VT-x/AMD-v virtualization must be enabled in your system BIOS\n\n### Software\n\n- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\n- If using macOS:\n- xhyve driver, [VirtualBox](https://www.virtualbox.org/wiki/Downloads), or VMware Fusion.\n- If using Linux:\n- [VirtualBox](https://www.virtualbox.org/wiki/Downloads) or KVM.\n\n**NOTE:** Minikube supports the `-vm-driver=none` option that runs Kubernetes components on the host and not in a VM. Docker is required to use this driver, but no the hypervisor.\n\n- If using Windows:\n- [VirtualBox](https://www.virtualbox.org/wiki/Downloads) or Hyper-V. VMware Workstation is not supported.\n\nSince VirtualBox is available on all three platforms, I will describe this option.\n\n## Install VirtualBox\n\nI will not cover the details of VirtualBox installation since it is very common and instructions are widely available online.\n\n1. Go to the [Virtualbox website](https://www.virtualbox.org/wiki/Downloads).\n2. Download and install the binaries required for your operating system.\n\nMake sure that you install [VirtualBox 5.2.0 Oracle VM VirtualBox Extension Pack](http://download.virtualbox.org/virtualbox/5.2.0/Oracle_VM_VirtualBox_Extension_Pack-5.2.0-118431.vbox-extpack) as well.\n\nWhen I was writing this blog post, the most current version was VirtualBox-5.2.0–118431.\n\nOnce VirtualBox is installed, you will see a screen similar to the following:\n\n![](https://cdn-images-1.medium.com/max/800/0*HztM26xqSWKiYaIx.png)\n\n**NOTE:** You can also use KVM, Hyper-V, and VMware Fusion.\n\n## Install Ubuntu\n\nCreate a new VM with 4 vCPUs, 4Gb memory, and 10GB disk space.\n\n![](https://cdn-images-1.medium.com/max/800/0*8wqBzAyAPf_LsbFk.png)\n\nDownload your preferred version of [Ubuntu](https://www.ubuntu.com/download). I will be using Ubuntu 16.04.3 LTS.\n\nUnder **VM Settings/Storage**, mount your ISO image and power on the VM.\n\nInstall Ubuntu with default options. I used *openebs/password* as username/password for simplicity. If you use something else make sure to replace it with yours when you follow the instructions.\n\nFinally login to your Ubuntu VM.\n\nOn your Ubuntu host, install the SSH server:\n\n    sudo apt-get install openssh-server\n\nNow you should be able to access your VM using SSH. Check the status by running:\n\n    sudo service ssh status\n\n![](https://cdn-images-1.medium.com/max/800/0*1rUwIrG2T0EzoBJj.png)\n\nDisable firewall on your Ubuntu VM by running:\n\n    sudo ufw disable\n    \n\nInstall curl if it’s not already installed:\n\n    sudo apt install curl\n\nBy default, for each virtual machine, VirtualBox creates a private network (10.0.2.x) which is connected to your laptop’s network using NAT. However, you may not be able to your VMs from your local host through SSH just yet. To access your VM, you need to configure port forwarding. In the network setting of the VM. Click on **Advanced/Port Forwarding** and create a rule with the **Host port 3022 **and **Guest Port 22**. Name it *SSH* and leave other fields blank.\n\n![](https://cdn-images-1.medium.com/max/800/0*uDKLTcZapcEZfK3E.png)\n\nNow you can connect to your Ubuntu VM from your laptop using SSH with localhost as the address and port 3022 instead of 22. Connect to your Ubuntu VM using the following credentials: `openebs/password`\n\n## Install Docker\n\nTo get the latest version of Docker, install it from the official Docker repository.\n\nOn your Ubuntu VM, run the following commands:\n\n    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n    sudo add-apt-repository “deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable”\n    sudo apt-get update\n\n![](https://cdn-images-1.medium.com/max/800/0*-4QRgWvjit9qyKaq.png)\n\nConfirm that you want to install the binaries from the Docker repository instead of the default Ubuntu repository by running:\n\n    sudo apt-get install -y docker-ce\n\n![](https://cdn-images-1.medium.com/max/800/0*Hh8nFvl7xArgJnN-.png)\n\nInstall Docker and make sure it’s up and running after installation is complete:\n\n    sudo apt-get install -y docker-ce\n    sudo systemctl status docker\n\n![](https://cdn-images-1.medium.com/max/800/0*NTvaIXL4LiPakwEy.png)\n\n## Add iSCSI Support\n\nOpenEBS uses iSCSI to connect to the block volumes. Therefore, you need to install the `open-iscsi` package on your Ubuntu machine.\n\nOn your Ubuntu host, run:\n\n    sudo apt-get update\n    sudo apt-get install open-iscsi\n    sudo service open-iscsi restart\n\n![](https://cdn-images-1.medium.com/max/800/0*OmIy-bxY3PrD_HYT.png)\n\nCheck that the iSCSI initiator name is configured:\n\n    sudo cat /etc/iscsi/initiatorname.iscsi\n\nVerify the iSCSI service is up and running:\n\n    sudo service open-iscsi status\n\n![](https://cdn-images-1.medium.com/max/800/0*30EupY6kOMa30SMj.png)\n\n## Set up minikube and kubectl\n\nOn your Ubuntu host, install minikube by running:\n\n    curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\n    chmod +x minikube\n    sudo mv minikube /usr/local/bin/\n\n![](https://cdn-images-1.medium.com/max/800/0*62DCuwG4tX8iU_AX.png)\n\nInstall kubectl:\n\n    curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\n    chmod +x kubectl\n    sudo mv kubectl /usr/local/bin/\n\n![](https://cdn-images-1.medium.com/max/800/0*9jZx-rusvrdn9mEe.png)\n\nSet up directories for storing minkube and kubectl configurations:\n\n    mkdir $HOME/.kube || true touch $HOME/.kube/config\n\nSet up an environment for minikube by adding the following lines to the end of the `~/.profile` file:\n\n     export MINIKUBE_WANTUPDATENOTIFICATION=false\n     export MINIKUBE_WANTREPORTERRORPROMPT=false\n     export MINIKUBE_HOME=$HOME\n     export CHANGE_MINIKUBE_NONE_USER=true\n     export KUBECONFIG=$HOME/.kube/config\n\nConfirm that environment variables are saved in your profile file:\n\n    cat ~/.profile\n\n![](https://cdn-images-1.medium.com/max/800/0*rxjoxM6qkYkppd5h.png)\n\nStart minikube:\n\n    sudo -E minikube start — vm-driver=none\n\n![](https://cdn-images-1.medium.com/max/800/0*UaQ_6Y2m4hv6P4oc.png)\n\nIf you forgot to install Docker, you will get the following error:\n\n![](https://cdn-images-1.medium.com/max/800/0*ysp8RnG5DWDu_Q0j.png)\n\nWhen using the none driver, the kubectl config and credentials generated will be root-owned and will appear in the root home directory. To fix this, set the correct permissions:\n\n    sudo chown -R $USER $HOME/.kube\n    sudo chgrp -R $USER $HOME/.kube\n    sudo chown -R $USER $HOME/.minikube\n    sudo chgrp -R $USER $HOME/.minikube\n\n## Verify minikube configuration\n\nVerify that minikube is configured correctly and it has started by running:\n\n    minikube status\n\n**Example:**\n\n![](https://cdn-images-1.medium.com/max/800/0*yK3Wlyy81I15tNZp.png)\n\n**Note**\n\n- If the minikube status displays **Stopped**, add the `sudo minikube start` command.\n- If you forgot to set the permissions, minikube will display errors indicating permissions denied to configuration files, fix the permissions by running the following commands:\n\n    sudo chown -R $USER $HOME/.kube\n    sudo chgrp -R $USER $HOME/.kube\n    sudo chown -R $USER $HOME/.minikube\n    sudo chgrp -R $USER $HOME/.minikube\n\n## Verify Kubernetes configuration\n\nCheck that kubectl is configured and services are up and running by getting the list of Kubernetes nodes and pods:\n\n    kubectl get nodes\n    kubectl get pods — all-namespaces\n\n![](https://cdn-images-1.medium.com/max/800/0*noWgoiv0GLk43BRB.png)\n\n## Set up OpenEBS\n\nDownload the latest OpenEBS Operator files using the following commands:\n\n    git clone https://github.com/openebs/openebs.git\n    cd openebs/k8s\n\n![](https://cdn-images-1.medium.com/max/800/0*UNKK2cZhYPJVbTDx.png)\n\nBy default, OpenEBS launches OpenEBS Volumes with two replicas. To set one replica, as is the case with a single-node Kubernetes cluster, in the openebs-operator.yaml file, specify the environment variable `DEFAULT_REPLICA_COUNT=1`. This is supported in OpenEBS version 0.4 onward.\n\n![](https://cdn-images-1.medium.com/max/800/0*SxXEzbDmpVA5ZhwS.png)\n\nApply the configuration changes:\n\n    kubectl apply -f openebs-operator.yaml\n\n![](https://cdn-images-1.medium.com/max/800/0*WB16UScHye4LClft.png)\n\nAdd the OpenEBS storage classes that can then be used by developers and applications:\n\n    kubectl apply -f openebs-storageclasses.yaml\n\n![](https://cdn-images-1.medium.com/max/800/0*mojNYfZbll-g6bdk.png)\n\n#### Running stateful applications with OpenEBS storage\n\nTo use OpenEBS as persistent storage for your stateful workloads, set the storage class in the Persistent Volume Claim (PVC) of your application to one of the OpenEBS storage class.\n\nGet the list of storage classes using the following command. Choose the storage class that best suits your application.\n\n    kubectl get sc\n\n![](https://cdn-images-1.medium.com/max/800/0*artfNnT8fZSziaKH.png)\n\nYou can find samples of YAML files for stateful workloads using OpenEBS under the the `openebs/k8s/demo` folder.\n\n![](https://cdn-images-1.medium.com/max/800/0*KCn5Z4-av-7Hevj_.png)\n\nNow you have your Kubernetes cluster up and running. In my next blog posts, I will cover installation of stateful workloads such as Cassandra and [PostgreSQL](http://containerized.me/how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs/), as well as benefits of running your stateful workloads on OpenEBS. Stay tuned!\n\n---\n\n*Originally published at [Containerized Me](http://containerized.me/how-to-install-openebs-with-kubernetes-using-minikube/)*.\n","slug":"how-to-install-openebs-with-kubernetes-using-minikube"},{"id":18,"title":"Why are users using OpenEBS *on* EBS?","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"19-10-2017","tags":["Container Native Storage"," Featured"," MySQL"," Kubernetes"," Openebs"],"excerpt":"We were a little surprised to see OpenEBS started to be used on top of EBS itself. So we dug in and asked why?","content":"\nWe were a little surprised to see OpenEBS started to be used on top of EBS itself. So we dug in and asked why?\n\nThe following lays out what we learned, focusing mostly on the most common use case.\n\nAs you likely know, broadly speaking, there are two types of stateful applications. We call them Mercy Apps and NoMercy apps (Not generic names, but we started using these names in the OpenEBS community discussions 🙂 )\n\n1. **Mercy Apps** — The apps deal with data resiliency at the application level; for example they synchronously replicate and disperse the data and will have less dependency on high availability of storage underneath. Some examples of mercy apps are Cassandra and even (usually) MongoDB.\n2. **NoMercy Apps** — The apps that have a single copy of the data and have no idea of synchronous replication of data. These applications assume that the underlying storage is always (at least highly) available. The most famous example for NoMercy apps is the famous “mysql server”.\n\nToday, most of the legacy apps are NoMercy Apps. Also mysql or Postgres tends to be the first choice for most of the developers and remain the most commonly used databases for a quick application development and deployment. The applications that use mysql underneath are being containerized and probably being moved to the cloud container services such as Amazon ECS. It is important to note that even NoSql databases like MongoDB that protect the data across nodes are often deployed as a single copy (as a NoMercy App) and that we are seeing cases where users of NoSql use the storage for node pre-population for example instead of relying on node rebalancing at the application / NoSql level.\n![](https://cdn-images-1.medium.com/max/800/1*Bayd4nQST787TIbYo_5aWg.png)  \n**Shifting from legacy to micro services**\n\nOnce you lift and shift your legacy app onto containers and the cloud, you ideally want to allow for Kubernetes to orchestrate the dynamism of container movements among various hosts; while this dynamism is core to the value of containerization, it also creates a unique challenge for the availability of data/storage to the application.\n\n![](https://cdn-images-1.medium.com/max/800/1*ISz4kvGREGlXZkBwiwSRjQ.png)  \n\n**EBS volume may not be immediately available**  \n\nAs the above drawing suggests, we learned from some OpenEBS community users that when app containers move from one host to another, the time it takes to detach the EBS volume from one host and to attach the same EBS volume to the new host can *cause downtime for the stateful application*.\n\n### There are two solutions to this problem.\n\n***First solution :*** Re-architect your application, and make it a mercy application. Use the new age databases like Cassandra or MongoDB and configure them to protect the data at application layer, which of course needs special training and quite a bit of work. Even the flavor of SQL support may change, so you may find yourself rewriting your queries, always a source of fun and enjoyment 🙂\n![](https://cdn-images-1.medium.com/max/800/1*rdabUhTkx6iF3Ncv3EKlrQ.png)  \n**Sync replicate at the db level**\n\nBtw, if the thought of moving to a new Database is daunting, you would be interested in using plug-in code to the existing no-mercy apps to perform the synchronous replication. In case of MySQL, one option is to migrate to MariaDB and then use the Galera sync replication plugin. You would be lucky if you already have a plugin that is resilient and doesn’t add performance overheads.\n\n***A second solution*** — that is probably the top reason users are running OpenEBS and similar containerized storage controllers ON EBS — is a more elegant one : *protect the data at the storage layer*. By putting OpenEBS into your pods as the provider of storage and letting it handle data placement on the local nodes (in this case one or more, yes, EBS volumes) while also replicating the data per the policies you prefer, you avoid rewiring your application.\n\n![](https://cdn-images-1.medium.com/max/800/1*3npgXXxGEOFD4uh_KRvPng.png)  \n**Using OpenEBS for high availability of Mysql DB data on AWS EBS**\n\nOk, great, however — you are now doing storage differently. Isn’t that itself a challenge?\n\nWell, if you are already moving towards Kubernetes than you are already learning the skills needed to run OpenEBS. OpenEBS is integrated into the Kubernetes storage architecture to make the volume provisioning basically the same behind the scenes experience as attaching the EBS volume for a given pod. Instead of attaching the AWS EBS volume to the application pod using kubernetes.io/aws-ebs provisioner, the developer simply uses kubernetes.io/openebs provisioner. The underlying pieces such as integrating the AWS EBS volume into OpenEBS volume are handled by the OpenEBS provisioner.\n\nMileage may of course vary. We are building OpenEBS in the open in part to get feedback from users like those that prompted me to write this blog in the first place. Please share with the community experience of running OpenEBS on your Kubernetes based AWS ECS — whether your applications are Mercy or NoMercy. You can find the instructions and help [here](http://openebs.readthedocs.io/en/latest/install/cloud_solutions.html#amazon-cloud). And — yes — we welcome other bloggers 🙂 We’ve seen a huge ramp in issues and PRs and so forth in the last couple of months. The next step might be users blogging — please feel free and we’ll help if useful.\n","slug":"why-are-users-using-openebs-on-ebs"},{"id":19,"title":"How to build an e2e?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"17-10-2017","tags":["Cloud Storage"," E2e Testing"," Featured"," Kubernetes"," Storage"],"excerpt":"e2e which expands into end to end speaks for itself. It can be treated as component testing, integration testing or something that tries to test stuff outside the scope of unit tests.","content":"\n### What is e2e?\n\nWell *e2e* which expands into end to end speaks for itself. It can be treated as component testing, integration testing or something that tries to test stuff outside the scope of unit tests. I got attracted to this side of development when I was surprised looking at the one of the smallest possible directory name ever in a code based project. As I speak, we get to see a number of Go based projects having an *e2e* folder. I believe, it has been popularized by the likes of etcd, Kubernetes and perhaps a few other open source communities.\n\n### How to build one?\n\nBefore even getting into the How’s part, we must rather be comfortable with following questions:\n\n— *Do we need to ?*  \n — *Does our project need one ?*\n\nMore often than not, a code based project will love to have one. Perhaps not with this name but the need will definitely exist. Some of the guiding principles highlighted in this article will also help us in getting the answers to these questions. So keep reading.\n\n### Assuming our project needs one, how to build it then?\n\nAre there any guidelines / rules that we can follow ? Here they are:\n\n— ***`Refer and re-use wherever possible than build from scratch`*** is the golden rule.\n\n— ***`Start Small`***. In this context it refers to '*not to gulp the entire code base and be very selective even to the point of refusing 90% of the code that is available for free*'. This is the learning I have had all these years as a programmer. This is essential if one wants to reach the milestones in time which will otherwise become a mirage. I have burnt my fingers multiple times with regards to this principle. The latest one was when I tried to reuse the entire Kubernetes e2e for [Maya’s](https://github.com/openebs/maya/) e2e. Needless to say I failed miserably. Some of these reasons are explained in this article.\n\n### Is that all?\n\nDefinitely not. We will soon get into the How’s part which in tursn is a repository of queries, doubts, and concerns.\n\nTo clarify it further, I had these queries when I started with the e2e journey for the [Maya](https://github.com/openebs/maya/) project.\n\n- Should e2e be shell wrappers over [CLI](https://en.wikipedia.org/wiki/Command-line_interface), for example, [kubectl](https://kubernetes.io/docs/user-guide/kubectl-overview/) & [mayactl](https://github.com/openebs/maya/tree/master/cmd/mayactl)?\n- Should it be tied to Go [*testing*](https://golang.org/pkg/testing/) library ? Any benefits ?\n- Should it use [*Ginkgo*](https://onsi.github.io/ginkgo/) library ? Anything to gain ?\n- Should it be moulded with [*Ansible*](https://www.ansible.com/) and let the scene get enacted by its players (*read playbooks)* ?\n\n### Simplicity — One Rule to Rule them All\n\nAll these queries should be answered with simplicity in mind. In other words, how to construct test code that is simple?\n\nWith simplicity in mind, let us pen down some dos and don’ts that will be an \nindicator of simplicity versus complexity.\n\n### Simplicity — Direct Thinking!!\n\nListed are some of the direct modes of thinking with regards to simplicity.\n\n- Code should just try to eliminate the repeating tasks of the developer, tester or operator. It will be simpler if it builds logic on only those ingredients that plays an inhibiting role in manual testing.\n- Find out one tool (*in other words a dependency*) that can make this test code easy to reason and comprehend. Build the code around this dependency. Though this dependency becomes a hard requirement, we are still good if it satisfies the simplicity rule.\n- It should be limited in its scope. For example in case of [Maya](https://github.com/openebs/maya/), it’s e2e is scoped to Kubernetes. Maya e2e avoids [*Ginkgo*](https://onsi.github.io/ginkgo/) etc libraries. It also avoids *Ansible* as the latter is not at all required.\n- It should be built using a high level language. Maya e2e uses Go as it’s only programming language. It does not use shell or any other scripts. This choice is also dependent on the scope the test code is targeting at. In case of Maya, [Kubernetes](https://kubernetes.io/) (*and host of other container orchestrators*) use Go as their primary language. This helps Maya to abide by the golden rules mentioned earlier.\n\n### Simplicity — Inverted Thinking!!\n\nListed are some of the inverted modes of thinking with regards to simplicity.\n\n- It should not try to be another [DSL](https://en.wikipedia.org/wiki/Domain-specific_language) in the making. In addition, it should not deal with some smart syntax. It will instantly seem smart to the eyes which developed it, but will definitely repel others.\n- It should not get into the way of the developer or the tester in form of auto \ngeneration of test code etc. This will lead to its brittleness.\n- It should not dedicate it’s logic to concurrency while running the test cases. It should not build it’s logic around CPU cores and parallelism for running the test cases either. It might seem concurrency is a required feature for a particular test case. However, do we take concurrency into factor while executing these cases manually ? The test logic can have the concurrency built later in an iterative fashion. Remember “*shipping is better than perfect”* in these cases.\n- It should not play around abstraction of containers and their orchestrators. Remember this is not the reason for its existence in the first place. It goes against the prescription of simplicity. Hence, cut this noise if they are not a natural fit.\n- It should not mandate running the tests in containers. It is considered cool these days to run test cases in containers. However, it can backfire. For example running your app and test cases as containers within a namespace or inside the same cluster. We do not want *100s* and *1000s* of containers getting spawned in the same setup that is meant to test your app which are again a set of containers.\n- It should not involve a learning curve. It should be an involving library that can take inputs from the team (*internal as well as external*) and evolve.\n- It `need not / must not` follow design patterns. The best it can do is to adhere to the core language’s best practices.\n\n### What else should the e2e try to achieve?\n\nAnswers to these questions will help you in getting the other aspects of your e2e.\n\n- Did we avoid fancy scripting ?\n- Is e2e (*especially the reusable code pieces*) better than the one it was created from ?\n- Will *`anybody be able to contribute to anything`* in this e2e project ?\n- Does it look similar to the practices followed by it’s programming language? Why? This leads to 0 learning curve and hence is simpler to understand?\n- Do you still remember the `Golden Rules` ? Add another one & that is **`End Small`**.\n\n*Thanks to Madhuri Hebbar and Uday Kiran.*\n","slug":"how-to-build-an-e2e"},{"id":20,"title":"Quick update on OpenEBS v0.4 — a developer friendly release!!","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"03-10-2017","tags":["Container Native Storage"," Container Orchestration"," Minikube"," Open Source"," Updates"," Openebs"],"excerpt":"OpenEBS v0.4.0 is out and I take pride in sharing that it is powered by the same set of tools, used by communities that have adopted DevOps DNA for delivering products.","content":"\n[OpenEBS v0.4.0](https://github.com/openebs/openebs/releases/tag/v0.4.0) is out and I take pride in sharing that it is powered by the same set of tools, used by communities that have adopted DevOps DNA for delivering products.\n\nPersonally for me, the most exciting part of this release is that it involves contributions from community members across the globe. We have crossed more than 100 Pull Requests from 25+ contributors.\n\nOur decision to remain OpenSource is paying off!! As new contributors come on-board, the following DevOps tools are helping us to sustain the quality:\n\n- [Github ](https://github.com/openebs/openebs/issues)for collaboration — managing code reviews, releases and now project management (issues and milestones).\n- [Travis ](https://travis-ci.org/openebs/)and [DockerHub ](https://hub.docker.com/r/openebs/)— validate the code commits and release new docker images\n- [Jenkins and Ansible](https://github.com/openebs/openebs/tree/master/e2e) — run the e2e tests on the new docker images.\n- Static Analysis is provided through a wide range of tools like gofmt, flake8, codecov, goreport, and the list needs to expand..\n- [ReadTheDocs ](http://openebs.readthedocs.io/en/latest/index.html)— updating the live documentation site\n\nOpenEBS, like other storage options (EBS, Rook, and others), is already deeply integrated with Kubernetes and is now part of the [kubernetes-incubator project](https://github.com/kubernetes-incubator/external-storage/tree/master/openebs). OpenEBS also provides similar intuitive mechanisms to provide block storage to your stateful application on Kubernetes using concepts like:\n\n- StorageClasses\n- PersistentVolumeClaims\n- PersistentVolumes\n- DynamicProvisioner\n\nIn addition, unlike others, OpenEBS delivers container native storage by *using Kubernetes (as opposed to running on Kubernetes) *itself as the underlying framework for scheduling and storing configuration data. There are also efforts underway for the upcoming release to make use of Kubernetes *LocalStorageManager, Kube-Dasbhoard and CNCF projects like Prometheus, FluentD, Grafana, Jaegar*, etc., for managing and monitoring the storage functionality.\n\nYou can easily get OpenEBS running on your Kubernetes Cluster with the following two commands and then point your application’s PVC to one of the OpenEBS Storage Classes.\n\nkubectl apply -f openebs-operator.yaml  \nkubectl apply -f openebs-storageclasses.yaml\n\nThe above yaml files can be downloaded from [here](https://github.com/openebs/openebs/tree/master/k8s). For detailed instructions refer to our [quick start guide](http://openebs.readthedocs.io/en/latest/getting_started/quick_install.html) or checkout our [sample stateful applications](http://openebs.readthedocs.io/en/latest/install/install_usecases.html) which include Percona, Jupyter, Postgresql, etc.,\n\nWhile you are at the documentation, you can also checkout the additional deployment options that we have added with this release:\n\n- [Running Kubernetes and OpenEBS on AWS](http://openebs.readthedocs.io/en/latest/install/cloud_solutions.html)\n- [Running Kubernetes within Minikube](http://openebs.readthedocs.io/en/latest/install/dev_solutions.html)\n\nThough, we are still in first leg of our journey, with OpenEBS v0.4, you get an usable container native storage, with enterprise storage capabilities like detailed *Volume IO statistics* and *Snapshots*.\n\n*Please refer to the [CHANGELOG](http://openebs.readthedocs.io/en/latest/release_notes/releasenotes.html), for summary of updates in v0.4 and [ISSUELOG](https://github.com/issues?q=user%3Aopenebs+and+is%3Apr+and+merged%3A%3E2017-06-23+sort%3Acreated-asc)for the list of Pull Requests.*\n\nAnd we are always looking for help from OpenSource savvy community members. You can contribute in several ways — take your pick from our growing [task list](https://github.com/openebs/openebs/labels). Join us on [#Slack](http://slack.openebs.io/).\n","slug":"quick-update-on-openebs-v04-a-developer-friendly-release"},{"id":21,"title":"Not Yet Another Distributed Storage System","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"10-09-2017","tags":["Kubernetes"," Docker"," Container"],"excerpt":"These days, it seems that a lot of storage vendors are taking a scale out approach to delivering high-performance storage to meet the increasing demand for IOPS and bandwidth.","content":"\nThese days, it seems that a lot of storage vendors are taking a scale out approach to delivering high-performance storage to meet the increasing demand for IOPS and bandwidth. Reduced latency is also high on the storage requirement list, however, scale out distributed systems typically result in the inverse, i.e., it increases latency.\n\nAlthough complex distributed systems are easier to build these days due to a variety of factors including: maturing software implementations of the likes of Paxos, distributed hash tables, and RAFT it seems that creating a storage system that utilizes these concepts and is easy to manage and maintain in production — is not.\n\nOn the other hand, if you want to leverage the distributed nature of storage at the client level, more often than not, the end-users are required to run specialized clients/drivers to unleash the enormous bandwidth these systems can deliver — and so now your storage has infected your client which makes it even less attractive.\n\nArguably, if you need hundreds of gigabytes of throughput for a particular workload, the Linux kernel comes preloaded with [one](http://www.orangefs.org/). So you have to look no further from a tech support side of things — as what better experts to find that concern themselves with the Linux kernel and thus OrangeFS, right? No need to search any further, right?\n\nLet’s first try to understand why a lot of people I’ve spoken to in the past typically chose **“scale out.”** It seems they all like the idea of “**add another box”** to add performance and capacity. The fact that you can’t scale performance decoupled from capacity is what they take for granted. However, due to economics forcing IT segments to do things cheaper and more predictably, this is not the case — anymore.\n\nSome storage vendors have found a solution for this, by not selling you expensive boxes but rather just the software. You simply scale in any cloud on any hardware or so they say. However, this **“any any”** approach does not fit in with the requirement to make things more predictable in fact quite the opposite.\n\nSo if we summarize the downsides:\n\n- Distributed storage difficult to develop and is hard and nasty to manage in production\n- Specialized drivers needed to unleash the real potential\n- Scaling the number of nodes does not decrease latency, in fact, usually the opposite (depending on implementation)\n- Best scales bandwidth and IOPS, however this is not what a typical workload requires\n- Complex consistency models create surprises regarding what is on disk or not\n- Not especially good at leveraging flash or NVMe to deliver great performance and a small footprint\n- Big blast radius — the more data you can put in one system, the more you might loose or at least lose access to when you most need it\n- The complexity and need for quick metadata updates across nodes both argue against multi-cloud deployments (though there are some scale out file systems being built that claim to address these issues)\n\nNow there will always be vendors out there that claim to have solved it all, unlimited scale out, never ending IOPS, more bandwidth than the whole of the internet combined and latency — sure we do that too…\n\nAt [OpenEBS](https://www.openebs.io/), however, we took a different approach by not trying to solve the distributed problems but to take a step back and try to determine what are the real problems people need to solve?\n\nSpeaking to our early tech-preview customers, we were shocked with awe to see that due to the complexity of storage these days, they simply revert to [Direct Attached Storage](https://en.wikipedia.org/wiki/Direct-attached_storage) (DAS). “It won’t go any quicker than that”, they say. And you have to make a very, very, strong case to argue against that. In fact, come to think of it, it is nearly impossible if you consider speed of NMVe devices.\n\nHas the storage market become so consumed with itself that it keeps making storage products so complex, with each vendor, having its own **“if — ands — or buts”** that they are fed up with it and revert back to DAS? Did it become so unpredictable? The time of consolidated storage churn?\n\nYes, the storage market is consumed with itself. But there is more, the storage ******needs****** have also changed. In the early SAN days, it was about consolidating islands of storage into a bigger one as it would be easier to manage and the performance of the SAN would be higher than sum individual devices. Virtual machines made it possible to consolidate compute which also made a lot of sense as boxes were mostly idle.\n\nHowever, all of this work was done for one reason and one only — to accommodate the piece of software that matter the most: the app.\n\nThe app is central and is the only thing that matters; everything around it is inflicted upon us.\n\nNobody wakes up one day and says, “I need to get myself a SAN” — it was likely the best of the worst options at that time.\n\nAs DevOps happened along side with containerization, the application itself has become a distributed system. A distributed system in the sense that subcomponents of the app as a whole may run on the same box, different box and are loosely coupled by APIs one way or the other and working together to solve a complex (business) problem.\n\nAs applications have become distributed systems themselves, they have become easier to scale and thus don’t always require high IOPS low latency storage devices to scale performance wise. So storage and capacity are now loosely coupled and suffer from data gravity in a different way than they once did. Additionally, data availability does not solely depend anymore on expensive storage arrays as applications are designed to replicate their data straight out of the GIT. As these apps are distributed by nature, we think that a distributed storage system is not only complex and nasty, but completely unneeded.\n\nSo — what’s a storage vendor to do? Well, we have it easier, as we don’t have much legacy — though we do have lots of experience building storage on containers as a part of our [ElastiStor](http://www.cloudbyte.com/products/elastistor-os/) product. And so we were able to start with the customer questions discussed above — in the age of microservices and cloud and containers, what job are they looking to do regarding serving, moving and protecting their data? And we can answer those questions in a way that is entirely free from whether it is storage strategy A, B or C. In future blogs we’ll talk about OpenEBS more (of course) — and maybe more importantly we would like to discuss with you how we think the job storage is being asked to do has changed and hence, how and why the old storage industry may be coming to an end.\n\nPlease, feel free to join us on [slack](http://slack.openebs.io/) to discuss in a more real time fashion.\n","slug":"not-yet-another-distributed-storage-system"},{"id":22,"title":"ARA - Recording Ansible Playbook Runs","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"31-08-2017","tags":["Ansible"," Automation"," DevOps"," Openebs"],"excerpt":"Ansible playbooks can generate quite a lot of console data. Add the -v (I do it by default !) and you have a quite a lot to scroll through.","content":"\nAnsible playbooks can generate quite a lot of console data. Add the -v (I do it by default !) and you have a quite a lot to scroll through. Often times, one tends to feel the need for a better reporting mechanism — one which is easy to scour for specific task status, whilst having the luxury to extract additional debug info for the same if needed. Also, it would be great if this aid is available for playbook runs across time, i.e., for older playbook runs as well. This would be especially beneficial when running ansible-based CI suites, like @OpenEBS, where the application deployments, test setup & execution is driven by Ansible.\n\nSounds like a perfect requirement for a UI-based solution, doesn’t it ?\n\nA lot of people using Ansible for medium-large scale deployments are known to use **Tower**, **Rundeck** or the opensource alternative **semaphore** to achieve this (Tower has a lifelong self-support trial license without a few features for under 10 nodes). There is also **Foreman**, which is great in environments where a hybrid tool set — puppet with ansible, or chef with ansible etc.., are used. Most of these are workflow management tools that do more than *just* what we desired above, i.e,. playbook recording. These tools provide a centralised management capability wherein inventory, users, task/play scheduling, notifications can all be controlled from a dashboard. Now, it is also possible to integrate these with other popular CI tools like Jenkins (watch [this](https://www.youtube.com/watch?v=CqjeIiHvy30&amp;feature=youtu.be)).\n\nHowever, if there is already a system in place to perform some of the things these tools do (dynamic inventories, playbook triggers/scheduling) while not really needing others (access control, graphs), and you are only looking for the ability to store and analyse playbook runs via UI, then **ARA** (Ansible Run Analysis) is your tool.\n\n![](/images/blog/ansible-run-analysis.png)\n\nHeavily used by openstack community in their CI projects, ARA is built to just *\"record\"* playbook runs (Read ARA’s [manifesto](http://ara.readthedocs.io/en/latest/manifesto.html#manifesto), to understand more about its narrow focus). It does this via an ansible callback plugin to store run details into a database and a web interface to visualise the database.\n\n![](/images/blog/playbook-tasks-summary-in-ara.png)  \n**Viewing playbook tasks summary in ARA!**\n\n![](/images/blog/viewing-tasks-details-in-ara.png)  \n**Viewing task details in ARA**\n\nWhile it uses sqlite and an embedded webserver, respectively, for these purposes, you could even customise it to use mysql & Apache. The UI includes nifty features like host fact lookup, playbook params page, search filter, property based sort and link to code snippets !\n\n![](/images/blog/see-specific-task-ran.png)  \n**Click on action to see where the specific task ran**\n\nA nice video explaining the web interface, with playbooks from openstack-ansible project is [here](https://www.youtube.com/watch?v=k3i8VPCanGo)\n\nIn addition to these, ARA also provides\n\n- Couple of ansible modules for persisting & viewing some user data that one may want to view on the browser-based UI (like an ansible “fact”, but for visualisation purposes :P).\n- A CLI to query the database (While I haven’t found much use for it till now, it is useful to custom create some reports)\n\nARA follows the same support cycle as the upstream Ansible community, and is under active development (See [github](https://github.com/openstack/ara))\n\nHere is an [ansible role](https://github.com/openebs/openebs/tree/master/e2e/ansible/roles/ara) we have written that you could use to quickly setup ARA on your ubuntu box 🙂\n\nWe @OpenEBS, have found great benefit in using this tool and would happily recommend it for the usecases discussed. !!\n","slug":"ara-recording-ansible-playbook-runs"},{"id":23,"title":"Ansible @ OpenEBS — The whys and hows","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"31-07-2017","tags":["Ansible"," Ci"," DevOps"," Jenkins"," Vagrant"],"excerpt":"We are using Ansible as one of the critical moving parts of our automated test suite in the CI pipeline @OpenEBS. The question was expected in some ways,","content":"\nDuring a telephone conversation with a former colleague and good friend I was confronted with an interesting question , “I know Ansible is a great configuration management tool, why bend it as a test automation framework ?”\n\nWe are using Ansible as one of the critical moving parts of our automated test suite in the CI pipeline @OpenEBS. The question was expected in some ways, what with the friend having spent a few good years working with more “traditional”, proprietary and hand-built-from-scratch test-automation frameworks based on perl. The subsequent discussion (mostly answers and follow up questions) helped me internalise why we chose Ansible at OpenEBS and how better to use it.\n\nFelt this warranted a blog post to make my thoughts public and hey, of course, gain more feedback !\n\nOK, that let the cat out of the bag\n\n## Infrastructure as Code (IaC)\n\nOne of the biggest IT trends over the last few years has been managing infrastructure through automation. One might argue that puppet started way back in 2005, thereby making this practice far older than most believe, but the way it has taken ops departments of most organisations by storm in the past 5–6 years is nothing less than a revolution. In fact, the paradigm of devops is built on managing infrastructure as code. And when we say code, the expectation of most ops personnel around the “language” would be that it doesn’t require deep programming knowledge and have a steep learning curve — which is what DSL (Domain Specific Language, sometimes also referred to as Domain Scripting Language) based frameworks like ansible achieve. It also helps that ansible adopts an imperative programming model (using YAML) that works well because of its alignment with the traditional command-based approach of ops teams.\n![](https://cdn-images-1.medium.com/max/800/1*7Di79EF1SxNqF0F0KD1E-A.jpeg)\n**Ansible GitHub trends (Courtesy: [https://www.ansible.com/blog/another-good-year-for-ansible-users](https://www.ansible.com/blog/another-good-year-for-ansible-users))**  \n\nBut, how does the above address our question ? \n\n**Answer**: A major portion of the test duration of infrastructure-based software, such as storage software involves “manipulation” of infrastructure. Setting up bare-metal boxes ,virtual machines, or containers, installing packages, executing various commands that control & alter system state, monitoring for specific behaviour are key aspects of this process. Consider the need to run the above as batch processes and perform parallel execution on multiple nodes — and the inevitability of a workflow orchestrator dawns upon you. Especially so when you are testing a solution like OpenEBS that is designed to provide storage for devops usecases (read more about this [here](https://blog.openebs.io/storage-infrastructure-as-code-using-openebs-6a76b37aebe6))\n\nIs not an approach (and the tool) soaked in “**devops-ness**” a pre-requisite to test the storage solution specifically designed for devops usecases 🙂 ?\n\n## Why Ansible, why not chef, puppet, salt etc., ?\n![](https://cdn-images-1.medium.com/max/800/0*NQOK_gId-YBZMe02.png)  \nErr.., this seems to have been done to death on the internet. Yet, new posts on this topic seem to spring up everytime I look. So, without discussing the why nots, let me touch upon the aspects about ansible that appealed most to us.\n\n**Powerful, yet very simple** : Ansible’s power comes from its simplicity. Under the hood, it is just a DSL for a task runner over secure shell (ssh) with intuitive modules for achieving most (if not all) system functions. The soft learning curve in ansible is one of its major advantages over its rivals (*Ok, I said I won’t do the why-nots, but there is a feeling that puppet, chef etc., are over-designed for the jobs they do..*) In an open-source project like OpenEBS, a need to build a template for the contributors to write their own test workflows without spending too much time was an important consideration.\n\n**Idempotency**: The ansible playbook (a set of tasks written using the modules mentioned previously) when run twice gives the same end result. This is a great help when it comes to reusing test beds.\n\n**Speed of execution** : One of the benefits of having an agent-less architecture (apart from a complexity-free install and usage experience) , ansible playbooks zip through configuration and other “system” tasks (mostly, test logic) fairly fast. While there are supposedly issues at scale (1000s of nodes) , it works just great for our needs. Want to setup a working kubernetes cluster with OpenEBS storage on-premise in less than 20 min ? — check out the playbooks on our [github repo](https://github.com/openebs/openebs/blob/master/e2e/ansible/openebs-on-premise-deployment-guide.md)\n\n**Rich module library** : Ansible has modules for most things under the sun 😐 Nuff said, go look : [Ansible modules](http://docs.ansible.com/ansible/latest/modules_by_category.html)\n\n(*As an aside, this was one of the other reasons why we started using ansible as a test engine, apart from the infrastructure angle*)\n\n**Plugins**: While ansible is great for configuration management, workflow orchestration etc., it needs to be able to work well with other tools/frameworks that make up the CI-CD pipeline( Jenkins, Vagrant etc.,) And all these have ansible plugins (How much we use them is a topic for another day, but the point is ansible does have integration if you choose to utilise it). More important than existing integrations is the ease with which you can extend ansible’s capabilities with custom plugins. Python was a dev + ops favourite, even before devops became a fad and ansible is built using it -so, there you go !\n\n**Community**: One of ansible’s biggest strengths is its community. We discussed about extending ansible’s capabilities via custom plugins. Chances are you never have to write one, because the community already has two versions of it (*okay, I may be exaggerating*), but the active community makes it a lot easier to adopt. There is a lot of documentation available as well. All of which means, for most purposes, you don’t have to opt for paid support for issues OR add-ons until you really scale or get complex.\n\n## How are we using Ansible ?\n\nAt OpenEBS, we are using ansible as :\n\na) A means to enable rapid deployments of applications in user environments. Today, you can use our ansible playbooks to get a Percona mysql server instance or a PostgreSQL statefulset up and running with OpenEBS storage on premise from plain vanilla VMs in double quick time, with a single command execution. Even as I write this, efforts are underway to create playbooks to perform such deployments on the cloud, right from provisioning VM instances to running test loads to verify setup stability.\n\nb) As a “***test orchestrator***”, i.e., for provisioning test beds, executing test logic and notifying users. That doesn’t mean we have stopped writing shell scripts or python scripts in QA (there are still functions which one might have to execute via shell or the ansible “shell” module or python, due to lack of actual ansible modules. Not to mention existing scripts which one wouldn’t bother converting into playbooks).\n\nOur current CI workflow involves a Jenkins master polling for updates to git repos, followed by bringing up VMs on-premise using vagrant, configuring those using ansible, followed by execution of test playbooks and user notification on slack. The CI is still evolving and efforts are on to make it more robust — you could join the OpenEBS-CI [slack channel ](http://slack.openebs.io/)& browse the [github pages](https://github.com/openebs/openebs/tree/master/e2e) if you are an enthusiast/would like to contribute !\n\nIn forthcoming blogs, I would like to discuss more on the “***How***” and share thoughts, challenges, solutions around using ansible both as a preferred application deployment mechanism as well as a “test orchestrator”.\n\nThanks for reading !!\n","slug":"ansible-openebs-the-whys-and-hows"},{"id":24,"title":"Are you afraid of Go?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"27-07-2017","tags":["Docker"," Go"," Openebs"," Programming Languages"," Programming Tips"," Tutorials"],"excerpt":"Are you an experienced C programmer or perhaps an adept Java hacker finding Go somewhat awkward to deal with.","content":"\nAre you an experienced **C** programmer or perhaps an adept **Java** hacker finding [**Go**](https://github.com/golang/go/wiki/whygo) somewhat awkward to deal with. There may be different elements of surprise or familiarity based on the programmer’s background e.g a Java programmer may relate the GOPATH settings with the settings associated with JAVA_HOME. On a similar note, the very same programmer might be surprised with Makefiles that are used to script the compilation, build & other stuff. I am sure though that this experience will be different for a seasoned C programmer.\n\nIf above and perhaps multiple of other reasons inhibit you from familiarising with Go then you are not the only one. The best thing is there are similar number of solutions that will help you play along the Go pitch.\n\nGoing back in time, this thorny feeling was exactly what we had faced when we started [***OpenEBS***](http://openebs.io) development a year back. However one of the core goals of *OpenEBS* is ease of use; whether it is for the admin or the operator or the developer, tester and so on. In other words, different personas involved during the Software Life cycle, Deployment & Maintenance should not go through a learning curve and rather experience *OpenEBS* as the simplest form of storage software that cuts through all the storage noise. This meant we did not want Go or any other programming language, as a matter of fact, to limit our way towards this enlightened journey.\n\nDuring those days we implemented some of the strategies that helped nullify above pain points and provide a smooth cruise to all current & future contributors of *OpenEBS*. This article will focus on our strategies meant for the newbies trying to get their hands dirty with Go.\n\n***I have itemised our strategies as these steps:***\n\n1. Start your baby steps at GO [**Playground**](https://play.golang.org/). This will remove the initial hassles of downloading Go and setting up GOPATH & stimulate you towards coding (read *familiarising with the newer syntax*) & start believing the language by viewing & analysing the output expected from your logic i.e. *WYSIWYG*.\n2. Get familiar with [**Vagrant**](https://www.vagrantup.com/) (*I understand this is a different tool & is no way related to Go programming*). Vagrant with its pitch for ‘*Development Environments Made Easy*’ will help you to set up VMs which has all the necessary Go based downloads and GOPATH settings. One can search for simple open source projects that does below:\n\n**a**.Vagrantfile that makes use of some sample Go programs (probably scripting a g*it clone to <some-github-url>*), &\n\n**b**. Makefiles that has the logic to compile & build.\n\nThere is one catch though! One has to install Vagrant & a preferred Hypervisor to enjoy the benefits of Step 2. So there is a bit of learning curve involved.\n\n***However, this should not deter one to avoid Step 2, as it has huge benefits going forward. You will appreciate this step once you understand the difficulties in managing projects with their right versions and dependencies. A trivial mistake here will lead to bug injections. This step will rather help you enjoy the taste of CI right from your laptop.***\n\nAfter gathering enough confidence via these steps one can try out fancier stuff. Does ***running the builds in Travis*** or ***compiling the source code in a Docker container*** challenge you. You might as well explore some of these stuff & others in our [**tool-room**](https://github.com/openebs).\n\nThere may be various other options (*probably even simpler ones*) available in this '**DevOps**' world that are not mentioned here. E.g. [**GVM**](https://github.com/moovweb/gvm). However, I have tried to list down the game plans that has worked well for us. Do get back with your valuable insights on how you have succeeded to tame the initial apprehensions while trying out a new language.\n","slug":"are-you-afraid-of-go"},{"id":25,"title":"Tech Enthusiasts weighing in on Container Native Storage","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"27-07-2017","tags":["Docker"," Game of Thrones"," Openebs"," Reddit"," Statefulcontainers"],"excerpt":"These redditers are like the nights-watch-men (Operations Team) who are guarding the wall (production services) from army of dead (issues).","content":"\n*Full disclosure: I contribute to OpenEBS and I relish GoT (not IoT).*\n\n*This post is inspired by the *[*Reddit thread (r/Docker)*](https://www.reddit.com/r/docker/comments/6l0y3v/persistent_storage_with_docker_in_production/)* discussing implementation approaches for Stateful Containers.*\n\nThese redditers are like the nights-watch-men (Operations Team) who are guarding the wall (production services) from army of dead (issues). These redditers are akin to “the tech Enthusiasts” as depicted in the following diagram, who can foresee the challenges and are looking for innovative solutions.  \n\n![](https://cdn-images-1.medium.com/max/800/1*11EOWUuoRjWn8pZ1uMXidg.png)\n\nWith S-less (server and state) architectures on the rise and faster networks at every possible end point, we can envision building and deploying services that can scale to yet unseen/unknown/unimaginable magnitude, **but!** (*Ned Stark once told me, that anything said before but*, ..*a GoT in-joke*) **State will be the bottleneck.**\n\nWhat ever you do with Compute (S-less) containers, you always need to start and end with Data. Data is State. *State — is the beginning and end! the Alpha and Omega!*\n\nS-less will have no (busine$$) value without State! (*Well, agreed that you can offload the maintenance of State to someone else. But at what cost! Whoever owns the data, owns the $$*)\n\nThe real question is where to put the State!\n\n*Probably over-simplifying, but we can save the State using one of the following:*\n\n- *Connected Storage — Further divided into File/Block*\n- *Container Native Storage*\n\n**Connected Storage**: save the State external to container hosts and use the Orchestrator Volume Plugins to attach/detach storage from SAN/NAS or Cloud Disks.\n\nThere is a huge community (of cash rich vendors, a.k.a Roses and Lions!) and a majority of enterprises (consumers of storage) locked-in with these vendors are working on making this option succeed.\n\nThese enterprises are stuck with Roses or Lions not because they love them, but these are the only options that are available to them. This reverberates in the comments of the Reddit thread, here is a gist of the views expressed:\n\n(a) Connecting to NFS or EFS (from AWS)\n\nApplied Use Cases:\n\n- Applications that store data in file — images or text or backup\n- Applications that need shared access to the data from multiple containers, running on different hosts.\n\nConcerns:\n\n- Hard to keep up with performance and capacity needs of the massively scalable applications\n- Seeing Performance Issues — when saving huge number of small sized files\n- Need to be careful about Data Integrity from shared access. Needs a lot of hand-holding for secured access\n- Not a good option for databases or high random write work-loads\n\n(b) Connecting to SAN or Cloud Disks (attached locally)\n\nApplied Use Cases:\n\n- Applications that are resilient to underlying storage failures like ElasticSearch/Cassandra\n- Databases like Percona/PostgreSQL\n\nConcerns:\n\n- Longer re-build times and degraded windows, as the size of the data increases.\n- Connecting one LUN per Container increases the boot-up times upto 10 minutes in worst cases\n\n*Roses and Lions have been there for a very long time, fighting for the dominion of the realms, by any means necessary. But these are summer lands. They are not prepared for the Great Winters that has begun in the North.*\n\nThe “tech Enthusiasts” (or the nights watch) have seen the challenges that the massive scaled applications (Winter) can bring and are seeking for alternate options.\n\nA handful of vendors like [portworx](https://t.co/Aawo9fr4Dz), [storage_os](https://storageos.com/), [rook](https://rook.io/), [openebs](https://www.openebs.io/) are working on alternate options, what is now being termed as [Cloud Native Storage](https://blog.openebs.io/cloud-native-storage-vs-marketers-doing-cloud-washing-c936089c2b58) or [Container Native Storage](https://storageos.com/storageos-vision-cloud-native-storage-todays-modern/).\n\n*While the blogs above (and many others) dwell into what makes a storage container native, the one that stands out is — ***the flexibility***.*\n\n*The tech enthusiasts/operations personnel will have the choice of technology used to deliver their services like Kubernetes, DockerSwarm, Mesos — on Google, Amazon, Azure or Private Cloud with storage that integrates seamlessly with these cloud environments.*\n\n**Container Native Storage:** storage controller functionality is containerized and can co-exist with the containers (even fly with them) across the clouds.\n\nPortworx, is leading the pack, has been successful in getting some reference customers (*we are yet to hear from them in the open forums — hard to convince the council at kings landing with just a reference!*)\n\nSome of the apprehensions surrounding this option are:\n\n- writing a new storage layer is hard.\n- missing some standard bench marking tools that can clearly demonstrate the performance boost obtained by this relatively new way of provisioning storage.\n- there are questions raised about Rook / CEPH performance for DBs\n- dependency on the kernel drivers (this is probably hinting at PortWorx, if I read, between the lines/comments).\n\n*Winter is Here My Lord — We need new alliances!* We need to hear from more Operations and DevOps Personnel grappling with the storage issues.\n\nWe need them to spend more time towards sharpening the solutions that are being built for containers using containers in Open Source!\n\nDo contribute and earn your Open Source Karma by weighing in your thoughts at this *[Reddit thread (r/Docker)](https://www.reddit.com/r/docker/comments/6l0y3v/persistent_storage_with_docker_in_production/) or at [OpenEBS Slack](http://slack.openebs.io/) or at the [GitHub/Container-Storage-Interface](https://github.com/container-storage-interface/spec)*\n","slug":"tech-enthusiasts-weighing-in-on-container-native-storage"},{"id":26,"title":"OpenEBS building Go Storage Kit Project — Maya","author":"Satyam Zode","author_info":"Go Developer @openebs | Open Source Contributor | Avid Learner","date":"25-07-2017","tags":["Golang"," Openebs"," DevOps"," Container Orchestration"],"excerpt":"I attended GopherCon India 2017, there was a talk on “Package Oriented Design In Go” by William Kennedy. In that talk, William explained some really important and thoughtful design principles which we can apply in our day to day life, while writing Go.","content":"\n## Motivation\n\nI attended [GopherCon India](http://www.gophercon.in/) 2017, there was a [talk](https://youtu.be/spKM5CyBwJA?list=PLFjrjdmBd0CoclkJ_JdBET5fzz4u0SELZ) on “Package Oriented Design In Go” by [William Kennedy](https://twitter.com/goinggodotnet). In that talk, William explained some really important and thoughtful design principles which we can apply in our day to day life, while writing [Go](https://golang.org/project/). I have attempted to absorb some of the design philosophies I learnt at GopherCon into practice at [OpenEBS](https://github.com/openebs). At [OpenEBS](https://github.com/openebs), as a open source and growing Go project, We value Go principles and We try hard to leverage Go’s offerings.\n\nBriefly, OpenEBS is a [container native storage](https://blog.openebs.io/cloud-native-storage-vs-marketers-doing-cloud-washing-c936089c2b58) that is built from containers for enabling stateful containers to get into production. Being container native, OpenEBS augments the Container Orchestration (CO) Layers like Kubernetes, DockerSwarm, Mesos etc., with Storage Specific Orchestration capabilities using “Maya” — Magic! I contribute mainly towards the “Maya” — which is a set of containerized control plane applications for hooking into several modules like the configuration, monitoring and alerting of CO.\n\n## What is the Go Kit Project?\n\nTo understand in plain terms, let us take an example where we end up writing same Go packages again and again to do the same task at different levels in the different Go projects under the same organization. We are all familiar with the custom logger package in the different Go projects.\n\nWhat if, the custom logger package is same across the organization and can be reused by simply importing it, then this custom logger package is the perfect fit for Kit project. The advantages of this approach go beyond avoiding duplicate code, improved readability of the projects in an organization, to savings in terms of time and cost as well :-)\n\nIf you go through the Bill’s talk, you will notice that Kit project is characterized by Usability, Purpose and Portability. In this blog, I will discuss how I have applied the refactored the code to use the “Kit Project” pattern for maya.\n\n## How to convert existing projects to have “kit”\n\nOpenEBS being a container native project is delivered via set of containers. For instance, with OpenEBS 0.3 release we have the following active maya related projects:\n\n1. openebs/maya aka ****maya-cli**** : is the command line interface like kubectl for interacting with maya services for performing storage operations.\n2. openebs/mayaserver : or ****m-apiserver**** abstracts a generic volume api that can be used to provision OpenEBS Disks using containers launched using the CO like K8s, nomad etc.,\n3. openebs/****openebs-k8s-provisioner**** : is the K8s controller for dynamically creating OpenEBS PVs\n\nWith these projects, we are already seeing how code gets duplicated when each of these projects are independently developed. For example *maya-cli* and *openebs-k8s-provisioner* both need to interact with *maya-apiserver*, which resulted in maya-apiserver-client code being written in *maya-cli* and *openebs-k8s-provisioner*. Similarly, *openebs-k8s-provisioner* and *maya-apiserver* have duplicated code w.r.t to accessing the K8s services.\n\nTo avoid this duplicity of code using the kit project, we are transforming openebs/maya into a Kit project for the Application projects like [maya-apiserver](https://github.com/openebs/mayaserver), openebs-k8s-provisioner and many more coming up in the future. openebs/maya contains all the kubernetes & nomad API’s, common utilities etc. needed for development of maya-apiserver and maya-storage-bot. In the near future, we are trying to push our custom libraries to maya. So that, it will become a promising Go kit project for OpenEBS community.\n\nLets now see, how maya (as kit project) adheres to the package oriented design principles:\n\n- ****Usability****  \nWe moved common packages such as orchprovider, types, pkg to maya from maya-apiserver. These packages are very generic and can be used in most of the Go projects in OpenEBS organization. Brief details about new packages in Maya.\n1. Orchprovider : orchprovider contains packages of different orchestrators such as kubernetes and nomad.\n2. types: types provides all the generic types related to orchestrator.\n3. pkg: pkg contains packages like nethelper, util etc.\n4. volumes: volumes contain packages related to volume provisioner and profiles.\n- ****Purpose****  \nWhile the Packages in the Kit project are categorised as per the functionality, the naming convention should ideally provide the reader with the information on what the package “provides”. So, the packages (in kit project) must provide, not contain. In maya, we have packages like types, orchprovider, volumes etc. name of these packages suggests the functionality provided by them.\n- ****Portability****  \nPortability is important factor for packages in kit project. Hence, we are making maya in such a way that it will be easy to import and use in any Go project. Packages in the Maya are not single point of dependency and all the packages are independent of each other. For example, types directory contains versioned Kubernetes and Nomad packages. These packages are simply importable to any project to use kubernetes and Nomad API’s.\n\n## Example usage of maya kit project\n\nMaya-apiserver uses maya as a Kit project. Maya-apiserver exposes OpenEBS operations in form of REST APIs. This allows multiple clients e.g. volume related plugins to consume OpenEBS storage operations exposed by Maya API server. Maya-apiserver will use volume provisioner as well as orchestration provider modules from Maya. Maya-apiserver will always have HTTP endpoints to do OpenEBS operations.\n\nSimilarly, openebs-k8s-provisioner will use the maya-kit project kubernetes API to query for details about the Storage Classes, etc.,\n\nAnother usage is of the maya-kit project, maya-apiserver client that is accessed by maya-cli as well as the openebs-k8s-provisioner to talk to maya-apiserver.\n\n## Conclusion\n\nGo Kit project should contain packages which are usable, purposeful and portable. Go Kit projects will improve the efficiency of the organization at both human and code level.\n","slug":"openebs-building-go-storage-kit-project-maya"},{"id":27,"title":"Cloud Native storage vs. marketers doing Cloud Washing","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"18-07-2017","tags":["Cloud Native"," DevOps"," Docker"," Kubernetes"," Openebs"],"excerpt":"let’s try to protect the phrases Cloud Native storage and Container Native storage; or maybe we should start using a yet more specific phrase such as Containerized Storage for Containers","content":"\nSome years ago, back when I was founding CEO of Nexenta during our high growth days, I tried to bring some rigor to the discussion around “software defined storage” by setting out a definition. My basic point was that it wasn’t enough for storage to have APIs of some sort and hence to be able to be controlled by software -> in addition the storage ought itself to *be software*, and hence be able to be provisioned as software and so forth.*1*\n\nI wrote those blogs setting out a definition for software defined storage because I was disgusted by the number of legacy storage vendors that went from denying that software defined storage was a thing to, almost overnight, claiming that they *already did* software defined storage. The risk was that the large sales and marketing budgets of legacy vendors would drown out the innovative companies that were actually building software that delivered on the benefits of software defined storage thanks to, you know, *actually being software defined*.\n\nFast forward 6 or 7 years and — **here we go again!**\n\nThis time we are seeing “Cloud Native storage” as a term being abused along with “Container Native storage.” Logically Cloud Native storage should be storage software that itself is, you know, *Cloud Native*. And that term is defined by people far smarter than me, however typically it includes some sense of microservices, and [12 factor approaches](https://12factor.net/), and the ability to consume cloud services. One great and lengthy definition of the term is explained by the inestimable Joe Beda [here](https://blog.heptio.com/cloud-native-part-1-definition-716ed30e9193).\n\nWe are even seeing Cloud Native storage applied to *any storage that serves Cloud Native applications*. Thanks to the work of Docker and Kubernetes and others, nearly any storage *can* serve storage for containers — albeit in a way that typically requires the user to change the way that they run the containers that are attached to the underlying storage to such an extent that many of the benefits of containerization are lost; I talk more about benefits of truly container native storage below. Calling hardware based storage that ties into a Kubernetes environment via plug-ins “Cloud Native storage” is absurd and yet it is starting to happen. Such storage is no more Cloud Native than any legacy monolithic application is “Cloud Native” just because you’ve been able to cram it onto a container somehow.\n\nSpeaking of cramming monolithic apps into containers, if you have a famously difficult to manage monolithic storage solution that you cram onto a container or two — even if you integrate it nicely into Kubernetes or other Cloud Native environments — what you have may be useful however it is NOT Cloud Native. Because, you know, it predates 12 factor and cloud native approaches to building software by many years and, as such, is no more Cloud Native than ye old SAP or other traditional n tier app.\n\nAhh, that feels better.\n\nBut you might ask — *so what*? What’s the big deal about marketers abusing the English language for their own ends and distorting the definition of Cloud Native storage?\n\nWell that comes down to whether we believe that the benefits of Cloud Native applications could apply to building storage software in a cloud native manner. Is what’s good for the goose, good for the gander? Is Cloud Native storage even a term worth fighting over? Could a truly Cloud Native storage solution deliver benefits much as other Cloud Native software does?\n\n![](/images/blog/goose.png)\n\n**Let’s all be cloud native like the whale: goose, gander, OpenEBS mules and friends**\n\nWell, why wouldn’t benefits such as:\n\n- better resiliency\n- better resource utilization\n- innate horizontal scalability\n- ease of troubleshooting\n\nand other benefits that apply to decomposed microservice based applications (aka “Cloud Native”) apply to software that is delivering a storage?\n\nPerhaps just as importantly, wouldn’t the teams and communities that are building the software be able to be better organized — themselves loosely coupled and able to *DevOps on* — than those that are working on monolithic software? [Conway’s Law ](https://en.wikipedia.org/wiki/Conway%27s_law)does seem to be a major reason for the success of Cloud Native and microservices.\n\nThe benefit of that better team organization in my experience can be massively greater developer productivity. As many have pointed out, the productivity of developers in high performing DevOps / Microservices organizations is far, far superior; these developers deliver usable code 10–100x more quickly than developers stuck building to long release cycles with massive dependencies.\n\nSo, in short, here is my request of you. Just as we have been so careful in (not entirely successfully) protecting the term DevOps, let’s try to protect the phrases Cloud Native storage and Container Native storage; or maybe we should start using a yet more specific phrase such as ***Containerized Storage for Containers***(warning, that’s a term we coined at OpenEBS). Otherwise we risk polluting everyone’s efforts for a better way to build and run software in a Cloud Native way with marketing BS.\n\n1.(note — as I’ve tried to [explain elsewhere](https://blog.openebs.io/software-defined-storage-finally-37fdffc0e37c), much of what we hoped to achieve with software defined storage is only now being enabled, largely thanks to Kubernetes and other open orchestrators and containers as well).\n","slug":"cloud-native-storage-vs-marketers-doing-cloud-washing"},{"id":28,"title":"Container Native Storage builds its High Availability in style","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"17-07-2017","tags":["Docker"," High Availability"," Kubernetes"," Openebs"," Storage"],"excerpt":"Infrastructure components are the toughest to build. It is meant to work always by default. ","content":"\nInfrastructure components are the toughest to build. It is meant to work always by default. It must be telecom grade as scores of applications rely on the infra component’s zero downtime, no deterioration in QOS, etc. However, we all know software has got defects and it is no different for infrastructure software components as well. One of things the software can do is implement high availability as its core feature and somehow buy time (by the virtue of HA) when one of these components experiences a break down due to defects or otherwise.\n\nImplementing the HA piece seems to be the elixir to all the unforeseen issues. Is that so simple then? Programmers who have built the HA in the past will swear to its complexity. It is another piece of software logic which is very difficult to get it right the first time or even after a couple of major releases.\n\n> The non HA programmer can have the flexibility to err. Well a programmer is supposed to be a human after all. However, this option is ruled out for the HA logic implementer.\n\nHaving said this, implementing high availability logic in a '*Container Native*' software solution has reasons to cheer. Most of the container orchestration platforms have abstracted the scheduling, placements, evacuations, prioritized jobs and what not and thus have freed the average programmer from these overwhelming tasks.\n\nAll of a sudden, programming becomes fun again (*HA logic becomes more like placing the [lego](https://en.wikipedia.org/wiki/Lego) blocks in a fashion / pattern to get your favorite character into action*).\n\nProgrammers now need to build the required HA logic by tying together appropriate placement components that results into a customised HA solution. We at OpenEBS [***toolroom***](https://github.com/openebs/) have been trying to maximise the offerings provided by [*Kubernetes*](https://kubernetes.io/) towards achieving a truly container native solution for OpenEBS high availability. All the advancements in Kubernetes will make OpenEBS better and the scenarios handled by OpenEBS (*which will never be simple*) can become a point of reference in Kubernetes.\n\nLet’s get into some storage specific HA basics:\n\n1. A typical persistent storage solution would require its data to be replicated across hosts within a cluster. There are also cases, where the production scenarios demand this replication to be across geographies. In addition, hybrid cases require some replicas to reside within the cluster while other replicas to be placed across zones, regions, etc.\n2. Since storage solutions derives its power from its underlying hardware resources, it makes sense to earmark exclusive hardware for storage components. In other words, the host(s) would want to avoid software components that are not storage specific.\n3. Solutions around placements alone are not sufficient for storage software to be highly available. There can be cases where a storage controller does not support active-active mode. Now relying just on placements can not avoid application outages due to this storage hiccups (*i.e. storage protocol connection breaks resulting in breakdown of the applications consuming this storage*). The evacuation should be fast & its new placement cannot take any time longer. Appropriate policies should be in-place to let these storage components be evacuated early before the application components. This becomes more essential during a node crash where every component will fight for survival.\n4. Storage HA cannot rely on half baked evacuations that may lead to split-brain conditions. Storage should either be evacuated or be let to die along with the crash. There should be no cases of hangs, stalls, freezes, you name it. There can be only one option & that is:\n\n***100% successful evacuation as well as 100% successful re-scheduling.***\n\nIn some cases, 100% successful evacuation might imply use of the logic called [**stonith**](https://en.wikipedia.org/wiki/STONITH) before boarding the re-schedule flight.\n\nWith above HA basics (*you may like to call it hardships*) in our mind let us find if the most popular container orchestrator has any feature, policy, etc that can simplify HA in storage. While looking at Kubernetes (version 1.7) I could find couple of policies that can help storage build it’s HA story with ease.\n\n> One: ‘Node affinity’ is a feature that constrains which nodes your pod is eligible to schedule on, based on labels on the node.\n\n> Two: ‘Inter-pod affinity and anti-affinity’ is a feature to constrain which nodes your pod is eligible to schedule on based on labels on pods that are already running on the node rather than based on labels on nodes.\n\n> Three: ‘Taints and tolerations’ work together to ensure that pods are not scheduled onto inappropriate nodes. One or more taints are applied to a node; this marks that the node should not accept any pods that do not tolerate the taints. Tolerations are applied to pods, and allow (but do not require) the pods to schedule onto nodes with matching taints.\n\nDoes above sound familiar? It does not introduce any new jargons except for the term 'Pod' and perhaps 'Labels'. Pod is a logical concept for a container or bunch of containers while labels can be understood as tags. Now if our persistent storage is really a piece of software that runs from within a container all the properties that Kubernetes exposes can be applied against this storage software & let it construct (or extend or even plug) its 'High Availability' feature.\n","slug":"container-native-storage-builds-its-high-availability-in-style"},{"id":29,"title":"Test Driven Development — The DevOps Way","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"13-07-2017","tags":["Docker"," Kubernetes"," Openebs"," Tdd"," Software Development"," DevOps"],"excerpt":"TDD is the abbreviated form for `Test Driven Development`. It might also be true in-case of newbies to have never heard of TDD in the current season where DevOps, NoOps, DataOps, ML, IOT rule the roost.","content":"\nWe might have all heard of TDD, don’t we ? TDD is the abbreviated form for 'Test Driven Development'. It might also be true in-case of newbies to have never heard of TDD in the current season where DevOps, NoOps, DataOps, ML, IOT rule the roost.\n\nTDD in simpler terms would be planning and implementing test logic before implementing its development logic. However, I find it very difficult to do this in practice. What I do instead is a little bit of planning & start building the development logic. In the next iteration, I would start writing corresponding test logic i.e. unit test programming (*remember those jUnit days*).\n\nReaders may still be wondering how “*DevOps is related to TDD*”. Well, here it is:\n\n> *How about using the best of DevOps tools towards TDD implementation?*\n\nThe logic behind this is no brainier.\n\n> I find the very best of the open source community busy in building & tuning tools old & new that are meant to satisfy DevOps culture & practices.\n\nIt makes sense for us to use these tools that meets our TDD needs.\n\nThe question that might be lingering now would be about DevOps vis-a-vis TDD. ***Is TDD not part of DevOps culture***? The answer is an emphatic yes. However, I am trying to pick up one thread at-a-time from the DevOps culture / practice. That thread here is TDD & is the focus area for this article. I would like to emphasise that TDD does not necessarily mean unit testing. It can be thought of as applying test logic, scenarios etc as the team continues with its development efforts, that in-turn brings in changes, discoveries, ideas in test as well as in development. ***To sum it up, it tries to remove the pain associated with latter stage design changes*** In addition, the team is ***no more afraid*** of new features, bug fixes, requirement changes, etc. due to the presence of test logic that gets triggered due to any of these changes.\n\nHope to talk again with some tangible implementations we are doing in [OpenEBS](https://blog.openebs.io/). I would end the story here with a tip.\n\n> *The popular currency of current age DevOps’ tooling is Docker & Kubernetes.*\n","slug":"test-driven-development-the-devops-way"},{"id":30,"title":"OpenEBS on the Growth Path! Releases 0.3","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS. ","date":"29-06-2017","tags":["Jupyter Notebook"," Kubernetes"," Openebs"," Postgresql"," Storage Containers"],"excerpt":"It gives me immense pleasure to watch this baby (OpenEBS) successfully cross another milestone with its 0.3 release. ","content":"\nIt gives me immense pleasure to watch this baby (OpenEBS) successfully cross another milestone with its 0.3 release. OpenEBS 0.3 not only marks the delivery of additional functionality, but also comes with an all-rounded growth.\n\nThanks to our growing community (as depicted in the diagram below), we have had great conversations with thought leaders in the container world, who are constantly looking for ways to simplify the usage of Containers and Container Orchestrators. We seem to have hit a sweet spot in terms of what we set out to deliver with OpenEBS, which is resonating loud and clear with anyone, who is venturing to run persistence workloads in containers.\n\n![](https://cdn-images-1.medium.com/max/800/1*wnMG__-zl8yO06f7AAJh5w.png)  \n\nWhile we have seen a steady growth in the followers/subscribers on our community channels, we have also seen a steady growth in the contributors to the project and we are happy to announce that we have been able to expand our team members at CloudByte(from across the world), to work full-time on OpenEBS.\n\nSignificant functionality changes include:\n\n- OpenEBS Storage Containers (VSMs) are completely orchestrated and managed via Kubernetes.\n- VSMs seamlessly work with your preferred pod networking\n- OpenEBS supports dynamic provisioner like EBS and GCP\n- *maya,* the Storage CLI can be used to fetch granular IO usage statistics similar to your Amazon Cloud Watch\n\nAdditional changes can be looked up at our [OpenEBS Project Tracker](https://github.com/openebs/openebs/wiki/Project-Tracker).\n\nWe are very attentive towards making the on-boarding experience as smooth and simple as possible. OpenEBS 0.3, fully integrates into Kubernetes, allowing you to use OpenEBS storage on your existing Kubernetes using the following simple commands:\n\n---\n\nkubectl apply -f openebs-operator.yaml  \nkubectl apply -f openebs-storageclasses.yaml\n\n---\n\nThe yaml files can be downloaded from [here](https://github.com/openebs/openebs/tree/master/k8s). If you don’t have an existing kubernetes cluster, you can easily set it up using our [vagrant box](https://blog.openebs.io/multi-node-kubernetes-1-6-cluster-provisioning-made-easy-using-sandbox-vagrant-box-53dfc2ecc3cd). Detailed instructions for running OpenEBS on GKE can be found [here](https://github.com/openebs/openebs/blob/master/k8s/hyperconverged/tutorial-configure-openebs-gke.md). You could also use our [Ansible Playbooks](https://github.com/openebs/openebs/blob/master/e2e/ansible/openebs-on-premise-deployment-guide.md) to setup kubernetes cluster with openebs storage on-premise on physical servers OR virtual machines.\n\nWe also have (with the help of the community) focused efforts in providing [examples](https://github.com/openebs/openebs/tree/master/k8s/demo) of persistence work-loads. In the current release, we are happy to provide the following:\n\n- Clustered PostgreSQL Setup (inspired from [CrunchyData](https://www.crunchydata.com/))\n- Containerized Jupyter Notebooks (inspired from [kensu.io](http://www.kensu.io/))\n\nThe growth, in terms of the distributed teams comes with the challenges of collaboration and maintaining the quality of the commits. One of our focus with OpenEBS release 0.3 has been to augment our repositories with the tools that keep a watch on the code and product quality — we are now fully integrated with Travis, Codecov, GoReport and have built Ansible Playbooks for running CI via Jenkins.\n\n---\n\nAs we accelerate towards our enterprise version of the product towards the end of this year, we are all excited about the immediate milestones w.r.t:\n\n- Flush-out the details of Storage Infrastructure as Code (single source of truth)\n- Integrating into Container Monitoring Frameworks\n- Providing a UI\n- Optimize for high performance storage and networking infra.\n- Provide additional examples of Persistence Workloads that make use of the Application aware intelligence provided by OpenEBS\n\nWe always love to hear from you and what you think are the biggest storage operations pain-points that you want to see eliminated. Do drop into our [*Slack Channel*](http://slack.openebs.io) or stay connected with us via our other channels *twitter (@openebs)*, [*github*](https://github.com/openebs/openebs/).\n","slug":"openebs-on-the-growth-path-releases-03"},{"id":31,"title":"Storage infrastructure as code using OpenEBS","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"29-06-2017","tags":["Containerised Storage"," DevOps"," Kubernetes"," Openebs"," Stateful Applications"],"excerpt":"With a vision to become de-facto block storage choice for stateful container applications, OpenEBS brings out many unique features to the open source storage space. ","content":"\nWith a vision to become de-facto block storage choice for stateful container applications, OpenEBS brings out many unique features to the open source storage space. One of the unique features that I talk in more depth in this blog is “how storage platform builders and storage platform users can manifest their requirements as code using OpenEBS”.\n\nWith all the agility in Container and DevOps space, we are moving towards the thinking — “using infrastructure components such as network and storage for the application development should not be external to the application development”. What I mean by this is, just like you write the code for your applications, you should be able to write some code or configuration for obtaining the storage and network infrastructure and you should get it.\n\n#### The YAML: Infrastructure coding language\n\nIn the paradigm of infrastructure as code, YAML is becoming the default coding language. Thanks to the increasing usage of yaml config files by the DevOps eco-system, they are becoming the default developer language to write the infrastructure code for the application development.\n\nSo, let us see what are the areas in which storage as infrastructure has to be thought in terms of code? This can be answered using the angle of who interacts with storage or the user persona. The simple answer would be the application developer and storage platform engineer. Next, what are the challenges today for a developer of a stateful application and the developer or engineer of underlying persistent storage platform? In short, the developer needs\n\n- Some amount of persistent storage\n- With guaranteed availability\n- With guaranteed latency\n\nThe developer needs to quantify the amount of storage and the latency levels, which is a challenge always. The developer always starts with a guesstimate and refine later. The guaranteed availability is a characteristic of the underlying storage platform, but the developer may still need to decide some aspects related to the availability such as “how many copies of the data is needed, how often backups are to be taken etc”. All these decisions to be taken by the developer, bring in the need of storage expertise or knowledge to the application developer, which usually is an additional burden to the developer. Traditionally, these decisions are taken by a storage administrators who are adjacent to the application developers, creating a gap between what is needed and what is available. As the application scales, this gap widens, application fails. **Yes, because something went wrong with storage !!**\n\nThe solution to this well known and well understood problem is to move towards a system where the application developer auto-magically gets help from the underlying storage system and he/she can continue to express / code the storage needs through the yaml language. The “so-called” storage administrator in the enterprise is going to be helped with an intelligent-storage-robot working continuously to align the storage to the application needs. With OpenEBS, the “intelligent-storage-robot” comes as an inherent component of the storage platform. The storage administrator can scale the platform and manage it at ease and do the job very well.\n\nThe intelligent-storage-robot or what we call at OpenEBS as “Storage bot” handles the tough job of automating the storage actions such as\n\n- Updating the storage catalogues for application developers\n- Work with the storage platform to identify the capacity change needs, migration needs, backup needs and coordinate with the application\n- Work with the application for scheduling application aware snapshots, capacity management, data migration changes, automated data recovery etc\n- Work with centralised ML engine (if there is one) to upload the application behaviour or to learn about the application behaviour so that it becomes more intelligent\n\n![](https://cdn-images-1.medium.com/max/800/1*3wWTPR7i1gAVagzBYlOBmg.png)\n**Storage bot helping app developer of stateful container application and storage admin of the platform** \n\nAs depicted above, the storage solution designer is replaced by a storage-Bot (code) which is more effective as it predicts and updates the parameters of storage platform as well as the application in real time.\n\n#### OpenEBS helps to manage storage needs with YAML language/code\n\nOpenEBS divides the storage configuration into two parts. One, that the storage platform engineer has to design/manage and the other that the application developer has to design/manage.\n\n**The platform yaml file**\n\nThe platform configuration is specific to OpenEBS and the initial version is available at “ ”\n\n[https://github.com/openebs/openebs/blob/master/k8s/openebs-config.yaml](https://github.com/openebs/openebs/blob/master/k8s/openebs-config.yaml)\n\nThe storage platform engineer develops this yaml file to scale the storage platform from few nodes to thousands of nodes across multiple locations. The yaml files can be version-controlled in a git repository and deployed into production to roll out the storage build-up process.\n![](https://cdn-images-1.medium.com/max/800/1*WiZS5A4iLPeMtwxUmdxunQ.png)\n\n**Storage platform deployment through yaml file automation**\n\nA real example of this automation would be something like —\n\n---\n\n*the storage bot senses that there is a flood of large block size reads about to hit on a postgres-volume-246 which has its copies on node2 and node4 and to satisfy the latency needs of this volume, the read-cache on node4 is insufficient and the one of the spare SSD on node4 can be re-purposed as read-cache temporarily. Storage bot learns this situation, makes the decision to do so and modifies the openebs-config.yaml on node4 as a new git version and rolls out the config file. Once the work loads is processed successfully after few hours/days, the read-cache SSD is re-purposed back by the storage-bot either by updating the config again or by rolling back the config change.*\n\n---\n\nThe above is a very simple example and more complex things like “automated data migration to a correct node or correct tier, adding compute and memory resources to the storage controller nodes on the fly, automated software upgrades etc” can all be achieved by the storage-bot using the git-versioned openebs-config.yaml files\n\n**The application yaml file**\n\nNow to the application developers paradise 🙂\n\nOpenEBS readily provides the storage configuration templates / storage catalogues for various stateful applications and application variants. The storage classes will be an ever-growing list with more participation from the community, but the initial version is at — [OpenEBS Storage Classes](https://github.com/openebs/openebs/blob/master/k8s/openebs-storageclasses.yaml)\n\nThe storage class will help the application developer with various storage config parameters. Some of the possibilities are:\n\n— Initial capacity, capacity growth rate per week/month, latency expectations, active data size (hot/cold data ratio), backup schedules, application data patterns, number of copies to be saved, typical instructions during upgrades, data migration boundary conditions etc\n\nAs you can see, the above actions form a major part of the job of a storage administer who plans, designs and executes the storage parameters. In the case of OpenEBS, the application developer can code this requirements into the application yaml file and the OpenEBS storage bot will enforce and help continuously optimise this file as well. This, I believe is a huge step forward in the journey of simplifying the storage infrastructure interface to the application developers.\n\nOpenEBS is in the early days. With the release of OpenEBS 0.3, the DevOps users have an option to get the container-native block storage for their stateful workloads orchestrated by kubernetes. OpenEBS 0.3 release is the first step in making the storage infrastructure as code possible.\n\nLooking forward to receiving feedback/comments/criticism on this topic. We are lurking on slack at [https://openebs-community.slack.com/](https://openebs-community.slack.com/)\n","slug":"storage-infrastructure-as-code-using-openebs"},{"id":32,"title":"Storage is Dead! Long live OpenEBS","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"28-06-2017","tags":["DevOps"," Kubernetes"],"excerpt":"In this blog I share something I’ve been saying for a while now that people suggested might just be audacious enough to spark a conversation.","content":"\nIn this blog I share something I’ve been saying for a while now that people suggested might just be audacious enough to spark a conversation.\n\nPlus — I explain why I’ve decided to help found another storage project — [OpenEBS](http://www.openebs.io/) — and to become CEO of the underlying company, [CloudByte](http://www.cloudbyte.com/), at a time in which venture capital funding to the space has declined (at least if you accept Rubrik and [Cloudian](https://cloudian.com/) and similar) funding as outliers :)).\n\nTL;DR: the old storage industry is ****dying**** like many stagnant and declining IT sectors before it, killed through outdated business practices and architectures and the emergence of a new set of personas that have radically different requirements, expectations, and even tastes. The new architectures and business models already exist — though they are unevenly distributed.\n\nI lay the story out in three points. I keep it brief and link to underlying technical resources w/ code and demos via those links for those that are interested. Please discuss below and/or at: [@epowell101](http://twitter.com/epowell101). Better yet, click here to be invited to our Slack channel: [https://openebsslacksignup.herokuapp.com](https://openebsslacksignup.herokuapp.com/)\n\n****Storage is dead? How so?****\n\n*On the one hand, massive data growth continues.* It is easy to look at a graph like the one above showing ongoing exponential growth in data created and conclude that the funding winter that has hit storage is just another irrationality of the venture market. Perhaps it is like 2006–2008 when too many of the top enterprise technology VCs had a couple of walking dead storage companies in in their portfolio and wouldn’t or couldn’t take on new investments.\n\nAnd many thanks to Mary Meeker and Kleiner Perkins for her [annual report](http://www.kpcb.com/internet-trends) on trends for the graph.\n\n****Cloud****\n\n*On the other hand, cloud.* The major cloud vendors are a) truly major and b) see storage as a way to control customers.\n\nTo the ‘truly major’ point — the three largest cloud providers are some of the largest companies the world has ever seen. Those of us that remember the power of WinTel in the 90s and early 2000s need to remember that this time is different in part because the companies are massively more wealthy thanks in large part to having business models that transcend technology.\n\nTo the ‘control customers’ point — data gravity exists. And it is further leveraged by cloud providers making it free to transfer data to them and rather expensive to get it back.\n\nWhich brings us to DevOps and cross cloud services…\n\n****DevOps and cross cloud services****\n\nAs I learned from my experience as a co-founder and CEO of [StackStorm](https://github.com/StackStorm/st2), DevOps is a radically better way of building and running software — as well as being a cultural movement.\n\nAnd while there are many, many characteristics of what constitutes a “DevOps environment” — one important aspect as I see it is that the intent of the developer can be fully manifested by the underlying infrastructure and related services.\n\nAnd a second aspect is that many capabilities are consumed by the applications and the application developers as services. This fits with the use of micro services as well, of course.\n\nLast but not least, DevOps is a culture and a set of practices that, as demonstrated by the story of the crucial book the Phoenix Project, is motivated in part by a realization of how broken, slow, dysfunctional, unfair, and brittle, proprietary IT systems and IT operations traditionally have been. From this perspective, applying infrastructure as code in part to insure cross team transparency and blameless postmortems and so forth are not just examples of useful techniques — they are manifestations of the values of a better culture.\n\nOne strength of clouds like AWS is that they enable you to consume storage in a DevOps friendly way — your orchestration or other automation can deal with the provisioning and management (or can rely on the solutions provided by the cloud provider) so that intent can flow from the application through the infrastructure; in addition, the infrastructure is there to be consumed dynamically, via APIs. Unfortunately the cloud providers themselves have become the new proprietary, which makes some in the DevOps world a bit uncomfortable as in the past lock-in was used by proprietary vendors to maximize their own prices at the expense of their customers. Kubernetes especially offers a chance to keep the wiring free from the cloud providers, hence providing some hope of avoiding lock-in.\n\n****Uhh, huh — and OpenEBS?****\n\n![](/images/blog/uhh-huh-openebs.png)\n\n**Uhh huh — data, cloud, DevOps, lock-in and, err, OpenEBS?**\n\nIn short, the highest level vision for OpenEBS is one in which the DevOps friendly aspects of running storage in the cloud is now available on premise and across your clouds, thus freeing you from vendor lock-in much in the way that Kubernetes helps you avoid the risk of locking yourself in through the use of cloud service specific wiring and workflow.\n\nWhat if your developers and devops teams could orchestrate your storage controllers just like other containers? How much more productive could they be?\n\nAnd what if that set of storage services allowed you to treat your stateful workloads on containers much like the ephemeral containers that have proliferated?\n\nAnd what if your storage and CIO teams were able to establish policies that governed your data without impeding the agility that was your purpose in moving towards containers and DevOps in the first place?\n\nLast but not least, what if, having tooled your environment to work with Amazon it just worked when you added the on-premise and cross cloud OpenEBS? Wouldn’t this limit your lock-in with any one cloud vendor?\n\nOpenEBS remains early. Today we are at release 0.3 and are just starting to be used by enterprises like Cap Gemini and others to deliver storage for stateful workloads on containers.\n\nI’m back into the storage industry because I’m sure that OpenEBS has a good chance to allow storage to slip into the background and “just work” to support the incredible boosts in agility delivered by DevOps.\n\nA bunch of us imagined a better storage industry — one more software like, one that eliminated vendor lock-in — back in the 2008 / 2009 time frame. Instead, we got some kick ass flash and quite cool hyperconverged solutions PLUS, mostly, AWS just working (well enough) with a far better business model and ability to scale.\n\nSo vendor lock in remained a problem. And storage far too often remains the bottleneck that slows down the good stuff, including the shift of real workloads onto containers.\n\n[OpenEBS](http://www.openebs.io/) is going to fix all of that and make storage and related storage services something you use to free yourself from lock-in while boosting your operational agility. Game on!\n\nYou can learn more about today’s release of OpenEBS 0.3 from our COO and co-founder’s blog [here](https://blog.openebs.io/@uma_mukkara). I think you’ll agree, what’s possible now reinvents storage fundamentally — with your help we’ll turn this project into a company and a complete solutions that we can all rely on.\n\nOther resources include demos of OpenEBS working seamlessly with Kubernetes and interesting stateful workloads including PostgreSQL and the Spark notebook Jupyter in our demo repo [here](https://github.com/openebs/openebs/tree/master/k8s/demo/crunchy-postgres).\n","slug":"storage-is-dead-long-live-openebs"},{"id":33,"title":"Data Scientists adopting tools and solutions that allow them to focus more on Data Science and less…","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"24-05-2017","tags":["Adalog"," Data Science"," Kubernetes"," Openebs"," Jupyter Notebook"," Solutions"],"excerpt":"Data Science as we all know is becoming crucial to many if not most businesses around the world. Data Science and ML are decidedly, the most trendy skills that a lot of people are aspiring to acquire or be associated with.","content":"\nData Science as we all know is becoming crucial to many if not most businesses around the world. Data Science and ML are decidedly, the most trendy skills that a lot of people are aspiring to acquire or be associated with. In my recent interactions ( in the context of hiring for OpenEBS) with college graduates and software engineers, the one question that pops up is, if they join OpenEBS, will they get a chance to work on ML / Data Science (and the answer is a definite “maybe” :)).\n\nThe lure towards “Data Science” has gone beyond the $$ paid to the Data Scientists. It is about the process of creating wonders. “Data Science” puts forth an unique mix of interesting challenges, that requires grappling with the enormous amounts of data and the mind numbing application of the machine learning and computational algorithms, visualization and soft-skills. These aspects associated with “Data Science” are evolving, as depicted in this [data science venn diagram](https://www.infoq.com/articles/christine-doig-data-science-team-discipline).\n\n![](https://cdn-images-1.medium.com/max/800/0*FEPtZ-3YF48YMkRs.)\n\nYou can see this trend expressed in this graph of searches on Google as well. An interesting point is that “Machine Learning” has been neck and neck with “Data Science” until recently when “Machine Learning” started to be searched for approximately 30% more frequently. And the gap between searches about Data Science and about Data Scientists has widened in the last couple of years; it seems people are about 3x more likely to be interested in Data Science than in the Data Scientists that actually do the work 🙂\n\n![](https://cdn-images-1.medium.com/max/800/0*Usx-pyQi3bHCTyJe.)\n\nInterestingly, we have seen early OpenEBS users and contributors asking about OpenEBS delivering storage to containers running distributing nodes for Kafka or Spark or other pieces of a Data Science pipeline. We wanted to learn more about the needs of these users.\n\nThankfully, we are a little bit of a sister company to [Kensu.io](http://www.kensu.io/) as our Chairman [Evan Powell](https://twitter.com/epowell101) has been advising [Kensu](https://twitter.com/kensuio) as well. So we got in touch with the Kensu.io founders [Andy](https://twitter.com/noootsab) and [Xavier](https://twitter.com/xtordoir), who are co-creators of the [spark-notebook](http://spark-notebook.io/), which is the leading Scala notebook for data scientists working in the Spark community. [Andy](https://twitter.com/noootsab) and [Xavier](https://twitter.com/xtordoir) and their team have built and have helped to run some of the largest Data Science pipelines in finance and related fields in Europe; plus they are O’Reilly authors. They have been really generous with their time.\n\nThe TL;DR is — *data scientists still spend way too much time hacking together Data Science pipelines and if they only could orchestrate the end to end pipeline with Kubernetes/Mesos (which seems to be common in these environments) so that storage itself worked simply, this could be more productive, could recreate their results more easily, and might even work together better.*\n\nIn the rest of the blog I set out a little more specifically what we have learned and we share the beginnings of a recipe for Data Science on containers with OpenEBS as the storage. Please provide feedback to this blog or join the now hundreds of people on the [OpenEBS slack channel](http://slack.openebs.io/) and post your comments and feedback there.\n\n**Data Science workflow hindered by infrastructure management tasks**\n\nThe workflow of a data science project typically comprises of four stages as outlined below, with data scientists going back and forth between these stages, before arriving at product/insights in the form of a report, dashboard or a data service.\n\n![](https://cdn-images-1.medium.com/max/800/0*UCJHD8p2bNOemyC9.)\n\nEach of these stage involves tasks that can be further classified into three distinct types depending on the nature of the task as follows:\n\nType 1 : Data Science\n\nType 2 : Best Practices or Governance\n\nType 3 : Administer Infrastructure/Tools\n\nData Scientists are primarily interested in *Type 1 : Data Science tasks,* some sample tasks under this category (at different stages of the workflow) are:\n\n![](https://cdn-images-1.medium.com/max/800/0*t41w0qHFapFBWtX_.)\n\n*One of the crucial requirement for the data scientist is to produce accurate and reproducible analysis by collaborating with larger teams.*[*Martin Hack*](https://twitter.com/mhackster)*, commented that he has come across situations where the accuracy of the models change from the time the models were generated to the time that they are presented to a wider audience. This is usually attributed to the change in the data using which the model was generated.*\n\nThe efficiency and confidence with which these tasks are performed or improved (in an iterative way) are dependent, in the current scenario, on some *best practices*. The best practices range from following certain naming conventions for the data files used to tuning infrastructure/tools — like databases, distributed systems that are used to run the analytical or modeling tasks.\n\nSome sample Type 2 : Tasks at different phases of the Data Science workflow are as follows:\n\n![](https://cdn-images-1.medium.com/max/800/0*IKPVzSqbyirvwZW5.)\n\nThe tasks mentioned above just provide a glimpse into the challenges associated with a typical data science workflow. In workflows that require creating models by using data from multiple live sources, tracking the accuracy of the data without having something like application error logs, becomes a harder problem to solve, if not impossible. This also leads to anxious data scientists who tend to keep their work private, unless a higher level of confidence is achieved on the models generated.\n\nTalking of confidence, today we take pride in writing code that goes into production on day-one, using automated continuous integration systems. Kensu is doing something similar, which can be considered as *Continuous Integration mixed with Live Monitoring of Data Sources.*\n\nAndy and Xavier and team are rolling out ***Adalog***, their software and SaaS solution, first for their existing professional service customers and then more broadly. While you can learn much more about Adalog on their website — [http://www.kensu.io](http://www.kensu.io) — as I understand its Adalog picks up all the relevant metadata of the data science pipeline and uses it, as well as the underlying systems themselves, to deliver compliance reporting and controls.\n\nData Science Notebooks (like [*Jupyter*](http://jupyter.org/), [Spark-Notebook](https://github.com/spark-notebook/spark-notebook), etc.,) and integrated products like Adalog have enabled improved and reproducible data since workflows, and deploying these notebooks towards containers have helped in boosting the productivity.\n\nYet, there are a few infrastructure related tasks that are not fully integrated into this workflow, which creates a manual dependency on the expertise of infrastructure administrators. At the same time, it also burdens the administrators/operations team to manage a new kind of workload in their environment.\n\nSome of the tasks that fall under this *Type 3 : Infrastructure / Operations* tasks from (from a storage operations perspective) are:\n\n![](https://cdn-images-1.medium.com/max/800/0*gcVdcir6RcbetPXe.)\n\n*Andy and Xavier stated that they have the integration pieces with the data science tools, he finds that storage infrastructure related challenges remain and many of these would seem to be best solved with tighter integration by products like OpenEBS that are fully containerized and hypercoverged, with products like Adalog.*\n\n*Without a solution like OpenEBS that natively integrates into the orchestration and that containerizes the storage itself*\n\n- *Capacity management is very tricky, where some of the tasks involve non-deterministic data bloating. Hitting disk space errors, may result in loss of many hours of processing.*\n- *Managing the capacity for the local copies that need to be maintained for external data sources and keeping them in sync and distributing to team members can be very time consuming*\n- *The dynamic nature of jobs that require bursts of IOPS/Throughput mean that to be safe the systems are massively over provisioned which then means you need a large budget request even to just mess around in trying out new models for example*\n- *Maintaining the provenance of the data along with the models for reproducing the results with the same accuracy they had during model generation is extremely difficult and without that the human workflow of many data science users is broken; imagine, for example, trying to compare the performance of multiple teams who are being evaluated based on the quality of their models if you cannot be sure that the training sets have remained trusted.*\n\n*Andy says, these infrastructure and hand-holding of the workflow operations are what makes Data Science more of engineering than science.*\n\n**Data Science workflow — storage management tasks automated by OpenEBS**\n\nDocker and Kubernetes have eased the operations around maintaining large scale computational clusters, and with containerized and hyper-converged storages like OpenEBS, the operations can now provide storage for millions of containers without having to maintain separate storage silos.\n\nKubernetes and OpenEBS will help in further simplifying the infrastructure management tasks for the data science workflows by supporting automated storage capacity management based on the data source changes, auto-tuning of the QoS depending on the priority of the analytical task and provide data provenance without laying extra burden on the data scientists by deeper integration with the notebooks.\n\n*For instance, the following is a glimpse of what can be achieved through deeper integration of Adalog with kubernetes and openebs:*\n\n1. *Data scientists starts a new notebook ( or project ). This project is instantiated on the container cluster (say Kubernetes).*\n2. *When a data source is specified for download, it would trigger provisioning of a new OpenEBS storage volume from this cluster for the data source. The capacity for this new volume is auto-managed by OpenEBS. Adalog would maintain the information of the volumes associated with a notebook.*\n3. *When the notebook finishes downloading of the data, it will trigger to create a snapshot of the downloaded data. Notebook can allow for regular syncing with the source to check for updates and download the incremental data etc., Adalog would track the snapshots of the volume used by the notebook.*\n4. *As data scientists start exploring the data, there are provided with a read-only access to the snapshot of the data-source that is already downloaded. And new storage volumes are created for storing the temporary files. Adalog can associate the volume created with the user who initiated the data generation.*\n5. *When a certain exploration is aborted or cleared from the notebook, the associated volume ( and all the temporary files) are also cleared from the storage. Adalog would keep track of the functions and models generated via the exploration phase along with metadata information about the results generated, even though the volumes (data) is deleted.*\n6. *OpenEBS volumes come with fine-grained allocation of resources and auto-tuning which can help with running high priority modeling jobs faster than the others.*\n7. *From Adalog, the user can trigger OpenEBS volumes (data) to be backed up or restored from S3 bucket.*\n\nAs a next step, we are planning to provide an sandboxed version of adalog running on kubernetes and storage managed by OpenEBS. Much like the vagrant box we built to enable OpenEBS to be tried out on Kubernetes — and then became a favorite tool of some largely for trying out Kubernetes — we are hopeful that this sandbox will be useful as well as being a way to see OpenEBS in action.\n\n*If you want to earn massive open source karma (and stickers of course) — let us know on our *[*OpenEBS Slack channel*](http://slack.openebs.io/)* that you’d like to help with this solution building exercise.*\n","slug":"data-scientists-adopting-tools-and-solutions-that-allow-them-to-focus-more-on-data-science-and-less"},{"id":34,"title":"Multi-Node Kubernetes 1.6 Cluster provisioning made easy using SandBox (Vagrant box)","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"23-05-2017","tags":["Kubeadm"," Kubernetes"," Openebs"," Vagrant"," Virtualbox"],"excerpt":"Working on OpenEBS, a containerized storage for containers which is orchestrated by Kubernetes, most of our tasks, be it development, testing and demo require us to setup and modify the nodes in Kubernetes cluster.","content":"\n### Background\n\nWorking on OpenEBS, a containerized storage for containers which is orchestrated by Kubernetes, most of our tasks, be it development, testing and demo require us to setup and modify the nodes in Kubernetes cluster. In addition, a multi-node cluster is a must as we go beyond the initial development and testing, to explore the high availability, scale, performance and upgrade aspects.\n\nWhile *minikube *and *minishift* provide an easy way to setup kubernetes single node cluster — for multi-node cluster the fastest ways to get going are usually cloud or hosted solutions. ***kubeadm*** is the closest we can get to easily setup a cluster, but since it is still in alpha, we keep running into some issues like — [kubadm init v1.6.1 fails](https://github.com/kubernetes/kubeadm/issues/226)\n\n*An ideal solution for a developer would be a Kubernetes Sandbox. A sandbox that can be easily setup on a laptop and can work on the move (without net connectivity.) This Sandbox should be shielded from the different API or CLI changes that happen with the frequent releases of kubeadm and kubernetes.*\n\nWe have used Vagrant, VirtualBox and Atlas to do just that.\n![](https://cdn-images-1.medium.com/max/800/1*7kkviZOwgh8ePDYRjFX0mQ.png)\n\n## Try It! It is Easy and Quick!\n\nOnce you have Vagrant (1.9.1 or higher) and VirtualBox (5.1.14 or higher) installed on your laptop/machine, just do the following:\n\nStep 1 : Download the Vagrantfile from [OpenEBS Github](https://raw.githubusercontent.com/openebs/openebs/master/k8s/lib/vagrant/test/k8s/1.6/Vagrantfile)\nStep 2 : Run **vagrant up**\n\nDetailed instructions can be found [here](https://github.com/openebs/openebs/tree/master/k8s/lib/vagrant/test/k8s/1.6).\n\nThe above two steps will provision the following:\n\n- Ubuntu VM with Kubernetes Master (kubemaster-01)\n- Ubuntu VM with Kubernetes Minion (kubeminion-01) associated with (kubemaster-01)\n- Setup *weave *as pod network\n- Setup the kubectl credentials ( admin.conf) on kubemaster-01\n- Sample kubernetes pod yaml files are located on (kubemaster-01) under the directory ( *~/demo/k8s/spec/* )\n\nIn addition to the above, the following OpenEBS provisioning tasks are also performed.\n\n- Install OpenEBS iSCSI FlexVolume Driver on the kubeminion-01\n- Ubuntu VMs installed with OpenEBS Maya Master and OpenEBS Storage Hosts. (If you don’t want to use the storage, you can skip installation of these VMs. Check the customization steps below).\n\n## Customizing the Kubernetes Sandbox\n\nThe above instructions include setting up Kubernetes and OpenEBS as well, but you can easily customize the Vagrantfile to skip installation of OpenEBS by prefixing ENV variables before the vagrant command as follows:\n\n    MM_NODES=0 MH_NODES=0 vagrant up\n\nSome of the configuration options available are:\n\n- KM_CPU — Number of CPUs for minion (*default 2*)\n- KM_MEM — Size of the RAM (in bytes) for minion (*default 2048*)\n- KH_NODES — Number of Kubernetes Minion VMs *(default 1)*\n- KH_CPU — Number of CPUs for minion (*default 2*)\n- KH_MEM— Size of the RAM (in bytes) for minion (*default 1024*)\n- MM_NODES — Number of OpenEBS Maya Master VMs *(default 1)*\n- MH_NODES — Number of OpenEBS Storage Host VMs *(default 2)*\n\nIf you are looking for an older release of Kubernetes, checkout — [kubernetes vagrant boxes with 1.5.5](https://blog.openebs.io/setting-up-kubernetes-1-5-5-cluster-with-vagrant-dda11e33b5bc)\n\n## Contributing to creating Kubernetes Sandboxes\n\nBtw, the process of creating these Kubernetes Sandboxes is Open Sourced.\n\nThe majority of the issues that are encountered during the kubernetes cluster setup using kubeadm are related to the software api/cli options changed across different versions of kubeadm or the interfaces between kubeadm and kubernetes. Another nagging issue is the need to have connectivity to the network.\n\nThese issues are resolved by having Sandbox (vagrant boxes) that pre-package the required software with versions that are compatible. The tasks of downloading the required software is automated via the scripts.\n\nOnce a VM is initialized with network/IP address details, certain initialization tasks will have to be executed. These are placed in the configuration scripts (which are also pre-packaged with the sandboxes) and are invoked from the Vagrantfile itself.\n\nCurrently, the Sandboxes use *weave* as a pod network, you can easily extend this to use different scheme for pod network.\n\nIf you like to contribute or learn more about these box generation scripts, checkout our [GitHub](https://github.com/openebs/openebs/tree/master/k8s/lib/vagrant) or join our [*Slack Channel*](http://slack.openebs.io).\n","slug":"multinode-kubernetes-16-cluster-provisioning-made-easy-using-sandbox-vagrant-box"},{"id":35,"title":"Rancher’s Longhorn announcement solidifies the OpenEBS story","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"18-04-2017","tags":["Docker"," Openebs"," Rancher"," Stateful Applications"," Longhorn"],"excerpt":"Today, Sheng Liang unveiled project Longhorn as a new way to build distributed block storage for cloud and container-based platform.","content":"\nToday, Sheng Liang [unveiled project Longhorn](http://rancher.com/microservices-block-storage/) as a new way to build distributed block storage for cloud and container-based platform. We, the OpenEBS team, are thrilled with this news as it solidifies our decision of using Longhorn as the underlying block storage system for OpenEBS.\n\nWhen I reviewed the OpenEBS vision with Sheng late last year, he introduced me to Longhorn project and asked me to study it and use it if it makes sense for OpenEBS. Clearly, Longhorn was sharing the OpenEBS block storage vision and we soon launched OpenEBS with Longhorn underneath.\n\nWhat I liked most about Longhorn was the nice separation of block protocol stack (Longhorn controller) and the actual block storage (Longhorn replica). This helped us containerize the storage software completely and efficiently. An OpenEBS VSM, or a storage pod, will have containerized longhorn controller and replica(s).\n\nAnother cool thing about Longhorn implementation is that it’s controller sits closer to the application docker containers thus enabling hyper-converged mode of deployment and it’s replica sits closer to the underlying storage with a simple sparse file based system for block data management.\n\nIt is so nice of Sheng to mention about OpenEBS’s usage of LongHorn. We will continue to contribute to the performance tuning of LongHorn, improvements to S3 integration, rebuilding logic of replicas etc\n\n### OpenEBS is an extension to the idea of Longhorn\n\nSheng Liang, in his blog, talks about Longhorn and other storage systems.\n\n“ *We wrote Longhorn as an experiment to build distributed block storage using containers and microservices. Longhorn is not designed to compete with or replace existing storage software and storage systems …..”*\n\nAs believers in the idea for which Longhorn is written, we are building OpenEBS as a credible enterprise storage with Longhorn at it’s core. As part of the journey with CloudByte ElastiStor, where we have containerized the storage volumes a few years ago, we picked up tremendous amount of real world experience in delivering enterprise storage to the customers. All this experience is being put into work at OpenEBS. OpenEBS will have most of the enterprise features that Sheng mentions, if not more. Some of them will be “scalable and reliable distributed file systems, a unified storage experience, enterprise data management, crash consistency, near disk performance etc”\n\nAgain, a ton of thanks to the awesome folks who contributed the development of Longhorn. With this announcement from Rancher, we are hoping to see more usage of Longhorn and OpenEBS. We are all ears to the community for any suggestions on OpenEBS and its usage of Longhorn ([slack.openebs.io](http://slack.openebs.io)).\n\nLong live Longhorn !!\n","slug":"ranchers-longhorn-announcement-solidifies-the-openebs-story"},{"id":36,"title":"OpenEBS sprinting ahead, 0.2 released","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"10-04-2017","tags":["Containerized Storage"," Docker"," Kubernetes"," Microservices"," Openebs"],"excerpt":"I am delighted that we have been able to push the OpenEBS 0.2 release for community consumption, a version that demonstrates that storage controllers can be containerized.","content":"\nI am delighted that we have been able to push the [OpenEBS 0.2 release](https://github.com/openebs/openebs/releases/tag/v0.2) for community consumption, a version that demonstrates that storage controllers can be containerized. This release comes with k8s flex volume driver called “openebs-iscsi”\n\nThe past week has been very exciting for the OpenEBS Team — engaging with container technology evangelists, enthusiasts and users at the [Bangalore Container Conference — BCC 2017](http://www.containerconf.in/), followed by a very interactive meetup on the [Containerized Storage for Containers](http://www.containerconf.in/) with [Evan Powell](https://twitter.com/epowell101), [Ian Lewis](https://twitter.com/IanMLewis) and my fellow Bangalore Entrepreneurs and OpenSource fans.\n\nBy containerizing the storage functionality, the OpenEBS delivers the core storage capabilities like block-layout and its management, data protection, consistency and availability as a “micro service”, thus bringing the advantages of containers to the storage volumes. Containerization also helps in dynamic provisioning at scale, scale up/down the storage cluster, monitoring, ease of upgrades etc,.\n\nWe understand that generic orchestration engines will not solve all the problems of storage orchestration. We are augmenting container orchestration engines with the storage intelligence by the OpenEBS orchestration layer — maya. In line with this vision, the 0.2 release has implemented m-apiserver that acts as an interface to the Volume Plugin drivers to provision the storage, while it takes care of interacting with the Container Orchestration Engine to find the right placement for the Storage Containers (VSM).\n\nOpenEBS 0.2 can be used to setup an Amazon EBS-like Block Storage Service for your containers, and consume block storage for your Stateful applications.\n\n![](https://cdn-images-1.medium.com/max/800/1*itiDxdwyTmdd9VsIYwFYiA.png)\n\nThe Ops team can easily setup an OpenEBS cluster using Bare Metal Machines or VMs, just like setting up Kubernetes Cluster. The Kubernetes minion nodes should be configured with the FlexVolume OpenEBS Driver (openebs-iscsi) to use OpenEBS Storage.\n\nThe DevOps or the Developers can configure Storage to their Stateful Apps from OpenEBS cluster by having their Application intent files point to OpenEBS Maya API Server.\n\nOpenEBS is a completely OpenSource Project that is being driven by the feedback received from the community. In our next milestone 0.3, we are working towards making OpenEBS hyper converged with Kubernetes. Enhance the capabilities around Core Storage for using additional type of disks for storing block data, providing the controls to the user to perform backup/restore to Amazon S3, etc., Do take a moment to check out our [Project Tracker](https://github.com/openebs/openebs/wiki/Project-Tracker).\n\nIf you are as cautious and skeptical about technology like me, then seeing is believing. To help you quickly get started, we have created Kubernetes and OpenEBS 0.2 Vagrant Boxes.\n\n[Try OpenEBS 0.2 today](https://github.com/openebs/openebs/blob/master/k8s/dedicated/tutorial-ubuntu1604-vagrant.md) and let us know what you think !\n\nHangout with us and help us with your valuable feedback at [slack.openebs.io](http://slack.openebs.io)\n","slug":"openebs-sprinting-ahead-02-released"},{"id":37,"title":"Software Defined Storage — finally","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"11-03-2017","tags":["DevOps"," Docker"],"excerpt":"In this blog I’ll discuss what went wrong — why we didn’t achieve the the promise of software defined storage — and why software defined storage is now, finally, possible.","content":"\nMany years ago there was a flowering of what we called software defined infrastructure. Those of us at the forefront of the trend were no doubt encouraged by the success of Martin Casado and the Nicera team who quickly went from PhD thesis to $1.26bn purchase by VMware thanks to the promise of software defined *networking*. In hindsight we were misguided, but a handful of us built companies built on the premise — why not *storage*?\n\nToday we finally have the ingredients in and around the storage industry to achieve what we all were shooting for 5–7 years ago. I’m so encouraged by these enabling trends that I’ve gotten back into storage even as it has fallen out of investor favor. Cutting edge users are now achieving the cost savings and boosts to their agility we all promised — and truly believed — were around the corner years ago.\n\nIn this blog I’ll discuss what went wrong — why we didn’t achieve the the promise of software defined storage — and why software defined storage is now, finally, possible.\n\nThere are at least a handful of reasons that storage failed to achieve the true promise of software defined storage — that we did not live up to the radical flexibility of virtualized compute for example, where compute jobs were largely freed from their underlying hardware:\n\n1. The lack of portability of the controllers themselves\n2. The inherent stickiness of the underlying data\n3. Inability to deliver performance in a dynamic environment\n4. Immature common standards\n\n****Controller portability and data stickiness:****\n\nStorage controllers have to be able to deliver the policies you want — share these folders with these thousands of people for example — while keeping the underlying data safe irrespective of hardware failure, bit rot, user error and more.\n\nFor a couple of reasons we in the industry at the time were unable to make our controllers truly software-like in the way that they were deployed in data centers: one, we didn’t sufficiently separate the policy engine or storage scheduler from the care and feeding of the underlying data on disk; two, in part because of this as well as the way that hardware drivers interact with operating systems, our storage controllers tended to need to be bare metal installs, and did not run well in a virtual machine. Perhaps more importantly, because our controllers needed to run on the same systems where the data was stored, they could only ever be as fluid and dynamic as the data itself. In other words, we were chained to our hardware in part by the physics of reading, transporting, and writing data.\n\n****Performance amidst dynamism:****\n\nInformation technology design is often a game of pass the bottleneck. For any given system there is one bottleneck or constraint that limits much of overall performance and hence that throttles the ability of the application to serve user needs. Historically the bottleneck has often been storage — and the rise of virtualization just tightened further this bottleneck thanks to the I/O scrambling that hypervisors perform on the read/ write patterns of the applications running on them.\n\nAnd yet if you are to treat storage — and storage controllers — as software that itself can be dynamically provisioned and moved about then you must be able to deliver performance from underlying systems irrespective of where the controller software is located. Perhaps more importantly, you need to be able to interpret the requirements of the applications themselves and deliver the combination of IOPS and latency they need to meet the requirements of their end users.\n\nThis problem has aspects of the traveling salesman problem, which is to say, it is not entirely solvable. The way it has been solved in practice is that storage has remained bound to particular sets of typically hugely over provisioned hardware and the combination of applications and underlying storage has itself had to be controlled through affinity rules in the compute schedulers from VMware and OpenStack and others. In the container world, for the most part, we have dealt with the challenges of delivering storage performance to so-called stateful containers **by not having stateful containers**. The vast majority of containers that are deployed don’t actually rely upon data storage in the way that databases for example do. Those containers that are stateful typically tightly couple the underlying storage to containers, thereby removing much of the dynamism and ease of management that was a primary point in moving to containers in the first place.\n\n****Immature common standards****\n\nAs if the inherent difficulty of somehow addressing QoS for storage, while allowing controllers themselves to become more flexible, was not hard enough, the industry structure of IT 4–5 years ago itself made it more difficult to deliver software defined storage. VMware tried hard to get everyone on the same page via their VASA APIs, which was a way to pass information about applications to the storage and for the storage to essentially sign-up for the performance needed,however this effort ended up making less transparent and more proprietary the DNA, or operating instructions, of the software defined data center. Perhaps because these operating instructions themselves were so opaque they never caught on in software defined data centers.\n\nToday the Kubernetes community is probably our best shot for having a set of commonly accepted application definitions that flow into the infrastructure, to actually deliver software defined infrastructure. In this case the DNA is human readable YAML and is managed by a set of open source technologies.\n\nQuick note — pod and resource definitions are not fully fleshed out by Kubernetes for storage. So you can do some basic things, such as limiting the amount of storage by user or application or pod, however storage specific QoS is not yet supported in these definitions. This is a work in progress.\n\nNonetheless, what is possible today gives a good idea of what is coming. For example:\n![](/images/blog/software-defined-storage-finally-example-code.png)\n\nAs you can see, very simple, human readable, and change controllable easily via GitHub or other system, which is fundamental to achieving high degree of automation and control.\n\n****The unevenly distributed future****\n\nWhile this blog and self assessment of where we got to in software defined storage may be a bit depressing, there are signs of hope.\n\nWithin the Kubernetes community, for example, hardy pioneers with deep technical expertise such as Pearson are using solutions like StackStorm and much else to build truly developer defined infrastructures that include the use of containers for stateful workloads.\n\nWhat I learned from Pearson and other StackStorm users led me to look for storage intellectual property — and the teams that built it — that could enable the storage freedom promised by Software Defined Storage. Specifically, I went looking for technologies that could virtualize or containerize storage controllers while somehow ensuring the delivery of QoS.\n\nIn CloudByte I found a solution that today delivers fine grained control of QoS via an architecture that features virtualized storage controllers. What this means is that the controllers themselves can be live migrated, for example, while continuing to serve storage. This is how CloudByte delivers non disruptive upgrades — and it also means that you can migrate pieces of your data center from on premise to the cloud and back — with confidence. However, without QoS controls moving your controllers around would be madness — and so the deep understanding of QoS and the ability to set QoS SLAs by user or by volume for example is crucially important.\n\n![](/images/blog/storage-controller-migrating-from-one-site-to-another.png)\n\nIn the above image I show a storage controller migrating from one site to another.\n\nAnd what CloudByte does for today’s primarily scale up workloads — largely “pets” — our emerging open source project called OpenEBS will do for emerging scale out workloads — so called cattle — through “containerized storage for containers.”\n\nIn short — as we plan to further illustrate through use case stories especially of hybrid cloud and backup use cases — in CloudByte / OpenEBS I’ve found not just the building blocks but the first instantiations of the future we all dreamed of several years ago.\n\nTime to reboot — and re energize; storage now has the ingredients needed to unshackle users and enable them achieve much more dynamic IT while keeping control of their data. Join me by taking a look at CloudByte and OpenEBS today. I look forward to your feedback.\n","slug":"software-defined-storage-finally"},{"id":38,"title":"Using OpenEBS to build a true on-premise container service","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"28-02-2017","tags":["Aws Ebs"," Container As A Service"," Openebs"," Persistent Storage"," Kubernetes"],"excerpt":"The top questions that could be lingering on the enterprise architect mind in an enterprise are","content":"\nThe top questions that could be lingering on the enterprise architect mind in an enterprise are\n\n- How do I build a true container service in my enterprise?\n- Do I really have to depend on the popular clouds such as Google, AWS, Digital Ocean to start my container journey?\n\nBuilding container services on AWS or GCP is practial today. These cloud platforms provide the infrastructure to start building your container platform. You get VMs for hosting K8s minions and masters and persistent disks (EBS disks or GP disks) to persist the block storage of your applications. If you want to build the similar container service in your enterprise on-premise data center, what are the choices for container infrastructure?\n\nWell, the troubling infrastructure piece to build the true container service in your enterprise is the persistent storage for your applications. No surprise there. VMs or baremetal can be deployed using the well known tools such as OpenStack and KVM, but for deploying EBS or GPD equivalent, you would need something like OpenEBS.\n\nOpenEBS helps the enterprises to build an AWS EBS equivalent or GPD equivalent platforms on-premise. OpenEBS is architected to ease the provisioning and management of persistent volumes at scale. It will have most the elements of the popular AWS EBS. I had discussed the comparison between AWS EBS and OpenEBS with few community members in our last meetup. The slides are posted at [https://www.slideshare.net/OpenEBS/openebs-containerized-storage-for-containers-meetup-2](https://www.slideshare.net/OpenEBS/openebs-containerized-storage-for-containers-meetup-2)\n\nContainerization of block storage volumes gives the benefit of flexible storage upgrade schedules, treating the storage volume as part of your K8s POD etc. However, there is more to consider as benefits of OpenEBS. OpenEBS is “Open source” EBS. A quick feature comparison is as follows\n\n![](https://cdn-images-1.medium.com/max/800/1*uu_mIhdqobjf3ftNOtf8KQ.png)\n\nNext, provisioning and consuming persistent volumes through OpenEBS is very similar and simple to that of AWS EBS\n\nIn AWS EBS a user creates and attaches a disk to an EC2 instance. The nuances of underlying storage protocols is hidden underneath and not exposed to the consumer/user.\n\n![](https://cdn-images-1.medium.com/max/800/1*zShnxODcXjTNu-X-qsJa5g.png)\n\nFlow of provisioning and consuming persistent block volumes on AWS EBS\nIn OpenEBS, it is very similar. Once the OpenEBS volumes are expressed as intent in the application yaml config file, the volumes are automatically created on the OpenEBS platform,mounted on K8s minions and the persistent storage is made available to the application.\n\nExample of OpenEBS volumes getting consumed through iSCSI:\n\n![](https://cdn-images-1.medium.com/max/800/1*Mh9MzX5a_YbV9K_LR8EynA.png)\n\nExample of OpenEBS volumes getting dynamically provisioned and consumed using k8s-openebs provider is shown below\n\n[https://github.com/openebs/openebs/blob/master/k8s-demo/my-nginx-pod-on-openebs.yaml](https://github.com/openebs/openebs/blob/master/k8s-demo/my-nginx-pod-on-openebs.yaml)\n\nThe next comparison of OpenEBS to AWS EBS is how the volume snapshots are managed for data protection.\n\n![](https://cdn-images-1.medium.com/max/800/1*elAnAeYarCwxeCEyXv_Xow.png)\n**Comparing snapshots management on OpenEBS to that of AWS EBS**  \n\nAs shown above, using OpenEBS, you will have a standard S3 snapshot upload capability so that you can choose your S3 provider. With on-premise S3 technologies like Minio, you can have the container backup infrastructure also as on-prem.\n\nOn the advanced features comparison, OpenEBS steps up to match AWS EBS. Granular QoS control, advanced IOPs management features such as using burst and credit IOPS are some of the features that will be home at OpenEBS\n\n![](https://cdn-images-1.medium.com/max/800/1*1WGi8-GdTamykwgnJ0lqjw.png)\n\nBuilding reliable storage platforms in open source is a hard thing. With all the expertise in serving for large enterprises, the team seems to be up for the challenge. We hope to see the incresing levels of community engagement in the months to come !!\n","slug":"using-openebs-to-build-a-true-onpremise-container-service"},{"id":39,"title":"Torus (from CoreOS) steps aside as Cloud Native Storage Platform. What now?","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"20-02-2017","tags":["DevOps"," Docker"," Storage Containers"," Kubernetes"],"excerpt":"Torus (from CoreOS), that aimed at providing container-native distributed storage announced that it would discontinue development due to lack of traction.","content":"\n[Torus (from CoreOS)](https://github.com/coreos/torus), that aimed at providing container-native distributed storage announced that it would discontinue development due to lack of traction. It just goes to show the dynamics of the OpenSource projects and how business needs could influence them.\n\nTorus attempted to solve one of the core infrastructure problems, and like any projects that aim to solve the infrastructure problems — compute, network or storage, are slightly harder problems to crack with only a handful of people really venturing into solving them. May be, this inertia is also due to the fact that, when infrastructure fails, hell breaks loose — we are all too familiar with those network outages and data loss situations where Database teams spend days recovering data.\n\nHarder problems require renewed focus, at least in the initial stages to get the product off the ground for the basic use case. The entry barrier must be minimal, if not totally absent. Once the core-value is established, in terms of ease of use or scale and just solving a problem in an intuitive way, it graduates into adoption phase.\n\nWith containers changing the landscape of applications, they pose additional set of requirements on the storage platform, which are covered in my earlier post — [Emerging Storage Trends for Containers](https://blog.openebs.io/emerging-storage-trends-for-containers-4970e4c51de#.ep5wl2u0z). *Any container-native storage platform developed today should be distributed and natively integrated into container orchestration platforms like Kubernetes.* Torus got these aspects right.\n\nWhile suspending further Torus development, I find it interesting that the committers at CoreOS mentioned Rook.\n\n[Rook](https://github.com/rook/rook), like [GlusterFS-container](https://github.com/gluster/gluster-containers), are not container-native, they provide wrapper projects that make it easy to deploy along side Kubernetes. In the short-term towards the journey of taking containers into production, this retro-fitting approach may be OK! If there is enough traction to refactor the existing projects (Ceph) as we move forward.\n\nBut as we saw with compute virtualization paving way for software defined storage, there is a need for container defined storage. PortWorx and OpenEBS alone currently come close to being container native storage platforms, built ground-up using containers by teams that have built enterprise and cloud storage platforms.\n\nOpenEBS is a distributed block storage that supports both hyper-converged and dedicated deployment models. However, the implementation of the block storage with OpenEBS follows a different approach for block replication ( forked out of [Rancher Longhorn](https://github.com/rancher/longhorn)), which optimizes the meta-data processing of the distributed blocks.\n\nOpenEBS also inherits the data protection capabilities, pushing backups onto Amazon S3. We are currently working on EBS like API for provisioning the storage from K8s. With its cloud integration capabilities, we envision the capabilities supported by OpenEBS to enable our customers to build On-prem container environments that are compatible to be moved into the Cloud and vice-versa.\n\nOpenEBS Storage is delivered through VSMs which are essentially containers — frontend and backend, that can be scheduled by Kubernetes along with the Application Pods. The storage specific parameters are fed into the scheduling algorithms through our OpenEBS storage orchestration layer — maya. This container mode of deployment also reduces the burden of managing separate storage network. The building blocks of the OpenEBS were covered in this post —[ OpenEBS building blocks](https://blog.openebs.io/openebs-building-blocks-rancher-longhorn-b8928b5921fa#.r7kzqlucd)\n\nIf you were planning to contribute to Torus or just interested in getting your hands dirty with container-native storage platform, please take a closer look at [OpenEBS](https://github.com/openebs/openebs), which is completely OpenSource.\n","slug":"torus-from-coreos-steps-aside-as-cloud-native-storage-platform-what-now"}]