[{"id":1,"title":"Deploying YugabyteDB on Google Kubernetes Engine with OpenEBS","author":"OPENEBS","author_info":"No author information","date":"05-04-2021","tags":["OpenEBS"," OpenSource"," Yugabyte"," Cloud Native Gke"],"excerpt":"In this blog post, we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.","content":"\n[OpenEBS](https://www.openebs.io/) is a CNCF project backed by [MayaData](https://mayadata.io/) that provides cloud-native, open source container attached storage (CAS). OpenEBS delivers persistent block storage and other capabilities such as integrated back-up, management of local and cloud disks, and more. For enterprise cloud-native applications, OpenEBS provides storage functionality that is idiomatic with cloud-native development environments, with granular storage policies and isolation that enable cloud developers and architects to optimize storage for specific workloads.\n\nBecause [YugabyteDB](https://www.yugabyte.com/) is a cloud-native, distributed SQL database that runs in Kubernetes environments, it can interoperate with OpenEBS and many other CNCF projects.\n\n***Wait, what is YugabyteDB?** It is an open source, and high-performance distributed SQL database built on a scalable and fault-tolerant design inspired by Google Spanner. Yugabyte’s YSQL API is PostgreSQL wire compatible.*\n\nIn this blog post we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\n\n**Why OpenEBS and YugabyteDB?**\nBecause YugabyteDB is a transactional database often used as a system of record, it needs to be deployed as a StatefulSet on Kubernetes and requires persistent storage. OpenEBS can be used for backing YugabyteDB local disks, allowing the provisioning of large-scale persistent volumes. \n\nHere are a few of the advantages of using OpenEBS in conjunction with a YugabyteDB database cluster:\n\n- There’s no need to manage the local disks as OpenEBS manages them.\n- OpenEBS and YugabyteDB can provision large size persistent volumes.\n- With OpenEBS persistent volumes, capacity can be thin provisioned, and disks can be added to OpenEBS on the fly without disruption of service. When this capability is combined with YugabyteDB, which already supports multi-TB data density per node, this can prove to be[ massive cost savings on storage.](https://docs.openebs.io/features.html#reduced-storage-tco-upto-50)\n- Both OpenEBS and YugabyteDB support multi-cloud deployments [helping organizations avoid cloud lock-in.](https://docs.openebs.io/docs/next/features.html#truely-cloud-native-storage-for-kubernetes)\n- Both OpenEBS and YugabyteDB integrate with another CNCF project, [Prometheus](https://prometheus.io/). This makes it easy to [monitor both storage and the database](https://docs.openebs.io/docs/next/features.html#prometheus-metrics-for-workload-tuning) from a single system.\n\nAdditionally, OpenEBS can do [synchronous replication](https://docs.openebs.io/docs/next/features.html#synchronous-replication) inside a geographic region. In a scenario where YugabyteDB is deployed across regions, and a node in any one region fails, YugaByteDB would have to rebuild this node with data from another region. This would incur cross-region traffic, which is more expensive and lower in performance. But, with OpenEBS, this rebuilding of a node can be done seamlessly because OpenEBS is replicating locally inside the region. This means YugabyteDB does not end up having to copy data from another region, which ends up being less expensive and higher in performance. In this deployment setup, only if the entire region failed, YugabyteDB would need to do a cross-region node rebuild. Additional detailed descriptions of OpenEBS enabled use cases can be found [here.](https://docs.openebs.io/docs/next/usecases.html)\n\nOk, let’s get started!\n\n**Prerequisites**\n![](/images/blog/yugabyte-work-flow.png)\n\n\nUsing the latest and greatest versions of the available software (as of this blog’s writing), below is the environment which we’ll use to run a YugabyteDB cluster on top of a Google Kubernetes Engine (GKE) cluster backed by OpenEBS\n\n1. YugabyteDB - [Version 2.5.3.1](https://docs.yugabyte.com/latest/quick-start/install/)\n2. OpenEBS - [Version 2.7.0](https://github.com/openebs/openebs)\n3. A [Google Cloud Platform](https://cloud.google.com/gcp/) account\n\n**Step 1: Setting Up a Cluster on GKE**\nTo deploy YugabyteDB on the Google Cloud Platform (GCP), we first have to set up a cluster using Ubuntu as our base node image.\n\n***Note**: GKE’s Container-Optimized OS does not come with an iSCSI client pre-installed and does not allow the installation of an iSCSI client. Therefore, we’ll be using the Ubuntu with Docker image type for our nodes.*\n\nFor the purposes of this demo, I used the Google Cloud Console to configure my Kubernetes cluster. Aside from the typical defaults, here’s the options under the* Node Pools > default-pool > Nodes*  I selected\n\n- **Image Type:** Ubuntu with Docker\n- **Series:** N1\n- **Machine Type: **n1-standard-4 (4 vCPU, 15 GB memory)\n\n![](/images/blog/yugabyte-nodes.png)\n\n\nClick *Create* and wait for the Kubernetes cluster to come online.\n\n**Step 2: Configure iSCSI**\nThe iSCSI client is a prerequisite for provisioning cStor and Jiva volumes. However, it is recommended that the iSCSI client is setup and* iscsid* service is running on worker nodes before proceeding with the OpenEBS installation. In order to set up iSCSI, we’ll first need to determine the names of the nodes in our cluster\n\n    $ kubectl get nodes\n    \n    NAME                                       \tSTATUS   ROLES    \tAGE   \tVERSION\n    gke-cluster-1-default-pool-be95f6dd-5x65  \tReady    <none>   \t18h   \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-rs6c  \tReady    <none>   \t18h \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-t4cp  \tReady    <none> \t18h  \tv1.18.15-gke.1501\n    \n    Now that we have the names of our nodes, we’ll want to log into each node and enable the iSCSI service.\n    \n    $ gcloud compute ssh <node name>\n    $ sudo systemctl enable iscsid && sudo systemctl start iscsid\n    \n    You can check the status of the iSCSI service using the following command:\n    \n    $ systemctl status iscsid\n    \n    iscsid.service - iSCSI initiator daemon (iscsid)\n       Loaded: loaded (/lib/systemd/system/iscsid.service; enabled; vendor preset: enabled)\n       Active: active (running) since Fri 2021-03-26 02:25:42 UTC; 18h ago\n         Docs: man:iscsid(8)\n      Process: 10052 ExecStart=/sbin/iscsid (code=exited, status=0/SUCCESS)\n      Process: 10038 ExecStartPre=/lib/open-iscsi/startup-checks.sh (code=exited, status=0/SUCCESS)\n     Main PID: 10059 (iscsid)\n        Tasks: 2 (limit: 4915)\n       CGroup: /system.slice/iscsid.service\n               ├─10057 /sbin/iscsid\n               └─10059 /sbin/iscsid\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Starting iSCSI initiator daemon (iscsid)...\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 iscsid[10052]: iSCSI logger with pid=10057 started!\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Started iSCSI initiator daemon (iscsid).\n    \n\n**Step 3: Install OpenEBS**\nNext, let’s install OpenEBS. I’ve found that the OpenEBS Operator is one of the simplest ways to get the software up and running.\n\n    $ kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml\n\nOnce the installation is completed, check and verify the status of the pods. You should something similar to this:\n\n    $ kubectl get pods -n openebs\n    \n    NAME                                            READY   STATUS    \n    maya-apiserver-dd655ff87-rbgmd                  1/1     Running  \n    openebs-admission-server-5965c94767-4h8rc       1/1     Running   \n    openebs-localpv-provisioner-5495669c66-z46lr    1/1     Running   \n    openebs-ndm-dss64                               1/1     Running  \n    openebs-ndm-gnv75                               1/1     Running   \n    openebs-ndm-operator-68949644b9-mqvlx           1/1     Running  \n    openebs-ndm-r5pws                               1/1     Running  \n    openebs-provisioner-544cb85449-w9spl            1/1     Running   \n    openebs-snapshot-operator-6d65b778dd-79zcn      2/2     Running \n\n**Step 4: Create and Attach Disks to Nodes**\nOur worker nodes need to have disks attached. These disks need to be unmounted and not have a filesystem on them. To accomplish this we’ll need to execute the following commands on each node.\n\n    $ gcloud compute disks create disk1 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-5x65 --disk disk1\n    \n    $ gcloud compute disks create disk2 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-rs6c --disk disk2\n    \n    $ gcloud compute disks create disk3 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-t4cp --disk disk3\n    \n    Next let’s verify that our block devices are indeed attached.\n    \n    $ kubectl get blockdevice -n openebs\n    \n    NAME              NODENAME                           SIZE          CLAIMSTATE   STATUS   \n    blockdevice-03... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    blockdevice-85... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active   \n    blockdevice-b0... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    \n\n**Step 5: Create a Storage Pool Claim**\nNow that we have the names of our block devices and have verified that they are active, the next step is to create a Storage Pool Claim. We’ll use this to then create a Storage Class, and finally use that for our Persistent Volume Claims. The first step in this chain of steps is to configure our Storage Pool Claim YAML file. In this demo, I’ve named it “cstor-pool1-config.yaml”.\n\n    $ vim cstor-pool1-config.yaml\n    \n    #Use the following YAMLs to create a cStor Storage Pool.\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-disk-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-disk-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n      blockDevices:\n        blockDeviceList:\n    - blockdevice-03e93d010db5169322eb16f3e18e33ed   \n    - blockdevice-22591882979084d0fe580fe229e0d84f   \n    - blockdevice-4d1b4bacbeec1650b337c2cfda7e3a48   \n    ---\n\n    Once you’ve figured out how to exit vim, the next step is to create the resource.\n    $ kubectl create -f cstor-pool1-config.yaml\n    \n    \n\nWe can verify our storage pool with the following command:\n\n    $ kubectl get csp\n    \n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE   \n    cstor-disk-pool-6cmf   1.85M       9.94G   9.94G      Healthy   false      striped\n    cstor-disk-pool-jql6   40.6M       9.90G   9.94G      Healthy   false      striped\n    cstor-disk-pool-vbz5   68.2M       9.87G   9.94G      Healthy   false      striped\n    \n\n**Step 6: Create a Storage Class**\nNow that we have a storage pool, let’s configure the YAML file for our storage class.  In this demo, I’ve named it “openebs-sc-rep1.yaml”.\n\n    $ vim openebs-sc-rep1.yaml\n    \n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-sc-rep1\n      annotations:\n        openebs.io/cas-type: cstor\n        cas.openebs.io/config: |\n          - name: StoragePoolClaim\n            value: \"cstor-disk-pool\"\n          - name: ReplicaCount\n            value: \"1\"\n    provisioner: openebs.io/provisioner-iscsi\n\nAssuming you have remembered how to exit vim from the previous step, we now need to create the storage class.\n\n    $ kubectl create -f openebs-sc-rep1.yaml\n\nFinally, let’s verify the storage class.\n\n    $ kubectl get sc\n    \n    NAME                  PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE \n    openebs-device        openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-hostpath      openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-jiva-default  openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-sc-rep1       openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-snapshot...   volumesnapshot.external...   Delete          Immediate\n    premium-rwo           pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n    standard (default)    kubernetes.io/gce-pd         Delete          Immediate\n    standard-rwo          pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n\nAt this point, we are now set up for Persistent Volume Claims.\n\n**Step 7: Install YugabyteDB**\n\nIn this final step we’ll install a 3 node YugabyteDB cluster running on top of GKE that will be backed by the OpenEBS deployment we just completed.\n\nThe first step is to create a namespace.\n\n*$ kubectl create namespace yb-demo*\n\nNext, let’s install the cluster using Helm.\n\n    $ helm install yb-demo yugabytedb/yugabyte --set resource.master.requests.cpu=1,resource.master.requests.memory=1Gi,\\\n    resource.tserver.requests.cpu=1,resource.tserver.requests.memory=1Gi,\\\n    enableLoadBalancer=True --namespace yb-demo  --set storage.master.storageClass=openebs-sc-rep1,storage.tserver.storageClass=openebs-sc-rep1 --set persistence.storageClass=openebs-cstor-disk --wait\n    \n\nNote that in the command above we are specifying the following so that YugabyteDB makes explicit use of OpenEBS:\n\n- *storage.master.storageClass=openebs-sc-rep1*\n- *storage.tserver.storageClass=openebs-sc-rep1*\n- *persistence.storageClass=openebs-cstor-disk*\n\nOnce the installation is complete you should be able log into the PostgreSQL compatible YSQL shell on port 5433 with the following command:\n\n    $ kubectl --namespace yb-demo exec -it yb-tserver-0 -- sh -c \"cd /home/yugabyte && ysqlsh -h yb-tserver-0\"\n    \n    ysqlsh (11.2-YB-2.5.3.1-b0)\n    Type \"help\" for help.\n    yugabyte=#\n    \n\nYou can also access the basic YugabyteDB web admin portal at:\n\n*http://<yb-master-ui-endpoint>:7000*\n\n![](/images/blog/yugabyte-master.png)\n\n**Viewing Services and Ingress**\nA quick and visual way to check out all the services and ingress is to go to the “Services and Ingress” view in the Google Cloud Console. If you’ve made it this far you should see something like this:\n\n![](/images/blog/yugabyte-ingress.png)\n\nNote: I have omitted the “Endpoints” column from the screenshot above, but in your view you’ll be able to see the IPs and ports of the various endpoints.\n\nThat’s it! You now have a 3 node YugabyteDB cluster running on GKE with OpenEBS storage.\n\n**Next Steps**\nAs mentioned, MayData is the chief sponsor of the OpenEBS project. It offers an enterprise-grade OpenEBS platform that makes it easier to run stateful applications on Kubernetes by helping get your workloads provisioned, backed-up, monitored, logged, managed, tested, and even migrated across clusters and clouds. You can learn more about MayaData [here.](https://mayadata.io/)\n\n- Learn more about OpenEBS by visiting the [GitHub](https://github.com/openebs/openebs) and [official Docs](https://docs.openebs.io/) pages.\n- Learn more about YugabyteDB by visiting the [GitHub](https://github.com/yugabyte/yugabyte-db) and [official Docs](https://docs.yugabyte.com/) pages.\n\n****About the author:****\n\n![Jimmy Guerrero](/images/blog/authors/jimmy-guerrero.png)\n\nJimmy Guerrero, VP Marketing, and Community at YugaByte.\n","slug":"deploying-yugabytedb-on-google-kubernetes-engine-with-openebs"},{"id":2,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks","author":"OPENEBS","author_info":"No author information","date":"22-03-2021","tags":["Mayastor","OpenEBS"],"excerpt":"Learn about Repeatable OpenEBS Mayastor deployments and benchmarks","content":"\n## Introduction\n\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\n\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\n\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\n\n\n## OpenEBS\n\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\n\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\n\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\n\n\n## OpenEBS Mayastor\n\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\n\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\n\n\n## Introducing: the Automation Playground\n\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\n\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\n\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\n\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\n\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars\n\n\n## Stages\n\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\n\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\n\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\n\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\n\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\n\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\n\n\n#### Stage 1: Provisioning\n\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\n\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\n\nThe nodes provisioned are of three varieties\n\n* Master nodes (for Kubernetes Masters)\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\n\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\n\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\n\n#### Stage 2: Start VPN\n\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\n\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\n\n#### Stage 3: Kubernetes setup\n\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\n\nCurrently two installation types are supported with more planned:\n\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\n\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\n\n#### Stage 4: Node preparation\n\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\n\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\n\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\n\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\n\n## Playbooks\n\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\n\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\n\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\n\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\n\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\n\n## Conclusion\n\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\n\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\n\nPlease visit us at https://mayadata.io and give the Demo Playground a spin at https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground.\n\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":3,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"12-03-2021","tags":["Localpv"," OpenEBS"," Flipkart"," TikTok"," Kubernetes"," Mayastor"," MayaData"],"excerpt":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","content":"\n**How to select the right local volume for your workloads?**\n\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\n\n![kg-image](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\n\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: https://github.com/openebs/openebs/blob/master/ADOPTERS.md.\n\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\n\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\n\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\n\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\n\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\n\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\n\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\n\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:\n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\n\n## Limitations of Kubernetes LocalPV\n\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\n\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\n\nWe have seen that cluster administrators are challenged by the following aspects:\n\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\n\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\n* Nodes have 8 to 16 high-performing NVMe SSDs.\n\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\n\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\n\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\n\n* Enforcing Capacity Limits/Thresholds\n* Securing the Volumes\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\n* Encrypting the Volumes\n* Enforce compliance with BCP by taking regular snapshots and full backups\n\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\n\n## Selecting your LocalPV\n\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\n\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\n\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\n\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\n\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\n\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\n\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: https://github.com/openebs/openebs/blob/master/ADOPTERS.md","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":4,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"13-01-2021","tags":["OpenEBS"],"excerpt":"Read about OpenEBS NDM, the go-to solution for managing Kubernetes Local Storage.","content":"\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\n\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\n\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\n\n## Key Storage Problems solved by NDM\n\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\n* Cluster-wide storage visibility\n* Detect the movement of storage devices across nodes\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\n\n## Getting Started with NDM\n\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\n\nMaster: 2 virtual disks\n\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\n\nWorker 2: 4 physical disks\n\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\n    ```\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml\n    ```\n    (The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\n\n* Once deployed, check the blockdevices present in the cluster using\n    ```\n    kubectl get bd -n openebs -o wide\n    ```\n    Some block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\n\n* Deploy a sample application to use the block device\n\n    Download the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\n    ```\n    kubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\n    ```\n    Now check the status of block devices again\n\n    We can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\n\n* Pool movement across nodes\n\n  NDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\n\n* Reserving storage for workloads\n\n  NDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\n\n## Future Roadmap\n\n* Southbound provisioning\n* Metrics (currently in alpha)\n* API Service to interact with NDM\n* Ability to create partitions or LVM volume groups - preparing storage in general.\n\n## Interested in Contributing to NDM?\n\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":5,"title":"Storage is Evolving!","author":"Nick Connolly","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.","date":"11-12-2020","tags":["OpenEBS"],"excerpt":"Learn how storage has evolved over the years. ","content":"\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\n\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\n\n## The hardware environment is changing!\n\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\n\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\n\n## Application development is changing!\n\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\n\n## A New Era\n\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\n\n## Container Attached Storage\n\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\n\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\n\n## Microsoft Windows\n\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not supported on Windows’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\n\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\n\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\n\n## Windows Platform Development Kit\n\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\n\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\n\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\n\n1. Enable high-performance access to NVMe storage directly from applications.\n2. Native software defined storage stacks, including OpenEBS Mayastor.\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\n\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to https://wpdk.github.io or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":6,"title":"OpenEBS on DigitalOcean Marketplace","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"3-12-2020","tags":["OpenEBS","chaosengineering","tutorials"],"excerpt":"Learn how to deploy OpenEBS on the DigitalOcean marketplace","content":"\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\n\nWORKFLOW:\n\nSTEP 1: Getting started\nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\n\nSTEP 2: Creation of cluster\nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\n\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\n\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\n\nSTEP 3: Connecting your cluster\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\n\nTo verify, execute the following command:\n\n```$ kubectl get ns```\n\nOutput:\n```\nNAME     STATUS    AGE\ndefault  Active    13m\nopenebs  Active    13m\n```\nThe output must contain openebs ns in an Active state.\n\nNext, execute:\n\n```$ kubectl get pods -n openebs```\n\nOutput:\n```\nNAME                                                 READY     STATUS    RESTARTS AGE\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\nopenebs-ndm-74njq                                    1/1       Running   0        13m\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\nopenebs-ndm-spttv                                    1/1       Running   0        13m\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\n```\nAll the pods must be in a running state.\n\nSTEP 4: Attaching BlockDevices\nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\n\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\n\nNOTE:\n\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\n\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\n\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\n\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":7,"title":"Atlassian Jira Deployment on OpenEBS","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"20-11-2020","tags":["OpenEBS"],"excerpt":"Learn how to deploy Atlassian Jira on OpenEBS in this short post.","content":"\n**Jira** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, Jira has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\n\n## Requirements\n\n#### Install OpenEBS\n\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\n\n#### Configure cStor Pool\n\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\n\n```\n#Use the following YAMLs to create a cStor Storage Pool.\n# and associated storage class.\napiVersion: openebs.io/v1alpha1\nkind: StoragePoolClaim\nmetadata:\n  name: cstor-disk\nspec:\n  name: cstor-disk\n  type: disk\n  poolSpec:\n    poolType: striped\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\n  #\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\n  # as the disk operator\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\n# Uncomment the below lines after updating the actual disk names.\n  blockDevices:\n    blockDeviceList:\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n---\n```\n\n#### Create Storage Class\n\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: openebs-cstor-disk\n  annotations:\n    openebs.io/cas-type: cstor\n    cas.openebs.io/config: |\n      - name: StoragePoolClaim\n        value: \"cstor-disk\"\n      - name: ReplicaCount\n        value: \"3\"       \nprovisioner: openebs.io/provisioner-iscsi\nreclaimPolicy: Delete\n```\n\n### Deployment of Jira\n\nSample Jira Yaml:\n\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: jira\n      name: jira\n    spec:\n      containers:\n        - name: jira\n          image: \"doriftoshoes/jira:7.3.6\"\n          resources:\n            requests:\n              cpu: \"2\"\n              memory: \"2G\"\n          volumeMounts:\n            - name: \"jira-home\"\n              mountPath: /opt/jira-home\n      volumes:\n        - name: jira-home\n          persistentVolumeClaim:\n            claimName: demo-vol1-claim\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  ports:\n    - port: 8080\n      targetPort: 8080\n  selector:\n    app: jira\n  type: LoadBalancer\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: demo-vol1-claim\nspec:\n  storageClassName: openebs-cstor-disk\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10G\n```\n\nNext, apply both the **Jira deployment** and service to your Kubernetes cluster.\n\n```kubectl apply -f jira.yaml```\n\n#### Verify Jira Pods:\n\n#### Run the following to get the status of Jira pods:\n\n```kubectl get pods```\n\nFollowing is an example output:\n\n```\nNAME                    READY   STATUS    RESTARTS   AGE\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\n```\n\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":8,"title":"Mayastor NVMe-oF TCP performance","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"19-11-2020","tags":["Mayastor"],"excerpt":"Overview of using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known.","content":"\nFor a while now, we have been saying that OpenEBS Mayastor is “high” performance and community members have written [blogs](https://medium.com/volterra-io/kubernetes-storage-performance-comparison-v2-2020-updated-1c0b69f0dcf4) showing that the performance of OpenEBS Mayastor indeed is much better or on par with others even when running on relatively slow cloud volumes. However, is Mayastor high performance or just “as fast” as the other things out there? \n\nIt used to be the case that CPUs were much faster than the storage systems they served. With modern NVMe, this does not ***have*** to be the case anymore. NVMe is a ***protocol*** that can go fast but does not have to be fast. What this means is that you can use NVMe as your transport protocol for any block device, not just flash. Yes, this is what Mayastor does. It is really useful to keep in mind the distinction between NVMe as a protocol and NVMe devices - you don’t need to use them together but, when you do, additional performance can be unlocked.\n\nIn this blog, we will be using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known. We will show what happens when you marry NVMe as a protocol (embedded within Mayastor) and fast NVMe devices from our friends at Intel.\n\nBefore we get started, you might wonder how we came to this point that a new project like OpenEBS Mayastor was able to deliver amongst the fastest storage available today. Richard Elling of Viking / Sanmina recently wrote an excellent blog on the trends in hardware design that puts NVMe and OpenEBS Mayastor into context:  [https://richardelling.substack.com/p/the-pendulum-swings-hard-towards](https://richardelling.substack.com/p/the-pendulum-swings-hard-towards)\n\n## Hardware setup\n\nLet’s get to it. We will be using three machines that will run kernel version 5.8. The hardware configuration of each host is as follows:\n\n- Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz\n- Intel Corporation NVMe Datacenter SSD [Optane]\n- Mellanox Technologies MT28908 Family [ConnectX-6]\n\n## Baseline performance\n\nTo understand the performance of the device we will be using throughout the test, we run the following Fio workload:\n\n    [global]\n    ioengine=linuxaio\n    thread=1\n    group_reporting=1\n    direct=1\n    norandommap=1\n    bs=4k\n    numjobs=8\n    time_based=1\n    ramp_time=0\n    runtime=300\n    iodepth=64\n    \n    \n    [random-read-QD64]\n    filename=/dev/nvme1n1\n    rw=randread\n    stonewall\n    \n    \n    [random-write-QD64]\n    filename=/dev/nvme1n1\n    rw=randwrite\n    stonewall\n    \n    \n    [random-rw-QD64]\n    filename=/dev/nvme1n1\n    rw=randrw\n    stonewall\n\n![](/images/blog/mayastor-nvme1.png)\nThese numbers are incredibly high and are provided by a ***single*** device. Note that the benchmark itself is rather synthetic in the sense that, in practice, no workload is 100% random.\n\n## High-level overview of the experiments\n\nMy approach in this benchmarking is very much OpenEBS Mayastor “the hard way”.  If you want an easier to use solution that for example automates pool creation and device selection and so on - we call that offering Kubera Propel (also open source btw). You can learn more about Kubera Propel on the [MayaData.io](https://mayadata.io/) website.    \n\nOn two of the nodes, we create a pool (MSP CRD) which we use in the control plane to determine replica placement. To construct pools, we must have what we call a persistence layer. We support several ways to access this persistence layer. To select a particular scheme we use URIs. In this case we will be using today the pcie:/// scheme. This means that Mayastor will directly write into the NVMe devices listed above. The nice thing is that from the user perspective, things do not change that much. We simply replace disks: [‘/dev/nvme0n1’] with disks: [‘pcie:///80:00.0’]. Note that this persistence layer is used to store the replicas of the PVC. Once we have this layer up and running, we will create storage classes and select that we want to use nvmf (NVMe-oF) as the transport layer between the replicas, resulting in NVMe all the way through. \n\nAfter we have deployed mayastor we applied to following two storage classes:\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf\n    parameters:\n      repl: '1'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n    ---\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf-mirror\n    parameters:\n      repl: '2'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n\nNote that `protocol: `nvmf` is just a shorthand for the NVMe-oF format mentioned above. We will be using both storage classes to run a single replica followed by a two way replica AKA mirror.  We use the following YAML to create the volume.\n\n    apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: ms-volume-claim\n    spec:\n      accessModes:\n       - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100G\n      storageClassName: nvmf\n\nAfter creating the PVC, Mayastor’s control plane creates a CRD, “Mayastor Volume” (MSV), that contains additional information about the corresponding volume.  Using kubectl describe msv -n mayastor we get:\n\n    Name:         ba081dc3-46db-445b-969c-7e5245aba146\n    Namespace:    mayastor\n    Labels:       <none>\n    Annotations:  <none>\n    API Version:  openebs.io/v1alpha1\n    Kind:         MayastorVolume\n    Metadata:\n      Creation Timestamp:  2020-09-11T08:49:30Z\n      Generation:          1\n      Managed Fields:\n        API Version:  openebs.io/v1alpha1\n        Fields Type:  FieldsV1\n        fieldsV1:\n          f:spec:\n            .:\n            f:limitBytes:\n            f:preferredNodes:\n            f:replicaCount:\n            f:requiredBytes:\n            f:requiredNodes:\n          f:status:\n            .:\n            f:nexus:\n              .:\n              f:children:\n              f:deviceUri:\n              f:state:\n            f:node:\n            f:reason:\n            f:replicas:\n            f:size:\n            f:state:\n        Manager:         unknown\n        Operation:       Update\n        Time:            2020-09-11T08:51:18Z\n      Resource Version:  56571\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/mayastor/mayastorvolumes/ba081dc3-46db-445b-969c-7e5245aba146\n      UID:               94e11d58-fed9-44c9-9368-95b6f0712ddf\n    Spec:\n      Limit Bytes:  0\n      Preferred Nodes:\n      Replica Count:   1\n      Required Bytes:  100000000000\n      Required Nodes:\n    Status:\n      Nexus:\n        Children:\n          State:     CHILD_ONLINE\n          Uri:       bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n        Device Uri:  nvmf://x.y.z.y:8420/nqn.2019-05.io.openebs:nexus-ba081dc3-46db-445b-969c-7e5245aba146\n        State:       NEXUS_ONLINE\n      Node:          atsnode3\n      Reason:\n      Replicas:\n        Node:     node3\n        Offline:  false\n        Pool:     pool-atsnode3\n        Uri:      bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n      Size:       100000000000\n      State:      healthy\n    Events:       <none>\n\n## Results single replica\n![](/images/blog/mayastor-nvme2.png)![Chart](https://lh5.googleusercontent.com/whpgDl_Id_oo4tUdl7RZDv-C1Uq2ZfvM6Eh7KXbwNkNTu5Mki14meunBgF1PMWMnWLoccSGgHqCfRKXgQpJTfQG42NaS0GkwWRCuNpWGh7znOhqQ94aJXiCODJkzNUs9-G2ucqMJ)\nFrom the results we can see that we are very close to the performance of the local device. To be sure we can put it in the right perspective, the difference between the experiments here is that with the baseline, the workload was local. With repl=1 we use the same NVMe device but export it through our pool layer (and thus provide volume management), but also go over the network.\n\n## Results 2 replicas (mirror)\n\nWe are going to repeat the same test, this time, we will use two replicas. As we now have double the disks bandwidth, we expect to see that the read performance will go up. For writes, however, we actually expect a drop in performance, because we must do each write to both disks before we can acknowledge the IO.  Note that Mayastor does not cache - if you read the blog referenced above from Richard Elling you can learn why caching seems to be falling out of favor for use cases in which millions of IOPS are desired.\n![](/images/blog/mayastor-nvme3.png)![Chart](https://lh4.googleusercontent.com/GJ7c_cZ6vuDxd9-jAnU3XxAc8L0idA9sscz2JB5XVa0taj8v56H6MSIFB56XqPQzQsy_p49-yHlwhCB8SVjZ05YfT0oRdlFt0EMBze1IDrCioqWgtWypidK9fBpb9p3ULI19Dhfa)\n## Wrapup\n\nWith the above experiments, we have demonstrated that with OpenEBS Mayastor we have built a foundational layer that allows us to abstract storage in a way that Kubernetes abstracts compute. While doing so, the user can focus on what's important -- deploying and operating stateful workloads. \n\nIf you’re interested in trying out Mayastor for yourself, instructions for how to setup your own cluster, and run a benchmark like **fio** may be found at [mayastor.gitbook.io/](https://mayastor.gitbook.io/introduction/).\n\nAnd if you are a Kubera Propel user, you’ll find that we’ve productized some of the benchmarking above so that platform teams and other users can programmatically use benchmarks in their decisions about workload placement. We are working with a number of users about operating OpenEBS Mayastor / Kubera Propel at scale. Please get in touch if you have suggestions, feedback, ideas for interesting use cases and so on. Contributions of all kinds are welcome!\n","slug":"mayastor-nvmeof-tcp-performance"},{"id":9,"title":"Mayastor Engine Reaches Beta","author":"Glenn Bullingham","author_info":"Director of Solution Architecture","date":"19-11-2020","tags":["OpenEBS"],"excerpt":"Mayastor, the storage engine by OpenEBS has reached the beta stage. Read the blog to know more.","content":"\ntitle: Mayastor Engine Reaches Beta\nAs I write this, it is early November, and the winds of change are blowing. The United States has a new president. Here in the United Kingdom, Keats' days of mists and mellow fruitfulness are departing, replaced by a low sun and the first morning frosts. And at MayaData, we see the Mayastor project carefully but tenaciously emerging from alpha/pre-release into its beta phase. In fact, Mayastor now undergirds MayaData’s commercial offering for performance sensitive containerized workloads, called [Kubera Propel](https://mayadata.io/product).\n\n> ***“Beta Software: Software considered to be feature complete and substantially free of known major defects”***\n\nSignificant contributions over the past 18 months have seen the project raised from concept to working software. A major requirement of our MVP specification is that it should carry minimal performance overhead; Mayastor is intended to satisfy demands for performance at all levels of scale. At the beginning of Autumn, working in conjunction with Intel’s labs in the UK, we were able to validate that assertion; deployed in conjunction with the latest generation of Optane NVMe devices, the Mayastor data plane was found to introduce less than 6% overhead; you can read more about that benchmarking [here](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/). Having addressed that performance criteria and the other principle MVP requirements, the Mayastor team at MayaData has begun to focus its contributions to the project on QA as we approach Beta and GA releases.\n\nIn particular, we’ve greatly increased end-to-end test coverage on Kubernetes. How MayaData tests Mayastor is something that I’ll elaborate upon in a forthcoming post.  However, suffice it to say customary suspects feature (Jenkins, mocha, nix, cargo test), whilst we’re also collaborating with our colleagues who maintain the [Litmus Chaos](https://litmuschaos.io/) project. By the time that you’re likely reading this, Mayastor-specific chaos tests should be available to all on [ChaosHub](https://hub.litmuschaos.io/).\n\n## Ease of Use, Perf, and Availability\n\nMayastor MVP requirements center on ease of use, performance, and availability. In the Beta phase and subsequent GA release, these will be realized as a CAS platform with full NVMe data path semantics, declarative configuration via CSI compliant dynamic provisioning, and N+1 synchronous mirroring of data at the persistent layer. This closely approaches functional parity with the current OpenEBS storage engines (cStor, Jiva, and Local PV), with snapshot and cloning functionality to be added in Q1 2021. Mayastor will also very soon be the recipient of a streamlined deployment and configuration experience, which is exclusive to this engine.\n\n## Try it Yourself\n\nIf you’re a member of the Kubernetes community looking to implement a platform-native storage solution in the new year, now is an ideal time to start evaluating Mayastor. The other venerable and respected engines of OpenEBS won’t be retiring overnight, but as full feature parity emerges, MayaData’s commercial products and services will on Mayastor as their default storage engine; we do recognize that some users will continue to prefer various flavors of Dynamic Local PV from OpenEBS - as a recent [blog](https://www.percona.com/blog/2020/10/01/deploying-percona-kubernetes-operators-with-openebs-local-storage/) from the CTO of Percona attests as do countless [Adopter.md case studies](https://github.com/openebs/openebs/blob/master/ADOPTERS.md) including that of the SaaS company Optoro, also a CNCF case study. Mayastor’s roadmap includes provisions for the inward migration of existing OpenEBS users. It’s an equally opportune moment to [consider becoming a contributor](https://github.com/openebs/Mayastor/issues/new/choose) to the project yourself.\n\nTo help with Mayastor onboarding as we prepare to go to full steam, we’re putting together a new documentation site over at[ GitBook](https://mayastor.gitbook.io/introduction/), which includes a comprehensive quick-start deployment guide (developer docs will remain, at least for now, with the OpenEBS/Mayastor GitHub repository). We’re also holding [Office Hours at Kubecon NA 2020 this month](https://kccncna20.sched.com/?searchstring=OpenEBS&amp;iframe=no&amp;w=&amp;sidebar=&amp;bg=), and we’d love to see you there.\n\nIf you’d like to try Mayastor from the source - you can do so, of course, from the GitHub repositories. If you’d like to also try out management utilities, including a cool management interface and available 24x7 support - please take a look at [Kubera Propel](https://go.mayadata.io/register-for-kubera-chaos-and-propel-technical-preview). A free forever for individual use tier is available.\n\n## Conclusion\n\nIt is a propitious time for MayaData and Mayastor - and for data on Kubernetes more broadly. If you have always wanted to run workloads on Kubernetes but were put off by the stories of performance challenges, you can now move forward with confidence. Kubernetes enabled storage with the help of Mayastor performs faster than that of traditional shared everything storage while retaining the ease of use, open source community, and Kubernetes semantics for which OpenEBS has become famous.\n","slug":"mayastor-engine-reaches-beta"},{"id":10,"title":"Migrate CSPIs to a different node by moving the disks","author":"Sai Chaithanya","author_info":"A developer who is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate about Data Science. Enjoys playing kabaddi and traveling.","date":"04-11-2020","tags":["OpenEBS"],"excerpt":"Step by step guide to migrate CStorPoolInstances from one node to different nodes by moving the set of underlying disks","content":"\n\nThis blog describes steps to migrate CStorPoolInstances from one node to different nodes by **moving the set of underlying disks to a new node that participates in the pool provisioning**. There were a couple of use cases where this feature can be helpful:\n\n1. Scaling down and scaling up nodes in the cluster(in a cloud environment) by retaining external volumes(for cost savings).\n2. Replacing failed storage nodes with new nodes by attaching the same old disks to the new node.\n\n**Steps to migrate the CSPI to different node:**\n\n1. Detach the disks belonging to the CSPI that you wish to migrate from the node and attach it to the new node. If you are using a cloud platform, check on their documentation, or ask the administrator about the steps to do this.\n2. Change the node selector in the CSPC YAML (next section describes how to do this).\n\n![](https://lh4.googleusercontent.com/XTwKu6lE3lyoZ3cHRO9HNJGUaTOoGfE-OWGuscrmukbxEKJNPSaEqxUPbbNnnc3dcD-Aybc2_AF0y2Scf0QBxSDG_f9QZWRu67sXZjoMKO6nymhgelEWfDzPjfGKi4D9UwLBaN0D)\n\n**Existing setup**:\n\nI have a three-node cluster with CSPC and CSI volumes already provisioned(To create CSPC pools and CSI volume click [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md#quickstart)). Here is detailed information:\n\n**Cluster details**:\n\n    Kubernetes Cluster: AWS\n    Kubernetes Version: v1.15.9\n    OpenEBS Version: 2.2.0 \n\n****Node and BlockDevice details**: **Attached three disks to three nodes(each node has one disk)\n\n    Kubectl get nodes\n    \n    NAME                STATUS   ROLES    AGE   VERSION\n    ip-192-168-29-151   Ready    <none>   16m   v1.15.9\n    ip-192-168-36-89    Ready    <none>   8h    v1.15.9\n    ip-192-168-74-129   Ready    <none>   8h    v1.15.9\n    \n    Kubectl get bd -n openebs\n    NAME                                           NODENAME          SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-36-89  10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-74-129 10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-29-151 10737418240   Claimed      Active\n\n****CSPC Manifest**: **Applied following CSPC manifest to provision cStor pools\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-74-129\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-36-89\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-29-151\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nAfter applying the above CSPC manifest, the following three CStorPoolInstances(CSPI) were created.\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-74-129 24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-36-89  24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-29-151   24100M   24113200k   false     ONLINE   8h\n\nNow everything looks good. After some time, the cluster has been scaled down **0** nodes and scaled back to **3** nodes. So after scaling operations following are new nodes in the cluster.\n\n    Kubectl get nodes\n    \n    NAME               STATUS   ROLES    AGE     VERSION\n    ip-192-168-14-90   Ready    <none>   118s    v1.15.9\n    ip-192-168-49-43   Ready    <none>   5m55s   v1.15.9\n    ip-192-168-94-113  Ready    <none>   4m6s    v1.15.9\n\nAttached old disks that participated in pool creation to new nodes, and the following is blockdevice output.\n\n    Kubectl get bd -n openebs\n    \n    NAME                                           NODENAME            SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-49-43    10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-94-113   10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-14-90    10737418240   Claimed      Active\n\nFrom the above and previous output following are blockdevice mappings with zn old node and new node:\n\n    Blockdevice  Name                                    Old Node            New Node \n    blockdevice-7d311a98255a454a717427b5c2d38426    ip-192-168-36-89        ip-192-168-49-43\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b    ip-192-168-74-129       ip-192-168-94-113\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3    ip-192-168-29-151       ip-192-168-14-90\n\nOpenEBS **NodeDiskManager**(NDM) will automatically update the details in blockdevice CRs when the disks migrate to a new node. Based on the above output, update the CSPC manifest with new **nodeSelector** values.\n\n****Updated CSPC Manifest**:**\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-94-113\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-49-43\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-14-90\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nOnce the CSPC manifest is updated then CSPIs will automatically migrate to the new node (which can be verified using ****kubectl get cspi -n openebs****).\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-94-113   24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-49-43    24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-14-90    24100M   24113200k   false     ONLINE   8h\n\n**Note:** Along with CStorPoolInstance migration, CStorVolumeReplicas belongs to CSPI will also migrate automatically.\n","slug":"migrate-cspis-to-a-different-node-by-moving-the-disks"},{"id":11,"title":"OpenEBS Backup/Restore for ZFS-LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"27-10-2020","tags":["OpenEBS"],"excerpt":"Overview of how to use Velero Backup/Restore plugin for ZFS-LocalPV to protect it against data loss.","content":"\n## Overview: OpenEBS Backup/Restore for ZFS-LocalPV\n\n**Backup** is the process of copying the data to a different/remote location to protect against accidental or corruption or any other type of data loss. Restore is the process of getting back the data from the backup. In this blog, I will discuss how we can use *Velero Backup/Restore* plugin for ***ZFS-LocalPV*** to protect it against data loss.\n\n### Pre-requisites\n\nWe should have installed the ZFS-LocalPV 1.0.0 or later version for Backup and Restore, see my previous[ blog](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d) for the steps to install the ZFS-LocalPV driver.\n\n### Setup\n\n**1.Install Velero CLI**\n\nDownload the 1.5 or later binary for ZFS-LocalPV. For Linux on amd64, we need to download below\n\n    wget\n    https://github.com/vmware-tanzu/velero/releases/download/v1.5.1/velero-v1.5.1-linux-amd64.tar.gz\n\nExtract the tarball:\n\n    tar -xvf velero-v1.5.1-linux-amd64.tar.gz\n\nMove the extracted velero binary to somewhere in your $PATH (/usr/local/bin for most users).\n\nSee the detailed steps[ here](https://velero.io/docs/v1.5/basic-install/).\n\n**2.Deploy Velero**\n\nWe will be using minio for storage purpose in this blog, we need to setup the credential file first\n\n    $ cat /home/pawan/velero/credentials-minio\n    [default]\n    aws_access_key_id = minio\n    aws_secret_access_key = minio123\n\nWe can install Velero by using below command\n\n    $ velero install --provider aws --bucket velero --secret-file /home/pawan/velero/credentials-minio --plugins velero/velero-plugin-for-aws:v1.0.0-beta.1 --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://minio.velero.svc:9000 --use-volume-snapshots=true --use-restic\n\nWe have to install the velero 1.5 or later version of velero for ZFS-LocalPV.\n\n**3.Deploy MinIO**\n\nDeploy the MinIO for storing the backup:-\n\n    $ kubectl apply -f\n    https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/sample/minio.yaml\n\nThe above MinIO uses tmp directory inside the pod to store the data for the demonstration purpose, so when restart happens, the backed up data will be gone. We should change the above YAML to use persistence storage to store the data when deploying it for the production.\n\nCheck the Velero Pods are UP and Running\n\n    $ kubectl get po -n velero\n    NAME                      READY   STATUS      RESTARTS   AGE\n    minio-d787f4bf7-xqmq5     1/1     Running     0          8s\n    minio-setup-prln8         0/1     Completed   0          8s\n    restic-4kx8l              1/1     Running     0          69s\n    restic-g5zq9              1/1     Running     0          69s\n    restic-k7k4s              1/1     Running     0          69s\n    velero-7d9c448bc5-j424s   1/1     Running     3          69s\n\n**4.Setup OpenEBS Plugin**\n\nWe can Install the Velero Plugin for ZFS-LocalPV using the below command\n\n    velero plugin add openebs/velero-plugin:2.2.0\n\nWe have to install the velero-plugin 2.2.0 or later version, which has the support for ZFS-LocalPV. Once the setup is done, we can go ahead and create the backup/restore.\n\n**5.Create the VSL**\n\nThe VSL(Volume Snapshot Location) has information about where the snapshot should be stored. To create the Backup/Restore, we can create the Volume Snapshot Location by applying the below YAML:\n\n    apiVersion: velero.io/v1\n    kind: VolumeSnapshotLocation\n    metadata:\n     name: default\n     namespace: velero\n    spec:\n     provider: openebs.io/zfspv-blockstore\n     config:\n       bucket: velero\n       prefix: zfs\n       namespace: openebs # this is the namespace where ZFS-LocalPV creates all the CRs, passed as OPENEBS_NAMESPACE env in the ZFS-LocalPV deployment\n       provider: aws\n       region: minio\n       s3ForcePathStyle: \"true\"\n       s3Url: http://minio.velero.svc:9000\n\nHere, we have to provide the namespace, which we have used as OPENEBS_NAMESPACE env while deploying the ZFS-LocalPV. The ZFS-LocalPV Operator yamls uses “openebs” as the default value for OPENEBS_NAMESPACE env. Verify the volumesnapshot location:\n\n    kubectl get volumesnapshotlocations.velero.io -n velero\n\n### Create Backup\n\nWe can use the below Velero command to create the backup:\n\n    velero backup create my-backup --snapshot-volumes --include-namespaces=<backup-namespace> --volume-snapshot-locations=default --storage-location=default\n\nwe can add all the namespaces we want to be backed up in a comma-separated format in --include-namespaces parameter. We have to provide the VSL that we have created in --volume-snapshot-locations parameter.\n\nWe can check the backup status using the velero backup get command:\n\n    $ velero backup get\n    NAME        STATUS       CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR\n    my-backup   InProgress   2020-09-14 21:09:06 +0530 IST   29d       default            <none>\n\nThe status InProgress means that the backup is in progress. Wait for it to be Completed.\n\nWe can also create a scheduled backup which will take the backup periodically. For example, to take the full backup at every 5 min, we can create the below schedule :\n\n    velero create schedule schd --schedule=\"*/5 * * * *\" --snapshot-volumes --include-namespaces=<backup-namespace1>,<backup-namespace2> --volume-snapshot-locations=default --storage-location=default\n\n### Restore\n\nIf the application and its PVC has been deployed in a namespace, then we can use the below Velero command to create the backup of the entire namespace:\n\n    velero restore create --from-backup my-backup --restore-volumes=true --namespace-mappings <source-ns>:<dest-ns>\n\nThe above command will create the backup of everything that is there in the namespace provided as --include-namespaces argument. We can provide the namespace mapping if we want to restore in a different namespace as --namespace-mappings parameter. If namespace mappings are not provided, it will restore in the source namespace only where the original pod and pvc was present. Now we can check the restore status:\n\n    $ velero restore get\n    NAME                       BACKUP      STATUS       WARNINGS   ERRORS   CREATED                         SELECTOR\n    my-backup-20200914211331   my-backup   InProgress   0          0        2020-09-14 21:13:31 +0530 IST   <none>\n\nOnce the Status is Completed, we can check the pods in the destination namespace and verify that everything is up and running. We can also verify that the data has been restored.\n\n### Summary\n\nAs demonstrated in this blog, OpenEBS makes it easy to take the backup of the Kubernetes applications, which we can use to Restore as part of disaster recovery. In my next blog, I will talk about how we can take the incremental backup of the volumes, which is space optimized backup for ZFS-LocalPV\n\n## Important links\n\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n[https://velero.io/docs/](https://velero.io/docs/v1.5/basic-install/)\n","slug":"openebs-backuprestore-for-zfslocalpv"},{"id":12,"title":"OpenEBS 2.2.0 - Enhancements And New Storage Capabilities","author":"Ashutosh Kumar","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut","date":"20-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS 2.2.0 is here! Read this post to learn about the new updates.","content":"\n### **OpenEBS 2.2.0 is here**\n\nWe are excited to announce yet another ***OpenEBS*** release that comes with new storage capabilities, control plane enhancements, bug fixes, and new APIs for the world’s fastest storage engine built on RUST, also known as Mayastor.\n\nOpenEBS has seen a wider adoption among the users, thanks to the vibrant and growing community. Like in most of the OpenEBS releases, this release responds to the feedback received in the community. If you want to learn more about the project roadmap, please browse the following link:\n[https://github.com/openebs/openebs/blob/master/ROADMAP.md](https://github.com/openebs/openebs/blob/master/ROADMAP.md)\n\nIncremental Backup and Restore in ZFS local PV and pool and volume migration in cStor are the major release milestones made into the release. The pool migration in cStor solves the use-case of replacing a bad node with a new node or sending a node for maintenance on on-premise clusters. The migration feature provides great value in cloud-managed Kubernetes clusters, too, e.g., GKE, where node reboots or voluntary scale down of nodes can cause the disks to get removed. \n\nThis release is also special due to the [*Hacktoberfest*](https://hacktoberfest.digitalocean.com/) festival and would like to give a shout out to first-time contributors [@didier-durand](https://github.com/didier-durand), [@zlymeda](https://github.com/zlymeda), [@avats-dev](https://github.com/avats-dev), and many more.\n\n### **Key Highlights of OpenEBS 2.2.0 Release:**\n\n- Mayastor aims to be the world’s fastest container attached storage and is currently in alpha. The release introduced block device enumeration feature via the gRPC API and enhancement around storage pool finalizers.\n- ZFS local PV has become a popular storage engine built on local storage design and provides powerful storage features like snapshots and clones, raw block volume, etc. It also supports day two operations like volume resize and backup and restore via the pluggable Velero interface.\nSupport for Incremental Backup and Restore by enhancing the OpenEBS Velero Plugin has been a significant highlight for ZFS local PV release. \nTo learn more about this, please refer to the document [here](https://github.com/openebs/zfs-localpv/blob/master/docs/backup-restore.md).\n- OpenEBS Velero plugin connects the Velero interface to the OpenEBS storage engines to deliver backup/restore functionality. Velero Plugin has been enhanced to restore ZFS Local PV into a different cluster or a different node in the cluster and use custom certificates for S3 object storage.\n- CStor went into beta in 2.0 and has been enhanced to migrate the storage pool from one node to another node. This will help with scenarios where a Kubernetes node can be replaced with a new node but can be attached with the block devices from the old node that contain cStor Pool and the volume data.\n- OpenEBS node disk manager helps in block device discovery and management in a Kubernetes cluster and powers storage engines like cStor. Support to exclude multiple devices that could be mounted as host filesystem directories has been added.\nAn issue where NDM could cause data loss by creating a partition table on an uninitialized iSCSI volume has also been fixed.\n\n### **Useful Links and Summary:**\n\nIf you are interested in knowing more details regarding the changes that made to this release, please visit the release note [link](https://github.com/openebs/openebs/releases/tag/v2.2.0). To try out OpenEBS, you can visit [https://docs.openebs.io/](https://docs.openebs.io/) and follow the user guides.\n\nYou can visit the following link to learn more or experiment with Mayastor\n[https://github.com/openebs/mayastor](https://github.com/openebs/mayastor)\n\nYou can visit the following link to learn more or experiment with ZFS local PV\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n\nTo learn more about the new cStor CSPC API, please visit the following link:\n[https://github.com/openebs/cstor-operators](https://github.com/openebs/cstor-operators)\n\nIf you have any feedback, questions, or suggestions — please reach out to the community on the #openebs channel in the Kubernetes workspace or consider opening a relevant issue at [Github](https://github.com/openebs/openebs).\n","slug":"openebs-220-enhancements-and-new-storage-capabilities"},{"id":13,"title":"Scaling up cStor Volume Replica","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"07-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS provides volume replication through different storage engines. Learn how to scale up cStor Volume Replica.","content":"\nEven if a cluster is reliable, nodes can and do fail. Rebooting a node does not simulate a crash. There can be many reasons, such as catastrophic hardware failure, Operating System failure, or communication failure among the nodes. To overcome this hazardous situation, the Replication of volume becomes necessary.\n\nReplication is the process by which one or more volumes can be copied to maintain the significance of a cluster and to avoid data loss. OpenEBS provides volume replication through different storage engines. One of them is cStor Volume Replication.\n![Synchronous replication of data](https://lh5.googleusercontent.com/ijS24Ywabw-QkWWYbSLoOshGTi2SHZhdEFATaHIYbkNGK8lUq5SJrct6fNHfPjWcPTHGyvByS7uD1vYct2m5D6-HdRC2ZoMpS_c4Crw-9sREhPU-tXE8KAt-nWj7vYw99Ee_s1pE)\n#### Prerequisite for scaling up the replicas of cStor volume:\n\n- A cStor pool should be available, and replicas of this cStor volume should not be present on this cStor pool.\n- The OpenEBS version should be 1.3.0 or more.\n\n### Please follow the below steps for cStor Volume Replication:\n\nGet the StorageClass name using the following command:\n\n    kubectl get sc\n\nExample Output:\n![](https://lh5.googleusercontent.com/lTma7ZqsAavmXEzGG_b4BXDMUEYXjFXf0xxnWgE70znfR_EzP3IorVFp0evkKoLMsBQ0D7gwOQxivB_bZxEcv2vhYZOe17k7mNyDBaPewTgiUdusrd3ow12ClBeQvZVmVzjDrdsI)\nThe storage class for cStor is ***openebs-sc-cstor***. Perform the following command to get the details of the corresponding StorageClass, which is used for creating the cStor volume :\n\n    Kubectl get sc openebs-sc-cstor\n\nWe will get the Yaml file of the corresponding StorageClass ***openebs-sc-cstor***.\n![](https://lh5.googleusercontent.com/81DQJ-DhT3AKseMRfCZ4NpkmOPl2Tckm76jrUxE2eECY7lrejvNz3OjomFWmNiCRwm0L2seAWzmJJhe-8xcqFirBsEUedf2xzPN4NHq2RM2YYEZZv-iKpsE03j06EQi_D5kqnDCi)\nIn the Yaml above, We can see the Replica count Value is 1.\n\nGet the volume name using the following command:\n\n    Kubectl get pvc\n\nGet the VOLUME name and use it in the following command to get the details of corresponding cStor volume. All commands are performed by considering the above PVC.\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=<Vol-name>\n\nExample output:\n![](https://lh4.googleusercontent.com/FIOJchscq3lm7UJLwnk7i1oNne_RxhjIJzI3FMANxxkRhz4yWZAue-Wu1jD03ii2aMjtdDu3zr9C-0ZGaeazkvxb_JkGnxBBDza605w_p-v9BY1ER40f6DityHwimJvhvuAR8FcT)\nGet the details of existing cStor Volume Replica details using the following command:\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nExample output:\n![](https://lh3.googleusercontent.com/68NvgkfD7audTNZN1QLt6SVw4OvN_B3MIlnFnWm8MfgDziiexFX2qeI3tX6H1TCJJgrCA8b-nZQJoM6hx1QoYWOv4q74tKwB7nrZLc9xdluXRCvWTpj-sU6sIv7aJ0AMgL3rr1AR)\nPerform the following command to get complete details of the existing cStor volume replica:\n\n    kubectl get cvr -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nGet the available cStor Pools for creating new cStor volume replica. The following command will get the other associated cStor pools details:\n\n    kubectl get csp -l openebs.io/storage-pool-claim=cstor-disk-pool | grep -v cstor-disk-pool-hgt4\n\nExample Output:\n![](https://lh6.googleusercontent.com/lcbO830nSZgValr-I4ci7FHRa6Qvqf3eG-bycWHHAniRD8mb8dwRHOwxeVObFqj4FqvXbNkb_oZUdWhMgAQuHvU1pYDecvWXhDetYGdJADBQhWfzMuwJm4d9Ywgg6bAKkj-Sd79a)\nFrom the above example output, there are 2 cStor pools available, i.e., ***cstor-disk-pool-2phf*** and ***cstor-disk-pool-zm8l***. So it is possible to scale up the current volume replica count to 3 from 1. If there are no cStor pools available to perform volume replica scale-up, then follow the [steps](https://docs.openebs.io/docs/next/ugcstor.html#expanding-cStor-pool-to-a-new-node) to create a new cStor pool by updating existing SPC configuration.\n\nPerform the following command to get the details of the cStor Pool where new replica will be created:\n\n    kubectl get csp -n openebs cstor-disk-pool-2phf -oyaml\n\nNote down following parameters from the output:\n\n- metadata.labels.cstorpool.openebs.io/name\n- metadata.labels.cstorpool.cstorpool.openebs.io/uid\n- metadata.annotations.cstorpool.openebs.io/hostname\n\nThe sample CVR Yaml is provided below:\n![](https://lh3.googleusercontent.com/JePqVqyIryf396SEkCf9NoS3kmPDXM0huqehkN3kX5f-eE7nX3-mCr42xriJeDKSNRgfVxSeQG_SUHkbqEZS4ktIzzcJ8VKCsFXuz4VhtdXpikLADE3eJdkgwH3zFd5PXRPfYc70)\nApply the updated CVR YAML spec to create the new replica of cStor volume using the following command:\n\n    kubectl apply -f cvr.yaml\n\nExample Output:\n![](https://lh5.googleusercontent.com/JElB0d8zFXHoUh6wM0QpAshOmYbVXOvH5RIR9UjJ_svM67ZR2pq6cQ4ckrq0Qw6ACpRnOqO-6nUbvLUrDhFKvgZxjrh-ke0VHnKW-pR2oyzkgXdQuRATSwy9EVN19G458ZyR_9Xd)\nVerify if new CVR is created successfully using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh4.googleusercontent.com/ql9j6Zcod6DT1vKhJrlJJaxk4YUN8Mf_o7LT3e-fBjjoybINByEwwDS5fln6K5BEJGW6vFfE8h2JA_2tFvQY5PQKo62eJvQfTE5j5JwECIz2oO3u_ypKHWRylL3gmU4KYlo4axtU)\nFrom the above output, a new replica of the cStor volume is created, and STATUS is showing as Offline.\n\nUpdate Desired Replication Factor in cStor volume with a new replica count. This can be updated by editing corresponding cStor volume CR YAML.\n\n    kubectl edit cstorvolume pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8 -n openebs\n\nThe following is the snippet of updated cStor volume CR YAML:\n![](https://lh3.googleusercontent.com/lAisXwgequP2MyeCw1cVuwUYFG9G9L5U88olJ2CjbjIOpHjlMwn-K8p11ktaCjQfxK-u5EL-ebpZofD0W_LOKmfFa-wW3eTLtBpqSt7EPYvz5rQciYeaFdT6_7PCsJkdxPVHZCVg)\n\nIn the above snippet, the desiredReplicationFactor is updated to 2 from 1. Example output:\n![](https://lh6.googleusercontent.com/uBkJft958gfjATk070ZFZOMXaq7Sb1xnd5lBVMa2sKuXo-nxwrRxQS58TPgdpoLjMuMHvT4LwPscxPdT6kgwpaDVSraLmsNwWhfanMUrNVO72K8WgxwT3_or4EdzqQkWBgI-Ka84)\nVerify if the rebuilding has started on the new replica of the cStor volume. Once rebuilding has been completed, it will update its STATUS as Healthy. Get the latest status of the CVRs using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh6.googleusercontent.com/1KjmeLgtvoFcBh0vVmB0iwj_gjo-Tkd3vVTTmaw3OaREY9KbvDUQLqyEu0Hj_aYKDpTIRSDVG2sOrTPMczJAPASlzFitSHDyocPV4Bb6IgajW-ArUpDKhi8StFesnHYZrUc3X9DJ)\n","slug":"scaling-up-cstor-volume-replica"},{"id":14,"title":"\"Hacktoberfest 2020 - Contribute to OpenEBS\"","author":"MayaData Marketing","author_info":"Mayadata Marketing Team","date":"30-09-2020","tags":["OpenEBS"],"excerpt":"Hacktoberfest 2020 is almost here. Contribute to open source project, OpenEBS, to win exciting swag.","content":"\n### Hacktoberfest returns! Contribute to OpenEBS and win exciting swag\n\nThe seventh annual [***Hacktoberfest ***](https://hacktoberfest.digitalocean.com/) celebration is almost here, and we at *OpenEBS* are happy to be participating in the contest once again. In August 2017, the OpenEBS community began growing and building a strong foundation for an open source project.\n\nWe were first introduced to *Hacktoberfest* by friends and peers at the DigitalOcean Bangalore Meetup and were immediately interested in participating. We enlisted OpenEBS as one of the projects participating in Hacktoberfest 2017. We were pleasantly surprised by the participation and enthusiasm that Hacktoberfest attracts from developers around the world. The PRs have been at their peak during Hacktoberfest.\n![](https://lh4.googleusercontent.com/Og_t8KLCiRni_LS66bpJsonSXMjcoAX671c8a2LD7ZjbkVdYZgZCRFq47sDC7hsEZt6qcaoCJPZi_gm2FnKmuzMvlg4UZAQKofU0agH2Z11TRmw6vBCQ8u3ssGfre75BN9OV-vOO)\n### Get started with OpenEBS this Hacktoberfest\n\nFollowing the smashing success we had when we participated in the event last few years, we’re going to do the same this year! MayaData makes it more exciting to participate in **Hacktoberfest **by running multiple Meetups throughout the month and helping contributors to get started with their favorite areas (in any of the programming languages) like website development and documentation enhancements. \n\nTo top it all, there are exciting prizes to be won and every contribution deserves an additional swag from MayaData. Read [this blog](https://blog.mayadata.io/openebs/experience-with-openebs-in-this-hacktoberfest) by Aswath K, one of last year’s weekly winners, who writes about his experience with OpenEBS in Hacktoberfest 2019.\n![](https://lh6.googleusercontent.com/2POqPppb7pyGM0OWwl_LlkHzwz-DSWXMMggxIeNCXvsU6EVVmNHdiIzIoTw23-ceK9R5iBleFMGiK-lw9JLtCP5VVjFGQS1QhIOXbpQhtvku5Gp5aCw4Eul_r6JcM-o0WuVZRZmj)\n### How do I contribute to OpenEBS?\n\nThat is an excellent question! OpenEBS is a Kubernetes native Container Attached Storage (CAS) that simplifies running Stateful workloads on Kubernetes. It is built on Microservices architectural patterns, fully automated development, and build pipelines.\n\nOpenEBS has several components that need your help from simple fixes like adding GitHub issue templates, to enhancing the components. These are developed using Go, Rust, Python, Javascript, Ansible, and many more interesting tools. OpenEBS is also a great way to start your journey into the exciting world of storage, containers, and Kubernetes.\n\nThe [architecture overview document ](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) is a great place to start learning and picking up a component that speaks to your passion. You could start your first contribution by enhancing that document itself for providing more clarity.\n\nThere are many other [good first issues](https://github.com/search?q=org%3Aopenebs+is%3Aissue+label%3A%22good+first+issue%22) to pick from.\n\nContributions can be anything from creating issues, improving user and contributor documents, enhancing build and docker tools, fixing and enhancing code, or unit tests and e2e tests. If you are unsure where to start, begin a discussion with the contributors on [GitHub Discussions](https://github.com/openebs/openebs/discussions) or by joining [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).\n\n### Will there be swag?\n\nYes. A big fat YES!\n\nThe official [Hacktoberfest](https://hacktoberfest.digitalocean.com/) will be giving away free t-shirts to every person making four pull requests to open source repositories during October, as well as limited-edition Hacktoberfest stickers to everyone who participates.\n\nOn top of this, you will also be able to get some exclusive and limited OpenEBS swag. When your PR to any OpenEBS repository is merged, we will contact you to fill out a form to send a special edition swag designed for Hacktoberfest.\n\nNot only this but by becoming a top weekly contributor, you’ll be able to grab even more swag.\n\nPrizes will be sent to quality contributions. The best PR will win a grand prize. Stay tuned to find out more.\n\nSo, what are you waiting for! Go get your git on and start contributing - we can’t wait to receive your PR.\n\nHappy hacking!\n\n### Getting Started:\n\n1. [https://hacktoberfest.digitalocean.com/](https://hacktoberfest.digitalocean.com/)\n2. Join [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F)\n3. Checkout the [OpenEBS Contributing guide](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md)\n4. Learn about the [architecture and components](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) of OpenEBS\n5. Create new issues for your contribution or pick one of the existing issues from [https://github.com/openebs/openebs/issues](https://github.com/openebs/openebs/issues)\n","slug":"hacktoberfest-2020-contribute-to-openebs"},{"id":15,"title":"OpenEBS StorageClasses For ZFS-LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"09-09-2020","tags":["Openebs"," Localpv"," Zfs"],"excerpt":"In this blog, I will discuss various storage classes we can use to dynamically provision the volumes backed by ZFS-LocalPV Storage Pool.","content":"\nIn this blog, I will discuss various storage classes we can use to dynamically provision the volumes backed by ZFS Storage Pool.\n\nPlease read my previous[ post](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d?__hstc=216392137.7dc0753f698b104ea002a16b84268b54.1580207831486.1580207831486.1580207831486.1&amp;__hssc=216392137.1.1580207831487&amp;__hsfp=818904025) for instructions on setting up the *ZFS-LocalPV*. Alternatively, you can also go through the [README](https://github.com/openebs/zfs-localpv/blob/master/README.md) section of the [*ZFS-LocalPV* repository](https://github.com/openebs/zfs-localpv).\n\n### **StorageClass Backed by ZFS Dataset**\n\nWe can create a StorageClass with the fstype as “zfs”. Here, the ZFS-LocalPV driver will create a ZFS dataset for the persistence storage. The application will get a dataset for the storage operation. We can also provide recordsize, compression, or dedup property in the StorageClass. The dataset will be created with all the properties mentioned in the StorageClass:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: openebs-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     recordsize: \"4k\"\n     thinprovision: \"no\"\n     fstype: \"zfs\"\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n\nWe have the thinprovision option as “no” in the StorageClass, which means that do reserve the space for all the volumes provisioned using this StorageClass. We can set it to “yes” if we don’t want to reserve the space for the provisioned volumes.\n\nThe allowVolumeExpansion is needed if we want to resize the volumes provisioned by the StorageClass. ZFS-LocalPV supports online volume resize, which means we don’t need to scale down the application. The new size will be visible to the application automatically.\n\nOnce the storageClass is created, we can go ahead and create the PVC and deploy a pod using that PVC.\n\n### **StorageClass Backed by ZFS Volume**\n\nThere are a few applications that need to have different filesystems to work optimally. For example, Concourse performs best using the “btrfs” filesystem ([https://github.com/openebs/zfs-localpv/issues/169](https://github.com/openebs/zfs-localpv/issues/169)). Here we can create a StorageClass with the desired fstype we want. The ZFS-LocalPV driver will create a ZVOL, which is a raw block device carved out from the mentioned ZPOOL and format it to the desired filesystem for the applications to use as persistence storage backed by ZFS Storage Pool:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: opeenbs-zfspv\n    parameters:\n     volblocksize: \"4k\"\n     thinprovision: \"yes\"\n     fstype: \"btrfs\"\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n\nHere, we can mention any fstype we want. As of 0.9 release, the driver supports ext2/3/4, xfs, and btrfs fstypes for which it will create a ZFS Volume. Please note here, if fstype is not provided in the StorageClass, the k8s takes “ext4\" as the default fstype. Here also we can provide volblocksize, compression, and dedup properties to create the volume, and the driver will create the volume with all the properties provided in the StorageClass.\n\nWe have the thinprovision option as “yes” in the StorageClass, which means that it does not reserve the space for all the volumes provisioned using this StorageClass. We can set it to “no” if we want to reserve the space for the provisioned volumes.\n\n### **StorageClass for Sharing the Persistence Volumes**\n\nBy default, the ZFS-LocalPV driver does not allow Volumes to be mounted by more than one pod. Even if we try to do that, only one Pod will come into the running state, and the other Pod will be in ContainerCreating state, and it will be failing on the mount.\n\nIf we want to share a volume among multiple pods, we can create a StorageClass with the “shared” option as “yes”. For this, we can create a StorageClass backed by ZFS dataset as below :\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: openebs-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     fstype: \"zfs\"\n     shared: \"yes\"\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n\nOr, we can create the StorageClass backed by ZFS Volume for sharing it among multiple pods as below :\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: openebs-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     fstype: \"ext4\"\n     shared: \"yes\"\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n\nHere, we have to note that all the Pods using that volume will come to the same node as the data is available on that particular node only. Also, applications need to be aware that the volume is shared by multiple pods and should synchronize with the other Pods to access the data from the volume.\n\n### **StorageClass With k8s Scheduler**\n\nThe ZFS-LocalPV Driver has its own scheduling logic, where it creates the volume where the ZFS Pool is less loaded with the volumes. Here, it just checks the volume count and creates the volume where less volume is configured in a given ZFS Pool. It does not account for other factors like available CPU or memory while making scheduling decisions. So if you want to use node selector/affinity rules on the application pod or have CPU/Memory constraints, the Kubernetes scheduler should be used. To make use of Kubernetes scheduler, we can set the volumeBindingMode as WaitForFirstConsumer in the storage class:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: openebs-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     fstype: \"zfs\"\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n    volumeBindingMode: WaitForFirstConsumer\n\nHere, in this case, the Kubernetes scheduler will select a node for the POD and then ask the ZFS-LocalPV driver to create the volume on the selected node. The driver will create the volume where the POD has been scheduled.\n\n### **StorageClass With Custom Node Labels**\n\nThere can be a use case where we have certain kinds of ZFS Pool present on certain nodes only, and we want a particular type of application to use that ZFS Pool. We can create a storage class with `allowedTopologies` and mention all the nodes there where that pool is present:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: nvme-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n    allowedTopologies:\n    - matchLabelExpressions:\n     - key: openebs.io/nodename\n       values:\n         - node-1\n         - node-2\n\nHere we can have ZFS Pool of name “zfspv-pool” created on the nvme disks and want to use this high performing ZFS Pool for the applications that need higher IOPS. We can use the above SorageClass to create the PVC and deploy the application using that.\n\nThe ZFS-LocalPV driver will create the Volume in the Pool “zfspv-pool” present on the node with fewer of volumes provisioned among the given node list. In the above StorageClass, if there provisioned volumes on node-1 are less, it will create the volume on node-1 only. Alternatively, we can use `volumeBindingMode: WaitForFirstConsumer` to let the k8s select the node where the volume should be provisioned.\n\nThe problem with the above StorageClass is that it works fine if the number of nodes is less, but if the number of nodes is huge, it is cumbersome to list all the nodes like this. In that case, what we can do is, we can label all the similar nodes using the same key value and use that label to create the StorageClass.\n\n    pawan@pawan-master:~/pawan$ kubectl label node pawan-node-2 openebs.io/zpool=nvme\n    node/pawan-node-2 labeled\n    pawan@pawan-master:~/pawan$ kubectl label node pawan-node-1 openebs.io/zpool=nvme\n    node/pawan-node-1 labeled\n\nNow, restart the ZFS-LocalPV Driver (if already deployed otherwise, please ignore) so that it can pick the new node label as the supported topology.\n\n    $ kubectl delete po -n kube-system -l role=openebs-zfs\n\nNow, we can create the StorageClass like this:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: nvme-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n    allowedTopologies:\n    - matchLabelExpressions:\n     - key: openebs.io/zpool\n       values:\n         - nvme\n\nHere, the volumes will be provisioned on the nodes which has label “openebs.io/zpool” set as “nvme”.\n\n### **Conclusion :**\n\nWe can set up different kinds of StorageClasses as per our need, and then we can proceed with PVC and POD creation. The driver will take the care of honoring the requests put in the PVC and the StorageClass.\n\nI hope you found this post useful. Feel free to contact me with any feedback or questions by using the comment section below.\n","slug":"openebs-storageclasses-for-zfslocalpv"},{"id":16,"title":"Handling node down/cluster scaling on ZFS LocalPV backed workloads","author":"Ranjith Raveendran","author_info":"Ranjith is working as a Software Engineer at MayaData and working in the OpenEBS project. In his free time, he listens to music, watches movies, and goes for bike riding.","date":"01-09-2020","tags":["Kubernetes"],"excerpt":"Step-by-step blog on how MySQL app deployment runs on OpenEBS ZFS LocalPV device, handled when a node down/cluster scale down situation happens in GKE cluster","content":"\nKubernetes is increasingly used for running production-grade stateful services. Organizations are making progress on a containerized form of their production workloads for running in Kubernetes. There are already solutions available for the containerized version of stateful applications, network, storage, etc.\n\nAs everyone knows, OpenEBS is one of the leading containerized storage solutions for Kubernetes, and it is a growing Sandbox project in CNCF. MayaData is the primary maintainer and contributor of OpenEBS along with other companies. MayaData also contributed another open source project, Litmus, into CNCF, which does mostly Chaos engineering in Kubernetes, which helps SREs and developers to do all kinds of testing of their applications and components in Kubernetes before going into Production.\n\nA persistent storage solution for running any stateful application is a must requirement, be it a **Deployment** or **StatefulSet**. OpenEBS provides various storage engines, and each storage engine is suitable for specific applications or workloads. Some engines provide storage level synchronous replication, capable of taking snapshots and cloning, backup and restore, volume expansion, CSI complaint, performance-oriented, etc. So choosing the engine based on the workload requirement is an important activity.\n\nOpenEBS provides dynamic provisioning of ***ZFS LocalPV*** using external device/devices. OpenEBS ZFS driver binds a ZFS file system into the Kubernetes environment and allows users to provision and de-provision volumes dynamically. Using a ***ZFS Local PV*** has the following advantages   as opposed to Kubernetes native Local PV backed by direct-attached devices:\n\n- Sharing of the devices among multiple application pods.\n- Enforcing quota on the volumes makes sure the pods don’t consume more than their capacity.\n- Ability to take snapshots of the LocalPV\n- Ability to sustain the disk failures — using the ZPOOL RAID functionality\n- Ability to use data services like compression and encryption.\n- Ability to resize the PV capacity.\n\nIn this article, we provisioned a MySQL deployment on an ***OpenEBS ZFS LocalPV*** device dynamically.\n\nThis article is a step-by-step instruction. We will mention how a MySQL application deployment running on the OpenEBS ZFS LocalPV device volume is getting handled when a Node down scenario or a cluster scale down situation happens in the GKE cluster. In GKE and some other managed clusters like EKS, the node name will change if the cluster undergoes a scale down and scale up operation has performed. So the application running on the OpenEBS ZFS LocalPV device will not be able to attach to the new node since the corresponding PV and ZFS Volume has a binding of volume node affinity. We need to update the new node name details in PV and ZFS volume, where the disk got attached.\n\nIn this article, we are discussing the steps that need to be performed to make the application into a running state when a Node down / scale down cluster scenario has happened. This situation is usually required in case of Managed clusters where the Node name will get changed during this scenario. As stated earlier, the following approach works fine for both Deployment type and StatefulSet type, but ensure that the next steps are correctly performed. Let’s start with the step by step instructions once you have scaled up the cluster after a scale down scenario.\n\n1. Verify all nodes are now in Ready state.\n    ```\n    $ kubectl get node\n    NAME                                           STATUS   ROLES    AGE   VERSION\n    gke-openebs-mysql-default-pool-dd23ce6b-f8rd   Ready    <none>   24m   v1.16.13-gke.1\n    gke-openebs-mysql-default-pool-dd23ce6b-lwr3   Ready    <none>   24m   v1.16.13-gke.1\n    gke-openebs-mysql-default-pool-dd23ce6b-zzqx   Ready    <none>   24m   v1.16.13-gke.1\n    \n2. Label all the nodes with the same custom label used in the nodeSelector field in the STS app. In my case, there is no custom node label used in application deployment. So we are skipping this step.\n\n3. Attach the disk randomly to any node in the same zone.\n    \n    ```\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-dd23ce6b-j894 --disk mysql-disk1 --device-name mysql-disk1 --zone=us-central1-c\n\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-dd23ce6b-prv2 --disk mysql-disk2 --device-name mysql-disk2 --zone=us-central1-c\n\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-dd23ce6b-tf5j --disk mysql-disk3 --device-name mysql-disk3 --zone=us-central1-c\n\n4. Ensure that ZFS utils packages are installed on your worker nodes. If it is not installed, ZFS packages can be installed.\n    \n    ```\n    $ sudo su -\n    $ sudo apt-get update\n    $ apt-get install zfsutils-linux -y\n    $ zpool import zfspv-pool\n    ```\n    \n    Verify Zpool information.\n    \n    ```\n    $ zpool list\n    NAME         SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\n    zfspv-pool  14.5G   463M  14.0G         -     0%     3%  1.0\n\n5. Verify the details of the ZFS dataset detail where the volume is present. This information is required in step 10. In the case of Statefulset, the ZFS dataset will be present on multiple nodes. So you should note down the details of the ZFS dataset and corresponding node information.\n    \n    ```\n    $ sudo su\n    $ root@gke-openebs-mysql-default-pool-dd23ce6b-tf5j:~# zfs list\n    NAME                                                  USED  AVAIL  REFER  MOUNTPOINT\n    zfspv-pool                                           10.6G  3.42G    96K  /zfspv-pool\n    zfspv-pool/pvc-e299a9db-0903-417b-8034-03c3dc77af87  10.6G  13.6G   462M  -\n    ```\n\n    From the above information, the ZFS dataset is present on Node `gke-openebs-mysql-default-pool-dd23ce6b-tf5j`. We have to update this node information in the nodeSelector field in step 10 and as `ownerNodeID` in step 11.\n\n6. Ensure OpenEBS ZFS driver pods are running in the `kube-system` namespace.\n    \n    ```\n    $ kubectl get pods -n kube-system -l role=openebs-zfs\n    NAME                       READY   STATUS           RESTARTS   AGE\n    openebs-zfs-controller-0   5/5     Running          0          91m\n    openebs-zfs-node-29dlp     2/2     Running          0          14m\n    openebs-zfs-node-bssq7     2/2     Running          0          14m\n    openebs-zfs-node-p54tq     2/2     Running\t    0          14m\n\n7. Check the status of the application pod. It will be in the `Pending` state.\n    \n    ```\n    $ kubectl get pod\n    NAME                      READY   STATUS    RESTARTS   AGE\n    percona-9fbdb8678-z79vr   0/1     Pending   0          70m\n\n8. Get the PV details of the associated application\n    \n    ```\n    $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS     REASON   AGE\n    pvc-e299a9db-0903-417b-8034-03c3dc77af87  10Gi         RWO            Delete           Bound    default/demo-vol1-claim   openebs-zfspv           33m\n\n9. Create a directory and copy the YAML spec of all the associated PVs into it like below.\n    \n    ```\n    $ mkdir mysql-restore\n    $ cd mysql-restore/\n    $ kubectl get pv pvc-e299a9db-0903-417b-8034-03c3dc77af87 -o yaml --export > pv1.yaml\n    ```\n    \n    Note: If it is StatefulSet, take the YAML spec of all the associated PVs of that application.\n\n10. Modify the above-copied YAML with the new hostname in the copied YAML of PV. The following is a snippet of PV spec where it mentions the new node name where the ZFS volume is created. The node information will be obtained from step 5.\n    ```\n    nodeAffinity:\n        required:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: openebs.io/nodename\n              operator: In\n              values:\n              - gke-openebs-mysql-default-pool-dd23ce6b-tf5j\n      persistentVolumeReclaimPolicy: Delete\n      storageClassName: openebs-zfspv\n\n11. Also, update the node information where the ZFS dataset resides into `zv`(ZFS volume) cr. The node name has to be given to the path  `spec.ownerNodeID`.\n    \n    ```\n    $ kubectl edit zv pvc-e299a9db-0903-417b-8034-03c3dc77af87 -n openebs\n    ```\n    \n    The following is the snippet of the modified information.\n    \n    ```\n    spec:\n      capacity: \"10737418240\"\n      compression: \"off\"\n      dedup: \"off\"\n      fsType: ext4\n      ownerNodeID: gke-openebs-mysql-default-pool-dd23ce6b-tf5j\n      poolName: zfspv-pool\n\n12. Now get the PV and then delete the PV\n    \n    ```\n    spec:\n      capacity: \"10737418240\"\n      compression: \"off\"\n      dedup: \"off\"\n      fsType: ext4\n      ownerNodeID: gke-openebs-mysql-default-pool-dd23ce6b-tf5j\n      poolName: zfspv-pool\n    ```\n    ```\n    $ kubectl delete pv pvc-e299a9db-0903-417b-8034-03c3dc77af87\n    persistentvolume \"pvc-e299a9db-0903-417b-8034-03c3dc77af87\" deleted\n    ```\n    \n    The deletion of the PV will not be completed since it has the finaliser set with the PV. So we need to cancel the ongoing operation and then edit the PV and remove Finalizers. Once finalizers are removed, the volume will be automatically deleted.\n\n13. Verify that the PV of the application has been removed successfully.\n    \n    ```\n    $ kubectl delete pv pvc-e299a9db-0903-417b-8034-03c3dc77af87\n    persistentvolume \"pvc-e299a9db-0903-417b-8034-03c3dc77af87\" deleted\n\n14. Now, apply the updated YAML files of the PV. \n    \n    ```\n    $ kubectl apply -f  pv1.yaml \n    ```\n    \n    Note: Perform the same for other PVs as well if the application is a StatefulSet.\n\n15. Verify that if PODs are started `Running` from `Pending` state.\n    \n    ```\n    $ kubectl get pod -o wide\n    NAME                      READY   STATUS    RESTARTS   AGE     IP         NODE                                           NOMINATED NODE   READINESS GATES\n    percona-9fbdb8678-z79vr   1/1     Running   0          6h43m   10.4.2.2   gke-openebs-mysql-default-pool-dd23ce6b-tf5j   <none>           <none>\n    ```\n    \n    Verify the PV, PVC, and ZV associated with the MySQL application.\n    \n    ```\n    $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS    REASON   AGE\n    pvc-e299a9db-0903-417b-8034-03c3dc77af87   10Gi       RWO            Delete           Bound    default/demo-vol1-claim   openebs-zfspv            150m\n\n    $ kubectl get pvc\n    NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE\n    demo-vol1-claim   Bound    pvc-e299a9db-0903-417b-8034-03c3dc77af87   10Gi       RWO            openebs-zfspv   7h7m\n\n    $ kubectl get zv -n openebs\n    NAME                                       ZPOOL        NODE                                           SIZE          STATUS   FILESYSTEM   AGE\n    pvc-e299a9db-0903-417b-8034-03c3dc77af87   zfspv-pool   gke-openebs-mysql-default-pool-dd23ce6b-tf5j   10737418240   Ready    ext4         7h7m\n\n16. Login to the application and verify that you are able to access the data.\n    ```\n    $ kubectl exec -it percona-9fbdb8678-z79vr sh\n    sh-4.2$ mysql -uroot -pk8sDem0;\n    mysql: [Warning] Using a password on the command line interface can be insecure.\n    Welcome to the MySQL monitor.  Commands end with ; or \\g.\n    Your MySQL connection id is 2\n    Server version: 5.7.30-33 Percona Server (GPL), Release 33, Revision 6517692\n    \n    Copyright (c) 2009-2020 Percona LLC and/or its affiliates\n    Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n    \n    Oracle is a registered trademark of Oracle Corporation and/or its\n    affiliates. Other names may be trademarks of their respective\n    owners.\n    \n    Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n    \n    mysql> SHOW DATABASES;\n    +--------------------+\n    | Database           |\n    +--------------------+\n    | information_schema |\n    | mysql              |\n    | performance_schema |\n    | pets               |\n    | sys                |\n    +--------------------+\n    5 rows in set (0.11 sec)\n    \n    mysql> USE pets;\n    Reading table information for completion of table and column names\n    You can turn off this feature to get a quicker startup with -A\n    \n    Database changed\n    mysql> SELECT * FROM cats;\n    +----+---------+--------+------------+\n    | id | name    | owner  | birth      |\n    +----+---------+--------+------------+\n    |  1 | Sandy   | Lennon | 2015-01-03 |\n    |  2 | Cookie  | Casey  | 2013-11-13 |\n    |  3 | Charlie | River  | 2016-05-21 |\n    +----+---------+--------+------------+\n    3 rows in set (0.00 sec)\n","slug":"handling-node-downcluster-scaling-on-zfs-localpv-backed-workloads"},{"id":17,"title":"Recover from Volume Multi Attach Error in On-Prem Kubernetes Clusters","author":"Prateek Pandey","author_info":"Contributor and Maintainer @OpenEBS. Software Developer at @mayadata_inc. OpenSource Enthusiast","date":"27-08-2020","tags":["Kubernetes"],"excerpt":"In this blog, we'll talk about recovering from volume multi attach error in On-Prem Kubernetes clusters.","content":"\nIf you have an unmanaged Kubernetes Cluster that you have deployed on-prem or on cloud, you would have noticed that your Stateful Application pods error out with Multi-attach error whenever the node running the stateful application is abruptly shut down.\n\nThis has been a long outstanding issue in Kubernetes and is being actively worked on. Please refer to the following Kubernetes issues:\n\n- [https://github.com/kubernetes/enhancements/pull/1116](https://github.com/kubernetes/enhancements/pull/1116)\n- [https://github.com/kubernetes/kubernetes/issues/86281](https://github.com/kubernetes/kubernetes/issues/86281)\n- [https://github.com/kubernetes/kubernetes/issues/53059#issuecomment-619428689](https://github.com/kubernetes/kubernetes/issues/53059#issuecomment-619428689)\n\nThe main reason for this issue being hard to resolve is that there is no right way to determine if the node is really shut down or if it is due to a network/split-brain condition to the master nodes. And it gets a little harder with Stateful applications as we need to really determine that data is written down from older nodes to the disks, before forcibly remounting onto the new node.\n\nIn this blog, I will provide an alternate approach that can be used to work around this issue and bring your applications back online. The solution is loosely based on the same approach that Managed Kubernetes clusters like GKE/EKS perform to handle this scenario. The managed clusters use out-of-band communication to determine if the node is shut down and delete the node resources.\n\nI will demonstrate the approach of removing the node resource as a safe way to recover volumes using the following example.\n\n## **Problem**\n\n### **1. Start with a Stateful application:**\n\nI have a three node cluster with k8s version 1.15.3, to reproduce the\nVolume multi-attach error scenario. Deployed OpenEBS version 1.3, using cstor csi based volume and mounted to Percona pod scheduled in node csi-node2.mayalabs.io.\n\n    $ kubectl get nodes\n    NAME                     STATUS     ROLES    AGE   VERSION\n    csi-master.mayalabs.io   Ready      master   39d   v1.15.3\n    csi-node1.mayalabs.io    Ready      none   39d   v1.15.3\n    csi-node2.mayalabs.io    Ready      none   39d   v1.15.3\n    csi-node3.mayalabs.io    Ready      none   39d   v1.15.3\n    \n\n    $ kubectl get pvc\n    NAME                     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS               AGE\n    demo-csi-vol-claim   Bound    pvc-b39248ab-5a99-439b-ad6f-780aae30626c   10Gi       RWO            openebs-csi-cstor-sparse   72m\n    \n\n    $ kubectl get pods -owide\n    NAME                       READY   STATUS    RESTARTS   AGE    NODE\n    percona-6795d6fb68-pqvqh   1/1     Running   0          66m    csi-node2.mayalabs.io\n    \n\nVolumeAttachment resource created only for volume attached to Node2 in case of CSI based persistent volumes\n\n    $ kubectl get volumeattachment\n    NAME                                                                   ATTACHER                 PV                                         NODE                    ATTACHED   AGE\n    csi-9f7704015b456f146ce8c6c3bd80a5ec6cc55f4f5bfb90c61c250d0b050a283c   openebs-csi.openebs.io   pvc-b39248ab-5a99-439b-ad6f-780aae30626c   csi-node2.mayalabs.io   true       66m\n    \n\n### **2. Node ShutDown:**\n\nShutting down kubelet service in Node2 as Percona application pod has been scheduled here, to make node `NotReady` state in the Kubernetes cluster.\n\n    $ kubectl get nodes\n    NAME                     STATUS     ROLES    AGE   VERSION\n    csi-master.mayalabs.io   Ready      master   39d   v1.15.3\n    csi-node1.mayalabs.io    Ready      none   39d   v1.15.3\n    csi-node2.mayalabs.io    NotReady   none    5m   v1.15.3\n    csi-node3.mayalabs.io    Ready      none   37d   v1.15.3\n    \n\nIn this case, the Percona pod will get stuck in a container creating a state with a multi-attach error.\n\n## **Solution:**\n\nAlthough these solutions are generic to recover the volume from the multi attach error. Based on some extra steps, I have divided them into two different sanctions based on the type of Kubernetes volumes. One is dynamic in-tree or external Kubernetes volumes, an older way of provisioning Kubernetes volumes, and the other one is CSI based Kubernetes volumes.\n\n### **Dynamic/Static Provisioner Based Volumes:**\n\n#### **Deleting Node Resource:**\n\nHere After deleting the Node resource below node related events will be generated which will trigger the force deletion of the pods, and they apparently will be scheduled to other available nodes:\n\n    $ kubectl delete nodes csi-node2.mayalabs.io\n    node \"csi-node2.mayalabs.io\" deleted\n    \n\n    $ kubectl get nodes\n    NAME                     STATUS     ROLES    AGE   VERSION\n    csi-master.mayalabs.io   Ready      master   39d   v1.15.3\n    csi-node1.mayalabs.io    Ready      none   39d   v1.15.3\n    csi-node3.mayalabs.io    Ready      none   37d   v1.15.3\n    \n\n##### **Check the kube-controller logs for events:**\n\n    I1021 10:37:44.336523       1 attach_detach_controller.go:573] error removing node \"csi-node2.mayalabs.io\" from desired-state-of-world: failed to delete node \"csi-node2.mayalabs.io\" from list of nodes managed by attach/detach controller--the node still contains 1 volumes in its list of volumes to attach\n    I1021 10:37:45.003243       1 event.go:258] Event(v1.ObjectReference{Kind:\"Node\", Namespace:\"\", Name:\"csi-node2.mayalabs.io\", UID:\"30ca0f5e-3a8f-4d0f-99fc-776d7051fd3d\", APIVersion:\"\", ResourceVersion:\"\", FieldPath:\"\"}): type: 'Normal' reason: 'RemovingNode' Node csi-node2.mayalabs.io event: Removing Node csi-node2.mayalabs.io from Controller\n    \n    \n    I1021 10:37:55.273070       1 gc_controller.go:62] PodGC is force deleting Pod: kube-system/openebs-csi-node-cjzlz\n    I1021 10:37:55.318908       1 gc_controller.go:166] Forced deletion of orphaned Pod kube-system/openebs-csi-node-cjzlz succeeded\n    I1021 10:37:55.318979       1 gc_controller.go:62] PodGC is force deleting Pod: openebs/openebs-ndm-8ntsv\n    I1021 10:37:55.352796       1 gc_controller.go:166] Forced deletion of orphaned Pod openebs/openebs-ndm-8ntsv succeeded\n    I1021 10:37:55.354071       1 gc_controller.go:62] PodGC is force deleting Pod: openebs/cspc-sparse-disk-pool-gg82-d9b4bff4d-9fmbn\n    I1021 10:37:55.420779       1 event.go:258] Event(v1.ObjectReference{Kind:\"Pod\", Namespace:\"openebs\", Name:\"cspc-sparse-disk-pool-gg82-d9b4bff4d-9fmbn\", UID:\"\", APIVersion:\"\", ResourceVersion:\"\", FieldPath:\"\"}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod openebs/cspc-sparse-disk-pool-gg82-d9b4bff4d-9fmbn\n    I1021 10:37:55.442403       1 gc_controller.go:166] Forced deletion of orphaned Pod openebs/cspc-sparse-disk-pool-gg82-d9b4bff4d-9fmbn succeeded\n    I1021 10:37:55.442568       1 gc_controller.go:62] PodGC is force deleting Pod: default/percona-6795d6fb68-b7dvl\n    I1021 10:37:55.446368       1 event.go:258] Event(v1.ObjectReference{Kind:\"ReplicaSet\", Namespace:\"openebs\", Name:\"cspc-sparse-disk-pool-gg82-d9b4bff4d\", UID:\"04f87ed3-c401-4688-8691-0716dc4693fe\", APIVersion:\"apps/v1\", ResourceVersion:\"7063677\", FieldPath:\"\"}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: cspc-sparse-disk-pool-gg82-d9b4bff4d-q2l2b\n    I1021 10:37:55.541929       1 event.go:258] Event(v1.ObjectReference{Kind:\"Pod\", Namespace:\"default\", Name:\"percona-6795d6fb68-b7dvl\", UID:\"\", APIVersion:\"\", ResourceVersion:\"\", FieldPath:\"\"}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod default/percona-6795d6fb68-b7dvl\n    I1021 10:37:55.599155       1 gc_controller.go:166] Forced deletion of orphaned Pod default/percona-6795d6fb68-b7dvl succeeded\n    I1021 10:37:55.599224       1 gc_controller.go:62] PodGC is force deleting Pod: kube-system/kube-proxy-b9q25\n    I1021 10:37:55.613517       1 event.go:258] Event(v1.ObjectReference{Kind:\"ReplicaSet\", Namespace:\"default\", Name:\"percona-6795d6fb68\", UID:\"50b82272-9874-4688-8362-7c759ae63aef\", APIVersion:\"apps/v1\", ResourceVersion:\"7063669\", FieldPath:\"\"}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: percona-6795d6fb68-pqvqh\n    W1021 10:37:55.621461       1 reconciler.go:328] Multi-Attach error for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" (UniqueName: \"kubernetes.io/csi/openebs-csi.openebs.io^pvc-b39248ab-5a99-439b-ad6f-780aae30626c\") from node \"csi-node1.mayalabs.io\" Volume is already exclusively attached to node csi-node2.mayalabs.io and can't be attached to another\n    I1021 10:37:55.629191       1 event.go:258] Event(v1.ObjectReference{Kind:\"Pod\", Namespace:\"default\", Name:\"percona-6795d6fb68-pqvqh\", UID:\"26ee6109-9d7e-4729-843b-18bb88926c87\", APIVersion:\"v1\", ResourceVersion:\"7063944\", FieldPath:\"\"}): type: 'Warning' reason: 'FailedAttachVolume' Multi-Attach error for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" Volume is already exclusively attached to one node and can't be attached to another\n    I1021 10:37:55.742498       1 gc_controller.go:166] Forced deletion of orphaned Pod kube-system/kube-proxy-b9q25 succeeded\n    I1021 10:37:55.742697       1 gc_controller.go:62] PodGC is force deleting Pod: kube-system/calico-node-4fv7n\n    I1021 10:37:55.787435       1 gc_controller.go:166] Forced deletion of orphaned Pod kube-system/calico-node-4fv7n succeeded\n    \n\n### **CSI Based Volumes:**\n\n#### **Attach-Detach Controller:**\n\nIf the volume is created using CSI Provisioner, a custom resource `volumeattachment` would be created. The Attach-detach controller will wait for the `maxWaitForUnmountDuration` i.e., 6 minutes to forcefully detach the attached volume from the node. Then the CR will be recreated and attach to any available node. To recover from the multi-attach error, this `volumeattachment` CR can be deleted along with node CR. Therefore the time taken to mount the volume on a new node will be reduced by 6 minutes.\n\n    $ kubectl get volumeattachment pvc-b39248ab-5a99-439b-ad6f-780aae30626c\n    NAME                                                                   ATTACHER                 PV                                         NODE                    ATTACHED   AGE\n    csi-6ae3ead0d1c3a6e73e7d4c8e27f9098b927f3e4edc21bcf6bb7cf3fcdb4101de   openebs-csi.openebs.io   pvc-b39248ab-5a99-439b-ad6f-780aae30626c   csi-node1.mayalabs.io   true       11m\n    \n\n    \n    $ kubectl logs -f kube-controller-manager-csi-master.mayalabs.io -n kube-system\n\n    \n    ```\n    W1021 10:43:55.629673       1 reconciler.go:232] attacherDetacher.DetachVolume started for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" (UniqueName: \"kubernetes.io/csi/openebs-csi.openebs.io^pvc-b39248ab-5a99-439b-ad6f-780aae30626c\") on node \"csi-node2.mayalabs.io\" This volume is not safe to detach, but maxWaitForUnmountDuration 6m0s expired, force detaching\n    I1021 10:43:55.671000       1 operation_generator.go:526] DetachVolume.Detach succeeded for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" (UniqueName: \"kubernetes.io/csi/openebs-csi.openebs.io^pvc-b39248ab-5a99-439b-ad6f-780aae30626c\") on node \"csi-node2.mayalabs.io\" \n    I1021 10:43:55.730390       1 reconciler.go:288] attacherDetacher.AttachVolume started for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" (UniqueName: \"kubernetes.io/csi/openebs-csi.openebs.io^pvc-b39248ab-5a99-439b-ad6f-780aae30626c\") from node \"csi-node1.mayalabs.io\" \n    I1021 10:43:55.752273       1 operation_generator.go:358] AttachVolume.Attach succeeded for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" (UniqueName: \"kubernetes.io/csi/openebs-csi.openebs.io^pvc-b39248ab-5a99-439b-ad6f-780aae30626c\") from node \"csi-node1.mayalabs.io\" \n    I1021 10:43:55.753344       1 event.go:258] Event(v1.ObjectReference{Kind:\"Pod\", Namespace:\"default\", Name:\"percona-6795d6fb68-pqvqh\", UID:\"26ee6109-9d7e-4729-843b-18bb88926c87\", APIVersion:\"v1\", ResourceVersion:\"7063944\", FieldPath:\"\"}): type: 'Normal' reason: 'SuccessfulAttachVolume' AttachVolume.Attach succeeded for volume \"pvc-b39248ab-5a99-439b-ad6f-780aae30626c\" \n    ```\n    \n\nThat's it for today's post. I hope you find it helpful. Feedback and comments are appreciated.\n","slug":"recover-from-volume-multi-attach-error-in-onprem-kubernetes-clusters"},{"id":18,"title":"Resize Kubernetes StatefulSets without impact","author":"Sai Chaithanya","author_info":"A developer whos is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate towards Data Science. Enjoys playing kabaddi and traveling.","date":"25-08-2020","tags":["Kubernetes"," Openebs"],"excerpt":"Read this post if you are a cStor CSI user who's looking to resize statefulsets without any impact of StatefulSet applcations. ","content":"\nIn large scale environments, storage is one of the hard things to manage, and it will be the most crucial component as it has DATA with it. OpenEBS, leading open source Cloud Native Storage, makes managing storage easier in Kubernetes environments. Mayadata, the company behind the OpenEBS project, has the vision of achieving data agility by transforming Kubernetes as a data plane. cStor is one of the storage engines of OpenEBS.\n\nThis blog is for OpenEBS users, specifically cStor CSI users looking to resize their ***Kubernetes StatefulSets*** without any impact of StatefulSet applications.\n\n### **Steps involved to resize** ***Kubernetes StatefulSets***\n\n1. Increase the volume size of the PVC.\n\n2. Update StatefulSet volumeClaimTemplate storage capacity.\n\n### Infrastructure details:\n\n    Kubernetes Cluster: Bare Metal\n    Kubernetes Version: v1.17.2\n    OpenEBS Version: 2.0.0\n\n### Installation of CStor setup:\n\nApplied OpenEBS 2.0.0 version of cStor operator [yaml](https://github.com/openebs/charts/blob/gh-pages/2.0.0/cstor-operator.yaml) and ndm operator [yaml](https://github.com/openebs/charts/blob/gh-pages/2.0.0/ndm-operator.yaml) via kubectl apply and provisioned cStor pools using CSPC API by following the steps mentioned [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md).\n\n    system@master$ kubectl get cspc -n openebs\n    NAME          HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE\n    cspc-stripe   3                  3                      3                  3m23s\n\n### Create StorageClass:\n\nCreate a StorageClass pointing to the above cStor pool(cspc-stripe) which will help in provisioning the cStor volume. For expanding the volumes **allowVolumeExpansion** parameter should set to true\n\n    system@master$ cat csi-sc.yaml \n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: openebs-csi-sc\n    provisioner: cstor.csi.openebs.io\n    allowVolumeExpansion: true\n    parameters:\n      cas-type: cstor\n      replicaCount: \"1\"\n      cstorPoolCluster: cspc-stripe\n\n### Provision StatefulSet:\n\nCreate StatefulSet to point to the above storageclass. In this example, mongo statefulset will be provisioned and volume size will be expanded from 5Gi to 15Gi. Below is the sample statefulset used for expansion:\n\n    system@master$ cat mongo-sts.yaml \n    apiVersion: apps/v1\n    kind: StatefulSet\n    metadata:\n      name: mongo\n      Namespace: mongo-ns\n    spec:\n      selector:\n        matchLabels:\n          role: mongo\n          environment: test\n      serviceName: \"mongo\"\n      replicas: 3\n      template:\n        metadata:\n          labels:\n            role: mongo\n            environment: test\n        spec:\n          terminationGracePeriodSeconds: 10\n          containers:\n          - name: mongo\n            image: mongo:latest\n            imagePullPolicy: IfNotPresent\n            command:\n              - mongod\n              - \"--replSet\"\n              - rs0\n            ports:\n              - containerPort: 27017\n            volumeMounts:\n              - name: mongo-persistent-storage\n                mountPath: /data/db\n          - name: mongo-sidecar\n            image: cvallance/mongo-k8s-sidecar\n    ...\n    ...\n      volumeClaimTemplates:\n        - metadata:\n            name: mongo-persistent-storage\n          spec:\n            storageClassName: \"openebs-csi-sc\"\n            accessModes: [\"ReadWriteOnce\"]\n            resources:\n              requests:\n                storage: 5Gi\n\nAfter applying the above YAML. This results in the provisioning of volumes with **5Gi** capacity as mentioned in **volumeClaimTemplates,** and applications are in Running state.\n\n    system@master$ kubectl get pods -n mongo-ns\n    NAME      READY   STATUS    RESTARTS   AGE\n    mongo-0   2/2     Running   0          8m24s\n    mongo-1   2/2     Running   0          7m5s\n    mongo-2   2/2     Running   0          6m4s\n    \n    -----------------------------------------------------------------------------------\n    system@master$ kubectl get pvc -n mongo-ns\n    NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS     AGE\n    mongo-persistent-storage-mongo-0   Bound    pvc-4926e6bb-3226-4de9-add5-e603ea2b948b   5Gi        RWO            openebs-csi-sc   6m48s\n    mongo-persistent-storage-mongo-1   Bound    pvc-fcde1fde-65ee-48ab-8f79-b7c68edfb934   5Gi        RWO            openebs-csi-sc   5m29s\n    mongo-persistent-storage-mongo-2   Bound    pvc-d94e5304-7f29-4d6c-b157-1e65f75511f1   5Gi        RWO            openebs-csi-sc   4m28s\n\nNow verify the size of the volume by exec into any one of the application pods. In below output **/dev/sde **is the persistent volume and it’s capacity is **5G**.\n\n    system@master$ kubectl exec -it mongo-0 -n mongo-ns -c mongo -- df -h\n    Filesystem      Size  Used Avail Use% Mounted on\n    overlay          98G   12G   82G  13% /\n    tmpfs            64M     0   64M   0% /dev\n    tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup\n    /dev/sde        4.8G  311M  4.5G   7% /data/db\n    /dev/sda1        98G   12G   82G  13% /etc/hosts\n    shm              64M     0   64M   0% /dev/shm\n    tmpfs           3.9G   12K  3.9G   1% /run/secrets/kubernetes.io/serviceaccount\n    tmpfs           3.9G     0  3.9G   0% /proc/acpi\n    tmpfs           3.9G     0  3.9G   0% /proc/scsi\n    tmpfs           3.9G     0  3.9G   0% /sys/firmware\n\nNow, let’s resize the volume capacity by following the steps mentioned in the blog's beginning.\n\nStep1: Increase the volume size of PVC\n\nExpand the size of the PVC size by applying below command on all the StatefulSet volumes:\n\n    kubectl patch pvc mongo-persistent-storage-mongo-0 -p '{ \"spec\": { \"resources\": { \"requests\": { \"storage\": \"15Gi\" }}}}' -n mongo-ns\n    \n    kubectl patch pvc mongo-persistent-storage-mongo-1 -p '{ \"spec\": { \"resources\": { \"requests\": { \"storage\": \"15Gi\" }}}}' -n mongo-ns\n    \n    \n    kubectl patch pvc mongo-persistent-storage-mongo-2 -p '{ \"spec\": { \"resources\": { \"requests\": { \"storage\": \"15Gi\" }}}}' -n mongo-ns\n\nAfter patching the above PVCs **openebs-cstor-csi **plugin is responsible for performing the resize operation on cStor volume. Verify whether volumes are expanded successfully by performing the following commands\n\n    system@master:  kubectl get pvc -n mongo-ns\n    NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS     AGE\n    mongo-persistent-storage-mongo-0   Bound    pvc-4926e6bb-3226-4de9-add5-e603ea2b948b   15Gi       RWO            openebs-csi-sc   32m\n    mongo-persistent-storage-mongo-1   Bound    pvc-fcde1fde-65ee-48ab-8f79-b7c68edfb934   15Gi       RWO            openebs-csi-sc   30m\n    mongo-persistent-storage-mongo-2   Bound    pvc-d94e5304-7f29-4d6c-b157-1e65f75511f1   15Gi       RWO            openebs-csi-sc   29m\n\nAbove PVC shows that volumes are expanded successfully. Now verify capacity by exec in to any one of the application pods\n\n    system@master$ kubectl exec -it mongo-0 -n mongo-ns -c mongo -- df -h\n    Filesystem      Size  Used Avail Use% Mounted on\n    overlay          98G   12G   82G  13% /\n    tmpfs            64M     0   64M   0% /dev\n    tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup\n    /dev/sde         15G  313M   15G   3% /data/db\n    /dev/sda1        98G   12G   82G  13% /etc/hosts\n    shm              64M     0   64M   0% /dev/shm\n    tmpfs           3.9G   12K  3.9G   1% /run/secrets/kubernetes.io/serviceaccount\n    tmpfs           3.9G     0  3.9G   0% /proc/acpi\n    tmpfs           3.9G     0  3.9G   0% /proc/scsi\n    tmpfs           3.9G     0  3.9G   0% /sys/firmware\n\nNote: This step only helps to resize the volumes that are already provisioned for consuming via statefulsets. If StatefulSet is scaled up, then the newly provisioning volume will have the old size(since the volumeClaimTemplate is not yet updated in the application spec).\n\n**Step2: Update StatefulSet volumeClaimTemplate storage size**\n\nSince natively resizing of statefulset volumeClaimTemplates is not yet supported in Kubernetes, one needs to follow this step to update size in the volume claim template. For further updates, track the enhancement proposal [here](https://github.com/kubernetes/enhancements/pull/1848).\n\nUpdate the capacity in volumeClaimTemplate of applied statefulset yaml lke below example:\n\n    system@master$ cat mongo-sts.yaml\n    cat mongo-sts.yaml \n    apiVersion: apps/v1\n    kind: StatefulSet\n    metadata:\n      name: mongo\n      namespace: mongo-ns\n    spec:\n      selector:\n        matchLabels:\n          role: mongo\n          environment: test\n      serviceName: \"mongo\"\n      replicas: 3\n    ...\n    ...\n      volumeClaimTemplates:\n        - metadata:\n            name: mongo-persistent-storage\n          spec:\n            storageClassName: \"openebs-csi-sc\"\n            accessModes: [\"ReadWriteOnce\"]\n            resources:\n              requests:\n                storage: 15Gi\n\nNow delete the statefulset without deleting the statefulset pods for not to have any down time for application and apply the updated volumeClaimTemplate.\n\n    system@master$ kubectl delete sts mongo -n mongo-ns --cascade=false\n    statefulset.apps \"mongo\" deleted\n    \n    system@master$ kubectl apply -f mongo-sts.yaml \n    statefulset.apps/mongo created\n    service/mongo unchanged\n\nVerify changes by describing the sts\n\n    system@master$ kubectl describe sts mongo -n mongo-ns\n    \n    Name:               mongo\n    Namespace:          mongo-ns\n    CreationTimestamp:  Mon, 17 Aug 2020 16:38:51 +0530\n    Selector:           environment=test,role=mongo\n    ...\n    ...\n    Volume Claims:\n      Name:          mongo-persistent-storage\n      StorageClass:  openebs-csi-sc\n      Labels:        <none>\n      Annotations:   <none>\n      Capacity:      15Gi\n      Access Modes:  [ReadWriteOnce]\n\nIn the above output, capacity has been updated from **5Gi** to **15Gi**. So successfully updated the statefulset capacity without any down time.\n","slug":"resize-kubernetes-statefulsets-without-impact"},{"id":19,"title":"Handling node down/cluster scaling on LocalPV backed workloads","author":"Ranjith Raveendran","author_info":"Ranjith is working as a Software Engineer at MayaData and working in the OpenEBS project. In his free time, he listens to music, watches movies, and goes for bike riding.","date":"21-08-2020","tags":["Localpv"," Openebs"],"excerpt":"In this article, we'll discuss the steps that is getting handled when a node down/cluster scaling on LocalPV backs workloads.","content":"\nKubernetes is increasingly used for running production-grade stateful services. Organizations are making progress on a containerized form of their production workloads for running in Kubernetes. There are already solutions available for the containerized version of stateful applications, network, storage, etc.\n\n### Handling node down / cluster scaling on Local PV backed workloads\n\nOpenEBS is one of the leading containerized storage solutions for Kubernetes, and it is a rapidly growing Sandbox project in CNCF. MayaData is the primary maintainer and contributor of OpenEBS along with other companies. MayaData also contributed another open source project, Litmus, into CNCF, which does mostly Chaos engineering in Kubernetes, which helps SREs and developers to do all kinds of testing of their applications and components in Kubernetes before going into production.\n\nIt is a must requirement of a persistent storage solution for running the stateful application, be it a **Deployment **or **StatefulSet**. OpenEBS provides many storage engines, and each storage engine is suitable for specific applications or workloads. Some engines provide storage level synchronous replication, capable of taking snapshots and cloning, backup and restore, volume expansion, CSI complaint, performance-oriented, etc. So choosing the engine based on the workload requirement is an important activity.\n\nOpenEBS provides dynamic provisioning of LocalPV using an external device, and this external device will be allocated entirely to an application. You can also use the partitioned disk for using OpenEBS LocalPV by using the `openebs-hostpath` storage engine. In this article, we provisioned a MySQL deployment on an OpenEBS LocalPV device dynamically.\n\nThis article is a step-by-step instruction. We will mention how a MySQL application deployment running on ***OpenEBS LocalPV ***device volume is getting handled when a Node down scenario or a cluster scale down situation happens in the GKE cluster. In GKE and some other managed clusters like EKS, the node name will change if the cluster undergoes a scale down and scale-up operation has performed. So the application running on the ***OpenEBS LocalPV*** device will not be able to attach to the new node since the corresponding PV has volume node affinity. We need to update the new node name details in PV, where the disk got attached.\n\nIn this article, we discuss the steps that need to be performed to make the application into a running state when a Node down / scale down cluster scenario has happened. This situation is usually required in case of managed clusters where the node name will get changed during this scenario. As stated earlier, the following approach works fine for both Deployment type and StatefulSet type, but ensure that the following steps are correctly satisfied. Let’s start with the step by step instructions once you have scaled up the cluster after a scale down scenario.\n\n1. Verify all nodes are now in Ready state.\n    ```\n    $ kubectl get node\n    NAME                                           STATUS   ROLES    AGE   VERSION\n    gke-openebs-mysql-default-pool-d55297a7-bjjp   Ready    <none>   74s   v1.16.13-gke.1\n    gke-openebs-mysql-default-pool-d55297a7-j1vm   Ready    <none>   80s   v1.16.13-gke.1\n    gke-openebs-mysql-default-pool-d55297a7-pvg4   Ready    <none>   85s   v1.16.13-gke.1\n\n2. Ensure OpenEBS pods are in Running state.\n    ```\n    $ kubectl get pod -n openebs\n    NAME                                           READY   STATUS    RESTARTS   AGE\n    maya-apiserver-76cb4df9b8-wpbf6                1/1     Running   0          22m\n    openebs-admission-server-5cf696b8d5-d97bn      1/1     Running   0          22m\n    openebs-localpv-provisioner-7654f6dbd9-hskq8   1/1     Running   0          22m\n    openebs-ndm-7dtts                              1/1     Running   0          2m19s\n    openebs-ndm-c4r4m                              1/1     Running   0          2m23s\n    openebs-ndm-lnb5c                              1/1     Running   0          2m12s\n    openebs-ndm-operator-6cfc59b69b-684nx          1/1     Running   0          22m\n    openebs-provisioner-7d9884d4ff-tfcxj           1/1     Running   0          22m\n    openebs-snapshot-operator-7ff577c889-kfttj     2/2     Running   0          22m\n\n3. Check the status of the application pod. It will be in the `Pending` state.\n    ```\n    $ kubectl get pod\n    NAME                      READY   STATUS    RESTARTS   AGE\n    percona-9fbdb8678-lncd5   0/1     Pending   0          17m\n\n4. Label all the nodes with the same custom label used in the `nodeSelector` field in the STS app. In my case, there is no custom node label used in application deployment. So we are skipping this step.\n\n5. Attach the disk randomly to any node in the same zone. Note down the device name and node name where it is getting attached. This information will be needed in step 9.\n    ```\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-d55297a7-bjjp --disk mysql-disk1 --device-name mysql-disk1 --zone=us-central1-c\n\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-d55297a7-j1vm --disk mysql-disk2 --device-name mysql-disk2 --zone=us-central1-c\n\n    $ gcloud compute instances attach-disk gke-openebs-mysql-default-pool-d55297a7-pvg4 --disk mysql-disk3 --device-name mysql-disk3 --zone=us-central1-c\n\n6. Verify BDs are updated with new node names\n    ```\n    $ kubectl get bd -n openebs\n    NAME                                           NODENAME                                       SIZE          CLAIMSTATE   STATUS   AGE\n    blockdevice-4f51859193d333687a873af7acf8ad78   gke-openebs-mysql-default-pool-d55297a7-j1vm   32212254720   Unclaimed    Active   37m\n    blockdevice-967d7816c2a2d73b91c8c6310dc70465   gke-openebs-mysql-default-pool-d55297a7-bjjp   32212254720   Claimed      Active   37m\n    blockdevice-ddfc782ea661fc9007a896438f483e3d   gke-openebs-mysql-default-pool-d55297a7-pvg4   32212254720   Unclaimed    Active   37m\n\n7. Get the PV details of the associated application\n    ```\n    $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS     REASON   AGE\n    pvc-5cd17649-efe4-46e1-a5f3-f779b0e03999   5G         RWO            Delete           Bound    default/demo-vol1-claim   openebs-device            33m\n\n8. Create a directory and copy the YAML spec of all the associated PVs into it like below\n    ```\n    $ mkdir mysql-restore\n    $ cd mysql-restore/\n    $ kubectl get pv pvc-5cd17649-efe4-46e1-a5f3-f779b0e03999 -o yaml --export > pv1.yaml\n    ```\n    Note: If it is StatefulSet, take the YAML spec of all the associated PVs of that application.\n\n9. Modify the above-copied YAML with the new hostname in the copied YAML of PV. The following is that snippet of PV spec where it mentions the new node name where the Local disk is attached.\n    ```\n    path: /dev/disk/by-id/scsi-0Google_PersistentDisk_mysql-disk1\n      nodeAffinity:\n        required:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: kubernetes.io/hostname\n              operator: In\n              values:\n              - gke-openebs-mysql-default-pool-d55297a7-bjjp\n\n10. Now get the PV and then delete the PV\n   \n    ```\n    $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS     REASON   AGE\n    pvc-5cd17649-efe4-46e1-a5f3-f779b0e03999   5G         RWO            Delete           Bound    default/demo-vol1-claim   openebs-device            36m\n \n    $ kubectl delete pv pvc-5cd17649-efe4-46e1-a5f3-f779b0e03999\n    persistentvolume \"pvc-5cd17649-efe4-46e1-a5f3-f779b0e03999\" deleted\n    ```\n    The deletion of the PV will not be completed since it has the finaliser set with the PV. So we need to cancel the ongoing operation and then edit the PV and remove Finalizers. Once finalizers are removed, the volume will be automatically deleted.\n\n11. Verify that the PV of the application has been removed successfully.\n    ```\n    $ kubectl get pv\n    No resources were found in the default namespace.\n\n12. Now, apply the updated YAML files of the PV.\n    ```\n    $ kubectl apply -f  pv1.yaml \n    ```\n    Note: Perform the same for other PVs as well if the application is a StatefulSet.\n\n13. Verify that if PODs are started `Running` from `Pending` state.\n    ```\n    $ kubectl get pod -o wide\n    NAME                      READY   STATUS    RESTARTS   AGE   IP          NODE                                           NOMINATED NODE   READINESS GATES\n    percona-9fbdb8678-lncd5   1/1     Running   0          29m   10.16.0.2   gke-openebs-mysql-default-pool-d55297a7-bjjp   <none>           <none>\n\n14. Log in to the application and verify that you are able to access the data.\n\n    ```\n    $ kubectl exec -it percona-9fbdb8678-lncd5 sh\n    kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\n    sh-4.2$ mysql -uroot -pk8sDem0;\n    mysql: [Warning] Using a password on the command line interface can be insecure.\n    Welcome to the MySQL monitor.  Commands end with ; or \\g.\n    Your MySQL connection id is 2\n    Server version: 5.7.30-33 Percona Server (GPL), Release 33, Revision 6517692\n    \n    Copyright (c) 2009-2020 Percona LLC and/or its affiliates\n    Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n    \n    Oracle is a registered trademark of Oracle Corporation and/or its\n    affiliates. Other names may be trademarks of their respective\n    owners.\n    \n    Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\n    mysql> SHOW DATABASES;\n    +--------------------+\n    | Database           |\n    +--------------------+\n    | information_schema |\n    | mysql              |\n    | performance_schema |\n    | pets               |\n    | sys                |\n    +--------------------+\n    5 rows in set (0.07 sec)\n    \n    mysql> use pets;\n    \n    Reading table information for completion of table and column names\n    You can turn off this feature to get a quicker startup with -A\n    \n    Database changed\n    mysql> SELECT * FROM cats;\n    +----+---------+--------+------------+\n    | id | name    | owner  | birth      |\n    +----+---------+--------+------------+\n    |  1 | Sandy   | Lennon | 2015-01-03 |\n    |  2 | Cookie  | Casey  | 2013-11-13 |\n    |  3 | Charlie | River  | 2016-05-21 |\n    +----+---------+--------+------------+\n    3 rows in set (0.00 sec)","slug":"handling-node-downcluster-scaling-on-localpv-backed-workloads"},{"id":20,"title":"OpenEBS-Velero backup/restore of stateful applications","author":"Vishnu Itta","author_info":"Developer who is always eager to learn, loves math, algorithms, & programming. Have a good experience in storage protocols, ZFS, FreeBSD internals, Linux, device drivers.","date":"04-08-2020","tags":["Openebs"," Velero"],"excerpt":"In this blog, we will go through the backup/restore solution provided to its users by OpenEBS with the help of Velero.","content":"\n### **Backup/Restore of stateful applications in OpenEBS**\n\nSREs play a crucial role in automating operations. This role includes handling infrastructure upgrades and the upgrades of software running on that infrastructure. When running stateful workloads, the data must be backed up before any upgrades.\n\nAdditionally, workloads on Kubernetes are often different than traditional monolithic applications since Kubernetes supports microservices and loosely coupled workloads. This brings-in the need for a `cloud-native` design of backup/restore per workload or application. Once implemented this approach provides benefits to users such as an app-centric view, ease of management, setting of RPO/RTO at the workload level, and others. To learn more about cloud native backup drivers and requirements - please read this [thenewstack.io article](https://thenewstack.io/cloud-native-backups-disaster-recovery-and-migrations-on-kubernetes/).\n\nThe below graphic shows microservices, and their loosely coupled nature. Managing backups and the tuning of RPO/RTO per microservice is required to preserve the loosely coupled nature of these workloads and of the teams responsible for them.\n![Openebs Velero backup/restore of stateful applications: fig 1](https://lh4.googleusercontent.com/JyIxZZtj-1rBOGo2z1bKcYlD9-halM8dXpChtOIPro_aZEhQObTL_K5_Be_hLgqXl7aT68jYqFjNE9C6rZK0IRaV_neH4DURZhUr3z5FkVirzMirk_z8FiscY6_sb3JPhlAx1XRL)\nThe following are **challenges** in redesigning backup/restore of K8s applications:\n\n- Ability to look from the application view rather than only the data\n- Dependencies with K8s constructs like node names, PVCs, storage classes, topologies in them\n- Snapshots of selected volumes rather than entire mount point/disk in hyper-converged infrastructure\n- K8s application deployment workflow to copy data during a restore whether using operators or another method\n\nIn this blog, we will go through a backup/restore solution for ***OpenEBS ***with the help of ***Velero***. OpenEBS is leading open source container attached storage solution, and Velero is one of the most used open-source tools for backups in Kubernetes environments.\n\n### **Backup/Restore solution**\n\nThis solution, with Velero, provides a declarative way for users to specify\n\n- object storage as the destination location to store backed-up data\n- K8s applications and its resources which are part of the backup\n- storage provider configuration to backup/restore data\n- schedules to take a backup at regular intervals\n- restore selected resources from the selected backup\n- app-specific hooks to execute before and after performing backup/restore\n\nLet's start by examining what OpenEBS, as container attached storage, offers. It has many kinds of storage engines as below:\n\n- Local PV host path and block device\n- Jiva\n- CStor\n- Local PV ZFS\n\n### **Local PV / Jiva Volumes + Restic + Restore Item Action plugin**\n\nOpenEBS Local PV volumes are prominent among cloud-native applications. These applications themselves take care of replicating data and snapshotting. As the name suggests, these are used in hyper-converged infrastructure. This brings in a few challenges during backup/restoration.\n\nLocal PVs related storage classes will have `WaitForFirstConsumer`. It provides delayed binding of volumes until Pod gets scheduled on the node. K8s sets the node name as an annotation on PVC. Restoring that PVC onto the destination cluster will leave the pod in pending state. This solution takes care of it by applying node name mapping in PVC annotation. Restore Item Action plugin, contributed by OpenEBS, in Velero performs this mapping.\n\nVelero's in-built file-based `Restic` plugin helps in backing up the application's data. `Init` container will be injected into the application to copy data from the destination location to the volume.\n\nJiva volumes are used by applications that need replication functionality from storage providers. File-based `Restic` plugin can be used to backup/restore applications using jiva volumes.\n\n### **CStor / Local PV ZFS + Velero plugin**\n\nStandard applications use OpenEBS cStor volumes. These applications need replication, snapshotting, cloning, etc., from storage providers. Also, these applications are free to run-anywhere-in-the-cluster nature. OpenEBS have a cStor velero-plugin for crash-consistent backup of data. This plugin performs pausing of IOs on the volume before the snapshot is taken on all the replicas. It resumes IOs once the point-in-time snapshot is taken. It reads the snapshot content from one of the replicas and backs it up at the object location. When a Schedule is newly created, full data will be backed up at the destination location. The plugin manages the completion status of the backup. On the next iterations, the plugin just backups the changes from previous successful backup.\n\nBased on the replication settings of cStor at the destination, the plugin takes care of copying data to the configured number of replicas. The connection between iSCSI target pod and replica pods is not established until data is copied into the volume. This avoids usage of the PV by any application during restore time.\n\nCStor plugin also provides an option to keep backups locally with the main volume in the form of local snapshots. Users can create a backup of applications and with local snapshots. Restoring these backups, which consists of local snapshots, can be done in a different namespace of the same cluster.\n\nWork-related to local PV ZFS plugin is in-active development to provide all the features as mentioned above and much more.\n\n### **Summary**\n\nTo summarize, a new kind of thinking (or) a new kind of approach is required to do cloud-native backups. OpenEBS has made tremendous progress in achieving it and provides various features and flavors of backup/restoration of its volumes.\n\n- File-based\n- Point-in-time block-based local snapshot and restore\n- Full and incremental block-based remote backup and restore\n- Per-workload backups\n- K8s resources transformations\n\nCredits to the Velero team for building a wonderful open-source backup/restore tool.\n\nPlease visit [https://docs.openebs.io](https://docs.openebs.io/), [https://velero.io](https://velero.io/) for more details about storage class, backup/restore examples, Velero.\n","slug":"openebsvelero-backuprestore-of-stateful-applications"},{"id":21,"title":"Kubernetes StatefulSet on ppc64le using OpenEBS LocalPV provisioner","author":"Peeyush Gupta","author_info":"Peeyush, Sr. Developer Advocate, DigitalOcean, is a cloud enthusiast with 5+ years of experience in developing cloud platforms and helping customers migrate their legacy applications to the cloud.","date":"16-07-2020","tags":["Openebs"," Kubernetes"," Localpv"],"excerpt":"In this blog, we'll explain how to install OpenEBS on Kubernetes StatefulSet running on the ppc64le platform & to using the OpenEBS LocalPV provisioner to deploy a StatefulSet.","content":"\nGuest post by Peeyush Gupta, Sr. Developer Advocate, DigitalOcean\n\n**OpenEBS** is the leading open-source project for container-attached and container-native storage on **Kubernetes**. OpenEBS adopts Container Attached Storage (CAS) approach, where each workload is provided with a dedicated storage controller. OpenEBS implements granular storage policies and isolation that enable users to optimize storage for each specific workload. OpenEBS runs in userspace and does not have any Linux kernel module dependencies. Here is how the setup looks like for OpenEBS LocalPV hostpath:\n![Kubernetes StatefulSet on ppc64le using OpenEBS LocalPV provisioner](https://lh4.googleusercontent.com/-erccwTcJCmyJGswEZ3Pul1-pvJO-kvn34nr22mqYumR1IHUVhX8BWOeennt1u91EYUKtpUfAPBSiP1XD_1z6XYmG8Tlywvl9GellLpkr8EyYTFLXT3YpIZ_nneRcen_G8uKVV6Q)\nIn this tutorial, we will see how we can install OpenEBS on Kubernetes running on the ppc64le platform. Then we will use the OpenEBS LocalPV provisioner to deploy a StatefulSet. The ppc64le servers used in this tutorial are running on IBM Cloud.\nKubernetes support multi-arch platforms. You can deploy the cluster on ppc64le based servers using kubeadm. For this tutorial, I am using a 3 node cluster:\n\n    root@openebs-k8s-server:~# kubectl  get nodes\n    NAME                 STATUS   ROLES    AGE   VERSION\n    openebs-k8s-server   Ready    master   17h   v1.18.5\n    openebs-worker-1     Ready    <none>   17h   v1.18.5\n    openebs-worker-2     Ready    <none>   17h   v1.18.5\n\nWe will be deploying OpenEBS lite on this cluster. Here is an excellent blog post on how to do that: [https://help.mayadata.io/hc/en-us/articles/360031969532-Installing-OpenEBS-with-only-Local-PV-support](https://help.mayadata.io/hc/en-us/articles/360031969532-Installing-OpenEBS-with-only-Local-PV-support). To get started, deploy the openebs-operator-lite.yaml file for ppc64le using:\n\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite-ppc64le.yaml\n\nOnce deployed, you should be able to see the node-disk-manager and LocalPV components running. Note that node-disk-manager is not a mandatory component for provisioning LocalPV hostpath volumes . OpenEBS LocalPV provisioner can be installed and run standalone as well.\n\n    root@openebs-k8s-server:~# kubectl  get pods --all-namespaces\n    NAMESPACE     NAME                                           READY   STATUS    RESTARTS   AGE\n    kube-system   coredns-66bff467f8-njjc9                       1/1     Running   0          17h\n    kube-system   coredns-66bff467f8-tndsx                       1/1     Running   0          17h\n    kube-system   etcd-openebs-k8s-server                        1/1     Running   0          17h\n    kube-system   kube-apiserver-openebs-k8s-server              1/1     Running   0          17h\n    kube-system   kube-controller-manager-openebs-k8s-server     1/1     Running   0          17h\n    kube-system   kube-proxy-55fbj                               1/1     Running   0          17h\n    kube-system   kube-proxy-gt5rw                               1/1     Running   0          17h\n    kube-system   kube-proxy-l5pz2                               1/1     Running   0          17h\n    kube-system   kube-scheduler-openebs-k8s-server              1/1     Running   0          17h\n    kube-system   weave-net-c2gmk                                2/2     Running   1          17h\n    kube-system   weave-net-qp5c7                                2/2     Running   0          17h\n    kube-system   weave-net-trgr6                                2/2     Running   1          17h\n    openebs       openebs-localpv-provisioner-7bb7dc9958-ln284   1/1     Running   0          16h\n    openebs       openebs-ndm-kqhpr                              1/1     Running   0          16h\n    openebs       openebs-ndm-nxswk                              1/1     Running   0          16h\n    openebs       openebs-ndm-operator-746d6cd4fd-bm2fp          1/1     Running   1          16h\n\nNext, we will deploy the storage class. This storage class will be used with PersistentVolumeClaim to create volumes.\n\n    kubectl apply -f https://openebs.github.io/charts/openebs-lite-sc.yaml \n\nThis will create 2 storage classes, openebs-device, and openebs-hostpath, on the cluster. \n\n    root@openebs-k8s-server:~/openebs-localpv# kubectl  get sc\n    NAME               PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\n    openebs-device     openebs.io/local   Delete          WaitForFirstConsumer   false                  6m12s\n    openebs-hostpath   openebs.io/local   Delete          WaitForFirstConsumer   false                  6m12s\n\nIn our case, we are interested in the `openebs-hostpath` storage class for this tutorial. Now, we are ready to deploy the StatefulSet that will consume the volume created using the above storage class. Here is a sample StatefulSet:\n\n    apiVersion: apps/v1\n    kind: StatefulSet\n    metadata:\n      name: local-test\n    spec:\n      serviceName: \"local-service\"\n      replicas: 1\n      selector:\n        matchLabels:\n          app: local-test\n      template:\n        metadata:\n          labels:\n            app: local-test\n        spec:\n          containers:\n          - name: test-container\n            image: busybox\n            command:\n            - \"/bin/sh\"\n            args:\n            - \"-c\"\n            - \"sleep 100000\"\n            volumeMounts:\n            - name: openebs-localpv-hostpath\n              mountPath: /usr/test-pod\n      volumeClaimTemplates:\n      - metadata:\n          name: openebs-localpv-hostpath\n        spec:\n          accessModes: [ \"ReadWriteOnce\" ]\n          storageClassName: \"openebs-hostpath\"\n          resources:\n            requests:\n              storage: 5G\n\nThe above YAML creates a StatefulSet named `local-test`, which has a container named `test-container`. This container has a volume mounted at path `/usr/test-pod`. The claim for this particular volume references the `openebs-hostpath` storage class. We will save this YAML using the name openebs-localpv-stateful.yaml, and this can be deployed using kubectl create:\n\n    kubectl apply -f openebs-localpv-stateful.yaml\n\nYou can verify the respective pv and pvc:\n\n    root@openebs-k8s-server:~/openebs-localpv# kubectl  get pvc\n    NAME                                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE\n    openebs-localpv-hostpath-local-test-0   Bound    pvc-e61a4156-b0bb-4199-b991-9c42b1830ec5   5G         RWO            openebs-hostpath   17s\n    root@openebs-k8s-server:~/openebs-localpv# kubectl  get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                           STORAGECLASS       REASON   AGE\n    pvc-e61a4156-b0bb-4199-b991-9c42b1830ec5   5G         RWO            Delete           Bound    default/openebs-localpv-hostpath-local-test-0   openebs-hostpath            18s\n\nOnce the volume is bound to the claim, the relevant pod i.e. local-test-0 comes up in running state:\n\n    root@openebs-k8s-server:~/openebs-localpv# kubectl  get pods --all-namespaces\n    NAMESPACE     NAME                                           READY   STATUS    RESTARTS   AGE\n    default       local-test-0                                   1/1     Running   0          13s\n    kube-system   coredns-66bff467f8-njjc9                       1/1     Running   0          21h\n    kube-system   coredns-66bff467f8-tndsx                       1/1     Running   0          21h\n    kube-system   etcd-openebs-k8s-server                        1/1     Running   0          21h\n    kube-system   kube-apiserver-openebs-k8s-server              1/1     Running   0          21h\n    kube-system   kube-controller-manager-openebs-k8s-server     1/1     Running   0          21h\n    kube-system   kube-proxy-55fbj                               1/1     Running   0          21h\n    kube-system   kube-proxy-gt5rw                               1/1     Running   0          21h\n    kube-system   kube-proxy-l5pz2                               1/1     Running   0          21h\n    kube-system   kube-scheduler-openebs-k8s-server              1/1     Running   0          21h\n    kube-system   weave-net-c2gmk                                2/2     Running   1          21h\n    kube-system   weave-net-qp5c7                                2/2     Running   0          21h\n    kube-system   weave-net-trgr6                                2/2     Running   1          21h\n    openebs       openebs-localpv-provisioner-6fc9664557-njvbg   1/1     Running   0          24m\n    openebs       openebs-ndm-754qs                              1/1     Running   0          24m\n    openebs       openebs-ndm-operator-798f74c6b9-24jvv          1/1     Running   0          24m\n    openebs       openebs-ndm-x96ks                              1/1     Running   0          24m\n\nIf you describe the pvc, you can see the volume is being provisioned using openebs-localpv-provsioner:\n\n    root@openebs-k8s-server:~/openebs-localpv# kubectl  describe pvc\n    Name:          openebs-localpv-hostpath-local-test-0\n    Namespace:     default\n    StorageClass:  openebs-hostpath\n    Status:        Bound\n    Volume:        pvc-b89a1c70-beeb-4bdc-a555-348b01832443\n    Labels:        app=local-test\n    Annotations:   pv.kubernetes.io/bind-completed: yes\n                   pv.kubernetes.io/bound-by-controller: yes\n                   volume.beta.kubernetes.io/storage-provisioner: openebs.io/local\n                   volume.kubernetes.io/selected-node: openebs-worker-1\n    Finalizers:    [kubernetes.io/pvc-protection]\n    Capacity:      5G\n    Access Modes:  RWO\n    VolumeMode:    Filesystem\n    Mounted By:    local-test-0\n    Events:\n      Type    Reason                 Age                From                                                                                                Message\n      ----    ------                 ----               ----                                                                                                -------\n      Normal  WaitForFirstConsumer   13s                persistentvolume-controller                                                                         waiting for first consumer to be created before binding\n      Normal  ExternalProvisioning   13s (x2 over 13s)  persistentvolume-controller                                                                         waiting for a volume to be created, either by external provisioner \"openebs.io/local\" or manually created by system administrator\n      Normal  Provisioning           13s                openebs.io/local_openebs-localpv-provisioner-6fc9664557-njvbg_884920b8-e474-4635-9daf-8b4a8f113b10  External provisioner is provisioning volume for claim \"default/openebs-localpv-hostpath-local-test-0\"\n      Normal  ProvisioningSucceeded  11s                openebs.io/local_openebs-localpv-provisioner-6fc9664557-njvbg_884920b8-e474-4635-9daf-8b4a8f113b10  Successfully provisioned volume pvc-b89a1c70-beeb-4bdc-a555-348b01832443\n\nYou can cleanup the whole setup using:\n\n    kubectl delete -f openebs-localpv-stateful.yaml\n    kubectl delete -f openebs-lite-sc.yaml\n    kubectl delete -f openebs-operator-lite-ppc64le.yaml\n\n### About the author:\n\nPeeyush Gupta is a cloud enthusiast with 5+ years of experience in developing cloud platforms and helping customers migrate their legacy applications to the cloud. He has also been a speaker at multiple meetups and loves to contribute to open-source projects. He is currently working with DigitalOcean as Sr. Developer Advocate.\n","slug":"kubernetes-statefulset-on-ppc64le-using-openebs-localpv-provisioner"},{"id":22,"title":"Data Migration Within Kubernetes Clusters","author":"Sai Chaithanya","author_info":"A developer whos is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate towards Data Science. Enjoys playing kabaddi and traveling.","date":"02-07-2020","tags":["Kubernetes"],"excerpt":"In this blog, we'll talk about migrating data within Kubernetes from one node to another without any downtime of the application.","content":"\nIn large scale environments, storage is one of the hard things to manage, and it will be the most crucial component as it has DATA with it. OpenEBS, leading open source Cloud Native Storage, makes managing storage easier in Kubernetes environments. Mayadata, the company behind the OpenEBS project, has the vision of achieving data agility by transforming Kubernetes as a data plane. cStor is one of the storage engines of OpenEBS. \nThis blog is for OpenEBS users, specifically **cStor CSI** users looking to **migrate data within Kubernetes** from one node to another without any downtime of the application.\n\n![Data Migration from Kubernetes from Node2 to Node3](/images/blog/2020/07/Data-migration-diagram.png)Migrate data from Node2 to Node3\n\n### Create cStor Pools(CSPC):\n\nCreate cStor pools by following the steps mentioned [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md). Once the pools are created, wait till all the cStor pools marked as Healthy. Check the cStor pools status by executing `kubectl get cspc -n openebs` command(cspc - cStorPoolCluster)\n\n    NAME            HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE\n    cspc-stripe-pool   3                  3                       3              4m13s\n\nFollowing command `kubectl get cspi -n openebs`(cStorPoolInstances) will be helpful to know more information about the pool.\n\n    NAME                   HOSTNAME   ALLOCATED FREE CAPACITY READONLY  TYPE   STATUS  AGE\n    cspc-stripe-pool-6qkw  e2e1-node1   230k    9630M   10G   false   stripe   ONLINE  21m\n    cspc-stripe-pool-pn9p  e2e1-node2   230k    9630M   10G   false   stripe   ONLINE  12s\n    cspc-stripe-pool-psz5  e2e1-node3   230k    9630M   10G   false   stripe   ONLINE  21m\n\n### Create CSI Volume:\n\nCreate CSI volumes on cStor pools created above by following the steps mentioned [here](https://github.com/openebs/cstor-csi#provision-a-cstor-volume-using-openebs-cstor-csi-driver). As part of volume provisioning, a resource called `CStorVolumeConfig` will be created. Once the volume is provisioned successfully, then CVC(cStorVolumeConfig) status will update to Bound, which means all the CStorVolume resources are successfully created. Following is the command which will help to get CVC status `kubectl get cvc -n openebs`.\n\n    NAME                                       STATUS     AGE\n    pvc-d1b26676-5035-4e5b-b564-68869b023306   Bound      5m56s\n    \n\n### **Inspect CVC**:\n\nInterfere CVC to know on which node data exists. When we do `kubectl get cvc <PV_NAME> -n <openebs_namespace> -o yaml`.\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorVolumeConfig\n    name: pvc-d1b26676-5035-4e5b-b564-68869b023306\n    …\n    …\n    spec:\n      capacity:\n        storage: 5Gi\n    ...\n    ...\n      policy:\n        replicaPoolInfo:\n        - poolName: cspc-stripe-pool-6qkw\n        - poolName: cspc-stripe-pool-pn9p\n    status:\n      phase: Bound\n      poolInfo:\n      - cspc-stripe-pool-6qkw\n      - cspc-stripe-pool-pn9p\n\nFrom the above info CStorVolumeReplicas(CVR) are scheduled on cStor pools **cspc-stripe-pool-6qkw** and **cspc-stripe-pool-pn9p** from the **status.poolInfo** since above pools are on **e2e1-node1** and **e2e1-node2(**able to find node info from cspi output)sodata also will be available on the same node. Info under spec i.e **spec.policy.replicaPoolInfo** will convey where to schedule cStorVolumeReplicas.\n\nTo know more details of CVR we can get from `kubectl get cvr -n openebs`\n\n    NAME                                                             USED    ALLOCATED   STATUS     AGE\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-6qkw   1.47G    1.26G      Healthy    15h\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-pn9p   1.47G    1.26G      Healthy    15h\n\n**Steps to migrate data from one node to other:**\n\n1. Scale the CStorVolumeReplica to the desired Node.\n2. Scale down the CStorVolumeReplicas from unwanted Node.\n\n**Step1:****Scale the CStorVolumeReplicas to the desired node**\n\nGet cStor pool name, which doesn’t have corresponding volume CVR in it and add it under **spec.policy.replicaPoolInfo **of CVC.\n\nWe can get pool name name which doesn’t have CVR in it by comparing outputs of `kubectl get cspi -n openebs -l openebs.io/cstor-pool-cluster=<cspc_name>` and `kubectl get cvc <pv_name> -o yaml` as stated inspect CVC. In this example CVR of volume pvc-d1b26676-5035-4e5b-b564-68869b023306 doesn’t not exist in cStor pool **cspc-stripe-pool-psz5.** After finding the pool name add it under **policy.replicaPoolInfo** list in CVC.\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorVolumeConfig\n    name: pvc-d1b26676-5035-4e5b-b564-68869b023306\n    …\n    …\n    spec:\n    …\n    ...\n      policy:\n        replicaPoolInfo:\n        - poolName: cspc-stripe-pool-6qkw\n        - poolName: cspc-stripe-pool-pn9p\n        - poolName: cspc-stripe-pool-psz5\n    …\n    …\n    status:\n      poolInfo:\n      - cspc-stripe-pool-6qkw\n      - cspc-stripe-pool-pn9p\n      - cspc-stripe-pool-psz5\n\n**Superb!**\nOnce the pool was added into the `spec.replicaPoolInfo` then the status of CVC will be updated with a new pool name as shown above, and raise an event which means that CVR was created on a newly added pool. We can get the CVR status by executing `kubectl get cvr -n openebs`\n\n**Events**: Events on corresponding CVC\n\n    Events:\n    Type        Reason                Age                 From                         Message\n    ----      ------                  ----                ----                         -------\n    Normal   ScalingVolumeReplicas  14s (x2 over 15h)   cstorvolumeclaim-controller  successfully scaled volume replicas to 3\n\n**CVR status(by executing the command)**:\n\n    NAME                                                             USED    ALLOCATED           STATUS              AGE\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-6qkw   1.48G    1.25G              Healthy             16h\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-pn9p   1.48G    1.26G              Healthy             16h\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-psz5   91.4M    42.4M   ReconstructingNewReplica       33s\n\nIn the above output, newly created CVRs convey that it reconstructed data from scratch by talking to peer replicas. Wait till the newly created CVR marked as **Healthy**. To know status periodically execute `kubectl get cvr -n openebs` command.\n\n    NAME                                                             USED    ALLOCATED           STATUS           AGE\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-6qkw   1.48G     1.25G             Healthy          16h\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-pn9p   1.48G     1.25G             Healthy          16h\n    pvc-d1b26676-5035-4e5b-b564-68869b023306-cspc-stripe-pool-psz5   1.48G     1.25G             Healthy          5m28s\n\nNote:\n\n- Reconstructing will take time, depending on the amount of data it has to rebuild.\n\n**Step2:** **Scale down the CStorVolumeReplicas from unwanted nodes**\n\nOnce the newly created CVR is marked as Healthy, then we can remove the unwanted pool name from Spec of CVC replicaInfo and save it. \n\nIn this example, I need to remove the data from the pool **cspc-stripe-pool-pn9p,** scheduled on **e2e1-node2.** Once the pool name is removed from CVC **spec.policy.replicaPoolInfo, **then corresponding CVR in that pool will be deleted. CVC will generate events and status of CVC also will be updated.\n\nEvents on CVR:\n\n    Events:\n    Type       Reason                  Age                       From                            Message\n    ----       ------                  ----                       ----                            -------\n    Warning    ScalingVolumeReplicas   4s (x2 over 64m)     cstorvolumeclaim-controller     Scaling down volume replicas from 3 to 2 is in progress\n    Normal     ScalingVolumeReplicas   4s (x2 over 64m)     cstorvolumeclaim-controller     successfully scaled volume replicas to 2\n\nFrom output of `kubectl get cspi -n openebs`\n\n    NAME                     HOSTNAME       ALLOCATED   FREE     CAPACITY    READONLY     TYPE       STATUS    AGE\n    cspc-stripe-pool-6qkw    e2e1-node1      1260M      8370M    9630M         false      stripe      ONLINE   17h\n    cspc-stripe-pool-pn9p    e2e1-node2      230k       9630M    9630M         false      stripe      ONLINE   16h\n    cspc-stripe-pool-psz5    e2e1-node3      1260M      8370M    9630M         false      stripe      ONLINE   17h\n\n**Perfect!**\n\nFrom the above storage usage, I can successfully migrate the data from one node to another without any downtime of the application.\n","slug":"data-migration-within-kubernetes-clusters"},{"id":23,"title":"Restricting cStor pool usage within a specified threshold value","author":"Giridhara Prasad","author_info":"Lead Engineer at Mayadata Inc. Giridhar is experienced in software test automation, chaos engineering. Currently, he's working on Litmus, an Open Source chaos engineering project.","date":"20-05-2020","tags":["Openebs"," cStor"],"excerpt":"Learn how to restrict cStor pool usage within a specified threshold value","content":"\ncStor is one of the storage engines provided by OpenEBS. The integral component of the cStor engine is its storage pool from which the volumes are created. The storage pool is constructed with the collection of block devices. When the pool is completely utilized, it may misbehave in such a way that the pool itself cannot be imported successfully to recover from failures.\n\nIn order to overcome this situation, cStor recommends the optimal usage of storage capacity in the pool by restricting the write I/Os by converting it into read-only when the threshold limit is exceeded. While creating cStor SPC, the field *roThresholdLimit* has to be specified in percentage value under pool spec as follows:\n\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n        roThresholdLimit: 80\n      blockDevices:\n        blockDeviceList:\n        - blockdevice-31e0768585cb80ed2352affa73ec94e2\n        - blockdevice-ab636ddeba8f8cd45f7e91a6b55c15e5\n        - blockdevice-75275112e966e43c2ac1311a7a492fac\n\nIn the above snippet, *roThresholdLimit: 80*  indicates that the pool will become read-only when the usage exceeds 80% of its total capacity. Upon trying to create the above SPC, the following CSPs will be created.\n\n    NAME              ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE      AGE\n    cstor-pool-0vl0   45G         4.7G   49.8G      Healthy   true      striped   2m8s\n    cstor-pool-qnm1   77K         49.7G   49.8G      Healthy   false      striped   2m8s\n    cstor-pool-x4gj   77K         49.7G   49.8G      Healthy   false      striped   2m8s\n\nThe read-only status of each CSP is indicated, as shown in the above template.\n\nWhen the usage of the pool crosses 80% of its actual capacity, it will become read-only. It means all the replicas in that pool won’t serve further write IOs irrespective of the amount of space they consumed. As an impact, if the persistent volumes do not have enough healthy storage replicas, then the volume will become read-only.\n\nThe status of active replica where write IOs were happening turns offline when the pool becomes read-only whereas, for the idle replica, it remains healthy. The sample output of CVR is as below. Here, one replica is in Offline state as its pool is in a read-only state.\n\n    k8s@master:kubectl get cvr -n openebs\n    NAME                                                                  USED    ALLOCATED   STATUS    AGE\n    pvc-261d6832-8b23-476c-8aa3-b95104e20030-cstor-pool-0vl0   1.15G   1.04G       Offline   23m\n    pvc-f38f5517-a7bc-492d-a6eb-27ac510ced3b-cstor-pool-qnm1   74.7K   17.7K       Healthy   23m56s\n\nThe *roThresholdLimit* is the configurable value. In case, if you want to increase/decrease the percentage value, it has to be modified at each CSP level. Editing at SPC config won’t be effective. In case if the administrator didn’t set the *roThresholdLimit* field during SPC creation, the default value would be set to, 85% considering it as the optimal value for usage. Administrators can set the roThresholdLimit value in CSP from 0 to 100 though the OpenEBS team won't recommend setting it to 100 percent.\nWhen the pool became read-only, the administrator can either increase the pool capacity by executing the steps specified [here](https://github.com/openebs/openebs-docs/blob/day_2_ops/docs/cstor_add_disks_to_spc.md) or increase the roThresholdLimit value in that CSP to make pool RW.\n","slug":"restricting-cstor-pool-usage-within-a-specified-threshold-value"},{"id":24,"title":"Getting started with K3s in vSphere and OpenEBS cStor","author":"Giridhara Prasad","author_info":"Lead Engineer at Mayadata Inc. Giridhar is experienced in software test automation, chaos engineering. Currently, he's working on Litmus, an Open Source chaos engineering project.","date":"26-03-2020","tags":["Openebs"],"excerpt":"In this blog, more of a tutorial, I will walk you through the steps to install K3OS and setup OpenEBS.","content":"\n[K3OS](https://github.com/rancher/k3os/) is a Linux distribution built to run lightweight Kubernetes clusters called[https://github.com/rancher/k3s/](https://github.com/rancher/k3s/)[K3s](https://github.com/rancher/k3s/). It is specifically designed only to have what is needed to run[https://github.com/rancher/k3s](https://github.com/rancher/k3s)[k3s.](https://github.com/rancher/k3s)\n\nIn this blog, more of a tutorial, I will walk you through the steps to install K3OS and setup OpenEBS, a CNCF project, and leading Open Source Container Attached Storage solution for Kubernetes Stateful Workloads.\n\n#### **Setting up K3OS in vSphere**\n\nK3OS kernel is forked from Ubuntu-18.04 LTS, and its userspace binaries are from alpine. So, you need to select Ubuntu Linux (64 bit) as the guest operating system while creating a virtual machine.\n\n![Select guest operating system](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage.png)\n\nDownload the latest K3OS iso file(currently v0.9.0) from its[https://github.com/rancher/k3os/releases](https://github.com/rancher/k3os/releases)[GitHub release](https://github.com/rancher/k3os/releases) page. Attach the iso file into a virtual machine and start it with the live installation option, as shown below.\n\nSelect the option *K3OS LiveCD & install* and boot the operating system.\n\n![Live installation](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-3.png)\n\nAfter booting up successfully, you will be landed in a login prompt. The default user in K3OS is rancher. You can login as rancher user without any password.\n\n![Login prompt](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-6.png)\n\nAfter performing a live install, You need to install the Operating system into a disk and can configure the machine either as a server(Master) or an agent(worker). This can be performed by executing the command sudo k3os install.\n\nSelect option 1. Install to disk to install K3OS into the disk. In the preceding questions, set up a new password for rancher user for enabling ssh communication to the server.\n\n![Installing into disk](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-4.png)\n\n### \n**Installing into disk**\n\nYou need to select either server or agent to install the relevant components in the machine. Select 1.server to deploy K3s server components. You can set up a token or cluster secret that could be used while joining K3s agents to the server.\n\n![server installation](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-7.png)\n\nAfter completing the installation, a screen similar to the following one will be displayed.\n\n![Login prompt](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-1.png)\n\nThus, the K3s server can be configured successfully. In case if DHCP is not configured, you need to assign an IP address and other networking details using connmanctl utility. Login into the server as rancher user and enter the password configured in the previous step.\n\nLet us find the connman network service bound to the eth0 device by executing the below command.\n\n    sudo connmanctl services\n\nThe above command will list the services below.\n\n![connmanctl services](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-5.png)\n\nAfter identifying the service, you can assign the IP address, netmask, gateway, and DNS server through the following command.\n\n    sudo connmanctl config <ethernet service> --ipv4 manual <IP Address> <Netmask> <gateway> --nameservers <DNS Address>\n\nAfter executing the above command, ensure if the network is configured correctlly through ifconfig command.\n\nReboot the machine after setting up networking.\n\n#### **Install K3s agent**\n\nIn K3s nomenclature, Kubernetes workers are called as agents. While installing k3os into a disk, you need to select the option 2. agent to configure K3s agent in the machine.\n\n![Run K3s agent](/images/blog/2020/03/114---getting-started-with-k3s-in-vsphere-and-use-openebs-cstor-for-its-persistent-storage-2.png)\n\nAfter selecting Agent, you need to provide the URL of the server to which the agent has to be configured. The URL of the k3s server could be formed in the following way.\n\n    https://<K3s Server IP Address>:6443\n\nAfter entering the URL, you need to provide the cluster secret, which was configured during server installation.\n\nAfter providing all the above inputs, initiate the agent deployment.\n\nConfigure networking in the same way as performed above for server and reboot the machine.\n\nAfter rebooting the agent machine, check the cluster status in the server as follows.\n\n    k3os-1374 [~]$ kubectl get nodes\n    NAME         STATUS   ROLES    AGE     VERSION\n    k3os-1374    Ready    master   10m    v1.17.2+k3s1\n    k3os-15360   Ready    <none>   10m    v1.17.2+k3s1\n    k3os-1091    Ready    <none>   10m    v1.17.2+k3s1\n\nCheck if all the cluster components are configured successfully and all the pods are running successfully by executing the below command.\n\n    k3os-1374 [~]$ kubectl get pods -n kube-system\n    NAME                                      READY   STATUS      RESTARTS   AGE\n    helm-install-traefik-nmjvj                0/1     Completed   0          3d\n    svclb-traefik-gp9ff                       2/2     Running     1         2d23h\n    svclb-traefik-qgdlx                       2/2     Running     0         2d23h\n    local-path-provisioner-58fb86bdfd-wkdtm   1/1     Running     1         3d\n    metrics-server-6d684c7b5-mrxsr            1/1     Running     0         3d\n    svclb-traefik-c4v7l                       2/2     Running     0         3d\n    coredns-d798c9dd-td5tr                    1/1     Running     0         3d\n    traefik-6787cddb4b-n57jz                  1/1     Running     0         3d\n\n#### **Install OpenEBS**\n\nOpenEBS is a CNCF project delivering persistent block storage to the workloads deployed in Kubernetes.[https://docs.openebs.io/docs/next/cstor.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807](https://docs.openebs.io/docs/next/cstor.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807)[cStor](https://docs.openebs.io/docs/next/cstor.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807) is one of the storage engines provided by OpenEBS besides [https://docs.openebs.io/docs/next/jiva.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807](https://docs.openebs.io/docs/next/jiva.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807)[Jiva](https://docs.openebs.io/docs/next/jiva.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807) and   [https://docs.openebs.io/docs/next/localpv.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807](https://docs.openebs.io/docs/next/localpv.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807)[Local PV.](https://docs.openebs.io/docs/next/localpv.html?__hstc=216392137.6a5433d986ca5a9bb31cbcea3a03df67.1585216160857.1585216160857.1585216160857.1&amp;__hssc=216392137.1.1585216160858&amp;__hsfp=170476807)\n\ncStor was not supported in K3OS till k3os-v0.8.0 due to this[https://github.com/rancher/k3os/issues/151](https://github.com/rancher/k3os/issues/151)[issue](https://github.com/rancher/k3os/issues/151). This issue has been addressed in v0.9.0 by adding udev support.\n\n    k3os-1374 [~]$ kubectl apply -f openebs-operator-1.7.0.yaml \n    namespace/openebs created\n    serviceaccount/openebs-maya-operator created\n    clusterrole.rbac.authorization.k8s.io/openebs-maya-operator created\n    clusterrolebinding.rbac.authorization.k8s.io/openebs-maya-operator created\n    deployment.apps/maya-apiserver created\n    service/maya-apiserver-service created\n    deployment.apps/openebs-provisioner created\n    deployment.apps/openebs-snapshot-operator created\n    configmap/openebs-ndm-config created\n    daemonset.apps/openebs-ndm created\n    deployment.apps/openebs-ndm-operator created\n    deployment.apps/openebs-admission-server created\n    deployment.apps/openebs-localpv-provisioner created\n\nCheck if all the OpenEBS components are running successfully.\n\n    k3os-1374 [~]$ kubectl get pods -n openebs\n    NAME                                           READY   STATUS    RESTARTS   AGE\n    openebs-admission-server-f67f77588-8kl78       1/1     Running   0          65s\n    openebs-provisioner-7b8c68bf44-7bjw8           1/1     Running   0          66s\n    openebs-ndm-qp26v                              1/1     Running   0          66s\n    openebs-ndm-84zb4                              1/1     Running   0          66s\n    openebs-ndm-dzghs                              1/1     Running   0          66s\n    openebs-localpv-provisioner-5c87bbd974-55486   1/1     Running   0          65s\n    openebs-ndm-operator-5fccfb7976-dvhj6          1/1     Running   0          66s\n    openebs-snapshot-operator-6c4c64d4bc-qxdwd     2/2     Running   0          66s\n    maya-apiserver-84785d7fbd-ck7sh                1/1     Running   0          66s\n\nOpenEBS cStor engine requires external disks to be attached to the agents which group to form cStor Pools.\n\nThe disks or block devices are managed by the component called *Node disk manager, shortly called as* NDM. After attaching the disks to agent machines, check the block devices by executing the following command.\n\n    k3os-1374 [~]$ kubectl get blockdevices -n openebs\n    NAME                                           NODENAME     SIZE          CLAIMSTATE   STATUS   AGE\n    blockdevice-30a3eb18f5b9e2d470de45e39f1036b0   k3os-15360   17179869184   Unclaimed    Active   1h\n    blockdevice-86fc964305abe8970fc1508538a61dbc   k3os-1374    17179869184   Unclaimed    Active   1h\n    blockdevice-b8735721689d5843bca10e7028f60a4e   k3os-1091    17179869184   Unclaimed    Active   1h\n\nIn this case, one block device has been attached to each K3s agent machine. Let us populate these block devices in the below pool creation manifest under *spec.blockDevices* and create the pool.\n\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-disk-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-disk-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n      blockDevices:\n        blockDeviceList:\n        - blockdevice-30a3eb18f5b9e2d470de45e39f1036b0\n        - blockdevice-86fc964305abe8970fc1508538a61dbc \n        - blockdevice-b8735721689d5843bca10e7028f60a4e\n\nAfter applying the above definition, check if the pools are created successfully by executing the following command.\n\n    k3os-1374 [~]$ kubectl get csp\n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    TYPE      AGE\n    cstor-disk-pool-rgy3   270K        15.9G   15.9G      Healthy   striped   2m3s\n    cstor-disk-pool-gij4   270K        15.9G   15.9G      Healthy   striped   2m2s\n    cstor-disk-pool-09l1   270K        15.9G   15.9G      Healthy   striped   2m2s\n\nAll the pool instances should be healthy and each instance runs a pod which can be found by executing the following command.\n\n    k3os-1374 [~]$ kubectl get pods -n openebs -l app=cstor-pool\n    NAME                                    READY   STATUS    RESTARTS   AGE\n    cstor-disk-pool-rgy3-57f965b48c-srz2x   3/3     Running   0          8m33s\n    cstor-disk-pool-gij4-77bb4b8f44-s6k89   3/3     Running   0          8m33s\n    cstor-disk-pool-09l1-56d444996b-m698h   3/3     Running   0          8m33s\n\nAfter creating cStor pool, we can proceed to create volume. For illustration, let us deploy a busybox with cstor volume as its persistent storage. Before creating a pool, we need to create a storage class specifying the storagePoolClaim that was created in the above step as follows:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-cstor\n      annotations:\n        openebs.io/cas-type: cstor\n        cas.openebs.io/config: |\n          - name: StoragePoolClaim\n            value: \"cstor-disk-pool\"\n          - name: ReplicaCount\n            value: \"3\"\n    provisioner: openebs.io/provisioner-iscsi\n\nPopulate storagePoolClaim and ReplicaCount as per your requirement in the above definition and create storage class. You have to use this storage class while creating PVC.\n\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n      name: openebs-pvc\n    spec:\n      storageClassName: openebs-cstor\n      accessModes:\n        - ReadWriteOnce\n      resources:\n        requests:\n          storage: 10Gi\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n      labels:\n        name: busybox\n      name: busybox\n    spec:\n      clusterIP: None\n      selector:\n        app: busybox\n    ---\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: busybox\n      labels:\n        app: busybox\n    spec:\n      selector:\n        matchLabels:\n          app: busybox\n      template:\n        metadata:\n          labels:\n            app: busybox\n        spec:\n          containers:\n          - name: app-busybox\n            imagePullPolicy: IfNotPresent\n            image: busybox\n            command: [\"/bin/sh\"]\n            args: [\"-c\", \"while true; do sleep 10;done\"]\n            env:\n            volumeMounts:\n            - name: data-vol\n              mountPath: /busybox\n          volumes:\n          - name: data-vol\n            persistentVolumeClaim:\n              claimName: openebs-pvc\n\nAfter updating the storage class in the above manifest, let us deploy the busybox application by applying the above definition.\n\nCheck if the PVC is created and mounted successfully on the application pod by checking their status.\n\n    k3os-1374 [~]$ kubectl get pvc\n    NAME          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE\n    openebs-pvc   Bound    pvc-6cd2b30a-49ed-4605-b1e0-dd23c45e548d   10Gi       RWO            openebs-cstor   4m35s\n    \n    k3os-1374 [~]$ kubectl get pods\n    NAME                       READY   STATUS    RESTARTS   AGE\n    busybox-748fb77c75-9lwzz   1/1     Running   0          4m42s\n\nAs we specified ReplicaCount as 3 in the storage class, 3 volume replicas will be created which can be found by executing the following command.\n\n    k3os-1374 [~]$ kubectl get cvr -n openebs\n    NAME                                                            USED    ALLOCATED   STATUS    AGE\n    pvc-6cd2b30a-49ed-4605-b1e0-dd23c45e548d-cstor-disk-pool-09l1   7.95M   116K        Healthy   6m37s\n    pvc-6cd2b30a-49ed-4605-b1e0-dd23c45e548d-cstor-disk-pool-rgy3   7.95M   116K        Healthy   6m37s\n    pvc-6cd2b30a-49ed-4605-b1e0-dd23c45e548d-cstor-disk-pool-gij4   7.95M   116K        Healthy   6m37s\n\nThus, the cStor engine can be used to provision persistent volume for the workloads in K3s.\n\nPlease leave your valuable comments or feedback in the comment section below if you find this tutorial helpful.\n","slug":"getting-started-with-k3s-in-vsphere-and-openebs-cstor"},{"id":25,"title":"Resizing the ZFS-LocalPV Volumes","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"26-03-2020","tags":["Localpv"," Openebs"],"excerpt":"In this post, we will focus on how we can resize the volumes provisioned by ZFS-LocalPV without restarting the application.","content":"\nBefore reading this post, please read my previous[ post](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d?__hstc=216392137.7dc0753f698b104ea002a16b84268b54.1580207831486.1580207831486.1580207831486.1&amp;__hssc=216392137.1.1580207831487&amp;__hsfp=818904025) for instructions on setting up the ZFS-LocalPV for dynamically provisioning the volumes on the ZFS storage. Here, we will focus on how we can resize the volumes provisioned by ZFS-LocalPV without restarting the application.\n\n### **Prerequisite**\n\nPlease make sure you have installed the ZFS-LocalPV Driver version v0.5 or later:\n\n    $ kubectl apply -f\n    https://raw.githubusercontent.com/openebs/zfs-localpv/v0.5.x/deploy/zfs-operator.yaml\n\nMake sure you are using k8s version 1.16+ as this feature is in beta. In Kubernetes 1.14 and 1.15, this feature was in alpha status and required enabling the following feature gate:\n\n    --feature-gates=ExpandCSIVolumes=true\n\nAlso for Kubernetes 1.14 and 1.15, online expansion feature gate has to be enabled explicitly:\n\n    --feature-gates=ExpandInUsePersistentVolumes=true\n\n### **Introduction**\n\nThe ZFS-LocalPV CSI driver supports ONLINE volume expansion, which means, if the application is using the volume, you can perform the volume expansion. This also means that the volume expansion will be performed when an application is using that volume. So, if an application is not running and we have performed the resize operation, the Driver will wait for the application to start for the resize operation to complete.\n\n### **Setup**\n\nCreate the StorageClass with allowVolumeExpansion as true. We can resize only those volumes which are using the StorageClass with this flag as true.\n\n    $ cat sc.yaml\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n     name: openebs-zfspv\n    allowVolumeExpansion: true\n    parameters:\n     poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n    $ kubectl apply -f sc.yaml\n    storageclass.storage.k8s.io/openebs-zfspv created\n\nCreate the PVC using the above StorageClass:\n\n    $ cat pvc.yaml\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n     name: csi-zfspv\n    spec:\n     storageClassName: openebs-zfspv\n     accessModes:\n       - ReadWriteOnce\n     resources:\n       requests:\n         storage: 5Gi\n    $ kubectl apply -f pvc.yaml\n    persistentvolumeclaim/csi-zfspv created\n\nNow deploy the application using the above PVC. Here, we will be using below Percona application:\n\n    $ cat percona.yaml\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n     annotations:\n     name: sqltest\n     namespace: default\n    data:\n     sql-test.sh: |\n       #!/bin/bash\n    DB_PREFIX=\"Inventory\"\n       DB_SUFFIX=`echo $(mktemp) | cut -d '.' -f 2`\n       DB_NAME=\"${DB_PREFIX}_${DB_SUFFIX}\"\n    echo -e \"\\nWaiting for mysql server to start accepting connections..\"\n       retries=10;wait_retry=30\n       for i in `seq 1 $retries`; do\n         mysql -uroot -pk8sDem0 -e 'status' > /dev/null 2>&1\n         rc=$?\n         [ $rc -eq 0 ] && break\n         sleep $wait_retry\n       done\n    if [ $rc -ne 0 ];\n       then\n         echo -e \"\\nFailed to connect to db server after trying for $(($retries * $wait_retry))s, exiting\\n\"\n         exit 1\n       fi\n       mysql -uroot -pk8sDem0 -e \"CREATE DATABASE $DB_NAME;\"\n       mysql -uroot -pk8sDem0 -e \"CREATE TABLE Hardware (id INTEGER, name VARCHAR(20), owner VARCHAR(20),description VARCHAR(20));\" $DB_NAME\n       mysql -uroot -pk8sDem0 -e \"INSERT INTO Hardware (id, name, owner, description) values (1, \"dellserver\", \"basavaraj\", \"controller\");\" $DB_NAME\n       mysql -uroot -pk8sDem0 -e \"DROP DATABASE $DB_NAME;\"\n    ---\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n     name: percona\n     labels:\n       name: percona\n    spec:\n     replicas: 1\n     selector:\n       matchLabels:\n         name: percona\n     template:\n       metadata:\n         labels:\n           name: percona\n       spec:\n         containers:\n           - resources:\n             name: percona\n             image: openebs/tests-custom-percona:latest\n             imagePullPolicy: IfNotPresent\n             args:\n               - \"--ignore-db-dir\"\n               - \"lost+found\"\n             env:\n               - name: MYSQL_ROOT_PASSWORD\n                 value: k8sDem0\n             ports:\n               - containerPort: 3306\n                 name: percona\n             volumeMounts:\n               - mountPath: /var/lib/mysql\n                 name: demo-vol1\n               - mountPath: /sql-test.sh\n                 subPath: sql-test.sh\n                 name: sqltest-configmap\n             livenessProbe:\n               exec:\n                 command: [\"bash\", \"sql-test.sh\"]\n               initialDelaySeconds: 30\n               periodSeconds: 1\n               timeoutSeconds: 10\n         volumes:\n           - name: demo-vol1\n             persistentVolumeClaim:\n               claimName: csi-zfspv\n           - name: sqltest-configmap\n             configMap:\n               name: sqltest\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n     name: percona-mysql\n     labels:\n       name: percona-mysql\n    spec:\n     ports:\n       - port: 3306\n         targetPort: 3306\n     selector:\n         name: percona\n\nApply the above YAML to deploy the Percona application:\n\n    $ kubectl apply -f percona.yaml\n    configmap/sqltest created\n    deployment.apps/percona created\n    service/percona-mysql created\n\nNow the setup is ready and the application is running:\n\n    $ kubectl get po\n    NAME                      READY   STATUS    RESTARTS   AGE\n    percona-9449b4b9c-48qpw   1/1     Running   0          38s\n\nCheck the volume size at the application size:\n\n    $ kubectl exec -it percona-9449b4b9c-48qpw bash\n    root@percona-9449b4b9c-48qpw:/# df -h\n    Filesystem      Size  Used Avail Use% Mounted on\n    none             91G   18G   69G  21% /\n    tmpfs           3.9G     0  3.9G   0% /dev\n    tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup\n    /dev/sda1        91G   18G   69G  21% /etc/hosts\n    shm              64M     0   64M   0% /dev/shm\n    /dev/zd0        4.9G  234M  4.7G   5% /var/lib/mysql\n    tmpfs           3.9G   12K  3.9G   1% /run/secrets/kubernetes.io/serviceaccount\n    tmpfs           3.9G     0  3.9G   0% /sys/firmware\n\nFrom above o/p we can see that the volume has been created of size 5Gi and it is attached to the application at the given mount point (/var/lib/mysql**).**\n\n### **Volume Resize**\n\nHere, we just have to update the PVC with the new size and apply it. Please note that volume shrinking is not supported, so you have to change the size to a higher value. Here, in our case, we will update the size to 8Gi\n\n    $ cat pvc.yaml\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n     name: csi-zfspv\n    spec:\n     storageClassName: openebs-zfspv\n     accessModes:\n       - ReadWriteOnce\n     resources:\n       requests:\n         storage: 8Gi\n\nApply the above YAML to perform the resize:\n\n    $ kubectl apply -f pvc.yaml\n    persistentvolumeclaim/csi-zfspv configured\n\nNow, we can keep checking the PVC for the new size to be updated, it may take a while. Once resize operation is done we can see the PVC output with the updated size:\n\n    $ kubectl get pvc\n    NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE\n    csi-zfspv   Bound    pvc-9b5c22a5-29be-428e-aa96-5e183c1c4c62   8Gi        RWO            openebs-zfspv   33m\n\nWe can also exec into the application pod and verify that the new size is visible to the application:\n\n    $ kubectl exec -it percona-9449b4b9c-48qpw bash\n    root@percona-9449b4b9c-48qpw:/# df -h\n    Filesystem        Size      Used    Avail     Use%    Mounted on\n    none               91G       18G      69G      21%    /\n    tmpfs             3.9G         0     3.9G       0%    /dev\n    tmpfs             3.9G         0     3.9G       0%    /sys/fs/cgroup\n    /dev/sda1          91G       18G      69G      21%    /etc/hosts\n    shm                64M         0      64M       0%    /dev/shm\n    /dev/zd0          7.9G      237M     7.6G       3%    /var/lib/mysql\n    tmpfs             3.9G       12K     3.9G       1%    /run/secrets/kubernetes.io/serviceaccount\n    tmpfs             3.9G         0     3.9G       0%    /sys/firmware\n\nI hope you find this post useful. Feel free to contact me with any feedback or questions by using the comment section below.\n","slug":"resizing-the-zfslocalpv-volumes"},{"id":26,"title":"Snapshot and Clone for ZFS LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"03-03-2020","tags":["Openebs"," Zfs"," Open Source"],"excerpt":"In this post, we will focus on how we can create a snapshot and clone for volumes provisioned by ZFS-LocalPV.","content":"\nBefore reading this post, please read my previous[ post](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d?__hstc=216392137.2b738ae93497639f7465a332e1aef247.1584602510099.1584602510099.1584602510099.1&amp;__hssc=216392137.1.1584602510100&amp;__hsfp=2870217423) for instructions on setting up the ZFS-LocalPV for dynamically provisioning the volumes on the ZFS storage. Here, we will focus on how we can create a snapshot and clone for volumes provisioned by ZFS-LocalPV.\n\n#### **Prerequisite**\n\nFor clone, we need to have VolumeSnapshotDataSource support, which is in beta in Kubernetes 1.17. If you are using the Kubernetes version less than 1.17, you have to enable the VolumeSnapshotDataSource feature gate at kubelet and kube-apiserver.\n\n#### **Snapshot**\n\nWe can create a snapshot of a volume that can be used further for creating a clone and for taking a backup. To create a snapshot, we have to first create a SnapshotClass just like a storage class where you can provide deletionPolicy as Retain or Delete.\n\n    $ cat snapshotclass.yaml\n    kind: VolumeSnapshotClass\n    apiVersion: snapshot.storage.k8s.io/v1beta1\n    metadata:\n      name: zfspv-snapclass\n      annotations:\n        snapshot.storage.kubernetes.io/is-default-class: \"true\"\n    driver: zfs.csi.openebs.io\n    deletionPolicy: Delete\n\nApply the snapshotclass YAML:\n\n    $ kubectl apply -f snapshotclass.yaml\n    volumesnapshotclass.snapshot.storage.k8s.io/zfspv-snapclass created\n\nFind a PVC for which snapshot has to be created\n\n    $ kubectl get pvc\n    NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE\n    csi-zfspv   Bound    pvc-73402f6e-d054-4ec2-95a4-eb8452724afb   4Gi        RWO            openebs-zfspv   2m35s\n\nCreate the snapshot using the created SnapshotClass for the selected PVC\n\n    $ cat snapshot.yaml\n    apiVersion: snapshot.storage.k8s.io/v1beta1\n    kind: VolumeSnapshot\n    metadata:\n      name: zfspv-snap\n    spec:\n      volumeSnapshotClassName: zfspv-snapclass\n      source:\n        persistentVolumeClaimName: csi-zfspv\n\nApply the snapshot.yaml\n\n    $ kubectl apply -f snapshot.yaml\n    volumesnapshot.snapshot.storage.k8s.io/zfspv-snap created\n\nPlease note that you have to create the snapshot in the same namespace where the PVC is created. Check the created snapshot resource, make sure readyToUsefield is true, before using this snapshot for any purpose.\n\n    $ kubectl get volumesnapshot.snapshot\n    NAME         AGE\n    zfspv-snap   2m8s\n    \n    $ kubectl get volumesnapshot.snapshot zfspv-snap -o yaml\n    apiVersion: snapshot.storage.k8s.io/v1beta1\n    kind: VolumeSnapshot\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/last-applied-configuration: |\n          {\"apiVersion\":\"snapshot.storage.k8s.io/v1beta1\",\"kind\":\"VolumeSnapshot\",\"metadata\":{\"annotations\":{},\"name\":\"zfspv-snap\",\"namespace\":\"default\"},\"spec\":{\"source\":{\"persistentVolumeClaimName\":\"csi-zfspv\"},\"volumeSnapshotClassName\":\"zfspv-snapclass\"}}\n      creationTimestamp: \"2020-02-25T08:25:51Z\"\n      finalizers:\n      - snapshot.storage.kubernetes.io/volumesnapshot-as-source-protection\n      - snapshot.storage.kubernetes.io/volumesnapshot-bound-protection\n      generation: 1\n      name: zfspv-snap\n      namespace: default\n      resourceVersion: \"447494\"\n      selfLink: /apis/snapshot.storage.k8s.io/v1beta1/namespaces/default/volumesnapshots/zfspv-snap\n      uid: 3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd\n    spec:\n      source:\n        persistentVolumeClaimName: csi-zfspv\n      volumeSnapshotClassName: zfspv-snapclass\n    status:\n      boundVolumeSnapshotContentName: snapcontent-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd\n      creationTime: \"2020-02-25T08:25:51Z\"\n      readyToUse: true\n      restoreSize: \"0\"\n\nCheck the OpenEBS resource for the created snapshot. Check, status should be Ready.\n\n    $ kubectl get zfssnap -n openebs\n    NAME                                            AGE\n    snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd   3m32s\n    \n    $ kubectl get zfssnap snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd -n openebs -oyaml\n    apiVersion: openebs.io/v1alpha1\n    kind: ZFSSnapshot\n    metadata:\n      creationTimestamp: \"2020-02-25T08:25:51Z\"\n      finalizers:\n      - zfs.openebs.io/finalizer\n      generation: 2\n      labels:\n        kubernetes.io/nodename: e2e1-node2\n        openebs.io/persistent-volume: pvc-73402f6e-d054-4ec2-95a4-eb8452724afb\n      name: snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd\n      namespace: openebs\n      resourceVersion: \"447328\"\n      selfLink: /apis/openebs.io/v1alpha1/namespaces/openebs/zfssnapshots/snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd\n      uid: 6142492c-3785-498f-aa4a-569ec6c0e2b8\n    spec:\n      capacity: \"4294967296\"\n      fsType: zfs\n      ownerNodeID: e2e1-node2\n      poolName: test-pool\n      volumeType: DATASET\n    status:\n      state: Ready\n\nWe can go to the node and confirm that snapshot has been created:\n\n    # zfs list -t all\n    NAME                                                                                               USED  AVAIL  REFER  MOUNTPOINT\n    test-pool                                                                                          818K  9.63G    24K  /test-pool\n    test-pool/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb                                                  24K  4.00G    24K  /var/lib/kubelet/pods/3862895a-8a67-446e-80f7-f3c18881e391/volumes/kubernetes.io~csi/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb/mount\n    test-pool/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb@snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd     0B      -    24K  -\n\n#### **Clone**\n\nWe can create a clone volume from a snapshot and use that volume for some application. We can create a PVC YAML and mention the snapshot name in the datasource.\n\n    $ cat clone.yaml\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n      name: zfspv-clone\n    spec:\n      storageClassName: openebs-zfspv\n      dataSource:\n        name: zfspv-snap\n        kind: VolumeSnapshot\n        apiGroup: snapshot.storage.k8s.io\n      accessModes:\n        - ReadWriteOnce\n      resources:\n        requests:\n          storage: 4Gi\n\nThe above yaml says that create a volume from the snapshot zfspv-snap. Applying the above yaml will create a clone volume on the same node where the original volume is present. The newly created clone PV will also be there on the same node where the original PV is there. Apply the clone yaml\n\n    $ kubectl apply -f clone.yaml \n    persistentvolumeclaim/zfspv-clone created\n\nNote that the clone PVC should also be of the same size as that of the original volume. Currently resize is not supported. Also, note that the poolname should also be same, as across the ZPOOL clone is not supported. So, if you are using a separate storageclass for the clone PVC, please make sure it refers to the same ZPOOL.\n\n    $ kubectl get pvc\n    NAME          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE\n    csi-zfspv     Bound    pvc-73402f6e-d054-4ec2-95a4-eb8452724afb   4Gi        RWO            openebs-zfspv   13m\n    zfspv-clone   Bound    pvc-c095aa52-8d09-4bbe-ac3c-bb88a0e7be19   4Gi        RWO            openebs-zfspv   34s\n\nWe can see in the above output that zfspv-clone claim has been created and it is bound. Also, we can check the zfs list on node and verify that clone volume is created.\n\n    $ zfs list -t all\n    NAME                                                                                               USED  AVAIL  REFER  MOUNTPOINT\n    test-pool                                                                                          834K  9.63G    24K  /test-pool\n    test-pool/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb                                                  24K  4.00G    24K  /var/lib/kubelet/pods/3862895a-8a67-446e-80f7-f3c18881e391/volumes/kubernetes.io~csi/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb/mount\n    test-pool/pvc-73402f6e-d054-4ec2-95a4-eb8452724afb@snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd     0B      -    24K  -\n    test-pool/pvc-c095aa52-8d09-4bbe-ac3c-bb88a0e7be19                                                   0B  9.63G    24K  none\n\nThe clone volume will have properties same as snapshot properties which are the properties when that snapshot has been created. The ZFSVolume object for the clone volume will be something like below:\n\n    $ kubectl describe zv pvc-c095aa52-8d09-4bbe-ac3c-bb88a0e7be19 -n openebs\n    Name:         pvc-c095aa52-8d09-4bbe-ac3c-bb88a0e7be19\n    Namespace:    openebs\n    Labels:       kubernetes.io/nodename=e2e1-node2\n    Annotations:  none\n    API Version:  openebs.io/v1alpha1\n    Kind:         ZFSVolume\n    Metadata:\n      Creation Timestamp:  2020-02-25T08:34:25Z\n      Finalizers:\n        zfs.openebs.io/finalizer\n      Generation:        1\n      Resource Version:  448930\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/openebs/zfsvolumes/pvc-c095aa52-8d09-4bbe-ac3c-bb88a0e7be19\n      UID:               e38a9f9a-fb76-466b-a6f9-8d070e0bec6f\n    Spec:\n      Capacity:       4294967296\n      Fs Type:        zfs\n      Owner Node ID:  e2e1-node2\n      Pool Name:      test-pool\n      Snapname:       pvc-73402f6e-d054-4ec2-95a4-eb8452724afb@snapshot-3cbd5e59-4c6f-4bd6-95ba-7f72c9f12fcd\n      Volume Type:    DATASET\n    Events:           none\n\nHere you can note that this resource has Snapname field which tells that this volume is created from that snapshot.\n\nI hope you found this post useful. Feel free to contact me with any feedback or questions by using the comment section below.\n","slug":"snapshot-and-clone-for-zfs-localpv"},{"id":27,"title":"Setup Continuous Integration for Helm chart","author":"Intakhab Ali","author_info":"Software Engineer at MayaData","date":"05-02-2020","tags":["Helm"," Openebs"," Tutorials"," Kubernetes"],"excerpt":"In this blog, we'll set up a continuous integration of the Helm chart. We'll package the Helm chart with the help of CI tools & push them to chart registry.","content":"\n[Helm](https://www.helm.sh/) is a package manager for Kubernetes that allows developers and operators to easily package, configure, and deploy applications and services onto Kubernetes clusters.\n\nHelm is now an official Kubernetes project and is part of the[ Cloud Native Computing Foundation](https://www.cncf.io/), a non-profit Linux Foundation that supports Open Source projects in and around the Kubernetes ecosystem.\n\nIn this tutorial, we will set up a continuous integration of the Helm chart. We will package the Helm chart with the help of CI tools like (Travis, Jenkins), and push it to chart registries like (Harbor, Chartmuseum).\n\n## Prerequisites:\n\n- Registry to store Helm like Harbor or Chartmuseum\n- Understanding of Helm and any of the CI platforms (Travis, Jenkins, circle, CI)\n- A Git repository to maintain version control of helm chart\n\n**I am going to use Travis as a CI platform and Harbor as a Helm registry to host the helm.**\n\n**As I choose Travis here, .travis.yml consists of the job lifecycle. Let’s write job cycle for the helm chart.**\n\n### Lifecycle 1:\n\nChoose the base language as Python\n\n    ---\n    language: python\n\nWe need to have some environment variables so that we can update whenever there’s a new version of the Helm release or change of the registry URL.\n\nHere is the list of a variable that we’ll need:\n\n***HELM_URL=[https://storage.googleapis.com/kubernetes-helm](https://storage.googleapis.com/kubernetes-helm) (this is the URL where we can download the helm package)***\n\n***HELM_TGZ=helm-v2.4.2-linux-amd64.tar.gz (this is the Helm tar filename)***\n\n***REPO_DIR=/home/travis/build/inyee786/test-helm (this is the path where Travis keep Git folder)***\n\n***YAMLLINT_VERSION=1.8.1 (this is yamllint version which is used to check lint of file)***\n\n***HARBOR_CHART_URL=https://harbor-test.mayadata.io/chartrepo (change this according to your chart registry url{harbor or Chartmuseum}***\n\n***HARBOR_PROJECT_NAME=maya (this is the Harbor project name, where we will store the chart)***\n\n***CHART_FOLDER=charts (this is the folder name, where we can keep the Helm charts)***\n\nIt looks like this\n\n    env:\n     global:\n       - HELM_URL=https://storage.googleapis.com/kubernetes-helm\n       - HELM_TGZ=helm-v2.4.2-linux-amd64.tar.gz\n       - REPO_DIR=/home/travis/build/inyee786/test-helm\n       - YAMLLINT_VERSION=1.8.1\n       - HARBOR_CHART_URL=https://harbor-\n    test.mayadata.io/chartrepo\n       - HARBOR_PROJECT_NAME=maya\n       - CHART_FOLDER=charts\n\nWe need some private variables, where we can store the credentials and push it to the Helm registry (Harbor has an excellent feature where we can have bot user, and you can use the bot credential). All we have to feed is-\n\n    HARBOR_USERNAME:\n    HARBOR_PASSWORD:\n\nInside Travis, go to (****settings > Environment Variables****) to set the private env\n\n![](/images/blog/2020/02/111.png)\n\n### Lifecycle 2 :\n\nInstall the Prerequisites to Set up a CI environment to build and check the YAML lint.\n\nDownload helm and ****untar**** the chart after downloading\n\n- wget ${HELM_URL}/${HELM_TGZ}\n- tar xzfv ${HELM_TGZ}\n- PATH=`pwd`/linux-amd64/:$PATH\n\nInitialize the helm client and update the helm repo\n\n- Helm init — client-only\n- Helm repo update\n\nInstall helm plugin to push chart on the registry\n\n- Helm plugin install[ https://github.com/chartmuseum/helm-push](https://github.com/chartmuseum/helm-push) — version v0.7.1\n\nInstall yamllint python package to check the lint\n\n- sudo pip install yamllint==”${YAMLLINT_VERSION}”\n\nIt looks like the below config\n\n    install:\n    # Installing Helm\n     - wget ${HELM_URL}/${HELM_TGZ}\n     - tar xzfv ${HELM_TGZ}\n     - PATH=`pwd`/linux-amd64/:$PATH\n     - helm init --client-only\n     # helm plugin to push helm chart\n     - helm plugin install https://github.com/chartmuseum/helm-\n    push --version v0.7.1\n     # Installing pip deps\n     - sudo pip install yamllint==\"${YAMLLINT_VERSION}\"\n     - helm repo update\n\n### Lifecycle 3 :\n\nBefore going further to build a chart, we need to run some script to check the lint in the chart and Travis file. It is a good practice to check the lint\n\nCheck the Helm lint of all Helm chart\n\n- For dir in `ls ${REPO_DIR}/${CHART_FOLDER}`; do\nhelm lint ${REPO_DIR}/${CHART_FOLDER}/$dir\nif [ $? != 0 ]; then\ntravis_terminate 1\nfi\n\nTo check the YAML lint for travis.yml, chart.yaml and value.yaml, we use the yamllint python package. We need the rule to check the lint.\n\n- yamllint -c .yamllint.yml -s .travis.yml .yamllint.yml\n- yamllint -c .yamllint.yml -s $(find . -type f -name “Chart.yaml”)\n- yamllint -c .yamllint.yml -s $(find . -type f -name “values.yaml”)\n\nThe script section should look like the below config\n\n    script:\n      # Check charts format\n      - >\n         for dir in `ls ${REPO_DIR}/${CHART_FOLDER}`; do\n          helm lint ${REPO_DIR}/${CHART_FOLDER}/$dir\n          if [ $? != 0 ]; then\n           travis_terminate 1\n          fi\n         done\n      # Check YAML styling\n      - yamllint -c .yamllint.yml -s .travis.yml .yamllint.yml\n      - yamllint -c .yamllint.yml -s $(find . -type f -name \"Chart.yaml\")\n      - yamllint -c .yamllint.yml -s $(find . -type f -name \"values.yaml\")\n\nHere comes the interesting part where we are going to build and package the chart.\n\n****Lifecycle 4:****\n\nIt’s better to build and push when we merge the chart in the **master** branch. So we run the below command when we merge the chart in the **master** branch\n\nWe need a temporary directory where we will build and package the chart\n\n- BUILD_DIR=$(mktemp -d)\n\nRun a loop to all the charts to build, package, and push it to the registry. The below commands will run on each chart\n\n- helm dep update ${REPO_DIR}/${CHART_FOLDER}/$dir\n\nPackage the chart with the below command\n\n- helm package ${REPO_DIR}/${CHART_FOLDER}/$dir\n\nThen push the chart to registry\n\n- helm push — username ${HARBOR_USERNAME} — password ${HARBOR_PASSWORD} ${REPO_DIR}/${CHART_FOLDER}/$dir ${HARBOR_CHART_URL}/maya\n\nBelow is the what the config will look like\n\n    # Temporary dir for storing new packaged charts and index files\n          BUILD_DIR=$(mktemp -d)      # Push temporary directory to the stack\n          pushd $BUILD_DIR      # Iterate over all charts are package them push it to Harbor\n          for dir in `ls ${REPO_DIR}/${CHART_FOLDER}`; do\n           helm dep update ${REPO_DIR}/${CHART_FOLDER}/$dir\n           helm package ${REPO_DIR}/${CHART_FOLDER}/$dir\n           helm push --username ${HARBOR_USERNAME} --password ${HARBOR_PASSWORD}  ${REPO_DIR}/${CHART_FOLDER}/$dir ${HARBOR_CHART_URL}/maya\n           if [ $? != 0 ]; then\n            travis_terminate 1\n           fi\n          done# Pop temporary directory from the stack\n          popd\n\nWow! We have successfully completed all the steps. Now, our setup is ready to build and push the helm chart to the registry.\n![](/images/blog/2020/02/0_BbWrwzeivY6Qkcgu.png)\nHere is the full Travis file\n[https://gist.github.com/inyee786/d779f347d7fa272aed4ee8457182af35.js](https://gist.github.com/inyee786/d779f347d7fa272aed4ee8457182af35.js)\n\nHere is .yamllint.yml file which contains lint rule for charts.yaml values.yaml and .travis.yaml\n[https://gist.github.com/inyee786/ef15b05c98bb4761b41af5f4fe268239.js](https://gist.github.com/inyee786/ef15b05c98bb4761b41af5f4fe268239.js)\n\n## Conclusion:\n\nHere we packaged the helm chart and pushed it to the helm registry.\n\n## About me\n\nYou can follow me at the below profiles and can ask any questions related to Angular, JavaScript, Travis, Kubernetes, etc.\n\n- [GitHub](https://github.com/inyee786/)\n- [Linkedin](https://www.linkedin.com/in/intakhab-ali/)\n- [Medium](https://medium.com/@intakhab.cusat)\n\nThis blog was originally published on 28th Jan 2020 on [MayaData’s blog](https://blog.mayadata.io/openebs/setup-continuous-integration-for-helm-chart).\n","slug":"setup-continuous-integration-for-helm-chart"},{"id":28,"title":"Monitoring ZFS-LocalPV Volumes","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"28-01-2020","tags":["Openebs"," Localpv"," Zfs"],"excerpt":"In this post, we will focus on how we can set up the Prometheus alert for Provisioned volumes when space utilization has reached a critical point.","content":"\nBefore reading this post, please read my previous [post](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d?__hstc=216392137.7dc0753f698b104ea002a16b84268b54.1580207831486.1580207831486.1580207831486.1&amp;__hssc=216392137.1.1580207831487&amp;__hsfp=818904025) for instructions on setting up the ZFS-LocalPV for dynamically provisioning the volumes on the ZFS storage. Here, we will focus on how we can set up the Prometheus alert for Provisioned volumes when space utilization has reached a critical point.\n\n### Prerequisite\n\nMake sure you are using k8s version 1.15+ to access the CSI volume metrics.\n\n### Setup helm\n\nThis step uses helm as the Kubernetes package manager. If you have not setup the helm, execute the below configuration. Otherwise, you can move on to the next step.\n\n    $ helm version\n    Client: &version.Version{SemVer:\"v2.16.1\", GitCommit:\"bbdfe5e7803a12bbdf97e94cd847859890cf4050\", GitTreeState:\"clean\"}\n    Server: &version.Version{SemVer:\"v2.16.1\", GitCommit:\"bbdfe5e7803a12bbdf97e94cd847859890cf4050\", GitTreeState:\"clean\"}\n    \n    $ helm init\n    Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\n    \n    Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\n    To prevent this, run `helm init` with the --tiller-tls-verify flag.\n    For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\n    \n    $ kubectl create serviceaccount --namespace kube-system tiller\n    serviceaccount/tiller created\n    \n    $ kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller\n    clusterrolebinding.rbac.authorization.k8s.io/tiller-cluster-rule created\n    \n    $ kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}'\n    deployment.extensions/tiller-deploy patched\n\n### Install Prometheus Operator\n\nOnce the helm is ready and the related tiller pods are up and running, use the Prometheus chart from the helm repository.\n\n    $ helm install stable/prometheus-operator --name prometheus-operator\n\nCheck all the required pods are up and running\n\n    $ kubectl get pods -l \"release=prometheus-operator\"\n    NAME                                                 READY   STATUS    RESTARTS   AGE\n    prometheus-operator-grafana-85bb5d49d-bffdg          2/2     Running   0          2m21s\n    prometheus-operator-operator-64844759f7-rpwws        2/2     Running   0          2m21s\n    prometheus-operator-prometheus-node-exporter-p9rl8   1/1     Running   0          2m21s\n\n### Set up the alert rule\n\nCheck all the rules available in the system:\n\n    $ kubectl get PrometheusRule\n    NAME                                                       AGE\n    prometheus-operator-alertmanager.rules                     4m21s\n    prometheus-operator-etcd                                   4m21s\n    prometheus-operator-general.rules                          4m21s\n    prometheus-operator-k8s.rules                              4m21s\n    prometheus-operator-kube-apiserver-error                   4m21s\n    prometheus-operator-kube-apiserver.rules                   4m21s\n    prometheus-operator-kube-prometheus-node-recording.rules   4m21s\n    prometheus-operator-kube-scheduler.rules                   4m21s\n    prometheus-operator-kubernetes-absent                      4m21s\n    prometheus-operator-kubernetes-apps                        4m21s\n    prometheus-operator-kubernetes-resources                   4m21s\n    prometheus-operator-kubernetes-storage                     4m21s\n    prometheus-operator-kubernetes-system                      4m21s\n    prometheus-operator-kubernetes-system-apiserver            4m21s\n    prometheus-operator-kubernetes-system-controller-manager   4m21s\n    prometheus-operator-kubernetes-system-kubelet              4m21s\n    prometheus-operator-kubernetes-system-scheduler            4m21s\n    prometheus-operator-node-exporter                          4m21s\n    prometheus-operator-node-exporter.rules                    4m21s\n    prometheus-operator-node-network                           4m21s\n    prometheus-operator-node-time                              4m21s\n    prometheus-operator-node.rules                             4m21s\n    prometheus-operator-prometheus                             4m21s\n    prometheus-operator-prometheus-operator                    4m21s\n\nYou can edit any of the default rules or create a new rule to get the alerts. Below is a sample rule to start generating alerts when available storage space is less than 10%.\n\n    apiVersion: monitoring.coreos.com/v1\n    kind: PrometheusRule\n    metadata:\n      labels:\n        app: prometheus-operator\n        chart: prometheus-operator-8.5.4\n        heritage: Tiller\n        release: prometheus-operator\n      name: prometheus-operator-zfs-alertmanager.rules\n      namespace: default\n    spec:\n      groups:\n      - name: zfsalertmanager.rules\n        rules:\n        - alert: ZFSVolumeUsageCritical\n          annotations:\n            message: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim\n              }} in Namespace {{ $labels.namespace }} is only {{ printf \"%0.2f\" $value\n              }}% free.\n          expr: |\n            100 * kubelet_volume_stats_available_bytes{job=\"kubelet\"}\n              /\n            kubelet_volume_stats_capacity_bytes{job=\"kubelet\"}\n              < 10\n          for: 1m\n          labels:\n            severity: critical\n\nNow apply the above YAML so that Prometheus can fire the alerts when available space is less than 10%.\n\n### Check the Prometheus alert\n\nTo view the Prometheus web UI, you must expose it through a Service. A simple way to accomplish this is to use a Service of type NodePort.\n\n    $ cat prometheus-service.yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: prometheus-service\n    spec:\n      type: NodePort\n      ports:\n      - name: web\n        nodePort: 30090\n        port: 9090\n        protocol: TCP\n        targetPort: web\n      selector:\n        prometheus: prometheus-operator-prometheus\n\nApply the above YAML\n\n    $ kubectl apply -f prometheus-service.yaml\n    service/prometheus-service created\n\nNow you can access the alert manager UI via “node’s-external-ip:30090”.\n\n    $ kubectl get nodes -owide\n    NAME                                         STATUS   ROLES    AGE    VERSION          INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME\n    gke-zfspv-pawan-default-pool-3e407350-xvzp   Ready    <none>   103m   v1.15.4-gke.22   10.168.0.45   34.94.3.140   Ubuntu 18.04.3 LTS   5.0.0-1022-gke   docker://19.3.2\n\nHere, we can access the alert manager via URL: [http://34.94.3.140:30090/](http://34.94.3.140:30090/)\n\n### Check the Alert Manager\n\nTo view the Alert Manager web UI, expose it through a Service of type NodePort.\n\n    $ cat alertmanager-service.yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: alertmanager-service\n    spec:\n      type: NodePort\n      ports:\n      - name: web\n        nodePort: 30093\n        port: 9093\n        protocol: TCP\n        targetPort: web\n      selector:\n        alertmanager: prometheus-operator-alertmanager\n\nApply the above YAML\n\n    $ kubectl apply -f alertmanager-service.yaml\n    service/alertmanager-service created\n\nNow you can access the alert manager UI via “node’s-external-ip:30093”.\n\n    $ kubectl get nodes -owide\n    NAME                                         STATUS   ROLES    AGE    VERSION          INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME\n    gke-zfspv-pawan-default-pool-3e407350-xvzp   Ready    <none>   103m   v1.15.4-gke.22   10.168.0.45   34.94.3.140   Ubuntu 18.04.3 LTS   5.0.0-1022-gke   docker://19.3.2\n\nAgain, we can access the alert manager via URL: [http://34.94.3.140:30093/.](http://34.94.3.140:30093/)\n\nI hope you found this post to be useful. Feel free to contact me with any feedback or questions by using the comment section below.\n\nThis blog was originally published on [Jan 22, 2020, on the MayaData blog](https://blog.mayadata.io/openebs/monitoring-zfs-localpv-volumes).\n","slug":"monitoring-zfslocalpv-volumes"},{"id":29,"title":"Uniquely identifying disks in OpenEBS on VMWare platform","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"22-01-2020","tags":["Openebs"," Vmware"," Vcenter"," Virtual Disk"," Kubernetes"],"excerpt":"A little bit of background. I work at a company called MayaData who develops a very cool Open Source software called OpenEBS (CNCF Sandbox project) that simplifies the deployment of stateful applications on Kubernetes.","content":"\nA little bit of background. I work at a company called [MayaData](https://mayadata.io/) who develops a very cool Open Source software called OpenEBS (CNCF Sandbox project) that simplifies the deployment of stateful applications on Kubernetes. You should check it out at [www.openebs.io](http://www.openebs.io/?__hstc=216392137.84d52389458ef57b0491fddb252202d6.1570688281471.1578466343199.1578469779597.19&amp;__hssc=216392137.2.1578469779597&amp;__hsfp=2854279793).\n\nKubernetes can be installed on any type of machine; be it a Virtual Machine, bare metal, or cloud machine. Kubernetes abstracts away most of the significant bits of a system, except storage. When it comes to storage, the main reason an abstraction will not work is that there is no uniqueness among the storage devices themselves. Every vendor and every virtualization platform implements it differently.\n\nWe hit this issue of unique virtual disks while deploying OpenEBS on Kubernetes backed by VMware VMS or other virtualization platforms because OpenEBS NDM is not able to uniquely identify the block devices themselves.\n\nChanging the absolute configuration on the Virtual Machine can help you get around this issue.\n\nHere are the steps to enable unique disk IDs in VMware via vSphere client:\n\n1. Right-click the virtual machine for which you want to enable the disk UUID attribute, and select Power > Power Off.\n2. The virtual machine powers off.\n3. Right-click the virtual machine, and click Edit Settings.\n4. Click the Options tab, and select the General entry in the settings column.\n5. Click Configuration Parameters. The Configuration Parameters window appears.\n6. Click Add Row.\n7. In the Name column, enter disk.Enable UUID\n8. In the Value column, enter TRUE.\n9. Click OK and click Save.\n10. Power on the virtual machine.\n\nThis will assign WWN to each disk in the Virtual Machine\n\nThat is it for today’s tutorial. If you have any questions, feedback, or any topic that you feel I should cover next, feel free to comment on our blog or reach out to us on our [Slack](https://slack.openebs.io./) channel.\n\nThis blog was originally published on [Oct 01, 2019, on the MayaData blog](https://blog.mayadata.io/openebs/uniquely-identifying-disks-in-openebs-on-vmware-platform).\n","slug":"uniquely-identifying-disks-in-openebs-on-vmware-platform"},{"id":30,"title":"Creating manual BlockDevice","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"16-01-2020","tags":["Block Devices"," Docker"," Uncategorized"," Disk"," Openebs"," Kubernetes"],"excerpt":"BlockDevices are the consumable units of storage in the OpenEBS storage solution. Users can create BlockDevices manually to support custom partitions/lvms, etc., which are not detected by NDM. To create a manual BlockDevice, follow the steps below","content":"\nBlockDevices are the consumable units of storage in the OpenEBS storage solution. Currently, NDM supports the discovery and management of only a complete disk.\n\nHowever, users can create BlockDevices manually to support custom partitions/lvms, etc., which are not detected by NDM. To create a manual BlockDevice, follow the steps below:\n\n1. Download the sample block device custom resource YAML file. \n    ```\n    wget\n    https://raw.githubusercontent.com/openebs/node-disk-manager/master/deploy/crds/openebs_v1alpha1_blockdevice_cr.yaml\n    ```\n\n2.  Edit the file and fill in the details of the blockdevice. Fields marked with optional are not mandatory and can be removed. All other fields are required and information provided will be used while claiming.\n    ```\n    apiVersion: openebs.io/v1alpha1\n    kind: BlockDevice\n    metadata:\n      name: example-blockdevice\n      labels:\n        kubernetes.io/hostname: <host name of the node in which disk/blockdevice is attached> # like gke-openebs-user-default-pool-044afcb8-bmc0\n        ndm.io/managed: \"false\" # for manual disk creation put false\n        ndm.io/blockdevice-type: blockdevice\n    status:\n      claimState: Unclaimed\n      state: Active\n    spec:\n      capacity:\n           storage: <total capacity in bytes> #like 53687091200\n      details:\n        firmwareRevision: <firmware revision> #optional\n        model: <model name of blockdevice> # like PersistentDisk, optional\n        serial: <serial no of disk> # like google-disk-2, optional\n        compliance: <compliance of disk> #like \"SPC-4\", optional\n        vendor: <vendor of disk> #like Google, optional\n      devlinks:\n      - kind: by-id\n        links:\n        - <link1> # like /dev/disk/by-id/scsi-0Google_PersistentDisk_disk-2\n        - <link2> # like /dev/disk/by-id/google-disk-2\n      - kind: by-path\n        links:\n        - <link1> # like /dev/disk/by-path/virtio-pci-0000:00:03.0-scsi-0:0:2:0\n      nodeAttributes:\n        nodeName: <node name> # output of `kubectl get nodes` can be used\n      path: <devpath> # like /dev/sdb\n      ```\n3.  Apply the YAML file.\n    ```\n    kubectl apply -f openebs_v1alpha1_blockdevice_cr.yaml\n    ```\n\nThe BlockDevice CR will be created and is then used by NDM Operator for claiming, but it won’t be managed by NDM Daemon for any changes that happen on the device. However, all the Claim/Unclaim operations and cleanup operations will be performed on this BlockDevice.\n\nPlease provide your valuable feedback & comments below and let me know what I can cover in my next blog.\n\nThis blog was originally published on Oct 22nd, 2019, on the [MayaData blog](https://blog.mayadata.io/openebs/creating-manual-blockdevice).\n","slug":"creating-manual-blockdevice"},{"id":31,"title":"OpenEBS Node Device Management (NDM) — Troubleshooting tips","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"08-01-2020","tags":["Docker"," Openebs"," Uncategorized"," Troubleshooting"," Tutorials"],"excerpt":"OpenEBS Node Device Management (aka NDM) helps in discovering the block devices attached to Kubernetes nodes. In this blog, I will walk through some of the scenarios I have seen working with users on the OpenEBS Slack Channel.","content":"\nOpenEBS Node Device Management (aka NDM) helps in discovering the block devices attached to Kubernetes nodes. For many clusters, the default configuration of NDM suffices, however there are some cases where further customizations are required.\n\n> In this blog, I will walk through some of the scenarios I have seen working with Users on the [OpenEBS Slack Channel](http://slack.openebs.io/)\n\n---\n\n### NDM Quick Overview\n\nFor setting up NDM in secure mode, please see my previous [blog](https://blog.mayadata.io/openebs/configuring-openebs-to-run-with-security-enhanced-linux), and you can learn how NDM works [here](https://docs.openebs.io/docs/next/ndm.html). Here is a quick snapshot of the key components of NDM.\n\n- NDM components are installed in the OpenEBS Namespace. Ensure that NDM pods part of the NDM DaemonSet are running on all the storage nodes. NDM Operator helps with allocating Block Devices to Block Device Claims and should be running.\n- NDM DaemonSet pod discovers all the block devices attached to the node and creates BlockDevice custom resource for each device. Note that NDM will filter out some of the devices like loopback device and so forth as configured in the NDM ConfigMap. `kubectl get bd -n openebs`\n- NDM creates a special type of devices called sparse devices depending on the `SPARSE_FILE_COUNT` and `SPARSE_FILE_SIZE` passed to the NDM Daemon. These devices are used in cases where nodes do not have any additional devices attached to the node and users would like to run their applications by carving out some spaces from the OS disk. The creation of sparse devices is disabled by default from OpenEBS 1.3.\n- Users or Operators like cStor Operator, Local PV provisioner interact with NDM by creating a BlockDeviceClaim CR. The BlockDeviceClaim will have properties like nodeName, required Capacity etc., The NDM operator will match these properties with the available BlockDevices and associate the one that matches all the requirements to BlockDeviceClaim.\n\n---\n\n### NDM Known Issues / Future Development Items\n\n- BlockDevices are not created for Partitions and LVM devices. If you need to use them, you have to manually create BlockDevice CR. The steps are mentioned in this [blog](https://blog.mayadata.io/openebs/creating-manual-blockdevice).\n\nOK. Let us get started with some common issues reported and how to troubleshoot them.\n\n---\n\n#### Scenario #1\n\n**BlockDevice CR is not created for a device available on my node.**\n\nI have some disks attached to the node. Installed openebs, but blockdevice resources are not created for the devices.\n\n**Symptom:** I have some disks attached to the node. Installed openebs, but blockdevice resources are not created for the devices.\n\n**Troubleshooting:**\n\n1. Check `lsblk` output of the node\n2. Get the NDM config map.\n3. Check if the mount point of the disk is excluded in the filter configurations in configmap.\n4. From lsblk output check if the blockdevice you want to use is an LVM/software raid/ partition/LUKS filesystem. NDM currently does not support these types.\n5. If none of the above works, the logs of NDM daemonset can be checked. It will have information of disk being detected , and at what point the disk was excluded from blockdevice creation, (like `excluded by path-filter`)\n\n![](https://cdn-images-1.medium.com/max/800/0*q8rBQFw284gRYqjg)\n\n**Resolution:** Update the filter configuration in configmap and restart the NDM DaemonSet pod. This will create the blockdevices.\n\n---\n\n#### Scenario #2\n\n**After node reboot, one blockdevice became inactive and another blockdevice was created.**\n\n**Symptom:** When a node in the cluster rebooted. A blockdevice resource on that node was marked as inactive and a new resource was created. The new blockdevice also has the same details as the old one.\n\n**Troubleshooting:**\n\n1. Check `lsblk` output of the node\n2. Get the yaml of both blockdevices and compare them.\n3. Check to see `spec.Path` is different in both outputs.\n4. If yes, then the new blockdevice resource was created because the path changed\n5. Check if `kubernetes.io/hostname` is different, if yes , then the blockdevice was created because the hostname of the node changed.\n\n**Resolution:** If using cStor, the newly generated BD can be added in both SPC and CSP instead of the old BD resource. Thus the storage engine will claim the new BD resource and start using it.\n\n**Root Cause:** Whenever the NDM deamonset pods shutdown, all the devices on that node will be marked into an UNknown state. When the pod comes backup, all the devices on that node are marked as inactive and then individual devices are processed for their statuses.\n\nNDM uses an md5 sum of WWN+Model+Serial of the disk to create its unique name. If none of these fields are available then NDM uses device path and hostname to create the blockdevice. There are chances that the device path/hostname has changed after reboot. If the path/hostname changes a new blockdevice resource will be created, and the old one will still be in the inactive state.\n\n---\n\n#### Scenario #3\n\n**BlockDevices are created for already used disks in which OS is installed**\n\n**Symptom:** NDM created blockdevice resources for disks which are already used for OS partitions. By default NDM excludes the blockdevices that are mounted at `/, /boot, /etc/hosts`. If these mount points are on an LVM or SoftRaid, NDM will not be able to identify that.\n\n**Resolution:** Support for LVM and software RAID is in the design phase. Once it is supported the issue will be resolved.\n\n---\n\n#### Scenario #4\n\n**Only one Blockdevice is created, when devices are connected in multipath configuration**\n\n**Symptom:** There is a disk attached in multipath configuration to a node. i.e both sdb & sdc are the same devices. But blockdevice resource is created only for sdc.\n\n**Resolution:** Support for detecting disks in multipath configuration and attaching the same disk to multiple nodes will be available in the future versions of NDM\n\n**Root Cause:** NDM generates the UID for disk identification using the disk details like WWN, Serial etc that are fetched from the disk. In case of a disk attached in multipath configuration, the details from both sdb and sdc will be the same. Therefore, NDM will first create a blockdevice for sdb, and then moves on to create for `sdc`. But at this stage it will find that a blockdevice with that UID already exists and will update the blockdevice information with the new path `sdc`. This results in a blockdevice existing only for sdc.\n\n---\n\n#### Scenario #5\n\n**Only single BlockDevice resource is created in a multi-node Kubernetes cluster on GKE.**\n\n**Symptom:** On a multinode kubernetes cluster in GKE, with an external GPD attached to each node. NDM is creating only one blockdevice resource, instead of one blockdevice resource per node.\n\n**Troubleshooting:**\n\n1. Was the GPD added using the gcloud CLI or google cloud console web UI.\n2. If the disk was added using gcloud CLI, check whether the ` — device-name` flag was specified during attaching the disk.\n\n**Resolution:** The command to add disk using gcloud CLI should be\n\n    gcloud compute instances attach-disk <node-name> --disk=disk-1 **--device-name=disk-1**\n\n**Root Cause:** gcloud CLI uses the value provided in the `device-name` flag as the serial number of the GPD when it is attached to the node. If it is left blank, google will assign a default serial number that is unique only to the node. When multiple nodes are present, and NDM generates the UID for the blockdevice, the disks on both nodes will have the same serial number and thus the same UID.\n\nNDM from one node will create the blockdevice resource and when the other NDM daemon tries to create the resource, it finds that a resource already exists and just updates the resource.\n\nThis blog was originally published on Jan 7th, 2020 on [MayaData blog](https://blog.mayadata.io/openebs/openebs-node-device-management-ndm-troubleshooting-tips).\n","slug":"openebs-node-device-management-ndmtroubleshooting-tips"},{"id":32,"title":"cStor Pool Operations via CSPC in OpenEBS","author":"Ashutosh Kumar","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut","date":"03-01-2020","tags":["Containerattachedstorage"," Cspc"," Kubernetes"," Openebs"," Operations"],"excerpt":"CStor Data Engine is popular for workloads needing efficient capacity management, replicas, point in time snapshots, incremental backups, etc. The tutorial will provision striped cStor pools and perform operations on them.","content":"\n**An enhanced schema for OpenEBS cStor Pool Management**\n\nCStor Data Engine is popular for workloads needing efficient capacity management, replicas, point in time snapshots, incremental backups, etc. Since achieving Beta last year, cStor Data Engine has been powering many Stateful Applications, including a variety of databases.\n\nWhile users love cStor for its data management capabilities, they have been providing feedback that it is not as easy to use as Jiva. We have started working on user feedback starting with OpenEBS 1.2 release and incrementally enhancing the cStor functionality.\n\nAs cStor is already running in production, the new changes are being introduced via a set of new cStor Custom Resources, which will get into in a bit. The users can continue to use the current schema, as we stabilize the new design and support a seamless migration. You can help us improve by providing feedback on the new design [here](https://github.com/openebs/openebs/tree/master/contribute/design/1.x/cstor-operator) or by raising [issues](https://github.com/openebs/openebs/issues).\n\nTo give a high-level overview of the new design, the following will be changed:\n\n- A new component/deployment called cspc-operator will be deployed for managing the new custom resources.\n- CSPC — cStor Pool Cluster will be replacing the SPC. The spec of the CSPC has been modified to provide cleaner abstractions for managing blockdevices on each node.\n- CSPI — cStor Pool Instance will be replacing CSP.\n\nThe new schema will only support manual cStor Pools creation as we learned that supporting both manual and auto using a single customer CR can lead to more confusion. In future releases, a new schema will be introduced to support the automatic creation of the cStor Pools.\n\nCSPC can be used to provision cStor pool as well as carry out day 2 pool operations such as: Following storage day 2 operations are supported via the CSPC schema:\n\n- Pool Expansion ( Supported in OpenEBS version >=1.2, alpha )\n- Pool Deletion ( Supported in OpenEBS version >=1.2, alpha )\n- Pool Scale Up ( Supported in OpenEBS version >=1.2, alpha )\n- Block Device Replacement ( Supported in OpenEBS version >=1.5, alpha)\n\nLet us go through a short hands-on tutorial to understand these.\n\nThe tutorial will provision striped cStor pools and perform operations on them (this can be done for other cStor raid groups too and I will post that in a separate blog).\n\n#### Prerequisite Steps\n\n- Kubernetes cluster of version >= 1.14 with 3 worker nodes.\n- Attach at least 2 disks to each of the nodes to follow up with the tutorial. I am using GKE and steps to create and attach a disk to a node are given in the following link :\n[https://cloud.google.com/sdk/gcloud/reference/compute/disks/create\n](https://cloud.google.com/sdk/gcloud/reference/compute/disks/create)[https://cloud.google.com/sdk/gcloud/reference/compute/instances/attach-disk\n](https://cloud.google.com/sdk/gcloud/reference/compute/instances/attach-disk)If you are using other providers, check with their reference manuals on how to attach a disk. Also, feel free to reach out on the OpenEBS slack channel if you need any assistance.\n- I have used the following script to create 6 disks.\n*{ for i in {1..6}; do gcloud compute disks create demo-disk-$i — zone=us-central1-a — size=100GB; done; }*\n- Now, I will attach 2 disks to each of the nodes. I have used the following commands to attach.\n\n*for i in {1..2}; do gcloud compute instances attach-disk gke-cstor-demo-default-pool-3385ab41–2ldq — disk demo-disk-$i — device-name demo-disk-$i — zone us-central1-a; done*\n\n*for i in {3..4}; do gcloud compute instances attach-disk gke-cstor-demo-default-pool-3385ab41-bb69 — disk demo-disk-$i — device-name demo-disk-$i — zone us-central1-a; done*\n\n*for i in {5..6}; do gcloud compute instances attach-disk gke-cstor-demo-default-pool-3385ab41-hrmr — disk demo-disk-$i — device-name demo-disk-$i — zone us-central1-a; done*\n\n- Install OpenEBS 1.5. Run following to install: ( Note that block device replacement support starts from OpenEBS version 1.5. There will be a separate blog post to describe that. )\n*kubectl apply -f* [*https://openebs.github.io/charts/openebs-operator-1.5.0.yaml*](https://openebs.github.io/charts/openebs-operator-1.6.0.yaml)\n- Install CStor-Operator. Run following to install:\nkubectl apply -f [https://raw.githubusercontent.com/openebs/openebs/master/k8s/cstor-operator.yaml](https://raw.githubusercontent.com/openebs/openebs/master/k8s/cstor-operator.yaml)\n\n#### Pool Provisioning\n\nYou need to specify cStor pool intent in a CSPC YAML to provision cStor pools on nodes. I am going to provision 3 stripe cStor pools. Let us prepare a CSPC YAML now.\n\nFollowing command list all block devices which represent your attached disks. I am going to pick 1 block device from each node to form a CSPC YAML.\n\n    $ kubectl get bd -n openebs\n    NAME                                           NODENAME                                    SIZE           CLAIMSTATE   STATUS   AGE\n\n    blockdevice-474d20376a541a8fb372d44f5bc361ea   gke-cstor-demo-default-pool-3385ab41-hrmr   107374182400   Unclaimed    Active   34s\n\n    blockdevice-9773ccb731e4e3e10c2838411f5f8b2a   gke-cstor-demo-default-pool-3385ab41-bb69   107374182400   Unclaimed    Active   37s\n\n    blockdevice-9c8df120e17379bfd1fe5c3ce9aa8185   gke-cstor-demo-default-pool-3385ab41-bb69   107374182400   Unclaimed    Active   37s\n\n    blockdevice-ada8ef910929513c1ad650c08fbe3f36   gke-cstor-demo-default-pool-3385ab41-2ldq   107374182400   Unclaimed    Active   34s\n\n    blockdevice-d2d59218ed78560b206143ab0641470c   gke-cstor-demo-default-pool-3385ab41-hrmr   107374182400   Unclaimed    Active   34s\n\n    blockdevice-f6408e135943e1ee45171034655a8b88   gke-cstor-demo-default-pool-3385ab41-2ldq   107374182400   Unclaimed    Active   34s\n\nMy CSPC YAML is on the following link ( you can copy/download and make changes accordingly).\n\n[https://raw.githubusercontent.com/openebs/elves/a8ce5d6401f1ab829a35214ea01c284ccfb03c13/demo/cspc/cspc-stripe.yaml](https://raw.githubusercontent.com/openebs/elves/a8ce5d6401f1ab829a35214ea01c284ccfb03c13/demo/cspc/cspc-stripe.yaml)\n\nSave the above file with your changes and apply the above YAML to provision cStor pools.\n\n    $ kubectl apply -f https://raw.githubusercontent.com/openebs/elves/a8ce5d6401f1ab829a35214ea01c284ccfb03c13/demo/cspc/cspc-stripe.yaml\n    cstorpoolcluster.openebs.io/cspc-stripe created\n\n    $ kubectl get cspi -n openebs\n\n    NAME               HOSTNAME                                    ALLOCATED   FREE    CAPACITY   STATUS   AGE\n\n    cspc-stripe-8vtx   gke-cstor-demo-default-pool-3385ab41-2ldq   69.5K       99.5G   99.5G      ONLINE   99s\n\n    cspc-stripe-h7kl   gke-cstor-demo-default-pool-3385ab41-bb69   69.5K       99.5G   99.5G      ONLINE   99s\n\n    cspc-stripe-x9pw   gke-cstor-demo-default-pool-3385ab41-hrmr   69.5K       99.5G   99.5G      ONLINE   99s\n\nIf you want to deploy a workload to use the cStor pool, go through the following cStor CSI driver link:\n[https://github.com/openebs/cstor-csi/blob/master/README.md](https://github.com/openebs/cstor-csi/blob/master/README.md)\n\nIn the next section, we will do pool expansion.\n\n#### Pool Expansion\n\nLet us expand one cStor stripe pool on a node by editing the CSPC cspc-stripe.\n\n    $ kubectl edit cspc cspc-stripe -n openebs\n\nSimply, add one more block device as follows. Make sure you do not put a block device that is a part of any other CSPC. I have added block device *blockdevice-d2d59218ed78560b206143ab0641470c* in my case.\n\n    $ kubectl edit cspc cspc-stripe -n openebs\n\n    ...\n    spec:\n      pools:\n      - nodeSelector:\n          kubernetes.io/hostname: gke-cstor-demo-default-pool-3385ab41-hrmr\n        poolConfig:\n          cacheFile: \"\"\n          compression: \"off\"\n          defaultRaidGroupType: stripe\n          overProvisioning: false\n        raidGroups:\n        - blockDevices:\n          - blockDeviceName: blockdevice-474d20376a541a8fb372d44f5bc361ea\n            capacity: \"\"\n            devLink: \"\"\n    # Block  device added. This must be attached to node\n    # gke-cstor-demo-default-pool-3385ab41-hrmr and should not be used by any other CSPC.\n          - blockDeviceName: blockdevice-d2d59218ed78560b206143ab0641470c\n\n          isReadCache: false\n          isSpare: false\n          isWriteCache: false\n          type: stripe\n    ...\n\nSave the above changes.\n\n    $ kubectl get cspi -n openebs\n\n    NAME               HOSTNAME                                    ALLOCATED   FREE    CAPACITY   STATUS   AGE\n\n    cspc-stripe-8vtx   gke-cstor-demo-default-pool-3385ab41-2ldq   268K        99.5G   99.5G      ONLINE   17m\n\n    cspc-stripe-h7kl   gke-cstor-demo-default-pool-3385ab41-bb69   292K        99.5G   99.5G      ONLINE   17m\n\n    cspc-stripe-x9pw   gke-cstor-demo-default-pool-3385ab41-hrmr   232K        199G    199G       ONLINE   17m\n\nYou can see that the pool cspc-stripe-x9pw got expanded. (Re-run the get cspi command if the bigger size is not shown instantaneously). Similarly, you can expand the other stripe cStor pools of the CSPC.\n\n#### Pool Deletion\n\nTo delete a cStor pool from node simple remove the node configuration from the CSPC.\n\nLet us delete one pool from CSPC cspc-stripe.\n\n    $ kubectl edit cspc cspc-stripe -n openebs\n    I have removed following entire config from the CSPC to delete pool on host gke-cstor-demo-default-pool-3385ab41-2ldq.\n    ...\n      - nodeSelector:\n          kubernetes.io/hostname: gke-cstor-demo-default-pool-3385ab41-2ldq\n        poolConfig:\n          cacheFile: \"\"\n          compression: \"off\"\n          defaultRaidGroupType: stripe\n          overProvisioning: false\n        raidGroups:\n        - blockDevices:\n          - blockDeviceName: blockdevice-ada8ef910929513c1ad650c08fbe3f36\n            capacity: \"\"\n            devLink: \"\"\n\n          isReadCache: false\n          isSpare: false\n          isWriteCache: false\n          type: stripe\n    ...\n\nAfter you are done removing, save it and you will see that pool on that node has been deleted.\n\n    $ kubectl get cspi -n openebs\n    NAME               HOSTNAME                                    ALLOCATED   FREE    CAPACITY   STATUS   AGE\n\n    cspc-stripe-h7kl   gke-cstor-demo-default-pool-3385ab41-bb69   335K        99.5G   99.5G      ONLINE   25m\n\n    cspc-stripe-x9pw   gke-cstor-demo-default-pool-3385ab41-hrmr   372K        199G    199G       ONLINE   25m\n\nYou can see that only two stripe pools are present.\n\n#### Pool Scale Up\n\nWe can even create a pool on other nodes by adding node config to the CSPC YAML. It is just the reverse of pool deletion.\n\nLet us try to add the same node config that we removed to again create the pool on the node. Make sure that while copy, pasting and editing indentation of YAML is not disturbed else error will be thrown and YAML will not be persisted.\n\nAdd the removed config from the pool deletion section to the CSPC.\n\n    $ kubectl get cspi -n openebs\n    NAME               HOSTNAME                                    ALLOCATED   FREE    CAPACITY   STATUS   AGE\n\n    cspc-stripe-h7kl   gke-cstor-demo-default-pool-3385ab41-bb69   318K        99.5G   99.5G      ONLINE   30m\n\n    cspc-stripe-twvv   gke-cstor-demo-default-pool-3385ab41-2ldq   50K         99.5G   99.5G      ONLINE   9s\n\n    cspc-stripe-x9pw   gke-cstor-demo-default-pool-3385ab41-hrmr   380K        199G    199G       ONLINE   30m\n\nYou can see that a new pool cspc-stripe-twvv has come up online.\n\nYou can also delete the CStorPoolCluster too. If you do so, all the CStorPoolInstances associated with it will get deleted.\n\nThe command is :\n\n    $ kubectl delete cspc <cspc-name> <cspc-namespace>\n\nNOTES:\n\n- Whenever a block device is used for pool creation or expansion a blockdeviceclaim CR is created and the block device will show a Claimed status.\nThe following are the commands to visualize this.\nkubectl get blockdevice -n openebs \nkubectl get blockdeviceclaim -n openebs\n- Whenever a pool is deleted for a CSPC by removing the node config, the associated block-device is not ‘Unclaimed’ and if the same block device needs to be used in another CSPC, the associated blockdeviceclaim needs to be cleared manually. Although, the block-device can be again used for the same CSPC.\n\nTo unclaim a block device claim, below are the steps.\n\n\n    $ kubectl get bdc -n openebs\n      NAME                                             BLOCKDEVICENAME                                PHASE   AGE\n\n      bdc-cstor-83b8e958-d978-11e9-b0e6-42010a800189   blockdevice-9773ccb731e4e3e10c2838411f5f8b2a   Bound   32m\n\n      bdc-cstor-8581dac0-d978-11e9-b0e6-42010a800189   blockdevice-ada8ef910929513c1ad650c08fbe3f36   Bound   32m\n\n      bdc-cstor-85bddd0e-d978-11e9-b0e6-42010a800189   blockdevice-474d20376a541a8fb372d44f5bc361ea   Bound   32m\n\n      bdc-cstor-85c0fd2a-d978-11e9-b0e6-42010a800189   blockdevice-d2d59218ed78560b206143ab0641470c   Bound   15m\n\nLet us say, we want to unclaim block device blockdevice-d2d59218ed78560b206143ab0641470c, then we need to delete the associated blockdeviceclaim i.e. bdc-cstor-85c0fd2a-d978–11e9-b0e6–42010a800189.\n\n    $ kubectl edit bdc bdc-cstor-85c0fd2a-d978-11e9-b0e6-42010a800189 -n openebs\n      Remove the finalizer \"cstorpoolcluster.openebs.io/finalizer\" by editing the bdc from above command.\n      After that, execute following\n\n    $ kubectl delete bdc bdc-cstor-85c0fd2a-d978-11e9-b0e6-42010a800189 -n openebs\n\nNow the device will get unclaimed. Please note the following:\nBDC CRs should be deleted only when their association with CSPC has been removed. Otherwise, data corruption can happen.\n\n#### Block Device Replacement\n\nThe CSPC operator in OpenEBS (≥1.5 version ) enables you to do the replacement of the block devices in case it has gone bad. I will follow up with another blog post that will cover this block device replacement scenario.\n\nHope that the tutorial helps in understanding the pool operations steps.\n\nIf you have any questions or face any problems, feel free to reach out to me on OpenEBS slack channel.\n\nThank You!\n\nThis blog was originally published on Dec 13, 2019 on [MayaData blog](https://blog.mayadata.io/openebs/cstor-pool-operations-via-cspc-in-openebs).\n","slug":"cstor-pool-operations-via-cspc-in-openebs"},{"id":33,"title":"OpenEBS Dynamic Volume Provisioning on ZFS","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"13-12-2019","tags":["Cncf"," Kubernetes"," Persistent Volume"," Zfs"," Openebs"],"excerpt":"OpenEBS’ ZFS driver binds a ZFS file system into the Kubernetes environment and allows users to provision and de-provision volumes dynamically. This blog will demonstrate how to deploy a Percona application on the ZFS storage system with OpenEBS.","content":"\nOpenEBS’ ZFS driver binds a ZFS file system into the Kubernetes environment and allows users to provision and de-provision volumes dynamically. This blog will demonstrate how to deploy a Percona application on the ZFS storage system with OpenEBS.\n\nUsing a ZFS Local PV has the following advantages — as opposed to Kubernetes native Local PV backed by direct attached devices:\n\n- Sharing of the devices among multiple application pods.\n- Enforcing quota on the volumes, making sure the pods don’t consume more than the capacity allocated to them.\n- Ability to take snapshots of the Local PV\n- Ability to sustain the disk failures — using the ZPOOL RAID functionality\n- Ability to use data services like compression and encryption.\n\nIn this post, I will demonstrate how we can use ZFS Local PV for deploying a Percona application.\n\n**Setup**\n\nWe will be using GKE with Kubernetes 1.14+ version with Ubuntu 18.4 installed on each node. We have to set up the node with ZFS utility once the cluster is up and running. We need to install [zfsutils-linux](https://packages.ubuntu.com/bionic/zfsutils-linux) on each node and use [ZFS commands](https://www.thegeekdiary.com/solaris-zfs-command-line-reference-cheat-sheet/) to set up a storage pool.\n\n    $ apt-get install -y zfsutils-linux\n\nCreate and Attach the disk (if not already attached) to the nodes for setting up the ZPOOL:\n\n    $ gcloud compute disks create <disk-name> --size <size> --type pd-standard  --zone us-central1-a\n\n    $ gcloud compute instances attach-disk <node-name> --disk <disk-name> --zone us-central1-a\n\nCreate the zpool on each node using the attached disks (sdb and sdc):\n\n    $ zpool create zfspv-pool mirror /dev/sdb /dev/sdc\n\nHere we are creating a mirrored ZPOOL, we can create any kind of pool as per our requirement (raidz, striped or mirror).\n\nCheck the zpool list:\n\n    $ zfs list\n    NAME USED AVAIL REFER MOUNTPOINT\n\n    zfspv-pool 644K 96.4G 176K /zfspv-pool\n\nInstall OpenEBS ZFS driver :\n\n    $ kubectl apply -f [https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/zfs-operator.yaml](https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/zfs-operator.yaml)\n\nCheck that the driver is installed:\n\n    $ kubectl get pods -n kube-system -l role=openebs-zfs\n\n    NAME READY STATUS RESTARTS AGE\n\n    openebs-zfs-controller-0 4/4 Running 0 5h28m\n\n    openebs-zfs-node-4d94n 2/2 Running 0 5h28m\n\n    openebs-zfs-node-gssh8 2/2 Running 0 5h28m\n\n    openebs-zfs-node-twmx8 2/2 Running 0 5h28m\n\n**Create The Storage Class:**\n\n    $ cat sc.yaml\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: percona-sc\n    allowVolumeExpansion: true\n    parameters:\n      poolname: \"zfspv-pool\"\n    provisioner: zfs.csi.openebs.io\n\nThe storage class has a *poolname* parameter, which means that any volume provisioned using this storage class will be provisioned in this pool (zfspv-pool here). The provisioner *zfs.csi.openebs.io* is the provisioner name for the ZFS driver. You can change the poolname to the name of the ZPOOL which you have created for the provisioning. Apply the YAML to create the storage class:\n\n    $ kubectl apply -f sc.yaml\n\n    storageclass.storage.k8s.io/percona-sc created\n\n**Create The PVC:**\n\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n      name: percona-pvc\n    spec:\n      storageClassName: percona-sc\n      accessModes:\n        - ReadWriteOnce\n      resources:\n        requests:\n          storage: 4Gi\n\nCreate the PVC using the storage class created for the ZFS driver. You can request for the storage space via storage parameter as shown in above PVC for putting a request for 4Gi storage. Apply the YAML to create the PVC request.\n\n    $ kubectl apply -f pvc.yaml\n\n    persistentvolumeclaim/percona-pvc\n\nCheck the PVC\n\n    $ kubectl get pvc\n\n    NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\n\n    percona-pvc Bound pvc-ecdb16e2-e03a-11e9-b418–42010a80006b 4Gi RWO percona-sc 5m39s\n\nHere, we can see that the PVC has been created and bound also as well.\n\n**Percona YAML:**\n\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n      annotations:\n      name: sqltest\n      namespace: default\n    data:\n      sql-test.sh: |\n        #!/bin/bash\n\n    DB_PREFIX=\"Inventory\"\n        DB_SUFFIX=`echo $(mktemp) | cut -d '.' -f 2`\n        DB_NAME=\"${DB_PREFIX}_${DB_SUFFIX}\"\n\n    echo -e \"nWaiting for mysql server to start accepting connections..\"\n        retries=10;wait_retry=30\n        for i in `seq 1 $retries`; do\n          mysql -uroot -pk8sDem0 -e 'status' > /dev/null 2>&1\n          rc=$?\n          [ $rc -eq 0 ] && break\n          sleep $wait_retry\n        done\n\n    if [ $rc -ne 0 ];\n        then\n          echo -e \"nFailed to connect to db server after trying for $(($retries * $wait_retry))s, exitingn\"\n          exit 1\n        fi\n        mysql -uroot -pk8sDem0 -e \"CREATE DATABASE $DB_NAME;\"\n        mysql -uroot -pk8sDem0 -e \"CREATE TABLE Hardware (id INTEGER, name VARCHAR(20), owner VARCHAR(20),description VARCHAR(20));\" $DB_NAME\n        mysql -uroot -pk8sDem0 -e \"INSERT INTO Hardware (id, name, owner, description) values (1, \"dellserver\", \"basavaraj\", \"controller\");\" $DB_NAME\n        mysql -uroot -pk8sDem0 -e \"DROP DATABASE $DB_NAME;\"\n    ---\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: percona\n      labels:\n        name: percona\n    spec:\n      replicas: 1\n      selector:\n        matchLabels:\n          name: percona\n      template:\n        metadata:\n          labels:\n            name: percona\n        spec:\n          containers:\n            - resources:\n              name: percona\n              image: openebs/tests-custom-percona:latest\n              imagePullPolicy: IfNotPresent\n              args:\n                - \"--ignore-db-dir\"\n                - \"lost+found\"\n              env:\n                - name: MYSQL_ROOT_PASSWORD\n                  value: k8sDem0\n              ports:\n                - containerPort: 3306\n                  name: percona\n              volumeMounts:\n                - mountPath: /var/lib/mysql\n                  name: demo-vol1\n                - mountPath: /sql-test.sh\n                  subPath: sql-test.sh\n                  name: sqltest-configmap\n              livenessProbe:\n                exec:\n                  command: [\"bash\", \"sql-test.sh\"]\n                initialDelaySeconds: 30\n                periodSeconds: 1\n                timeoutSeconds: 10\n          volumes:\n            - name: demo-vol1\n              persistentVolumeClaim:\n                claimName: percona-pvc\n            - name: sqltest-configmap\n              configMap:\n                name: sqltest\n\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: percona-mysql\n      labels:\n        name: percona-mysql\n    spec:\n      ports:\n        - port: 3306\n          targetPort: 3306\n      selector:\n          name: percona\n\nApply the configuration:\n\n    $ kubectl apply -f percona.yaml\n\n    configmap/sqltest created\n    deployment.apps/percona created\n    service/percona-mysql created\n\nCheck the status of the Pod.\n\n    $ kubectl get po\n\n    NAME READY STATUS RESTARTS AGE\n\n    percona-7456dc6f7b-nnfcz 1/1 Running 0 67s\n\nWe can go the node where percona pod is scheduled and see that a volume has been created in the pool zfspv-pool using the ZFS list command,:-\n\n    $ zfs list\n\n    NAME USED AVAIL REFER MOUNTPOINT\n\n    zfspv-pool 115M 96.3G 176K /zfspv-pool\n\n    zfspv-pool/pvc-ecdb16e2-e03a-11e9-b418–42010a80006b 102M 96.3G 102M -\n\n### Summary\n\nAs demonstrated in this blog, OpenEBS makes it easy for the Kubernetes applications to take advantage of all the technical features provided by ZFS storage.\n\n### Important links\n\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n","slug":"openebs-dynamic-volume-provisioning-on-zfs"},{"id":34,"title":"Cloud Native Chaos Engineering — Enhancing Kubernetes Application Resiliency","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"25-11-2019","tags":["Chaos Engineering"," Cloud Native"," Docker"," Kubernetes"," Uncategorized"],"excerpt":"In this blog, I would like to introduce a relatively new or less frequently used term called “Cloud Native Chaos Engineering”, defined as engineering practices focused on (and built on) Kubernetes environments, applications, microservices, and infrastructure.","content":"\n## Extending Cloud Native Principles to Chaos Engineering\n\nFaults are bound to happen no matter how hard you test to find them before putting your software into production — clouds and availability zones will have issues, networks will drop, and, yes, bugs will make their presence felt. Resilience is how well a system withstands such faults — a highly resilient system, for example, one built with loosely coupled micro services that can themselves be restarted and scaled easily, overcomes such faults without impacting users. Chaos Engineering is the practice of injecting faults into a system before they naturally occur. Chaos Engineering is now accepted as an essential approach for ensuring that today’s frequently changing and highly complex systems are achieving the resilience required. Through chaos engineering, unanticipated failure scenarios can be discovered and corrected before causing user issues.\n\nBroad adoption has made Kubernetes one of the most important platforms for software development and operations. The word “Cloud Native” is an overloaded term that has been co-opted by many traditional vendors to mean almost anything; even CNCF has allowed the use of the term cloud native to describe technologies that predate the cloud native pattern by, in some cases, decades. For the purposes of this blog, I’d like to use a more technical definition of cloud native; cloud native is here defined as an architecture where the components are microservices that are loosely coupled and, more specifically, are deployed in containers that are orchestrated by Kubernetes and related projects.\n\nIn this blog, I would like to introduce a relatively new or less frequently used term called “Cloud Native Chaos Engineering”, defined as engineering practices focused on (and built on) Kubernetes environments, applications, microservices, and infrastructure.\n\nCNCF is, first and foremost, an open-source community (while some projects may not be strictly cloud native, they are all open-source). If Kubernetes had not been open-source, it would not have become the defacto platform for software development and operations. With that in mind, I’d like to stake the claim that Cloud Native Chaos Engineering is necessarily based on open source technologies.\n\n## 4 Principles of a Cloud Native Chaos Engineering Framework\n\n1. Open source — The framework has to be completely open-source under the Apache2 License to encourage broader community participation and inspection. The number of applications moving to the Kubernetes platform is limitless. At such a large scale, only the Open Chaos model will thrive and get the required adoption.\n2. CRDs for Chaos Management — Kubernetes native — defined here as using Kubernetes CRDs as APIs for both Developers and SREs to build and orchestrate chaos testing. The CRDs act as standard APIs to provision and manage the chaos.\n3. Extensible and pluggable — One lesson learned why cloud native approaches are winning is that their components can be relatively easily swapped out and new ones introduced as needed. Any standard chaos library or functionality developed by other open-source developers should be able to be integrated into and orchestrated for testing via this pluggable framework.\n4. Broad Community adoption — Once we have the APIs, Operator, and plugin framework, we have all the ingredients needed for a common way of injecting chaos. The chaos will be run against a well-known infrastructure like Kubernetes or applications like databases or other infrastructure components like storage or networking. These chaos experiments can be reused, and a broad-based community is useful for identifying and contributing to other high-value scenarios. Hence a Chaos Engineering framework should provide a central hub or forge where open-source chaos experiments are shared, and collaboration via code is enabled.\n\n## Introduction to Litmus\n\nLitmus is a cloud native chaos Engineering framework for Kubernetes. It is unique in fulfilling all 4 of the above parameters. Litmus originally started as a chaos toolset to run E2E pipelines for the CNCF SandBox project OpenEBS — powering, for example, [OpenEBS.ci](https://openebs.ci/) — and has evolved into a completely open-source framework for building and operating chaos tests on Kubernetes based systems. It consists of four main components-\n\n- Chaos CRDs or API\n- Chaos Operator\n- Chaos libraries and plugin framework\n- Chaos Hub\n\n![Introduction to Litmus](https://cdn-images-1.medium.com/max/800/0*GSvTfFh5KgBKM7M5.png)\n\n## Chaos API\n\nCurrently, Litmus provides three APIs:\n\n- ChaosEngine\n- ChaosExperiment\n- ChaosResult\n\nChaosEngine: ChaosEngine CR is created for a given application and is tagged with appLabel. This CR ties one or more ChaosExperiments to an application.\n\nChaosExperiment: ChaosExperiment CR is created to hold and operate the details of actual chaos on an application. It defines the type of experiment and key parameters of the experiment.\n\nChaosResult: ChaosResult CR is created by the operator after an experiment is run. One ChaosResult CR is maintained per ChaosEngine. The ChaosResult CR is useful in making sense of a given ChaosExperiment. This CR is used for generating chaos analytics which can be extremely useful — for example when certain components are upgraded between the chaos experiments, and the results need to be easily compared\n\n## Chaos Operator\n\nThe Litmus Operator is implemented using the Operator-SDK. This operator manages the lifecycle of the chaos CRs. The lifecycle of Litmus itself can be managed using this operator as it follows the lifecycle management API requirements. The chaos operator is also available at [operatorhub.io](https://operatorhub.io/operator/litmuschaos)\n\n## Chaos Libraries and external Plugins\n\nThe actual injection of chaos is done by chaos libraries or chaos executors. For example, the Litmus project has already built a chaos library called “LitmusLib”. LitmusLib is aware of how to kill a pod, how to introduce a CPU hog, how to hog memory or how to kill a node, and several other faults and degradations. Like LitmusLib, there are other open-source chaos projects like Pumba or PowerfulSeal. The CNCF landscape has more details of various chaos engineering projects. As shown below, the Litmus plugin framework allows other chaos projects to make use of Litmus for chaos orchestration. For example, one can create a chaos chart for the pod-kill experiment using Pumba or PowerfulSeal and execute it via the Litmus framework.\n\n![Chaos Libraries and external Plugins](https://cdn-images-1.medium.com/max/800/0*0vm-YfScAxXoijFd.png)\n\n**PowerfulSeal and Pumba are shown as examples.**\n\n## Chaos Hub\n\nChaos charts are located at [hub.litmuschaos.io](https://hub.litmuschaos.io/). ChaosHub brings all the reusable chaos experiments together. Application developers and SRE share their chaos experiences for others to reuse. The goal of the hub is to have the developers share the failure tests that they are using to validate their applications in CI pipelines to their users, who are typically SREs.\n\n![Chaos Hub](https://cdn-images-1.medium.com/max/800/0*22JUDGxtNFNcgU5J.png)\n\nCurrently, the chaos hub contains charts for Kubernetes chaos and OpenEBS chaos. We expect to receive more contributions from the community going forward.\n\n### Example use cases of Litmus:\n\nThe most simple use case of Litmus is application developers using Litmus in the development phase itself. Chaos Engineering has been limited to the Production environment, and lately, we are seeing this practice being adopted in CI pipelines. But with Litmus, chaos testing is possible during development as well. Like Unit Testing, Integration Testing, and Behavior-Driven Testing, Chaos Testing is a test philosophy for developers to carry out the negative test scenarios to test the resiliency of the code before the code is merged to the repository. Chaos testing can be appended very easily to the application, as shown below: Chaos testing can be appended very easily to the application, as shown below:\n\n![](https://cdn-images-1.medium.com/max/800/0*xT_x1Wd2TFyM2LfR.gif)\n\nOther use cases of Litmus are for inducing chaos in CI pipelines and production environments.\n\n## Summary\n\nWith the introduction of chaos operator, chaos CRDs, and chaos hub, Litmus has all the key ingredients of cloud native Chaos Engineering.\n\n### Important links:\n\nGitHub: [github.com/litmuschaos](https://github.com/litmuschaos/litmus)\n\nTwitter: [@litmuschaos](https://twitter.com/litmuschaos)\n\nChaos Charts: [hub.litmuschaos.io](https://hub.litmuschaos.io/)\n\nCommunity Slack: [#litmus channel on K8S Slack](https://kubernetes.slack.com/messages/CNXNB0ZTN)\n\nThis post was originally published by Umasankar Mukkara, on [Nov. 06, 2019 on CNCF’s blog](https://www.cncf.io/blog/2019/11/06/cloud-native-chaos-engineering-enhancing-kubernetes-application-resiliency/).\n","slug":"cloud-native-chaos-engineeringenhancing-kubernetes-application-resiliency"},{"id":35,"title":"ECK & OpenEBS — Data Ops Streamlines Deployment","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"23-08-2019","tags":["Eck"," Elasticsearch"," Kubernetes"," Localpv"," Openebs"],"excerpt":"Using OpenEBS, administrators can easily manage local PV storage resources for ECK seamlessly across both on-premises and multiple clouds, simplifying ElasticSearch ECK scaling and resilience while finally delivering a completely declaratively-managed application stack.","content":"\n### TL;DR\n\nUsing OpenEBS, administrators can easily manage local PV storage resources for ECK seamlessly across both on-premises and multiple clouds, simplifying ElasticSearch ECK scaling and resilience while finally delivering a completely declaratively-managed application stack. Let’s review how.\n\n**Good News: The recently shipped** [**Elastic Cloud on Kubernetes (ECK)**](https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond)** delivers Elasticsearch clusters as native, distributed Kubernetes Operators. **Elasticsearch is a distributed, open source search and analytics engine for all types of data. Widely used, Elasticsearch is storage-intensive because it builds an inverted index of collections of JSON objects that are related to each other to allow very fast full-text searches. The result is a simplified deployment of ElasticSearch for the Kubernetes admins or SREs as well as a simplified developer experience.\n\n**Bad News: ElasticSearch uses fast local storage but it does not address storage provisioning and management.** ECK use of the [static provisioner for Local ](https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner)PV requires administrators to manually format, mount, and configure disks on Kubernetes nodes. This is a PITA, as they say.\n\n**Good News: OpenEBS removes the burden of Storage Operations for ECK Deployments.** With OpenEBS, administrators can easily manage local PV storage resources for ECK seamlessly across both on-premises and multiple clouds, simplifying ElasticSearch scaling and resilience.\n\n### Vanilla K8s (PITA)\n\nTypically, ElasticSearch is deployed one of two ways:\n\n- **Dedicated mode:** Elastic pods are using LocalPV which are real disks, and they need to be dynamically provisioned as the pods’ scale.\n- **Shared mode:** Elastic pods are using LocalPVs from shared storage for better capacity economics.\n\nHere is the detail on K8s static provisioners from [K8s documentation](https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner)\n\n*Note that the local storage provisioner is different from most provisioners and does not support dynamic provisioning. Instead, it requires that administrators preconfigure the local volumes on each node and if volumes are supposed to be*\n\n- *Filesystem volumeMode (default) PVs — mount them under discovery directories.*\n- *Block volumeMode PVs — create a symbolic link under discovery directory to the block device on the node.*\n\n*The provisioner will manage the volumes under the discovery directories by creating and cleaning up PersistentVolumes for each volume.*\n\n*This means a Kubernetes administrator must manually manage storage operations outside of the ECK operator itself. Specifically,*\n\n*– Capacity resize of underlying volumes.*\n\n*– Capacity management of shared storage when deployed in shared mode.*\n\n*– Shifting of some of the data volumes from one node to another automatically in case a node has to be cordoned or drained.*\n\n*– Move data to other Kubernetes clusters.*\n\n**Note: insert administrator sweat equity here^.**\n\n### OpenEBS LocalPV + Data Ops (Good)\n\nAn OpenEBS storage cluster, itself Kubernetes-native, simplifies and automates storage provisioning and management operations either on your data center or in the cloud (or spanning both!). OpenEBS provisioners use OpenEBS disk pool operators and built-in data management capabilities to dynamically provision LocalPVs in a host path or in a disk mode to ECK pods.\n\n![](https://cdn-images-1.medium.com/max/800/1*PHw4zrcvJF_w-VcTI90RbA.png)\n\n### K8s Advantage: Declarative Data Plane\n\nOpenEBS uses a Declarative Data Plane to manage storage operations which aligns architecturally with Kubernetes Operators generally, and specifically with the ECK operator. Storage is typically the last “architectural mile” of Kubernetes deployments. Storage has gravity for applications that tends to tie Kubernetes clusters to the storage infrastructure beneath it. The OpenEBS Declarative Data Plane removes that last architectural mile by providing a completely Kubernetes-native software-defined storage infrastructure that spans on-premise and cloud resources and lets administrators manage Kubernetes application gravity consistently across all sites.\n\n**OpenEBS-managed storage means that the end-to-end operations of the entire Kubernetes application stack is finally managed, top to bottom, in a completely declarative way.**\n\n### Configuring a Dynamic localPV for ECK\n\nThe StorageClass spec for [OpenEBS LocalPV](https://docs.openebs.io/docs/next/uglocalpv.html) for automatically choosing an available disk on the node and mounting that disk with ext4 volume would look like the following:\n\n    cat <<EOF | kubectl apply -f -\n    apiVersion: elasticsearch.k8s.elastic.co/v1alpha1\n    kind: Elasticsearch\n    metadata:\n     name: quickstart\n    spec:\n     version: 7.2.0\n     nodes:\n     — nodeCount: 3\n     config:\n     node.master: true\n     node.data: true\n     node.ingest: true\n     volumeClaimTemplates:\n     — metadata:\n     name: elasticsearch-data # note: elasticsearch-data must be the name of the Elasticsearch volume\n     spec:\n     accessModes:\n     — ReadWriteOnce\n     resources:\n     requests:\n     storage: 10Gi\n     storageClassName: OpenEBS-LocalPV\n    EOF\n\nThe StorageClass spec for [OpenEBS LocalPV](https://docs.openebs.io/docs/next/uglocalpv.html) for automatically choosing an available disk on the node and mounting that disk with ext4 volume would look like the following:\n\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-localpv-disk\n      annotations:\n        openebs.io/cas-type: local\n        cas.openebs.io/config: |\n          - name: StorageType\n            value: \"device\"\n          - name: FSType\n            value: ext4\n    provisioner: openebs.io/local\n    volumeBindingMode: WaitForFirstConsumer\n    reclaimPolicy: Delete\n    ---\n\nIn my next blog, I will give a simple tutorial of how to configure OpenEBS and ECK to realize the dynamic local PV allocations.\n\n### Summary\n\nUsing OpenEBS administrators can easily manage local PV storage resources for ECK seamlessly across both on-premises and multiple clouds, simplifying ElasticSearch ECK scaling and resilience while finally delivering a completely declaratively-managed application stack.\n\n### Important links\n\n- Haven’t joined our wonderful OpenEBS community? Join [here](https://slack.openebs.io).\n- [Free forever Kubernetes visibility](https://director.mayadata.io).\n","slug":"eck-openebsdata-ops-streamlines-deployment"},{"id":36,"title":"The Myth of THE database","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"21-08-2019","tags":["DevOps"," Kubernetes"," Openebs"," Postgresql"," Database"],"excerpt":"In this blog I briefly discuss the disaggregation of the DB at what might be called the macro or architecture level and then at the micro or intra DB level. ","content":"\nI feel blessed these days to be on the front lines of Kubernetes becoming the preferred platform for running all workloads, including high value stateful workloads.\n\nOne pattern many of my investor friends — and even new MayaData team members not already encamped in the CNCF ecosystem may be overlooking — is the demise of the THE database pattern. Actually looking back at a DBaaS on Kubernetes blog I wrote less than a year ago I think I didn’t emphasize enough that there is rarely one layer, or one DB at the core of it all. (see that blog [here](https://blog.openebs.io/running-your-own-dbaas-based-on-your-preferred-dbs-kubernetes-operators-and-containerized-storage-3cc36ba115b8) if you are curious — it is a popular one :))\n\nIn *this* blog I briefly discuss the disaggregation of the DB at what might be called the macro or architecture level and then at the micro or intra DB level. I then offer a couple of considerations.\n\n### Macro level — the THE database evaporates\n\nAs has been explained by Zhamak Deghani of ThoughtWorks in her excellent blog How to [Move Beyond a Monolithic Data Lake to a Distributed Data Mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html) and on [Software Engineering Daily ](https://softwareengineeringdaily.com/2019/07/29/data-mesh-with-zhamak-deghani)— the data mesh pattern implies:\n\n- Disaggregating or distributing responsibility and autonomy\n- Disaggregating or distributing the role of the DB itself\n\nTypically this pattern can be easily identified when chatting with a larger user of OpenEBS when we ask “so, what DBs and other stateful workloads like logging systems are you running?”\n\nIf they give us an answer such as MySql, Prometheus, one of the 438 new SQL projects* and maybe Elastic and then *stop* — then we know they are either early in their Kubernetes deployment or that IT still runs the show. As such they may not be a great fit for doing the work necessary to achieve the data agility that comes from containerizing and distributing your data and data management in a cloud native and cloud agnostic way.\n\nConversely if their reply to the question is to sort of look at us like that’s an *interesting* question — and reply by saying “pretty much all of them — whatever the teams need” then we are off and running — we’ve found a kindred spirit and we typically dig into a discussion covering all sorts of topics such as:\n\n- How they use GitOps to manage storage classes and possibly extend them to cover data resilience and back up?\n- What do they do about anti patterns that persist — such as the use of NFS?\n- What is the average tenure of a cluster? (often not long)\n- Rolling upgrades of stateful workloads?\n- Favorite and not so favorite operators?\n- WeaveScope / Kubera director for visualization or something else?\n- Lock-in — anyone care? (meh — bosses do)\n- Blast radius — anyone care? (generally yes)\n- How about consistency between dev, test, and production?\n- Encryption — key management — in flight and at rest?\n\nWe invariably learn a lot and by sharing what we have learned we teach a bit as well. I had such a conversation before sitting down to write this and the lessons the engineer had learned while helping to build a very large container based environment at a NYC financial environments were priceless.\n\nIn short, instead of having a central database to store all the things — or a data lake or similar — one disaggregates control over the data in order to “shift left” and enable small teams to move faster. A primary role of Kubernetes engineers working with data — sometimes the data ops or analytics infrastructure teams — then becomes to provide paved paths that come with compliance, back-up, monitoring and more “for free” from the perspective of the small loosely coupled teams building particular stateful microservices.\n\n### Micro level — the THE database itself is complex\n\nExamine any database closely and you’ll find that it is comprised of a number of components and that increasingly the architecture is pluggable — so you can have many different flavors of a database.\n\nAn example PostgreSQL has 5 primary types of configurations to consider — as explained in this well written blog by Chitji Chauhan of severalnines.\n\n[https://severalnines.com/database-blog/guide-postgresql-server-configuration-parameters](https://severalnines.com/database-blog/guide-postgresql-server-configuration-parameters)\n\nAnd choosing which one to use depends in part upon where the data is being stored and how that storage is configured.\n\nSo what can you do about it — how can you or your central committee of data architects pick THE right solution?\n\nAgain — the answer is to distribute the decision to those closest to the use cases for the data itself — the engineers building the microservices that include these workloads. Instead of endless meetings or design reviews to arrive at the perfect central DB or DB service — try what works for you and move along. If you run in a containerized way with the help of Kubernetes and a cloud agnostic storage layer like the CNCF project OpenEBS and you use something like Kafka or just NATS for messaging or maybe Pulsar for that matter — then you don’t have an irrevocable choice that may plague you for years to come and can better fit a particular database with a particular set of configurations for a particular job you want done.\n\nWe see users adopting OpenEBS for truly per workload, per DB storage, and deciding whether to use one of the storage engines within OpenEBS, either LocalPV or cStor, and settling upon some tuning and some patterns with the help of Litmus or other testing systems and Kubera Director or some other means of tracking performance and visualization. These best practices — for example which time series DB to use and how to configure it and even where to run it and how to back it up — are then encoded in YAML. And then something like Flux from Weaveworks or a home built GitOps solution is used to manage these artifacts. The promise is the ease of use of a public cloud — for the developer at least — with massively greater customization and control including freedom from cloud lock-in.\n\nDatabases will evolve further to leverage Kubernetes by using Kubernetes for capabilities that previously every distributed data system had to build and operate itself. As an example you have in almost all distributed systems including DBs a means of determining what resources are available — if you know Kubernetes than you’ll know that etcd plays this role in Kubernetes and that when it comes to storage resources such as disks and cloud volumes that the NDM components of OpenEBS extend etcd to play this role. Increasingly we see savvy technology companies looking at Kubernetes as their common denominator, and expecting their infrastructure to add to Kubernetes where appropriate as opposed to every piece of software reinventing the wheel.\n\n### TL;DR — Freedom from disaggregation is good\n\nThe good news is that it is increasingly less likely you’ll be stuck managing someone else’s NoSql or NewSql system du jour years after the choice was made. Yes, databases are sticky and important however increasingly they are also fit for *specific purposes* and able to be used and disposed of when no longer needed. As the team at MayaData has pointed out many times in various blogs and Slack sessions and talks, the average size of a database on Kubernetes in a microservices environment is smaller than in traditional centralized architectures featuring THE database.\n\nWhat is more — many of the benefits of going towards a distributed data model and moving beyond the “THE database” pattern are best captured if the underlying storage itself is disaggregated and distributed. Conversely, if you shift away from one central DB or data lake to a disaggregated model and then tie everything together with a single storage system or service or cloud then actually you’ve just shoved the issue and the constraints down a level. And they will bob to the surface when you are dealing with the rapids of the non happy path — for example, upgrades, or replacements, or migrations, or when you have an outage from which you need to recover.\n\nSo if you think that disaggregation and distributed control and responsibility are important for your databases, please do stop by and say hi to us in the OpenEBS community. There are a lot of folks there now helping to build the disaggregated data future — integrators, fellow developers, contributors from databases and OpenEBS and other projects.\n\nI hope to see you there. [https://openebs.io/join-our-slack-community](https://openebs.io/join-our-slack-community)\n\n![](https://cdn-images-1.medium.com/max/800/1*L1XVBW58MDn_wksYj2nKgg.png)\n","slug":"the-myth-of-the-database"},{"id":37,"title":"Using Chaos Engineering to harden applications that use NuoDB, OpenEBS","author":"Sudarshan Darga","author_info":"Senior Software Engineer at MayaData","date":"14-08-2019","tags":["Openebs"," K8s"," Litmus"," Kubernetes"," Nuodb"," NoSQL"," Chaos Engineering"],"excerpt":"Developer agility is key to increasing the efficiency of software development. One of the primary areas in which development could be slowed down is the process that kicks in once the code is merged by the developers.","content":"\nDeveloper agility is key to increasing the efficiency of software development. One of the primary areas in which development could be slowed down is the process that kicks in once the code is merged by the developers. In a typical organization with DevOps practices in place, CI/CD is set up for the application development, where developers are involved in the process until the code is merged.\n\nThen, CI pipelines take over the process of doing e2e testing and provide feedback to the developers. With applications moving towards being more cloud native, the number of components that run in containers has become increasingly high. Because these components are also of a cloud native nature, their delivery becomes agile and the software updates to these components become more frequent. Realistically, it should be easy enough to test the changes in these components in the pipelines.\n\nThis leads to an important question:\n\n- **How do we build a CI pipeline where verification and hardening of the infrastructure components can be done easily and devote more time to developing the pipeline jobs related to the application business logic?**\n\n![Building CI/CD pipeline jobs for infrastructure components should not take much time.](/images/blog/2019/08/building-cicd-pipelines-jobs.png)\n\nThe answer to this question lies in adopting the cloud native chaos engineering into the CI/CD pipelines. Chaos Engineering is quickly becoming the most sought after method wheb building resiliency into cloud native applications. In ideal chaos engineering applications, chaos should be inserted at all layers (application, database, networking, storage, and Kubernetes), both in the CI pipelines and in production. Litmus is a chaos engineering framework designed to help with this specific need. For a good introduction to Litmus, see the Litmus docs ([https://litmusdocs.openebs.io/](https://litmusdocs.openebs.io/?__hstc=216392137.c88247b0ad679226f41f93a581cb1abd.1579859560609.1579859560609.1579859560609.1&amp;__hssc=216392137.1.1579859560609&amp;__hsfp=3765904294) )\n\nIn this post, we specifically want to focus on what Litmus deployers and chaos jobs are available to build a CI/CD pipeline in order to harden an application using NuoDB on Kubernetes. Before we dive into NuoDB’s chaos engineering, let’s give a quick introduction to NuoDB.\n\n*NuoDB is an elastic SQL database designed with distributed application deployment challenges in mind. It’s a SQL service that provides all the properties of ACID-compliant transactions and standard relational SQL language support. It’s also designed from the start as a distributed system that scales the way a cloud service has to scale, providing high availability and resiliency with no single points of failure. Different from traditional shared-disk or shared- nothing architectures, NuoDB’s presents a new kind of peer-to-peer, on-demand independence that yields high availability, low-latency, and a deployment model that is easy to manage.*\n\n![NuoDB Overview and Benefits](/images/blog/2019/08/nuodb-overview-and-benefits.png)\n\n## Full stack view of a cloud native application using NuoDB and Kubernetes\n\n![Full Stack View of an Application using NuoDB, OpenEBS and Kubernetes](/images/blog/2019/08/full-stack-view.png)\n\nDevelopers and DevOps admins should really concentrate on building the test cases for the business logic involved in the application PODs. Pipelines for hardening the rest of the components of the stack, such as NuoDB implementation, OpenEBS implementation, and Kubernetes/OpenShift implementation, can be built using Litmus books. Later in this post, you will find reference implementation and example litmus books that you can use.\n\n## Elements of a NuoDB CI/CD pipeline\n\n![GitLab CI pipeline for NuoDB on OpenShift using OpenEBS as persistent storage](/images/blog/2019/08/gitlab-cicd-pipeline-for-nuodb.png)\n\nThe figure above is a sample GitLab pipeline that is running OpenShift EE 3.11 and NuoDB 3.3 EE with Litmus. The stages are:\n\n- CLUSTER-Setup\n- OpenEBS-Setup\n- FUNCTIONAL\n- CHAOS\n- CLEANUP\n\nLitmus provides almost-ready books for every stage except FUNCTIONAL. Here, the Developers and DevOps admins should be spending time creating the tests for their applications. The remaining stages are generic enough that Litmus can accomplish the work for you with the tuning of the parameters.\n\n## A reference implementation of a NuoDB pipeline:\n\nThe NuoDB GitLab pipeline implementation for OpenShift EE platform and the corresponding Litmus books are all available in the OpenEBS GitHub repository at the following location.\n\n[openebs/e2e-openshiftAutomation of OpenEBS E2E testing on OpenShift On-Premise — openebs/e2e-openshiftgithub.com](https://github.com/openebs/e2e-openshift/blob/nuodb/.gitlab-ci.yml)\n\n## NuoDB Solution Guide:\n\nHere is a handy solution doc for implementing NuoDB using OpenEBS as persistent storage on OpenShift EE platform.\n\n[https://mayadata.io/assets/pdf/nuodb-openebs-solution-docs.pdf](https://mayadata.io/assets/pdf/nuodb-openebs-solution-docs.pdf)\n\nIf you are an ansible enthusiast or NuoDB user and wish to contribute to Litmus, feel free to join our community slack channel: slack.openebs.io and visit #litmus channel. We welcome any contributions and feedback!\n\n### Summary:\n\nBuilding CI/CD pipelines for applications built on NuoDB, OpenEBS and Kubernetes/OpenShift is quick and easy and most of the pipeline is readily available through Litmus. You can use the readily available Litmus books to build Chaos Engineering into your GitLab pipelines.\n\n*LITMUS* **—** *Make Chaos Engineering simple for Kubernetes*\n\n### Authors:\n\nUma Mukkara, COO @ MayaData ([Uma Mukkara](https://medium.com/@uma_mukkara))\n\nSudarshan Darga, Lead Engineer — Chaos Engineering @ MayaData ([Sudarshan Darga](https://medium.com/@sudarshan.darga))\n\n---\n\n## Example litmus jobs for OpenShift EE\n\n### Litmus book for OpenShift EE Cluster Setup\n\nLitmus job for creating OpenShift Enterprise 3.10 cluster on on-premise virtual machines.\n\n[https://raw.githubusercontent.com/openebs/litmus/master/k8s/on-prem/openshift-installer/create_openshift_cluster.yml](https://raw.githubusercontent.com/openebs/litmus/master/k8s/on-prem/openshift-installer/create_openshift_cluster.yml)\n\n    ---\n    - hosts: localhost\n    \n      vars_files:\n        - vars.yml\n      \n    \n      tasks:\n        - block:\n            \n            - name: Getting master ip\n              shell: cat ip.csv | awk 'NR == 1'\n              register: master_ip\n    \n            - name: Generating master SSH key\n              shell: ssh -o StrictHostKeyChecking=no root@ 'ssh-keygen -t rsa -N \\\"\\\" -f ~/.ssh/id_rsa -y'\n              register: master_key\n    \n            - name: Getting compute-nodes ip\n              shell: cat ip.csv | grep -v \n              register: compute_ip\n              \n            - name: Generating compute-node SSH key\n              shell: ssh -o StrictHostKeyChecking=no root@{{item}} 'ssh-keygen -t rsa -N \\\"\\\" -f ~/.ssh/id_rsa -y'\n              with_items: \"\"  \n    \n            - name: Copying ssh-key into master\n              shell: | \n                ssh -o StrictHostKeyChecking=no root@ 'echo  >> ~/.ssh/authorized_keys'  \n                eval 'ssh-agent'\n    \n            - name: Copying the SSH key into compute nodes\n              shell: |\n                ssh -o StrictHostKeyChecking=no root@{{item}} 'echo  >> ~/.ssh/authorized_keys'\n                eval 'ssh-agent' \n              with_items: \"\"\n     \n            - name: SSH from master to each Nodes \n              shell: ssh -o StrictHostKeyChecking=no root@ 'ssh -o StrictHostKeyChecking=no root@{{item}} ls'\n              with_lines: cat ./ip.csv\n    \n            - name: Generating random number\n              shell: date +%s\n              register: rand_num\n    \n            - name: Setting up the master hostname \n              shell: |\n                ssh -o StrictHostKeyChecking=no root@ 'echo master-. > /etc/hostname'\n                ssh -o StrictHostKeyChecking=no root@ 'systemctl start systemd-hostnamed'\n    \n            - name: Setting up the compute nodes hostname\n              shell: |\n                ssh -o StrictHostKeyChecking=no root@ 'echo node-. > /etc/hostname'\n                ssh -o StrictHostKeyChecking=no root@ 'systemctl start systemd-hostnamed'  \n              with_together: \n                - [ '1', '2', '3' ]\n                - \"\" \n    \n    #The VMs are already subscribed with some credentials. Need to unsubscribe the VMs & subscribe it again with new credentials.\n            - name: Unsubscribing the nodes\n              shell: ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager unregister'\n              ignore_errors: true\n              with_lines: cat ./ip.csv \n    \n            - name: Subscribing the nodes\n              shell: |\n                ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager register --username= --password='\n                ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager attach --auto'\n                ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager refresh'\n              with_lines: cat ./ip.csv\n    \n            - name: Getting the pool-id\n              shell: ssh -o StrictHostKeyChecking=no root@ 'subscription-manager list --available --matches '*OpenShift*' | grep \"Pool ID\" | awk '\\''NR == 1'\\'' | awk '\\''{print $3}'\\'''\n              register: pool_id\n    \n            - name: Attaching pool to each nodes\n              shell: | \n                ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager attach --pool='\n                ssh -o StrictHostKeyChecking=no root@{{item}} 'subscription-manager repos     --enable=\"rhel-7-server-rpms\"     --enable=\"rhel-7-server-extras-rpms\"     --enable=\"rhel-7-server-ose-3.10-rpms\"     --enable=\"rhel-7-server-ansible-2.4-rpms\"'\n              with_lines: cat ./ip.csv\n    \n            - name: Joining the nodes to the DNS Server\n              shell: ssh -o StrictHostKeyChecking=no root@{{item}} 'echo  | realm join --user=Administrator '\n              with_lines:  cat ./ip.csv\n    \n            - name: SSH from master to master using DNS\n              shell: ssh -o StrictHostKeyChecking=no root@ 'ssh -o StrictHostKeyChecking=no root@master-. ls'  \n    \n            - name: SSH from master to compute nodes using DNS\n              shell: ssh -o StrictHostKeyChecking=no root@ 'ssh -o StrictHostKeyChecking=no root@node{{item}}-. ls'\n              with_items: \n                - 1\n                - 2\n                - 3  \n    \n            - name: Replacing master ip in inventory\n              replace:\n                path: ./inventory.yml\n                regexp: \"master_ip\"\n                replace: \"\"  \n    \n            - name: Replace compute node ip in inventory\n              replace:\n                path: ./inventory.yml\n                regexp: \"\"\n                replace: \"\"\n              with_together: \n                - [ 'node1_ip', 'node2_ip', 'node3_ip' ]\n                - \"\"  \n    \n            - name: Replacing master DNS in inventory\n              replace:\n                path: ./inventory.yml\n                regexp: \"master_dns\"\n                replace: \"master-.\"\n    \n            - name: Replacing nodes DNS in inventory\n              replace:\n                path: ./inventory.yml\n                regexp: \"\"\n                replace: \"\"\n              with_together:\n                - [ 'node1_dns', 'node2_dns', 'node3_dns' ]\n                - [ 'node1-.', 'node2-.', 'node3-.' ]          \n    \n            - name: Copying inventory into master\n              shell: scp -o StrictHostKeyChecking=no inventory.yml root@:/root/openshift-ansible/inventory/\n    \n            - name: Checking out to release branch-3.10\n              shell: ssh -o StrictHostKeyChecking=no root@ 'cd /root/openshift-ansible && git checkout release-3.10'\n    \n            - name: Running Openshift pre-requisites\n              shell: ssh -o StrictHostKeyChecking=no root@ 'ansible-playbook -i /root/openshift-ansible/inventory/inventory.yml /root/openshift-ansible/playbooks/prerequisites.yml -vv'\n              \n            - name: Deploying openshift cluster\n              shell: ssh -o StrictHostKeyChecking=no root@ 'ansible-playbook -i /root/openshift-ansible/inventory/inventory.yml /root/openshift-ansible/playbooks/deploy_cluster.yml -vv'\n    \n            - name: Disabling selinux on each nodes \n              shell: ssh -o StrictHostKeyChecking=no root@{{item}} 'setenforce 0'\n              with_lines: cat ./ip.csv  \n    \n            - name: Copying bash file in master & Executing\n              shell: | \n                scp -o StrictHostKeyChecking=no post_install_setting.sh root@:/root/ \n                ssh -o StrictHostKeyChecking=no root@ 'bash post_install_setting.sh && rm post_install_setting.sh'\n\n### App deployers\n\nLitmus job for deploying NuoDB EE using OpenEBS volumes for database requirements.\n\nPrerequisites for running this litmus job is to have NuoDB Enterprise edition subscription and have docker images available in the cluster.\n\n[https://raw.githubusercontent.com/openebs/litmus/master/apps/nuodb/deployers/OpenShift/run_litmus_test.yml](https://raw.githubusercontent.com/openebs/litmus/master/apps/nuodb/deployers/OpenShift/run_litmus_test.yml)\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: litmus-nuodb-\n      namespace: litmus\n    spec:\n      template:\n        metadata:\n          name: litmus\n          labels:\n            app: nuodb-deployment\n    \n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            imagePullPolicy: Always\n    \n            env:\n              - name: ANSIBLE_STDOUT_CALLBACK\n                #value: log_plays, actionable, default\n                value: default\n    \n              - name: PROVIDER_STORAGE_CLASS\n                # Supported values: openebs-standard, local-storage, openebs-standalone\n                value: openebs-cstor-sparse\n    \n              - name: NUODB_VERSION\n                value: ee\n    \n              - name: APP_PVC\n                value: demo-vol-claim\n    \n              - name: APP_NAMESPACE\n                value: nuodbns\n    \n                # Application label\n              - name: APP_LABEL\n                value: 'app=nuodb'\n    \n                # Use 'deprovision' for app-clean up\n              - name: ACTION\n                value: provision\n    \n                # Set THP to disable in case platform is AWS or OpenShift\n              - name: THP\n                value: disable\n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./nuodb/deployers/OpenShift/test.yml -i /etc/ansible/hosts -v; exit 0\"]\n\n### Chaos jobs — NuoDB\n\nLitmus job for inducing chaos on NuoDB application components such as Admin, Storage Manager and Transaction Engine.\n\nFor inducing various components chaos, user has to pass application component specific label as the Job Env to the litmus book.\n\n[https://raw.githubusercontent.com/openebs/litmus/master/apps/nuodb/chaos/app_pod_failure/run_litmus_test.yml](https://raw.githubusercontent.com/openebs/litmus/master/apps/nuodb/chaos/app_pod_failure/run_litmus_test.yml)\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: nuodb-app-chaos-\n      namespace: litmus\n    spec:\n      template:\n        metadata:\n          labels:\n            name: nuodb-app-chaos\n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            env:\n              - name: ANSIBLE_STDOUT_CALLBACK\n                value: default\n                \n              - name: APP_NAMESPACE\n                value: nuodbns \n                \n              - name: APP_LABEL\n                value: 'nodetype=sm'\n    \n              - name: DEPLOY_TYPE\n                value: statefulset\n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./nuodb/chaos/app_pod_failure/test.yml -i /etc/ansible/hosts -vv; exit 0\"]\n\n### Chaos jobs — Networking\n\nLitmus job for inducing network delays between application and openebs target pod.\n\n[https://raw.githubusercontent.com/openebs/litmus/master/experiments/chaos/openebs_target_network_delay/run_litmus_test.yml](https://raw.githubusercontent.com/openebs/litmus/master/experiments/chaos/openebs_target_network_delay/run_litmus_test.yml)\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: nuodb-app-chaos-\n      namespace: litmus\n    spec:\n      template:\n        metadata:\n          labels:\n            name: nuodb-app-chaos\n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            env:\n              - name: ANSIBLE_STDOUT_CALLBACK\n                value: default\n    \n              - name: APP_NAMESPACE\n                value: nuodbns \n    \n              - name: APP_LABEL\n                value: 'nodetype=sm'\n    \n              - name: DEPLOY_TYPE\n                value: statefulset\n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./nuodb/chaos/app_pod_failure/test.yml -i /etc/ansible/hosts -vv; exit 0\"]\n\n### Chaos jobs — Storage\n\nLitmus job for inducing OpenEBS cStor storage target kill and verify the application availability.\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: openebs-target-failure-\n      namespace: litmus\n    spec:\n      template:\n        metadata:\n          labels:\n            name: openebs-target-failure\n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            env:\n              - name: ANSIBLE_STDOUT_CALLBACK\n                #value: log_plays\n                #value: actionable\n                value: default\n    \n              - name: APP_NAMESPACE\n                value: nuodbns\n    \n              - name: TARGET_NAMESPACE\n                value: openebs\n    \n              - name: APP_LABEL\n                value: 'nodetype=sm'\n    \n              - name: APP_PVC\n                value: archive-sm-0\n    \n              - name: LIVENESS_APP_LABEL\n                value: \"\"\n    \n              - name: LIVENESS_APP_NAMESPACE\n                value: \"\"\n    \n              - name: DATA_PERSISTENCY\n                value: \"\"            \n    \n                # CHOS_TYPE values :  target-zrepl-kill , target-kill , target-delete \n              - name: CHAOS_TYPE\n                value: \"target-zrepl-kill\"\n                \n                # TARGET_CONTAINER values: cstor-volume-mgmt , cstor-istgt\n              - name: TARGET_CONTAINER\n                value: \"cstor-volume-mgmt\"\n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./percona/chaos/openebs_target_failure/test.yml -i /etc/ansible/hosts -vv; exit 0\"]\n\nLitmus job for inducing OpenEBS cStor storage pool kill and verify the application availability.\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: openebs-pool-failure-\n      namespace: litmus\n    spec:\n      template:\n        metadata:\n          labels:\n            name: openebs-pool-failure\n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n    \n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            imagePullPolicy: Always\n            env:\n              - name: ANSIBLE_STDOUT_CALLBACK\n                #value: log_plays\n                #value: actionable\n                value: default\n    \n              - name: APP_NAMESPACE\n                value: nuodbns\n    \n              - name: APP_LABEL\n                value: 'nodetype=sm'\n    \n              - name: APP_PVC\n                value: archive-sm-0\n    \n              - name: LIVENESS_APP_LABEL\n                value: \"\"\n    \n              - name: LIVENESS_APP_NAMESPACE\n                value: \"\"\n    \n              - name: DATA_PERSISTENCY\n                value: \"\"  \n    \n              - name: CHAOS_TYPE\n                value: \"pool-kill\"\n    \n              - name: CHAOS_ITERATIONS\n                value: \"2\" \n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./percona/chaos/openebs_pool_failure/test.yml -i /etc/ansible/hosts -vv; exit 0\"]\n\n### Chaos jobs — Kubernetes\n\nLitmus job for inducing kubelet/docker service crash and verify impact on the application running on the node.\n\nNote: This litmus job is specific to AWS platform.\n\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      generateName: openebs-app-svc-chaos-\n      namespace: litmus \n    spec:\n      template:\n        metadata:\n          labels:\n            name: openebs-app-svc-chaos\n        spec:\n          serviceAccountName: litmus\n          restartPolicy: Never\n    \n          #nodeSelector:\n          #  kubernetes.io/hostname:\n    \n          containers:\n          - name: ansibletest\n            image: openebs/ansible-runner:ci\n            imagePullPolicy: Always\n            env: \n              - name: ANSIBLE_STDOUT_CALLBACK\n                #value: log_plays\n                #value: actionable\n                value: default\n    \n              - name: OPERATOR_NAMESPACE\n                value: openebs\n     \n              - name: APP_NAMESPACE\n                value: nuodbns \n    \n              - name: APP_LABEL\n                value: 'nodetype=sm'\n    \n              - name: APP_PVC\n                value: archive-sm-0\n    \n              # Set value to kubelet/docker \n              - name: SVC_CHAOS\n                value: docker\n    \n              - name: CHAOS_DURATION\n                value: \"300\" # in seconds\n    \n              - name: LIVENESS_APP_LABEL\n                value: \"\"\n    \n              - name: LIVENESS_APP_NAMESPACE\n                value: \"\"\n    \n              - name: PLATFORM\n                value: \"AWS\"\n    \n            command: [\"/bin/bash\"]\n            args: [\"-c\", \"ansible-playbook ./percona/chaos/openebs_app_svc_chaos/test.yml -i /etc/ansible/hosts -vv; exit 0\"]\n","slug":"using-chaos-engineering-to-harden-applications-that-use-nuodb-openebs"},{"id":38,"title":"OpenEBS community releases v1.1, maintaining a faster release cadence.","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"08-08-2019","tags":["Kubernetes"," Microservices"," Openebs"," Persistent Volume"," Stateful Workloads"],"excerpt":"In this blog, I will provide a quick summary of the changes that were released as part of OpenEBS version 1.1 and also share some thoughts on the evolving project management process in OpenEBS and how it is helping to maintain a faster release cadence.","content":"\nIn this blog, I will provide a quick summary of the changes that were released as part of OpenEBS version 1.1 and also share some thoughts on the evolving project management process in OpenEBS and how it is helping to maintain a faster release cadence.\n\nOpenEBS Release 1.1 has been about fixing and documenting the cross-platform usability issues reported by users and also laying the foundation for some of the long-overdue backlogs like CSI Driver, automated upgrades, day 2 operations, and others.\n\nBefore we get into the specifics of the current release, the last three OpenEBS releases have set an interesting precedent towards attaining a *monthly release cadence.*\n\nOpenEBS was built by adopting the cloud-native and microservices principles, and it is almost only natural to also reap the benefits of true DevOps product with faster releases. It is easier said than done though! After having experimented with several tools and having looked at various open-source projects including Kubernetes, we have arrived at the following process, which is helping us maintain release cadence and thereby being responsive to the user requirements.\n\n- Responsiveness — Almost all the active contributors and maintainers of the OpenEBS project are reachable and online in the OpenEBS Community Slack. OpenEBS has been credited as being one of the most responsive CNCF community projects — and thanks to the community, OpenEBS Developers are getting feedback directly from end-users. This eliminates layers of requirements for implementation and improves the feedback loop.\n- Clarity of criteria for alpha and beta — Recently we clarified that our release gates are defined by OpenEBS Litmus based GitLab pipelines that run end-to-end tests on multiple different platforms and stateful workloads. Perhaps goes without saying — however we use these pipelines to catch any regressions. What is more — a feature is marked as Beta only after it has been added to the test pipelines. For example, LocalPV as of OpenEBS 1.1 is now Beta because it is passing these tests — and also is seeing a lot of production usage as well.\n- Backlog grooming — At the start of the release, we look at the backlogs which are on [GitHub](https://github.com/openebs/openebs/issues). Items are selected based on contributor availability and balancing the development of new features, fixing existing features, updating and improving documentation, improving e2e coverage, and hardening the usage of OpenEBS on new platforms. As an example of a new platform, we have seen quite a bit of usage of especially the low footprint Jiva on ARM and are now releasing container images for built for the ARM64 architecture, making OpenEBS operational on RPi4 as well as Amazon A1 instances or Packet’s powerful ARM Compute servers. As another example, we are hardening the use of OpenEBS for Konvoy from our friends at Day2IQ — and shortly we will see Konvoy on OpenEBS.ci. As reminder OpenEBS.ci is a public way for showing that all commits to OpenEBS master are tested against a set of workloads and platforms. OpenEBS also now appears in the [OpenShift Operator Hub](https://github.com/openebs/helm-operator/blob/master/olm/README.md) and on the [AWS Marketplace](https://aws.amazon.com/marketplace/pp/MayaData-OpenEBS-Cloud-Native-Storage/B07TFS9Q8D) as well\n- Tracking items — The list of selected items are tracked for the current release using these [Google Sheets](https://docs.google.com/spreadsheets/d/1bbphUqbxShBhgr1VHaEQUzIGMaJJacPNKc1ckNXU1QE/). It is not fancy, but it helps to get all the collaborators together and very easily provides a no-barrier objective follow-up — between release manager, leads and reviewers. The format of the sheet is a modified version of what is used by Kubernetes sig-storage.\n- Role of core committers — As core contributors, our responsibility is to detail the design and to list the implementation tasks — including covering the integration and upgrade tests. Each granular task is updated in the above project sheet and then we ask for help from the community to fix some of these items. The designs themselves are discussed and maintained as GitHub PRs [here](https://github.com/openebs/openebs/tree/master/contribute/design).\n- Role of RC1 and RC2 — functionality must be checked into master before RC1 builds are started. Post RC1 it is mostly about corner cases, integration and upgrade tests. Only those features that can complete the upgrade testing within the RC2 timelines are considered for the current release.\n- Role of release manager — Conducts follow-ups via daily standups on pending items and mitigating the risks by seeking additional help or by pushing the feature out of the release.\n- The final two weeks — As we reach the end of a one month release cycle the focus turns to refactoring and adding more test cases while stabilizing the features rather than introducing new features. The last two weeks are also about polishing documentation and trying to reach out to users whose requests have been incorporated into the product to get some early feedback.\n- What else? I haven’t spoken about the role of beta tests or dogfooding of the releases by using OpenEBS in our own hosted services such as OpenEBS director. Perhaps I’ll dig into these in a future blog. Bookkeeping tasks that start after the release also take a lot of time. For example, OpenEBS can be deployed via different partner platforms, each of which maintains their repositories for their Helm charts. Each of these partners are evolving with new guidelines for check-ins and they tend to go at their own pace. There is definitely room for improvement here and hopefully, the way the kubernetes apps are delivered will be standardized so that such bookkeeping tasks can be reduced.\n\n*How do you run your Open Source projects? What tools do you use to improve productivity? Please drop in a comment. Would love to hear from you and improve the care and feeding of the OpenEBS community.*\n\nGetting back to OpenEBS 1.1. The major features, enhancements and bug fixes in this release include:\n\n- Upgrades! Support for the upgrade of OpenEBS storage pools and volumes through Kubernetes Job. As a user, you no longer have to download scripts to upgrade. The procedure to upgrade via Kubernetes Job is provided [here](https://github.com/openebs/openebs/tree/master/k8s/upgrades/1.0.0-1.1.0). Kubernetes Job-based upgrade is a step towards completely automating the upgrades in the upcoming releases. Would love to hear your feedback on the [proposed design](https://github.com/openebs/openebs/tree/master/contribute/design/1.x/upgrade). Note: Upgrade job makes use of a new container image called quay.io/openebs/m-upgrade:1.1.0.\n- CSI — The CSI driver reached Alpha with initial functionality for provisioning and de-provisioning of cStor volumes. Once you have OpenEBS 1.1 installed, take the CSI driver for a spin on your development clusters using the instructions provided [here](https://github.com/openebs/csi). The addition of the CSI driver also requires a shift in the paradigm of how the configuration of the storage class parameters should be passed on to the drivers. We want to keep this seamless, please let us know if you have any inputs on what you notice as some of the nice to have as we shift towards the [CSI driver](https://github.com/openebs/openebs/tree/master/contribute/design/1.x/csi).\n- Day 2 automation ongoing — There is a tremendous amount of work ongoing to further automate Day 2 operations of the cStor storage engine. Most of these changes did not make the current release because the nature of schema changes were larger than could be taken within the current release cycle. The feature is under active development and if you are interested in providing feedback on how this feature is shaping up, you can find the proposed design [here](https://github.com/openebs/openebs/pull/2595). Thank you to everyone that has already chipped in with ideas and feedback.\n\nPerhaps the greatest highlight of this release is an increased involvement from OpenEBS user community pitching in with GitHub Issues as well as providing contributions.\n\n![](https://cdn-images-1.medium.com/max/800/1*hZ7FK18EK2_PfjdCJB2OTQ.png)\n\nHere are some issues that were raised and fixed within the current release.\n\n- Fixed an issue where backup and restore of cStor volume using OpenEBS velero-plugin was failing when OpenEBS was installed through Helm. [@gridworkz](https://github.com/gridworkz)\n- Fixed an issue with NDM where the kubernetes.io/hostname for Block Devices on AWS Instances was being set as the nodeName. This was resulting in cStor Pools not being scheduled to the node as there was a mismatch between hostname and nodename in AWS instances. [@obeyler](https://github.com/obeyler)\n- Fixed an issue where NDM was seen to crash intermittently on nodes where NVMe devices are attached. There was an issue in the handling of NVMe devices with write cache supported resulting in a segfault. [Private User]\n- Added support to disable the generation of default storage configuration like StorageClasses, in case the administrators would like to run a customized OpenEBS configuration. [@nike38rus](https://github.com/nike38rus)\n- Fixed an issue where the cStor Target would fail to start when the NDM sparse path is customized. [@obeyler](https://github.com/obeyler)\n- Fixed a regression that was introduced into the cStor Sparse Pool that would cause the entire Volume Replica to be recreated upon the restart of a cStor Sparse Pool. The fix was to make sure the data is rebuilt from the peer Sparse pools instead of recreating. Test cases have been added to the e2e pipeline to catch this behavior with Sparse Pools. Note that this doesn’t impact the cStor Pools created on Block Devices. [@vishnuitta](https://github.com/vishnuitta)\n- For Jiva Volumes, created a utility that can clear the internal snapshots created during replica restart and rebuild. For long-running volumes that have gone through multiple restarts, the number of internal snapshots can hit the maximum supported value of 255, after which the Replica will fail to start. The utility to check and clear the snapshots is available [here](https://github.com/openebs/openebs/tree/master/k8s/jiva). [@rgembalik](https://github.com/rgembalik)[@amarshaw](https://github.com/amarshaw)\n- Enhanced velero-plugin to allow users to specify a backupPathPrefix for storing the volume snapshots in a custom location. This allows users to save/backup configuration and volume snapshot data under the same location rather than saving the configuration and data in different locations. [@amarshaw](https://github.com/amarshaw)\n\n***For detailed change summary, steps to upgrade from a previous version, or to get started with v1.1 please refer to:***[***Release 1.1 Change Summary***](https://github.com/openebs/openebs/releases/tag/1.1.0)\n\nIn short, OpenEBS 1.1 shows that OpenEBS development is marching ahead faster and faster and delivering more and more features, fixes and platforms.\n\nAs always if you have any feedback or inputs regarding the OpenEBS project or project management — please reach out to me on [Slack](https://slack.openebs.io) or [GitHub](https://github.com/openebs/openebs/) or via comments here.\n","slug":"openebs-community-releases-v11-maintaining-a-faster-release-cadence"},{"id":39,"title":"OpenEBS Project Update and whats coming in v1.0","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"16-05-2019","tags":["Cncf"," Containerattachedstorage"," Storage"," Kubernetes"," Openebs"],"excerpt":"My heartfelt gratitude to hundreds of contributors and thousands of users and friends of OpenEBS who have contributed to OpenEBS becoming a CNCF Sandbox Project.","content":"\nMy heartfelt gratitude to hundreds of contributors and thousands of users and friends of OpenEBS who have contributed to OpenEBS becoming a CNCF Sandbox Project.\n\nFor those of you who have just heard of OpenEBS or are curious about the current state of OpenEBS, I put together this quick blog that *Looks back to where we started and how far we have come*. (I am pretty sure the GOT fans will get this reference). I then talk about the current release 0.9 and what is to come in 1.0.\n\nThe OpenEBS vision has been pretty clear since the start: provide an Open Source Storage Solution that enables Enterprises and Solution Architects to reap the Agility benefits promised by Container Native Architectures. We decided a few years ago that delivering data agility could best be done by using the tools that deliver agility in development and operations already — cloud native architectures, including containers and Kubernetes. Specifically we decided to move Stateful Workloads and the logic that delivers storage services to protect and manage them into a microservices based architecture deployed via containers. We also set out to enable agility by fighting the lock-in of data into vendor and cloud specific storage silos that lock users into specialized systems and services that themselves require special skills to run and scale.\n\nOver the last couple of years the notion of containerizing stateful workloads and managing them via Kubernetes has become increasingly accepted. We now see a great breadth of deployments of different workloads on different flavors of Kubernetes — you can read more about how the pattern of cloud native or what we call Container Attached Storage is being adopted on the CNCF blog we helped author here: [A Year Later — Updating Container Attached Storage](https://www.cncf.io/blog/2019/05/16/a-year-later-updating-container-attached-storage/).\n\n*Quick point that you may have already gathered: OpenEBS is completely Kubernetes native and if you know how to manage your applications in Kubernetes, you already know how to use OpenEBS.*\n\nSo, OpenEBS started out to build a Storage Solution that has:\n\n- *Stable Date Engines*, can be run on any underlying Kubernetes Platform. And it has got to be multiple storage engines, so administrators can compose or pick the right one for the right workload. For instance, an OpenEBS PV for Mongo can be using a completely different data engine compared to a PV for PostgreSQL or Jenkins.\n- *Standard Specs* to manage the Data Engines, so that administrators can use the existing Kubernetes tooling infrastructure to manage storage as well. Kubernetes Custom Resources and operators are used to manage everything with regards to OpenEBS.\n- *Security* controls that enable running on platforms like OpenShift, SuSE CAAS or in Kubernetes Clusters with strict Pod Security Policy.\n- *Scalable* architecture that can deliver the required performance to the Application, without adding much of an overhead over the underlying storage medium.\n\nAnd above all, it has to be ***simple and easy to use.***\n\nIt feels great for OpenEBS to be approaching 1.0!! We are extremely humbled at the amount of love in terms of both support and scrutiny that we have received over the last couple of years as we went through with building each block by block completely in the Open Source. OpenEBS has clearly established itself as the most simple to use and cost effective storage solution that is available out there to use with Kubernetes — and yet we know there is much more to do, especially as there seems to be a risk of higher level commands such as those covering data mobility being pulled back from Kubernetes into their own systems by proprietary vendors. More on that in a later blog and/or set of GitHub issues :) .\n\nIn the following sections, I go through in a bit more detail the current state of the main aspects of OpenEBS — Stability, Standard Spec (aka Storage Policies), Security Controls and Scalable architecture; followed by a quick summary of the current release (0.9) and what we are working on currently for v1.0.\n\n**Data Engines:** The data engines are the containers responsible for interfacing with the underlying storage devices or cloud volumes such as host filesystem, rotational drives, SSDs and NVMe devices. The data engines provide volumes with required capabilities like high availability, snapshots, clones, etc. Depending on the capabilities required, users can select the right data engine like cStor ( a CoW based) or Jiva or even Local PVs for a given volume.\n\nWe define a data engine as stable if it meets the following criteria:\n\n- Resilient against node, network or storage device errors. No data loss!\n- Ease of management ( including Day 2 Operations).\n- Users are running the data engine in production for more than 6 months and have gone through two or more OpenEBS version upgrades.\n\nThe current state of the 3 data engines supported by OpenEBS are as follows:\n\n- **Jiva (stable)** — The first and basic data engine that was supported by OpenEBS and has been deployed the longest in production by users. We have fixed several issues that came up with regards to cluster upgrades, node migrations, storage expansion and so forth. Ideal for cases where only replication of data is required. For backup and restore, Velero/Restic is used. Very easy to use, lightweight.\n- **cStor (beta)** — The most feature rich data engine that has the support for extremely efficient snapshots and clones. Highly recommended for cases where the nodes have storage devices attached. The current release contains Velero OpenEBS plugins that help with optimizing the backup/restore process. While already used in production by some of our users, we consider this as beta — until all day 2 operations are easily performed.\n- **OpenEBS Local PV (alpha)** — An extension to Kubernetes Local PV, with the plan to ease the management of disks by using the OpenEBS Node Storage Device Manager (NDM). The current OpenEBS 0.9 release contains the initial version of the OpenEBS Local PV Dynamic Provisioner. While we have tested OpenEBS Local PV extensively however per the criteria above it remains alpha as the newest engine. From an IO engine perspective, it is as stable as it can get. :-)\n\nAdditional details and how each of the Data engines operate are provided in this [Presentation](https://docs.google.com/presentation/d/1mjOkAQppyd23sw7PIryxu5kSrex352bT6bINzw6mUFY/edit?usp=sharing)\n\n![](/images/blog/2019/05/cas-example-openebs-cstor-volume.png)OpenEBS cStor Volume\n\n**Standard Specifications or API:** Standardization is achieved by architecting OpenEBS as a set of microservices using Kubernetes Custom Resources and Operator patterns. The same set of tooling used to manage the applications — like Helm, Prometheus, and Grafana — can also be used to manage OpenEBS itself. The configuration of OpenEBS is completely controlled via YAMLs (Custom Resources) and volumes are provisioned via the Kubernetes Dynamic Provisioners, Storage Classes and Persistent Volume Claims.\n\nThe components of OpenEBS that act on the user requests (via CRs) and generate / launch the Kubernetes Objects — like Deployments, Services and Persistent Volumes are collectively called as the *Storage Management or Control Plane*. The interactions to the Storage Management Plane can achieved via `kubectl`.\n\nThe administrators can customize the OpenEBS parameters by modifying the YAMLs. Some of the configuration that are possible are:\n\n- Setting up Taints and Tolerations to decide the nodes where the Storage Pods need to be deployed.\n- Setting up the Node Selectors or Anti-Affinity parameters to select the correct nodes for launching the Volume (Data Engine) pods.\n\nFor further details check: [https://docs.openebs.io](https://docs.openebs.io/?__hstc=216392137.f0da50a3ce0cf28f99a3c60d1f6006cf.1580117750726.1580117750726.1580117750726.1&amp;__hssc=216392137.1.1580117750727&amp;__hsfp=3765904294).\n\nAnother cool feature that has become a favorite of advanced OpenEBS users is that, as Kubernetes introduces new features that have to be passed on to the Dynamically generated Volume (Data Engine) Pods, users can directly patch the pods and also update the Volume Template YAMLs at run time. To learn more about this feature, hit us up on slack: [https://slack.openebs.io](https://slack.openebs.io/?__hstc=216392137.f0da50a3ce0cf28f99a3c60d1f6006cf.1580117750726.1580117750726.1580117750726.1&amp;__hssc=216392137.1.1580117750727&amp;__hsfp=3765904294)\n\nIn this regard, as we move towards 1.0, we would like to improve the documentation and governance around maintaining multiple versions of the API.\n\n**Security Controls:** Storage is a cluster add-on service. It needs to access the storage devices — either as hostpath or as block devices that are attached to the nodes. Since OpenEBS is completely Kubernetes native, access rights and privileges required by the individual components are completely transparent and can be controlled by the RBAC configuration by Kubernetes Cluster Administrators. One of the interesting feedback we received as Enterprises started to adopt OpenEBS was that — the IT Teams want to retain the control on the storage and shield the specifics of the node details or scheduling details from application developers.\n\nOpenEBS can now be configured easily to run in:\n\n- Security Enhanced Linux Platforms (selinux=on) like RHEL, CentOS or OpenShift. We talk in more detail about this [here](https://blog.openebs.io/configuring-openebs-to-run-with-security-enhanced-linux-1e5a90a91da2?__hstc=216392137.f0da50a3ce0cf28f99a3c60d1f6006cf.1580117750726.1580117750726.1580117750726.1&amp;__hssc=216392137.1.1580117750727&amp;__hsfp=3765904294).\n- OpenEBS can be used on clusters where the default setting is to not grant access to the hostpaths for Developer namespaces. To support this use case, we now support an option to run the Jiva Volumes Pods (that require access to hostpath) to be deployed in OpenEBS Namespace using a *StoragePolicy**—**DeployInOpenEBSNamespace*. The StoragePolicies in OpenEBS are configured via StorageClasses.\n- OpenEBS can be used on clusters enabled with Pod Security Policies. The PSP for OpenEBS has been contributed by a user and can be found [here](https://github.com/openebs/openebs-docs/issues/484).\n\n**Scale and Performance:** OpenEBS is architected to horizontally scalable with nodes — Persistent Volumes spreading out pretty evenly across the nodes or a subset of nodes designated for Storage. However the data of any given Persistent Volume is always fixed to a specific set of nodes, eliminating the need for expensive metadata lookups to find the data blocks as the number nodes get higher. What I like even better is, that the replica tells the controller that it has the data effectively inversing the responsibility from volume target/controller having to know where data is located to replicas telling I have the data.\n\nAnother aspect of OpenEBS Volumes when it comes to performance is that each Volume is completely isolated and doesn’t get impacted by work/load on other Volumes. For example, a node rebuild will not degrade ALL volumes in the cluster.\n\nAs OpenEBS is completely developed in user space and run as Kubernetes Pods, administrators get completely control on the resources like CPU/RAM that should be allocated to Storage. There won’t be cases of kernels hogging all the resources. Administrators also can tune for example the number of threads allocated and parallel IOs supported per Volume — tuning will have impact depending on the type of workloads (Sequential / Random).\n\nOf course, then we have workloads that require low latency, and need to work to be deployed on nodes with limited storage available, for example a couple of NVMe devices. OpenEBS Local PVs provide the functionality to make use of the Local Storage and help with dynamic provisioning of Local PVs. OpenEBS Local PVs offer an excellent choice for cases like NuoDB where replication is inherently taken by NuoDB itself and the expectation is only to get a persistent storage with node affinity configured for the storage pods. A default storage class called — `openebs-hostpath` is available in the current release. Check it out and let us know what you think.\n\nWe are seeing OpenEBS users progress from running CI/CD workloads in staging to now running critical databases in production on OpenEBS Volumes. If you are interested in performance, we have a OpenEBS user currently exploring and sharing the benchmarking numbers on several different platforms. Join the discussion on our slack — [https://slack.openebs.io](https://slack.openebs.io/?__hstc=216392137.f0da50a3ce0cf28f99a3c60d1f6006cf.1580117750726.1580117750726.1580117750726.1&amp;__hssc=216392137.1.1580117750727&amp;__hsfp=3765904294).\n\n— -\n\nWhile I covered earlier some of the items introduced recently in [0.9](https://github.com/openebs/openebs/releases), here is a summary of some significant changes:\n\n- Introduction of Dynamically provisioned OpenEBS Local PVs for making use of the storage available on the nodes itself for running NewSQL kind workloads. Refer to this [blog](https://blog.openebs.io/preview-dynamic-provisioning-of-kubernetes-local-pvs-using-openebs-a530c25cf13d?__hstc=216392137.f0da50a3ce0cf28f99a3c60d1f6006cf.1580117750726.1580117750726.1580117750726.1&amp;__hssc=216392137.1.1580117750727&amp;__hsfp=3765904294) to get started with OpenEBS Local PVs.\n- Enhanced the cStor Replica distribution logic for MongoDB or Cassandra Statefulsets to provide storage high availability and reducing the performance overhead\n- Backup and Restore processes for cStor Volumes using [OpenEBS Velero Plugin](https://github.com/openebs/velero-plugin) that can perform incremental snapshot backup and restore.\n- Enhance the Deployment and Placement of the Jiva Volume Pods to facilitate working in environments with strict Pod Security Policies and for Kubernetes clusters that tend to see a lot of pod evictions or node drains.\n- Introduced Web Admission Hook that will help with validation and avoiding misconfigurations.\n- Developed an upgrade framework using the CAS Templates that will help developing operator based upgrades from earlier releases to the current release. We are excited to use this framework for upgrading from 0.8.2 to 0.9\n- Enhanced the Prometheus exporters to support generating cStor Volume Replica metrics.\n- As always many other user reported issues made into this release. To learn more checkout the [release notes](https://github.com/openebs/openebs/releases).\n\nEach OpenEBS release goes through Litmus — GitLab Pipelines that verify new functionality, backward compatibility and also acceptance from users through pre-release build testing. Please reach out to us if you would like to be included in the pre-release notifications.\n\nI am very excited about the following active contributions that are filling in the gaps for 1.0\n\n- BDD tests that developers can execute as part of the feature development. This is an extension to the Sanity tests are executed in Travis CI and Litmus Tests in GitLab CI.\n- Updating the Design, Contributor and Governance related details with the help of CNCF guidelines.\n- Freezing on the cStor Specs based on the feedback received from users on how to make it more user friendly and easy to manage. The NDM Disk Specification has also changed to BlockDevice spec as per the feedback received in making it generic to Storage Devices.\n- Additional enhancements automatic the cStor Day 2 operations with regards to scaling up the capacity of cStor Pool by increasing the size of the underlying disks, scaling up and down the number of cStor Pools in a given cluster.\n- Support for integrating the OpenEBS Local PV into the BlockDevices discovered and managed by NDM.\n- Support for ARM builds.\n\nFor contributing to the above feature or learning more about them, you can reach out to us on the #contributors channel or check out the [milestones](https://github.com/openebs/openebs/milestones).\n\nI am very excited to be at KubeCon Europe and to meet in person some of the hundreds of contributors and many thousands of users of OpenEBS who have all made it possible for OpenEBS to be recently accepted as a CNCF Sandbox Project. Thank you Again!\n\nMayaData will be speaking about OpenEBS at the KubeCon events in Barcelona in the Cloud Native Storage Day and Open Data Autonomy Mini Summit on May 20th, and also at booth SE41 until Thursday in KubeCon Expo Hall.\n","slug":"openebs-project-update-and-whats-coming-in-v10"},{"id":40,"title":"Configuring OpenEBS to run with Security-Enhanced Linux","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"10-05-2019","tags":["Centos"," Kubernetes"," Openebs"," Selinux"," Uncategorized"," Openshift"," Tutorials"],"excerpt":"In this short How-To blog, I will walk you through the steps for running OpenEBS with Security Enhanced Linux (SELinux=on).","content":"\nIn this short How-To blog, I will walk you through the steps for running OpenEBS with Security Enhanced Linux (SELinux=on). This applies to both OpenShift based Kubernetes Cluster or Clusters using CentOS.\n\nOpenEBS can be treated as a Cluster Add-on service, that can convert the existing Kubernetes Cluster into a full fledged Storage Controllers — that can serve Persistent Volumes to Stateful Workloads while making use of the storage attached to the nodes. Since OpenEBS runs in containers and has to access the underlying storage devices, it needs to run in Privileged mode.\n\nThe component of OpenEBS ( Node Device Manager or Node Disk Manager or simply referred as NDM), is responsible for discovery of the devices and filtering out devices that should not be used by OpenEBS; for example the disk that has OS filesystem. Earlier, to detect the OS disk, the NDM pod by default mounted the `/proc/1/mounts` file, which is restricted on nodes that have SELinux=on. This is now fixed by mounting the `/proc` directory of the host inside the container and then loading the `mounts` file.\n\nSo at a high level, to allow OpenEBS to run in privileged mode in SELinux=on nodes, the cluster should be configured to grant privileged access to OpenEBS service account.\n\nHere are the steps I have followed:\n\n****Step 1: Setup appropriate security context for OpenEBS****\n\n**On OpenShift Clusters:** Select the right SCC for OpenEBS\n\nOpenEBS like other cluster add-on services requires its pods to be executed with privileged access as it needs to directly access the block devices. However, this will not mean that SELinux should be turned off.\n\nWhile running on OpenShift, we need to be aware of the security constraints available and to select the right security constraint for OpenEBS. There are 7 SCCs available.\n\n![](/images/blog/2019/05/0_nYHmjUbmME9DgkbN.png)Security Context Constraints (SCC) in OpenShift\n\nTo have OpenEBS pods running in privileged mode, add the OpenEBS service account (openebs-maya-operator) to use the privileged SCC; OpenShift will take care of setting the correct permissions (or SELinux labels) to make the container run in privileged mode. Sample commands to do this:\n\n    oc adm policy add-scc-to-user privileged system:serviceaccount:openebs:openebs-maya-operator\n\n**On CentOS/RHEL:** Enable Pod Security Policies for OpenEBS\n\nCreate a file `openebs-privileged-psp.yaml` with the below spec.\n\n    apiVersion: extensions/v1beta1\n    kind: PodSecurityPolicy\n    metadata:\n      name: openebs-privileged\n      annotations:\n        seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n    spec:\n      privileged: true\n      allowPrivilegeEscalation: true\n      allowedCapabilities:\n      - '*'\n      volumes:\n      - '*'\n      hostNetwork: true\n      hostPorts:\n      - min: 0\n        max: 65535\n      hostIPC: true\n      hostPID: true\n      runAsUser:\n        rule: 'RunAsAny'\n      seLinux:\n        rule: 'RunAsAny'\n      supplementalGroups:\n        rule: 'RunAsAny'\n      fsGroup:\n        rule: 'RunAsAny'\n\nThen apply the YAML file\n\n    kubectl apply -f openebs-privileged-psp.yaml\n\n****Step 2: Install OpenEBS****\n\nDownload the latest version of `openebs-operator.yaml` file.\n\n    wget https://openebs.github.io/charts/openebs-operator-0.8.2.yaml\n\n**On CentOS/RHEL:** An extra step of adding PSP to the Cluster Role is required.\n\nEdit the ClusterRole in the YAML to add `openebs-privileged` PSP\n\n    # Define Role that allows operations on K8s pods/deployments\n    kind: ClusterRole\n    apiVersion: rbac.authorization.k8s.io/v1beta1\n    metadata:\n      name: openebs-maya-operator\n    rules:\n    - apiGroups: [\"*\"]\n      resources: [\"nodes\", \"nodes/proxy\"]\n      verbs: [\"*\"]\n    - apiGroups: [\"*\"]\n      resources: [\"namespaces\", \"services\", \"pods\", \"deployments\", \"events\", \"endpoints\", \"configmaps\", \"jobs\"]\n      verbs: [\"*\"]\n    - apiGroups: [\"*\"]\n      resources: [\"storageclasses\", \"persistentvolumeclaims\", \"persistentvolumes\"]\n      verbs: [\"*\"]\n    - apiGroups: [\"volumesnapshot.external-storage.k8s.io\"]\n      resources: [\"volumesnapshots\", \"volumesnapshotdatas\"]\n      verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n    - apiGroups: [\"apiextensions.k8s.io\"]\n      resources: [\"customresourcedefinitions\"]\n      verbs: [ \"get\", \"list\", \"create\", \"update\", \"delete\"]\n    - apiGroups: [\"*\"]\n      resources: [ \"disks\"]\n      verbs: [\"*\" ]\n    - apiGroups: [\"*\"]\n      resources: [ \"storagepoolclaims\", \"storagepools\"]\n      verbs: [\"*\" ]\n    - apiGroups: [\"*\"]\n      resources: [ \"castemplates\", \"runtasks\"]\n      verbs: [\"*\" ]\n    - apiGroups: [\"*\"]\n      resources: [ \"cstorpools\", \"cstorvolumereplicas\", \"cstorvolumes\"]\n      verbs: [\"*\" ]\n    - apiGroups: ['extensions']\n      resources: ['podsecuritypolicies']\n      verbs:     ['use']\n      resourceNames:\n      - openebs-privileged\n    - nonResourceURLs: [\"/metrics\"]\n      verbs: [\"get\"]\n\nInstall OpenEBS\n\n    kubectl apply -f openebs-operator-0.8.2.yaml\n\n**Note: If you are using helm to install openebs, you will need to apply the above change after it has been installed. In a future release of the helm chart, I will work on making this configurable parameter.**\n\n****Step 3: (Optional) Create a new cStor Pool.****\n\nYou can skip this step if using the default cStor Sparse pool.\n\n****Step 3a****: Verify all pods are working and cStor Pools are running\n\n![](/images/blog/2019/05/0_Ti37dZo8QJWX8tUt.png)\n\n****Step 3b****: Verify that disks available on the nodes are discovered.\n\n    kubectl get disks\n\n\n![](/images/blog/2019/05/0_2GZtoi5eEYaJjP-S.png)Disks detected by NDM, along with sparse disks\n\n****Step 3c****: Create a storage pool claim using the instructions at [https://docs.openebs.io/docs/next/configurepools.html](https://docs.openebs.io/docs/next/configurepools.html)\n\nCreate a `cstor-pool-config.yaml` as mentioned in the docs.\n\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-pool1\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 1Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 2Gi\n    spec:\n      name: cstor-pool1\n      type: disk\n      maxPools: 3\n      poolSpec:\n        poolType: striped\n      disks:\n        diskList:\n        - disk-301722dba60542a05ec2817773ff11ed\n        - disk-a2d99f96090f0675b7ea60925b58414d\n        - disk-cd01d33213c3a42c6b1a9f0798277368\n\nApply this file `kubectl apply -f cstor-pool-config.yaml`\n\n![](/images/blog/2019/05/0_J_r91oMArxbXjZKU.png)\n\n****Step 3d****: Create a new storage class using SPC as `cstor-pool1` or edit the default storage class to use the newly created SPC. I have edited the already available default storageclass.\n\n****Step 4: Running Percona Application****\n\n    wget https://raw.githubusercontent.com/openebs/openebs/master/k8s/demo/percona/percona-openebs-cstor-sparse-deployment.yaml\n\nEdit the file to remove security context from the percona deployment.\n\nApply the yaml file\n\n    kubectl apply -f percona-openebs-cstor-sparse-deployment.yaml\n\n\n![](/images/blog/2019/05/0_IdPQ--1fhid-9EDI.png)\n\nThe `percona-cstor` pod will be up and running.\n\nThanks for reading my blog! We continue to look for feedback and suggestions on how we can improve OpenEBS integration with all possible platforms and workloads. If you have any feedback on my blog or see any area of improvement with OpenEBS in general, please provide feedback below or find us on Twitter or on the OpenEBS slack community. [http://slack.openebs.io](http://slack.openebs.io/)\n","slug":"configuring-openebs-to-run-with-securityenhanced-linux"},{"id":41,"title":"How to Easily Build a CI Dashboard","author":"Chandan Kumar","author_info":"Software Engineer at MayaData Inc","date":"26-04-2019","tags":["Ci Dashboard"," Git"," Kubernetes"," Pipeline"," Gitlab"],"excerpt":"In this tutorial, we’ll go through all the necessary steps for setting up the CI dashboard","content":"\nA code that is never executed for users is essentially a digital waste product. To prevent this building of waste and to showcase the results of code on the Kubernetes environment, we can use the CI Dashboard, along with chaos testing.\n\nThe CI dashboard allows users to view the commit and release-based build and run a chaos test using litmus on a different platform with different versions of Kubernetes.\n\nIn this tutorial, we’ll go through all the necessary steps for setting up the CI dashboard:\n\n1. *Create a project*\n2. *Push the code to GitHub*\n3. *Setup the CI of the project using Gitlab*\n4. *Select the chaos test from L*[*itmus*](https://github.com/openebs/litmus)\n5. *Add the script in Gitlab YAML to create pipelines for executing the chaos tests*\n6. *Build a CI dashboard(ex: *[*openebs.ci*](https://openebs.ci/)* ) to display the gitlab pipeline history and status*\n7. *Conclusion*\n\n### Step 1: Create a project\n\nFirst, create a [project](https://github.com/openebs/maya) and write some automated testing for it. You should also add the Dockerfile in the project to set up the CI.\n\n### Step 2: Put the codes on GitHub\n\nCreate a repository on GitHub and add a .gitignore file to ignore the auto-generated folder or file. Follow the script below to put changes into GitHub.\n\n    $ git init\n    $ git add .\n    $ git commit -s -m \"Initial commit\"\n    $ git remote add origin <origin_url>.git\n    $ git push origin master\n\n### Step 3: Setup the CI using gitlab\n\nAdd a *.gitlab.yaml* file to project and write the build and test steps. \n(Ex: [https://github.com/openebs/maya/blob/master/.gitlab-ci.yml](https://github.com/openebs/maya/blob/master/.gitlab-ci.yml)). Import the project in gitlab from GitHub. Setup the gitlab pipeline environment variable to push the docker image, or any other, if required. Add the pipeline trigger command in *.gitlab.yaml* file.\n\n### Step 4: Selection of chaos test\n\nSelect the chaos test (litmus book) from the [litmus](https://github.com/openebs/litmus) repository or write your own litmus book if needed. This will be used to test the product performance on different Kubernetes versions and with different cloud vendors.\n\n### Step 5: Add script in gitlab.yaml\n\nCreate a [repository](https://github.com/openebs/e2e-packet) for the execution of the platform-based pipeline. Add .gitlab.yaml file and related script to create a cluster, or use the executing cluster and run the different chaos tests in various stages of the [pipeline](https://gitlab.openebs.ci/openebs/e2e-packet/pipelines).\n\nReference the .gitlab.yaml file\n[https://raw.githubusercontent.com/openebs/e2e-packet/master/.gitlab-ci.yml](https://raw.githubusercontent.com/openebs/e2e-packet/master/.gitlab-ci.yml)\n\n    cleanup-packet:\n      when: always\n      image: chandankumar4/packet:v4\n      dependencies:\n        - packet-cluster\n      stage: CLUSTER-CLEANUP\n      script: \n        - chmod 755 ./script/packet-cleanup\n        - ./script/packet-cleanup\n    \n\n### Step 6: Build a CI dashboard\n![https://cdn-images-1.medium.com/max/800/1*RZEUR6sumkrI96tFgWFJqQ.png](https://lh4.googleusercontent.com/hoDf2G6VnpIhhkmkQXlF07ocFRm7bJjP5f1ZkA8TZCT6PXMOPkdCO966EecYpk7koCbHPKdMemOA3_kYz8M5qrvLevRDJPw2c0MfYn-yp-iLn4j-qV8wpwT_av2iBYBuMH-4EUeB)CI Dashboard\nCreate a project called [Ci dashboard backend](https://github.com/openebs/ci-e2e-dashboard-go-backend) that will fetch the pipeline details from gitlab by accessing their API and exposing the same on different API after some enhancement. Create another project called [Ci dashboard](http://github.com/openebs/ci-e2e-dashboard) that will display the gitlab pipeline details by accessing the data from the back end API.\n\n### Step 7: Conclusion\n\nCI dashboard will display the build history of the imported project and analyze the performance on different platforms and versions of Kubernetes.\n\n### References\n\n[https://openebs.ci/](https://openebs.ci/)\n\n[openebs/ci-e2e-dashboard](https://github.com/openebs/ci-e2e-dashboard)\n[Contribute to openebs/ci-e2e-dashboard development by creating an account on GitHub.github.com](https://github.com/openebs/ci-e2e-dashboard)\n\n[openebs/ci-e2e-dashboard-go-backend](https://github.com/openebs/ci-e2e-dashboard-go-backend)\n[OpenEBS CI Dashboard backend using Go and PostgreSQL. — openebs/ci-e2e-dashboard-go-backendgithub.com](https://github.com/openebs/ci-e2e-dashboard-go-backend)[openebs/maya](https://github.com/openebs/maya)\n[OpenEBS Maya extends Kubernetes capabilities to orchestrate CAS containers. — openebs/mayagithub.com](https://github.com/openebs/maya)\n","slug":"how-to-easily-build-a-ci-dashboard"},{"id":42,"title":"Deploying OpenEBS on SUSE CaaS platform","author":"Ashok Babu","author_info":"Senior DevOps consultant at Wipro works on App Anywhere & cloud-native technologies.","date":"24-04-2019","tags":["Kubernetes"," Cloud Native Storage"," Mayadata"," SUSE"," Containerattachedstorage"," Openebs"],"excerpt":"I am recently introduced to OpenEBS, an easy to use persistent storage option for Kubernetes and found it nicely working on the SuSE CaaS platform where I could certify the cloud native databases. ","content":"\nI am recently introduced to OpenEBS, an easy to use persistent storage option for Kubernetes and found it nicely working on the SuSE CaaS platform where I could certify the cloud native databases. In this blog, I cover a few quirks to get it running on the SuSE CaaS platform.\n\nSuSE CaaS Platform is an enterprise-class container management solution that leverage Kubernetes as the orchestration layer and SuSE MicroOS as the host operating system for master and worker nodes.\n\nSuSE CaaS provides enhanced security policies such as predefined pod security policies.\n\nIn SuSE MicroOS, a read-only Btrfs file system is used for the root file system with OverlayFS. Sub-volumes for data sharing is read-write.\n\nOutlined below are some of the steps that need to be taken care while installing OpenEBS version 0.8.1 on SuSE CaaS Platform 3\n\n## Issue\n\nDefault OpenEBS installation would fail on SuSE CaaS platform due to the following restrictions by the platform\n\n- NDM Daemonset fails to spin up as it requires privilege permission\n- Sparse pools will not be created as it uses by default /var/openebs directory which is read-only directory under root filesystem in SuSE CaaS.\n- Runtasks in operator uses /var/openebs directory for temporary file creation due to this cstor-target pods or cstor-pool pod gets stuck in “ContainerCreating” status\n\n## Resolution\n\n### Step1\n\nTo install OpenEBS on SuSE platform run the following custom yaml file instead of default operator yaml\n\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-susecaas.yaml\n\nThis is a customized operator yaml file for SuSE CaaS platform that uses the role suse:caasp:psp:privileged for creating privileged DaemonSet\n\n[https://www.suse.com/documentation/suse-caasp-3/singlehtml/book_caasp_admin/book_caasp_admin.html#ex.admin.security.pod_policies.daemonset](https://www.suse.com/documentation/suse-caasp-3/singlehtml/book_caasp_admin/book_caasp_admin.html#ex.admin.security.pod_policies.daemonset)\n\n### Step2:\n\nPerform the following changes in the runtask after completing step1\n\nNote: — This step is not required if you are using the openEBS version 0.9 which is the upcoming release.\n\n- **Change the path in runtask for cstor-pool-create-putcstorpooldeployment**\n\n    kubectl edit runtask cstor-pool-create-putcstorpooldeployment-default-0.8.1 -n openebs\n\nChange from\n\n    path: /var/openebs/shared-\n\nChange to\n\n    path /var/lib/overlay/openebs/shared-\n\n- **Change the path in runtask for cstor-volume-create-puttargetdeployment**\n\n    kubectl edit runtask cstor-volume-create-puttargetdeployment-default-0.8.1 -n openebs\n\nChange from\n\n    path: /var/openebs/shared--target\n\nChange to\n\n    path: path /var/lib/overlay/openebs/shared--target\n\n### Step 3:\n\n**Optional:** If you need to use sparse pool\n\n    kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/5860c0a4619a9feddf5d75d11f50f2ea8fdcec82/k8s/demo/fio/demo-cstor-sparse-pool-limits.yaml\n\n### Step 4:\n\nConfiguration of storage pool, storage class and PVC are like any other platform and the steps are outlined in [https://docs.openebs.io](https://docs.openebs.io/?__hstc=216392137.a6c0b8ba8416b65c52c0226c0e0b69fd.1579867391229.1579867391229.1579867391229.1&amp;__hssc=216392137.1.1579867391230&amp;__hsfp=3765904294)\n\nPool Configuration — [https://docs.openebs.io/docs/next/configurepools.html#manual-mode](https://docs.openebs.io/docs/next/configurepools.html?__hstc=216392137.a6c0b8ba8416b65c52c0226c0e0b69fd.1579867391229.1579867391229.1579867391229.1&amp;__hssc=216392137.1.1579867391230&amp;__hsfp=3765904294#manual-mode)\n\nStorage class — [https://docs.openebs.io/docs/next/configuresc.html#creating-a-new-class](https://docs.openebs.io/docs/next/configuresc.html?__hstc=216392137.a6c0b8ba8416b65c52c0226c0e0b69fd.1579867391229.1579867391229.1579867391229.1&amp;__hssc=216392137.1.1579867391230&amp;__hsfp=3765904294#creating-a-new-class)\n\nVolume — [https://docs.openebs.io/docs/next/provisionvols.html#provision-from-a-disk-pool](https://docs.openebs.io/docs/next/provisionvols.html?__hstc=216392137.a6c0b8ba8416b65c52c0226c0e0b69fd.1579867391229.1579867391229.1579867391229.1&amp;__hssc=216392137.1.1579867391230&amp;__hsfp=3765904294#provision-from-a-disk-pool)\n\n## Conclusion:\n\nAbove approach can be followed to install OpenEBS 0.8 on SuSE CaaS platform 3.0 which needs additional configuration.\n\nWith OpenEBS 0.9 it would be simplified such that you would need to only apply the operator yaml to perform the installation.\n\n**SUSE CaaS Platform:** (Container as a Service Platform) is an integrated software platform which automates the process of building, managing and upgrading of Kubernetes clusters. It combines the benefits of an enterprise-ready operating system with the agility of an orchestration platform for containerized applications. More details — [https://www.suse.com/products/caas-platform/](https://www.suse.com/products/caas-platform/)\n\n**OpenEBS:** OpenEBS is the leading open-source project for container-attached and container-native storage on Kubernetes. OpenEBS adopts Container Attached Storage (CAS) approach, where each workload is provided with a dedicated storage controller. OpenEBS implements granular storage policies and isolation that enable users to optimize storage for each specific workload. OpenEBS runs in userspace and does not have any Linux kernel module dependencies. More details — [https://openebs.io/](https://openebs.io/?__hstc=216392137.a6c0b8ba8416b65c52c0226c0e0b69fd.1579867391229.1579867391229.1579867391229.1&amp;__hssc=216392137.1.1579867391230&amp;__hsfp=3765904294)\n\nThey have a very responsive community. Visit [https://slack.openebs.io](https://slack.openebs.io)\n","slug":"deploying-openebs-on-suse-caas-platform"},{"id":43,"title":"High Availability For Jira Using OpenEBS","author":"Patrick Hoolboom","author_info":"Works @MayaData","date":"21-04-2019","tags":["Openebs"," Kubernetes"," K8s"," Jira"," Docker"," Mayaonline"],"excerpt":"Up time, high availability, disaster recovery. Anyone that has been working in development or IT operations roles knows these terms. Maintaining these things is always touted as the most critical of critical tasks.","content":"\nUp time, high availability, disaster recovery. Anyone that has been working in development or IT operations roles knows these terms. Maintaining these things is always touted as the most critical of critical tasks. Even with that in mind, we often slack in these areas. We don’t test our backups or run our applications with high availability in mind. One of the main factors that lead to these less than ideal deployments is that implementing a good high availability story, or testing our backups, adds time and/or complexity to our already busy day. All that being said, let’s take a look at a dead simple solution for one of those applications that many of us run: Jira.\n\nThe standard answer to making Jira highly available and provide a good disaster recovery story is to use Jira Data Center and follow this guide:\n\n[Jira Data Center Guide](https://confluence.atlassian.com/enterprise/jira-data-center-472219731.html)\n\nThat guide shows you how to cluster multiple instances of the application behind a load balancer, then use a shared file system and a shared database underneath. This blog is not about the application layer or even the database (though we do have some fantastic guides for deploying databases using OpenEBS in our documentation). This is going to focus on a simple way to create a replicated storage layer specifically for the file system. Jira stores information on disks such as issue attachments, import/export files, and logos. These are all important in keeping Jira working correctly.\n\nDeploying Jira on Kubernetes using OpenEBS is as simple as installing OpenEBS on Kubernetes, define a storage pool, define a storage class, define your persistent volume claim, and deploy the Jira container. That’s it…and if you are already using OpenEBS it is even simpler. Now, as for the specifics of how to do those things, see this guide:\n\n[Jira - OpenEBS docs](https://docs.openebs.io/docs/next/jira.html?__hstc=216392137.fb75a0ac1e54cb037dfbafd0edf1ad3f.1579868085240.1579868085240.1579868085240.1&amp;__hssc=216392137.1.1579868085240&amp;__hsfp=3765904294)\n\nOnce you have Jira deployed on your cluster, the easiest way to see your storage resources is through MayaOnline (hopefully you connected to MayaOnline while following the guide, if not the [instructions are here](https://docs.openebs.io/docs/next/mayaonline.html?__hstc=216392137.fb75a0ac1e54cb037dfbafd0edf1ad3f.1579868085240.1579868085240.1579868085240.1&amp;__hssc=216392137.1.1579868085240&amp;__hsfp=3765904294). Here is an example of a Jira deployment as visualized through the MayaOnline topology pane:\n\n![](/images/blog/2019/04/topology-plane.png)\n\nBy leveraging the power of replicas within OpenEBS we have quickly added fault tolerance to the storage attached to our Jira container. It was as simple as defining a replica count in the storage class. Since the replicas are spread across the cluster we no longer have to worry about the storage being a single point of failure. If one disk goes down, the controller will automatically route to one of the replicas with no intervention necessary.\n\nAs you can see OpenEBS has greatly simplified the process of making Jira more resilient in a containerized world. The ease of use of container attached storage makes tasks like these much simpler. It allows us to spend more time working on improving our applications or infrastructure, and less time worrying about its resiliency.\n","slug":"high-availability-for-jira-using-openebs"},{"id":44,"title":"A Primer on OpenEBS Continuous Integration","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"02-04-2019","tags":["Chaos Engineering"," Continuous Integration"," E2e Kubernetes Litmus"],"excerpt":"The OpenEBS project consists of several components (control plane & data plane) that directly support the dynamic provisioning & management of a persistent storage volume on the Kubernetes cluster.","content":"\n**This article is part of a #Concepts series on Kubernetes and Litmus. Here, we present an overview of the OpenEBS CI infrastructure with its Litmus powered e2e pipelines.**\n\nThe OpenEBS project consists of several components (control plane & data plane) that directly support the dynamic provisioning & management of a persistent storage volume on the Kubernetes cluster. As with any microservice-oriented system following the DevOps paradigm, there is a need to continuously build and test each component, both in isolation (via unit tests) as well as in relation with the other pieces (integration tests) with emphasis on standard end-user scenarios (e2e). Factor in the need for basic interoperability verification (in terms of supported OS/Platform/Cluster versions) and you have the requirements for the CI framework spelt out.\n\nThe OpenEBS CI infrastructure is based on the Cloud-Native Gitlab CI framework which is setup to monitor commits to the core components such as [Maya](https://github.com/openebs/maya), [Jiva ](https://github.com/openebs/jiva)& [cStor](https://github.com/openebs/zfs) and also [e2e ](https://github.com/openebs/e2e-packet)(reduces turnaround time to verify testcase sanity). It uses Litmus to drive the e2e pipelines, thereby providing a reference implementation for a Litmus-Experiment based e2e suite.\n\n## Gitlab Infrastructure\n\nSome of the reasons for adopting Gitlab as the CI framework of choice (amongst standard benefits such as tight integration with our existing SCM, 2-factor auth, webhook support, well-defined UI with pipeline graphs etc..,) was the need to move away from a plugin-based model (jenkins thrives on plugins, which may not always be advantageous) to a self-contained platform that supports simple pipeline definitions (.gitlab-ci.yaml is far easier to maintain than the groovy-based jenkinsfile!). Gitlab also offers a more mature kubernetes-native solution that gives users the ability to dogfood OpenEBS storage as the back-end store (PostgreSQL) for the Gitlab server.\n\n![Gitlab server](/images/blog/2019/04/openebs-control-and-data-plane.png)\n\nThe Gitlab server (with its microservices such as Unicorn, Shell, Workhorse, Registry, Sidekiq, Gitaly, PostgreSQL, Redis, Minio) is hosted on a multi-node baremetal OpenShift cluster and is configured with pull-based repository mirroring of the OpenEBS component Github repos and a webhook based setup that triggers the pipelines upon commits.\n\nWhile Maya and Jiva repos are mapped to shell-based executors due to certain build and integration-test requirements, cStor (zfs) and e2e repos are mapped to docker-machine based executors. The docker-machine executors are inherently auto-scaling, a necessary feature for e2e builds as multiple parallel jobs are spawned during the course of e2e pipelines.\n\n## OpenEBS CI Workflow\n\nEach commit to the component source triggers the “gitlab build” procedure, which can be split into two logical phases: “component build” and “e2e.”\nThe component build executes the respective makefile which typically involves running unit tests, building the GO binaries, creating docker images, running integration tests and pushing docker images tagged with the commit SHA to the respective container repositories. It also performs certain pre-e2e routines before finally triggering the e2e pipelines.\n\nThe e2e phase involves running several parallel pipelines (based on Kubernetes cluster platforms or versions), with each pipeline containing multiple stages such as test bed setup, application deployment, Litmus experiments (functional and chaos), and finally clean-up. Needless to say, the component versions used are the ones built in the previous phase.\n\n![OpenEBS CI Workflow](/images/blog/2019/04/openebs-ci-flow.jpg)\n\n**Note**: *Currently, the Gitlab CI works in a “retrospective mode,” as it is invoked on commits to the upstream branches. There is work in progress to extend the support for pull requests (presently, a travis-based build verifies commit sanity to aid PR acceptance).*\n\n## Baseline Commit\n\nBefore triggering the e2e pipelines as part of the final step, the build pipeline performs a pre-e2e routine to generate metadata about the impending e2e run. As is evident from the previous discussion, the e2e pipelines are triggered against commits to any of the OpenEBS component repos (maya, jiva, zfs/cstor, e2e). Images pushed as part of the build pipeline are deployed during the e2e. Therefore, it is necessary to baseline or identify an e2e run against the primary trigger (commit) while maintaining the details of image versions of the other relative components.\n\nThis is achieved by writing the details of the baseline commit (timestamp, component repo, branch and commit ID) into the file head of a “baseline artifact” maintained in a separate repository. Once the e2e pipeline is initiated, the baseline artifact is [parsed ](https://github.com/openebs/e2e-infrastructure/blob/master/env/env_exporter.py)ffor the “most current” image tags of each component, which will invariably include the current baseline commit and the latest ones for other components, in the test-bed preparation stage. This information is then used to [precondition ](https://github.com/openebs/e2e-infrastructure/blob/master/env-update/env.py)the OpenEBS Operator manifest before its deployment on the test clusters.\n\n## OpenEBS e2e Pipelines: Leveraging Litmus\n\n*One of the arguments against the inclusion of e2e as part of CI pipelines is that they could be flaky and time-consuming (under ideal circumstances it involves testing every moving part of the microservice and needs more maintenance). However, the e2e can confirm achievement of the goals that the solution was conceived and built to accomplish. The extent of coverage and the schedules can be optimized for development agility, but at OpenEBS, we feel it is a must-have in our CI pipelines.*\n\nOpenEBS CI makes use of Litmus to drive its e2e pipelines, right from test bed creation (cluster creation playbooks) all the way through the e2e tests (litmus experiments). The e2e pipeline involves several stages, with one or more gitlab jobs scheduled to run in a given stage. Each gitlab job is associated with a “runner script” that runs an “e2e test.” This in turn invokes/executes a litmus experiment (or litmus ansible playbook in the case of cluster creation/destroy jobs).\n\nThe various stages in the e2e pipeline are discussed below:\n\n![Various stages in the e2e pipeline](/images/blog/2019/04/e2e-pipelines.png)\n\n**Cluster Creation**: This stage calls up the Kubernetes cluster by executing the platform-specific playbooks. Cluster parameters are controlled via runtime arguments. The artifacts generated upon this job’s execution such as cluster config, which includes kubeconfig and cluster resource names, are passed over to subsequent stages as dependencies. The Litmus pre-requisites are also installed once the cluster is created. Currently, Litmus supports creation of clusters on these platforms:\n\n- Baremetal Cloud: Packet (ARM based physical servers)\n- Managed Kubernetes: GKE, EKS, AKS\n- Cloud Hosted/Self-Installed: AWS, GCP (via KOPS)\n- On-Premise: OpenShift (vSphere VMs)\n\n**Cluster Provision**: Provision equips the cluster with additional disk resources native to the specific platform (GPD, EBS, Packet Block Storage, Azure Block Device) used by the storage-engines as physical storage resources.\n\n**Provider Setup:** Here, the system deploys the customized/preconditioned OpenEBS Operator manifest (based on the baseline commit) on the cluster, thereby setting up the control plane and preparing default storage pool resources. The logging infrastructure (fluentd) is also setup on the created cluster.\n\n**Stateful Application Deployment**: The OpenEBS e2e verifies interoperability with several standard stateful applications such as Percona-MySQL, MongoDB, Cassandra, PostgreSQL, Prometheus, Jenkins, Redis etc. These applications are deployed with OpenEBS storage classes (tuned for each app’s storage requirement). Each application is accompanied by respective load-generator jobs that simulate client operations and real-world workloads.\n\n**App Functionality Tests:** Each deployed application is subjected to specific behavioural tests such as replica scale, upgrade, storage resize, app replica re-deployment, storage affinity etc. Most of these tests are common day-2 operations.\n\n**Storage/Persistent Volume Chaos Tests**: The PV components such as controller/replica pods are subjected to chaos (pod crash/kill, lossy networks, disconnects) using tools such as chaoskube, pumba, and kubernetes APIs (via kubectl) to verify data availability and application liveness during adverse conditions.\n\n**Infrastructure Chaos Tests:** The cluster components such as storage pools, nodes and disks are subjected to different failures using kubernetes APIs (forces evicts, cordon, drain) as well as platform/provider specific APIs (gcloud, awscli, packet) to verify data persistence and application liveness.\n\n**Stateful Application Cleanup:** TThe deployed apps are deleted in this stage, thereby verifying de-provisioning and cleanup functionalities in the OpenEBS control plane.\n\n**Cluster Cleanup:** The cluster resources (nodes, disks, VPCs) are deleted. With this final step, the e2e pipeline ends.\n\n## Gitlab e2e Job Runner Template\n\nEach Gitlab job running the e2e test executes (bash) scripts containing steps to run and monitor a Litmus experiment. These scripts are invoked using desired arguments, specified as part of the job definition in the e2e repository’s `.gitlab-ci.yml`. The standard template maintained in these (bash) runner scripts and the performed tasks are described below.\n\n![Gitlab runner template(E2E)](/images/blog/2019/04/gitlab-job-runner.png)\n\n**Generate Unique Test Name:** Each gitlab job is associated with a litmus experiment that has a test/experiment name. The result of this litmus experiment is stored in a Litmus Custom Resource (CR) of the same name. The success of a test and therefore the gitlab job is derived from this CR. Occasionally, it is possible that the same litmus experiment is run against different applications or storage engines in a pipeline, thereby necessitating a unique element or ID in the CR name. In this step, a user-defined input (run_id) is accepted to generate a unique test/CR name.\n\n**Setup Dependencies:** Depending on the nature of the gitlab job (cluster create/delete playbooks OR litmus experiments), the executor machine is updated with the appropriate directory structure and target cluster info (such as cluster configuration file, cluster names, disk details, VPC information etc.) to ensure successful test execution.\n\n**Precondition Litmusbook:** Each litmusbook (the Kubernetes job specification YAML) consists of a default set of test inputs such as placeholders for application, storage, chaos info, etc. These are overridden/replaced by desired values in this step. In addition, the default name of the test is replaced with the unique name generated by the runner at the start of execution.\n\n**Run Litmus Experiment:** The litmusbook is deployed and monitored for completion, with a polling interval of 10s. The status of both the litmus Kubernetes job and the ansible-runner container is checked as necessary and sufficient conditions, respectively, to determine completion of the litmus experiment.\n\n**Get Litmus Experiment Result:** The result CR with the unique name generated is queried to determine the Litmus experiment result. The runner script completes execution with a zero/non-zero exit code depending on a pass/failure result, thereby setting the gitlab job status.\n\n**Logging Framework for e2e**\n\nOpenEBS CI uses the popular EFK (Elasticsearch-Fluentd-Kibana) stack as the logging framework for the e2e pipelines. Each target cluster brought up as part of the e2e pipeline is configured with the fluentd-forwarder daemonset and fluentd-aggregator deployment, with the latter streaming the logs to the remote ElasticSearch instance running on the master (Gitlab-CI) cluster. These are then rendered by the Kibana visualization platform that is also running on the master cluster. The forwarders are configured with the appropriate filters based on pipeline and commit IDs to aid in a quick data analysis.\n\n![EFK-Based Logging framework](/images/blog/2019/04/efk-based-logging-framework.png)\n\n**Conclusion**\n\nHopefully this article has provided you with a better understanding of the CI/E2E practices in the OpenEBS project. CI is an important factor in contributor happiness as well as user confidence, and we are focused on continually making it more robust. Feel free to share your questions, comments and feedback with us — we are always listening!\n","slug":"a-primer-on-openebs-continuous-integration"}]