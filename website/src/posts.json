[{"id":1,"title":"Deploying YugabyteDB on Google Kubernetes Engine with OpenEBS","author":"OPENEBS","author_info":"No author information","date":"05-04-2021","tags":["OpenEBS"," OpenSource"," Yugabyte"," Cloud Native Gke"],"excerpt":"In this blog post, we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.","content":"\n[OpenEBS](https://www.openebs.io/) is a CNCF project backed by [MayaData](https://mayadata.io/) that provides cloud-native, open source container attached storage (CAS). OpenEBS delivers persistent block storage and other capabilities such as integrated back-up, management of local and cloud disks, and more. For enterprise cloud-native applications, OpenEBS provides storage functionality that is idiomatic with cloud-native development environments, with granular storage policies and isolation that enable cloud developers and architects to optimize storage for specific workloads.\n\nBecause [YugabyteDB](https://www.yugabyte.com/) is a cloud-native, distributed SQL database that runs in Kubernetes environments, it can interoperate with OpenEBS and many other CNCF projects.\n\n***Wait, what is YugabyteDB?** It is an open source, and high-performance distributed SQL database built on a scalable and fault-tolerant design inspired by Google Spanner. Yugabyte’s YSQL API is PostgreSQL wire compatible.*\n\nIn this blog post we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\n\n**Why OpenEBS and YugabyteDB?**\nBecause YugabyteDB is a transactional database often used as a system of record, it needs to be deployed as a StatefulSet on Kubernetes and requires persistent storage. OpenEBS can be used for backing YugabyteDB local disks, allowing the provisioning of large-scale persistent volumes. \n\nHere are a few of the advantages of using OpenEBS in conjunction with a YugabyteDB database cluster:\n\n- There’s no need to manage the local disks as OpenEBS manages them.\n- OpenEBS and YugabyteDB can provision large size persistent volumes.\n- With OpenEBS persistent volumes, capacity can be thin provisioned, and disks can be added to OpenEBS on the fly without disruption of service. When this capability is combined with YugabyteDB, which already supports multi-TB data density per node, this can prove to be[ massive cost savings on storage.](https://docs.openebs.io/features.html#reduced-storage-tco-upto-50)\n- Both OpenEBS and YugabyteDB support multi-cloud deployments [helping organizations avoid cloud lock-in.](https://docs.openebs.io/docs/next/features.html#truely-cloud-native-storage-for-kubernetes)\n- Both OpenEBS and YugabyteDB integrate with another CNCF project, [Prometheus](https://prometheus.io/). This makes it easy to [monitor both storage and the database](https://docs.openebs.io/docs/next/features.html#prometheus-metrics-for-workload-tuning) from a single system.\n\nAdditionally, OpenEBS can do [synchronous replication](https://docs.openebs.io/docs/next/features.html#synchronous-replication) inside a geographic region. In a scenario where YugabyteDB is deployed across regions, and a node in any one region fails, YugaByteDB would have to rebuild this node with data from another region. This would incur cross-region traffic, which is more expensive and lower in performance. But, with OpenEBS, this rebuilding of a node can be done seamlessly because OpenEBS is replicating locally inside the region. This means YugabyteDB does not end up having to copy data from another region, which ends up being less expensive and higher in performance. In this deployment setup, only if the entire region failed, YugabyteDB would need to do a cross-region node rebuild. Additional detailed descriptions of OpenEBS enabled use cases can be found [here.](https://docs.openebs.io/docs/next/usecases.html)\n\nOk, let’s get started!\n\n**Prerequisites**\n![](/images/blog/yugabyte-work-flow.png)\n\n\nUsing the latest and greatest versions of the available software (as of this blog’s writing), below is the environment which we’ll use to run a YugabyteDB cluster on top of a Google Kubernetes Engine (GKE) cluster backed by OpenEBS\n\n1. YugabyteDB - [Version 2.5.3.1](https://docs.yugabyte.com/latest/quick-start/install/)\n2. OpenEBS - [Version 2.7.0](https://github.com/openebs/openebs)\n3. A [Google Cloud Platform](https://cloud.google.com/gcp/) account\n\n**Step 1: Setting Up a Cluster on GKE**\nTo deploy YugabyteDB on the Google Cloud Platform (GCP), we first have to set up a cluster using Ubuntu as our base node image.\n\n***Note**: GKE’s Container-Optimized OS does not come with an iSCSI client pre-installed and does not allow the installation of an iSCSI client. Therefore, we’ll be using the Ubuntu with Docker image type for our nodes.*\n\nFor the purposes of this demo, I used the Google Cloud Console to configure my Kubernetes cluster. Aside from the typical defaults, here’s the options under the* Node Pools > default-pool > Nodes*  I selected\n\n- **Image Type:** Ubuntu with Docker\n- **Series:** N1\n- **Machine Type: **n1-standard-4 (4 vCPU, 15 GB memory)\n\n![](/images/blog/yugabyte-nodes.png)\n\n\nClick *Create* and wait for the Kubernetes cluster to come online.\n\n**Step 2: Configure iSCSI**\nThe iSCSI client is a prerequisite for provisioning cStor and Jiva volumes. However, it is recommended that the iSCSI client is setup and* iscsid* service is running on worker nodes before proceeding with the OpenEBS installation. In order to set up iSCSI, we’ll first need to determine the names of the nodes in our cluster\n\n    $ kubectl get nodes\n    \n    NAME                                       \tSTATUS   ROLES    \tAGE   \tVERSION\n    gke-cluster-1-default-pool-be95f6dd-5x65  \tReady    <none>   \t18h   \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-rs6c  \tReady    <none>   \t18h \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-t4cp  \tReady    <none> \t18h  \tv1.18.15-gke.1501\n    \n    Now that we have the names of our nodes, we’ll want to log into each node and enable the iSCSI service.\n    \n    $ gcloud compute ssh <node name>\n    $ sudo systemctl enable iscsid && sudo systemctl start iscsid\n    \n    You can check the status of the iSCSI service using the following command:\n    \n    $ systemctl status iscsid\n    \n    iscsid.service - iSCSI initiator daemon (iscsid)\n       Loaded: loaded (/lib/systemd/system/iscsid.service; enabled; vendor preset: enabled)\n       Active: active (running) since Fri 2021-03-26 02:25:42 UTC; 18h ago\n         Docs: man:iscsid(8)\n      Process: 10052 ExecStart=/sbin/iscsid (code=exited, status=0/SUCCESS)\n      Process: 10038 ExecStartPre=/lib/open-iscsi/startup-checks.sh (code=exited, status=0/SUCCESS)\n     Main PID: 10059 (iscsid)\n        Tasks: 2 (limit: 4915)\n       CGroup: /system.slice/iscsid.service\n               ├─10057 /sbin/iscsid\n               └─10059 /sbin/iscsid\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Starting iSCSI initiator daemon (iscsid)...\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 iscsid[10052]: iSCSI logger with pid=10057 started!\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Started iSCSI initiator daemon (iscsid).\n    \n\n**Step 3: Install OpenEBS**\nNext, let’s install OpenEBS. I’ve found that the OpenEBS Operator is one of the simplest ways to get the software up and running.\n\n    $ kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml\n\nOnce the installation is completed, check and verify the status of the pods. You should something similar to this:\n\n    $ kubectl get pods -n openebs\n    \n    NAME                                            READY   STATUS    \n    maya-apiserver-dd655ff87-rbgmd                  1/1     Running  \n    openebs-admission-server-5965c94767-4h8rc       1/1     Running   \n    openebs-localpv-provisioner-5495669c66-z46lr    1/1     Running   \n    openebs-ndm-dss64                               1/1     Running  \n    openebs-ndm-gnv75                               1/1     Running   \n    openebs-ndm-operator-68949644b9-mqvlx           1/1     Running  \n    openebs-ndm-r5pws                               1/1     Running  \n    openebs-provisioner-544cb85449-w9spl            1/1     Running   \n    openebs-snapshot-operator-6d65b778dd-79zcn      2/2     Running \n\n**Step 4: Create and Attach Disks to Nodes**\nOur worker nodes need to have disks attached. These disks need to be unmounted and not have a filesystem on them. To accomplish this we’ll need to execute the following commands on each node.\n\n    $ gcloud compute disks create disk1 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-5x65 --disk disk1\n    \n    $ gcloud compute disks create disk2 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-rs6c --disk disk2\n    \n    $ gcloud compute disks create disk3 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-t4cp --disk disk3\n    \n    Next let’s verify that our block devices are indeed attached.\n    \n    $ kubectl get blockdevice -n openebs\n    \n    NAME              NODENAME                           SIZE          CLAIMSTATE   STATUS   \n    blockdevice-03... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    blockdevice-85... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active   \n    blockdevice-b0... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    \n\n**Step 5: Create a Storage Pool Claim**\nNow that we have the names of our block devices and have verified that they are active, the next step is to create a Storage Pool Claim. We’ll use this to then create a Storage Class, and finally use that for our Persistent Volume Claims. The first step in this chain of steps is to configure our Storage Pool Claim YAML file. In this demo, I’ve named it “cstor-pool1-config.yaml”.\n\n    $ vim cstor-pool1-config.yaml\n    \n    #Use the following YAMLs to create a cStor Storage Pool.\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-disk-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-disk-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n      blockDevices:\n        blockDeviceList:\n    - blockdevice-03e93d010db5169322eb16f3e18e33ed   \n    - blockdevice-22591882979084d0fe580fe229e0d84f   \n    - blockdevice-4d1b4bacbeec1650b337c2cfda7e3a48   \n    ---\n\n    Once you’ve figured out how to exit vim, the next step is to create the resource.\n    $ kubectl create -f cstor-pool1-config.yaml\n    \n    \n\nWe can verify our storage pool with the following command:\n\n    $ kubectl get csp\n    \n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE   \n    cstor-disk-pool-6cmf   1.85M       9.94G   9.94G      Healthy   false      striped\n    cstor-disk-pool-jql6   40.6M       9.90G   9.94G      Healthy   false      striped\n    cstor-disk-pool-vbz5   68.2M       9.87G   9.94G      Healthy   false      striped\n    \n\n**Step 6: Create a Storage Class**\nNow that we have a storage pool, let’s configure the YAML file for our storage class.  In this demo, I’ve named it “openebs-sc-rep1.yaml”.\n\n    $ vim openebs-sc-rep1.yaml\n    \n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-sc-rep1\n      annotations:\n        openebs.io/cas-type: cstor\n        cas.openebs.io/config: |\n          - name: StoragePoolClaim\n            value: \"cstor-disk-pool\"\n          - name: ReplicaCount\n            value: \"1\"\n    provisioner: openebs.io/provisioner-iscsi\n\nAssuming you have remembered how to exit vim from the previous step, we now need to create the storage class.\n\n    $ kubectl create -f openebs-sc-rep1.yaml\n\nFinally, let’s verify the storage class.\n\n    $ kubectl get sc\n    \n    NAME                  PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE \n    openebs-device        openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-hostpath      openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-jiva-default  openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-sc-rep1       openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-snapshot...   volumesnapshot.external...   Delete          Immediate\n    premium-rwo           pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n    standard (default)    kubernetes.io/gce-pd         Delete          Immediate\n    standard-rwo          pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n\nAt this point, we are now set up for Persistent Volume Claims.\n\n**Step 7: Install YugabyteDB**\n\nIn this final step we’ll install a 3 node YugabyteDB cluster running on top of GKE that will be backed by the OpenEBS deployment we just completed.\n\nThe first step is to create a namespace.\n\n*$ kubectl create namespace yb-demo*\n\nNext, let’s install the cluster using Helm.\n\n    $ helm install yb-demo yugabytedb/yugabyte --set resource.master.requests.cpu=1,resource.master.requests.memory=1Gi,\\\n    resource.tserver.requests.cpu=1,resource.tserver.requests.memory=1Gi,\\\n    enableLoadBalancer=True --namespace yb-demo  --set storage.master.storageClass=openebs-sc-rep1,storage.tserver.storageClass=openebs-sc-rep1 --set persistence.storageClass=openebs-cstor-disk --wait\n    \n\nNote that in the command above we are specifying the following so that YugabyteDB makes explicit use of OpenEBS:\n\n- *storage.master.storageClass=openebs-sc-rep1*\n- *storage.tserver.storageClass=openebs-sc-rep1*\n- *persistence.storageClass=openebs-cstor-disk*\n\nOnce the installation is complete you should be able log into the PostgreSQL compatible YSQL shell on port 5433 with the following command:\n\n    $ kubectl --namespace yb-demo exec -it yb-tserver-0 -- sh -c \"cd /home/yugabyte && ysqlsh -h yb-tserver-0\"\n    \n    ysqlsh (11.2-YB-2.5.3.1-b0)\n    Type \"help\" for help.\n    yugabyte=#\n    \n\nYou can also access the basic YugabyteDB web admin portal at:\n\n*http://<yb-master-ui-endpoint>:7000*\n\n![](/images/blog/yugabyte-master.png)\n\n**Viewing Services and Ingress**\nA quick and visual way to check out all the services and ingress is to go to the “Services and Ingress” view in the Google Cloud Console. If you’ve made it this far you should see something like this:\n\n![](/images/blog/yugabyte-ingress.png)\n\nNote: I have omitted the “Endpoints” column from the screenshot above, but in your view you’ll be able to see the IPs and ports of the various endpoints.\n\nThat’s it! You now have a 3 node YugabyteDB cluster running on GKE with OpenEBS storage.\n\n**Next Steps**\nAs mentioned, MayData is the chief sponsor of the OpenEBS project. It offers an enterprise-grade OpenEBS platform that makes it easier to run stateful applications on Kubernetes by helping get your workloads provisioned, backed-up, monitored, logged, managed, tested, and even migrated across clusters and clouds. You can learn more about MayaData [here.](https://mayadata.io/)\n\n- Learn more about OpenEBS by visiting the [GitHub](https://github.com/openebs/openebs) and [official Docs](https://docs.openebs.io/) pages.\n- Learn more about YugabyteDB by visiting the [GitHub](https://github.com/yugabyte/yugabyte-db) and [official Docs](https://docs.yugabyte.com/) pages.\n\n****About the author:****\n\n![Jimmy Guerrero](/images/blog/authors/jimmy-guerrero.png)\n\nJimmy Guerrero, VP Marketing, and Community at YugaByte.\n","slug":"deploying-yugabytedb-on-google-kubernetes-engine-with-openebs"},{"id":2,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks","author":"OPENEBS","author_info":"No author information","date":"22-03-2021","tags":["Mayastor","OpenEBS"],"excerpt":"Learn about Repeatable OpenEBS Mayastor deployments and benchmarks","content":"\n## Introduction\n\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\n\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\n\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\n\n\n## OpenEBS\n\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\n\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\n\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\n\n\n## OpenEBS Mayastor\n\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\n\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\n\n\n## Introducing: the Automation Playground\n\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\n\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\n\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\n\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\n\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars\n\n\n## Stages\n\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\n\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\n\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\n\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\n\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\n\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\n\n\n#### Stage 1: Provisioning\n\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\n\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\n\nThe nodes provisioned are of three varieties\n\n* Master nodes (for Kubernetes Masters)\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\n\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\n\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\n\n#### Stage 2: Start VPN\n\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\n\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\n\n#### Stage 3: Kubernetes setup\n\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\n\nCurrently two installation types are supported with more planned:\n\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\n\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\n\n#### Stage 4: Node preparation\n\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\n\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\n\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\n\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\n\n## Playbooks\n\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\n\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\n\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\n\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\n\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\n\n## Conclusion\n\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\n\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\n\nPlease visit us at https://mayadata.io and give the Demo Playground a spin at https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground.\n\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":3,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"12-03-2021","tags":["Localpv"," OpenEBS"," Flipkart"," TikTok"," Kubernetes"," Mayastor"," MayaData"],"excerpt":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","content":"\n**How to select the right local volume for your workloads?**\n\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\n\n![kg-image](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\n\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: https://github.com/openebs/openebs/blob/master/ADOPTERS.md.\n\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\n\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\n\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\n\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\n\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\n\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\n\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\n\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:\n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\n\n## Limitations of Kubernetes LocalPV\n\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\n\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\n\nWe have seen that cluster administrators are challenged by the following aspects:\n\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\n\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\n* Nodes have 8 to 16 high-performing NVMe SSDs.\n\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\n\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\n\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\n\n* Enforcing Capacity Limits/Thresholds\n* Securing the Volumes\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\n* Encrypting the Volumes\n* Enforce compliance with BCP by taking regular snapshots and full backups\n\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\n\n## Selecting your LocalPV\n\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\n\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\n\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\n\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\n\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\n\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\n\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: https://github.com/openebs/openebs/blob/master/ADOPTERS.md","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":4,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"13-01-2021","tags":["OpenEBS"],"excerpt":"Read about OpenEBS NDM, the go-to solution for managing Kubernetes Local Storage.","content":"\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\n\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\n\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\n\n## Key Storage Problems solved by NDM\n\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\n* Cluster-wide storage visibility\n* Detect the movement of storage devices across nodes\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\n\n## Getting Started with NDM\n\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\n\nMaster: 2 virtual disks\n\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\n\nWorker 2: 4 physical disks\n\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\n    ```\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml\n    ```\n    (The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\n\n* Once deployed, check the blockdevices present in the cluster using\n    ```\n    kubectl get bd -n openebs -o wide\n    ```\n    Some block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\n\n* Deploy a sample application to use the block device\n\n    Download the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\n    ```\n    kubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\n    ```\n    Now check the status of block devices again\n\n    We can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\n\n* Pool movement across nodes\n\n  NDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\n\n* Reserving storage for workloads\n\n  NDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\n\n## Future Roadmap\n\n* Southbound provisioning\n* Metrics (currently in alpha)\n* API Service to interact with NDM\n* Ability to create partitions or LVM volume groups - preparing storage in general.\n\n## Interested in Contributing to NDM?\n\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":5,"title":"Storage is Evolving!","author":"Nick Connolly","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.","date":"11-12-2020","tags":["OpenEBS"],"excerpt":"Learn how storage has evolved over the years. ","content":"\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\n\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\n\n## The hardware environment is changing!\n\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\n\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\n\n## Application development is changing!\n\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\n\n## A New Era\n\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\n\n## Container Attached Storage\n\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\n\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\n\n## Microsoft Windows\n\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not supported on Windows’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\n\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\n\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\n\n## Windows Platform Development Kit\n\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\n\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\n\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\n\n1. Enable high-performance access to NVMe storage directly from applications.\n2. Native software defined storage stacks, including OpenEBS Mayastor.\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\n\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to https://wpdk.github.io or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":6,"title":"OpenEBS on DigitalOcean Marketplace","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"3-12-2020","tags":["OpenEBS","chaosengineering","tutorials"],"excerpt":"Learn how to deploy OpenEBS on the DigitalOcean marketplace","content":"\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\n\nWORKFLOW:\n\nSTEP 1: Getting started\nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\n\nSTEP 2: Creation of cluster\nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\n\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\n\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\n\nSTEP 3: Connecting your cluster\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\n\nTo verify, execute the following command:\n\n```$ kubectl get ns```\n\nOutput:\n```\nNAME     STATUS    AGE\ndefault  Active    13m\nopenebs  Active    13m\n```\nThe output must contain openebs ns in an Active state.\n\nNext, execute:\n\n```$ kubectl get pods -n openebs```\n\nOutput:\n```\nNAME                                                 READY     STATUS    RESTARTS AGE\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\nopenebs-ndm-74njq                                    1/1       Running   0        13m\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\nopenebs-ndm-spttv                                    1/1       Running   0        13m\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\n```\nAll the pods must be in a running state.\n\nSTEP 4: Attaching BlockDevices\nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\n\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\n\nNOTE:\n\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\n\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\n\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\n\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":7,"title":"Atlassian Jira Deployment on OpenEBS","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"20-11-2020","tags":["OpenEBS"],"excerpt":"Learn how to deploy Atlassian Jira on OpenEBS in this short post.","content":"\n**Jira** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, Jira has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\n\n## Requirements\n\n#### Install OpenEBS\n\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\n\n#### Configure cStor Pool\n\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\n\n```\n#Use the following YAMLs to create a cStor Storage Pool.\n# and associated storage class.\napiVersion: openebs.io/v1alpha1\nkind: StoragePoolClaim\nmetadata:\n  name: cstor-disk\nspec:\n  name: cstor-disk\n  type: disk\n  poolSpec:\n    poolType: striped\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\n  #\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\n  # as the disk operator\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\n# Uncomment the below lines after updating the actual disk names.\n  blockDevices:\n    blockDeviceList:\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n---\n```\n\n#### Create Storage Class\n\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: openebs-cstor-disk\n  annotations:\n    openebs.io/cas-type: cstor\n    cas.openebs.io/config: |\n      - name: StoragePoolClaim\n        value: \"cstor-disk\"\n      - name: ReplicaCount\n        value: \"3\"       \nprovisioner: openebs.io/provisioner-iscsi\nreclaimPolicy: Delete\n```\n\n### Deployment of Jira\n\nSample Jira Yaml:\n\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: jira\n      name: jira\n    spec:\n      containers:\n        - name: jira\n          image: \"doriftoshoes/jira:7.3.6\"\n          resources:\n            requests:\n              cpu: \"2\"\n              memory: \"2G\"\n          volumeMounts:\n            - name: \"jira-home\"\n              mountPath: /opt/jira-home\n      volumes:\n        - name: jira-home\n          persistentVolumeClaim:\n            claimName: demo-vol1-claim\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  ports:\n    - port: 8080\n      targetPort: 8080\n  selector:\n    app: jira\n  type: LoadBalancer\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: demo-vol1-claim\nspec:\n  storageClassName: openebs-cstor-disk\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10G\n```\n\nNext, apply both the **Jira deployment** and service to your Kubernetes cluster.\n\n```kubectl apply -f jira.yaml```\n\n#### Verify Jira Pods:\n\n#### Run the following to get the status of Jira pods:\n\n```kubectl get pods```\n\nFollowing is an example output:\n\n```\nNAME                    READY   STATUS    RESTARTS   AGE\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\n```\n\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":8,"title":"Mayastor NVMe-oF TCP performance","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"19-11-2020","tags":["Mayastor"],"excerpt":"Overview of using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known.","content":"\nFor a while now, we have been saying that OpenEBS Mayastor is “high” performance and community members have written [blogs](https://medium.com/volterra-io/kubernetes-storage-performance-comparison-v2-2020-updated-1c0b69f0dcf4) showing that the performance of OpenEBS Mayastor indeed is much better or on par with others even when running on relatively slow cloud volumes. However, is Mayastor high performance or just “as fast” as the other things out there? \n\nIt used to be the case that CPUs were much faster than the storage systems they served. With modern NVMe, this does not ***have*** to be the case anymore. NVMe is a ***protocol*** that can go fast but does not have to be fast. What this means is that you can use NVMe as your transport protocol for any block device, not just flash. Yes, this is what Mayastor does. It is really useful to keep in mind the distinction between NVMe as a protocol and NVMe devices - you don’t need to use them together but, when you do, additional performance can be unlocked.\n\nIn this blog, we will be using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known. We will show what happens when you marry NVMe as a protocol (embedded within Mayastor) and fast NVMe devices from our friends at Intel.\n\nBefore we get started, you might wonder how we came to this point that a new project like OpenEBS Mayastor was able to deliver amongst the fastest storage available today. Richard Elling of Viking / Sanmina recently wrote an excellent blog on the trends in hardware design that puts NVMe and OpenEBS Mayastor into context:  [https://richardelling.substack.com/p/the-pendulum-swings-hard-towards](https://richardelling.substack.com/p/the-pendulum-swings-hard-towards)\n\n## Hardware setup\n\nLet’s get to it. We will be using three machines that will run kernel version 5.8. The hardware configuration of each host is as follows:\n\n- Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz\n- Intel Corporation NVMe Datacenter SSD [Optane]\n- Mellanox Technologies MT28908 Family [ConnectX-6]\n\n## Baseline performance\n\nTo understand the performance of the device we will be using throughout the test, we run the following Fio workload:\n\n    [global]\n    ioengine=linuxaio\n    thread=1\n    group_reporting=1\n    direct=1\n    norandommap=1\n    bs=4k\n    numjobs=8\n    time_based=1\n    ramp_time=0\n    runtime=300\n    iodepth=64\n    \n    \n    [random-read-QD64]\n    filename=/dev/nvme1n1\n    rw=randread\n    stonewall\n    \n    \n    [random-write-QD64]\n    filename=/dev/nvme1n1\n    rw=randwrite\n    stonewall\n    \n    \n    [random-rw-QD64]\n    filename=/dev/nvme1n1\n    rw=randrw\n    stonewall\n\n![](/images/blog/mayastor-nvme1.png)\nThese numbers are incredibly high and are provided by a ***single*** device. Note that the benchmark itself is rather synthetic in the sense that, in practice, no workload is 100% random.\n\n## High-level overview of the experiments\n\nMy approach in this benchmarking is very much OpenEBS Mayastor “the hard way”.  If you want an easier to use solution that for example automates pool creation and device selection and so on - we call that offering Kubera Propel (also open source btw). You can learn more about Kubera Propel on the [MayaData.io](https://mayadata.io/) website.    \n\nOn two of the nodes, we create a pool (MSP CRD) which we use in the control plane to determine replica placement. To construct pools, we must have what we call a persistence layer. We support several ways to access this persistence layer. To select a particular scheme we use URIs. In this case we will be using today the pcie:/// scheme. This means that Mayastor will directly write into the NVMe devices listed above. The nice thing is that from the user perspective, things do not change that much. We simply replace disks: [‘/dev/nvme0n1’] with disks: [‘pcie:///80:00.0’]. Note that this persistence layer is used to store the replicas of the PVC. Once we have this layer up and running, we will create storage classes and select that we want to use nvmf (NVMe-oF) as the transport layer between the replicas, resulting in NVMe all the way through. \n\nAfter we have deployed mayastor we applied to following two storage classes:\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf\n    parameters:\n      repl: '1'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n    ---\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf-mirror\n    parameters:\n      repl: '2'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n\nNote that `protocol: `nvmf` is just a shorthand for the NVMe-oF format mentioned above. We will be using both storage classes to run a single replica followed by a two way replica AKA mirror.  We use the following YAML to create the volume.\n\n    apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: ms-volume-claim\n    spec:\n      accessModes:\n       - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100G\n      storageClassName: nvmf\n\nAfter creating the PVC, Mayastor’s control plane creates a CRD, “Mayastor Volume” (MSV), that contains additional information about the corresponding volume.  Using kubectl describe msv -n mayastor we get:\n\n    Name:         ba081dc3-46db-445b-969c-7e5245aba146\n    Namespace:    mayastor\n    Labels:       <none>\n    Annotations:  <none>\n    API Version:  openebs.io/v1alpha1\n    Kind:         MayastorVolume\n    Metadata:\n      Creation Timestamp:  2020-09-11T08:49:30Z\n      Generation:          1\n      Managed Fields:\n        API Version:  openebs.io/v1alpha1\n        Fields Type:  FieldsV1\n        fieldsV1:\n          f:spec:\n            .:\n            f:limitBytes:\n            f:preferredNodes:\n            f:replicaCount:\n            f:requiredBytes:\n            f:requiredNodes:\n          f:status:\n            .:\n            f:nexus:\n              .:\n              f:children:\n              f:deviceUri:\n              f:state:\n            f:node:\n            f:reason:\n            f:replicas:\n            f:size:\n            f:state:\n        Manager:         unknown\n        Operation:       Update\n        Time:            2020-09-11T08:51:18Z\n      Resource Version:  56571\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/mayastor/mayastorvolumes/ba081dc3-46db-445b-969c-7e5245aba146\n      UID:               94e11d58-fed9-44c9-9368-95b6f0712ddf\n    Spec:\n      Limit Bytes:  0\n      Preferred Nodes:\n      Replica Count:   1\n      Required Bytes:  100000000000\n      Required Nodes:\n    Status:\n      Nexus:\n        Children:\n          State:     CHILD_ONLINE\n          Uri:       bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n        Device Uri:  nvmf://x.y.z.y:8420/nqn.2019-05.io.openebs:nexus-ba081dc3-46db-445b-969c-7e5245aba146\n        State:       NEXUS_ONLINE\n      Node:          atsnode3\n      Reason:\n      Replicas:\n        Node:     node3\n        Offline:  false\n        Pool:     pool-atsnode3\n        Uri:      bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n      Size:       100000000000\n      State:      healthy\n    Events:       <none>\n\n## Results single replica\n![](/images/blog/mayastor-nvme2.png)![Chart](https://lh5.googleusercontent.com/whpgDl_Id_oo4tUdl7RZDv-C1Uq2ZfvM6Eh7KXbwNkNTu5Mki14meunBgF1PMWMnWLoccSGgHqCfRKXgQpJTfQG42NaS0GkwWRCuNpWGh7znOhqQ94aJXiCODJkzNUs9-G2ucqMJ)\nFrom the results we can see that we are very close to the performance of the local device. To be sure we can put it in the right perspective, the difference between the experiments here is that with the baseline, the workload was local. With repl=1 we use the same NVMe device but export it through our pool layer (and thus provide volume management), but also go over the network.\n\n## Results 2 replicas (mirror)\n\nWe are going to repeat the same test, this time, we will use two replicas. As we now have double the disks bandwidth, we expect to see that the read performance will go up. For writes, however, we actually expect a drop in performance, because we must do each write to both disks before we can acknowledge the IO.  Note that Mayastor does not cache - if you read the blog referenced above from Richard Elling you can learn why caching seems to be falling out of favor for use cases in which millions of IOPS are desired.\n![](/images/blog/mayastor-nvme3.png)![Chart](https://lh4.googleusercontent.com/GJ7c_cZ6vuDxd9-jAnU3XxAc8L0idA9sscz2JB5XVa0taj8v56H6MSIFB56XqPQzQsy_p49-yHlwhCB8SVjZ05YfT0oRdlFt0EMBze1IDrCioqWgtWypidK9fBpb9p3ULI19Dhfa)\n## Wrapup\n\nWith the above experiments, we have demonstrated that with OpenEBS Mayastor we have built a foundational layer that allows us to abstract storage in a way that Kubernetes abstracts compute. While doing so, the user can focus on what's important -- deploying and operating stateful workloads. \n\nIf you’re interested in trying out Mayastor for yourself, instructions for how to setup your own cluster, and run a benchmark like **fio** may be found at [mayastor.gitbook.io/](https://mayastor.gitbook.io/introduction/).\n\nAnd if you are a Kubera Propel user, you’ll find that we’ve productized some of the benchmarking above so that platform teams and other users can programmatically use benchmarks in their decisions about workload placement. We are working with a number of users about operating OpenEBS Mayastor / Kubera Propel at scale. Please get in touch if you have suggestions, feedback, ideas for interesting use cases and so on. Contributions of all kinds are welcome!\n","slug":"mayastor-nvmeof-tcp-performance"},{"id":9,"title":"Mayastor Engine Reaches Beta","author":"Glenn Bullingham","author_info":"Director of Solution Architecture","date":"19-11-2020","tags":["OpenEBS"],"excerpt":"Mayastor, the storage engine by OpenEBS has reached the beta stage. Read the blog to know more.","content":"\ntitle: Mayastor Engine Reaches Beta\nAs I write this, it is early November, and the winds of change are blowing. The United States has a new president. Here in the United Kingdom, Keats' days of mists and mellow fruitfulness are departing, replaced by a low sun and the first morning frosts. And at MayaData, we see the Mayastor project carefully but tenaciously emerging from alpha/pre-release into its beta phase. In fact, Mayastor now undergirds MayaData’s commercial offering for performance sensitive containerized workloads, called [Kubera Propel](https://mayadata.io/product).\n\n> ***“Beta Software: Software considered to be feature complete and substantially free of known major defects”***\n\nSignificant contributions over the past 18 months have seen the project raised from concept to working software. A major requirement of our MVP specification is that it should carry minimal performance overhead; Mayastor is intended to satisfy demands for performance at all levels of scale. At the beginning of Autumn, working in conjunction with Intel’s labs in the UK, we were able to validate that assertion; deployed in conjunction with the latest generation of Optane NVMe devices, the Mayastor data plane was found to introduce less than 6% overhead; you can read more about that benchmarking [here](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/). Having addressed that performance criteria and the other principle MVP requirements, the Mayastor team at MayaData has begun to focus its contributions to the project on QA as we approach Beta and GA releases.\n\nIn particular, we’ve greatly increased end-to-end test coverage on Kubernetes. How MayaData tests Mayastor is something that I’ll elaborate upon in a forthcoming post.  However, suffice it to say customary suspects feature (Jenkins, mocha, nix, cargo test), whilst we’re also collaborating with our colleagues who maintain the [Litmus Chaos](https://litmuschaos.io/) project. By the time that you’re likely reading this, Mayastor-specific chaos tests should be available to all on [ChaosHub](https://hub.litmuschaos.io/).\n\n## Ease of Use, Perf, and Availability\n\nMayastor MVP requirements center on ease of use, performance, and availability. In the Beta phase and subsequent GA release, these will be realized as a CAS platform with full NVMe data path semantics, declarative configuration via CSI compliant dynamic provisioning, and N+1 synchronous mirroring of data at the persistent layer. This closely approaches functional parity with the current OpenEBS storage engines (cStor, Jiva, and Local PV), with snapshot and cloning functionality to be added in Q1 2021. Mayastor will also very soon be the recipient of a streamlined deployment and configuration experience, which is exclusive to this engine.\n\n## Try it Yourself\n\nIf you’re a member of the Kubernetes community looking to implement a platform-native storage solution in the new year, now is an ideal time to start evaluating Mayastor. The other venerable and respected engines of OpenEBS won’t be retiring overnight, but as full feature parity emerges, MayaData’s commercial products and services will on Mayastor as their default storage engine; we do recognize that some users will continue to prefer various flavors of Dynamic Local PV from OpenEBS - as a recent [blog](https://www.percona.com/blog/2020/10/01/deploying-percona-kubernetes-operators-with-openebs-local-storage/) from the CTO of Percona attests as do countless [Adopter.md case studies](https://github.com/openebs/openebs/blob/master/ADOPTERS.md) including that of the SaaS company Optoro, also a CNCF case study. Mayastor’s roadmap includes provisions for the inward migration of existing OpenEBS users. It’s an equally opportune moment to [consider becoming a contributor](https://github.com/openebs/Mayastor/issues/new/choose) to the project yourself.\n\nTo help with Mayastor onboarding as we prepare to go to full steam, we’re putting together a new documentation site over at[ GitBook](https://mayastor.gitbook.io/introduction/), which includes a comprehensive quick-start deployment guide (developer docs will remain, at least for now, with the OpenEBS/Mayastor GitHub repository). We’re also holding [Office Hours at Kubecon NA 2020 this month](https://kccncna20.sched.com/?searchstring=OpenEBS&amp;iframe=no&amp;w=&amp;sidebar=&amp;bg=), and we’d love to see you there.\n\nIf you’d like to try Mayastor from the source - you can do so, of course, from the GitHub repositories. If you’d like to also try out management utilities, including a cool management interface and available 24x7 support - please take a look at [Kubera Propel](https://go.mayadata.io/register-for-kubera-chaos-and-propel-technical-preview). A free forever for individual use tier is available.\n\n## Conclusion\n\nIt is a propitious time for MayaData and Mayastor - and for data on Kubernetes more broadly. If you have always wanted to run workloads on Kubernetes but were put off by the stories of performance challenges, you can now move forward with confidence. Kubernetes enabled storage with the help of Mayastor performs faster than that of traditional shared everything storage while retaining the ease of use, open source community, and Kubernetes semantics for which OpenEBS has become famous.\n","slug":"mayastor-engine-reaches-beta"},{"id":10,"title":"Migrate CSPIs to a different node by moving the disks","author":"Sai Chaithanya","author_info":"A developer who is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate about Data Science. Enjoys playing kabaddi and traveling.","date":"04-11-2020","tags":["OpenEBS"],"excerpt":"Step by step guide to migrate CStorPoolInstances from one node to different nodes by moving the set of underlying disks","content":"\n\nThis blog describes steps to migrate CStorPoolInstances from one node to different nodes by **moving the set of underlying disks to a new node that participates in the pool provisioning**. There were a couple of use cases where this feature can be helpful:\n\n1. Scaling down and scaling up nodes in the cluster(in a cloud environment) by retaining external volumes(for cost savings).\n2. Replacing failed storage nodes with new nodes by attaching the same old disks to the new node.\n\n**Steps to migrate the CSPI to different node:**\n\n1. Detach the disks belonging to the CSPI that you wish to migrate from the node and attach it to the new node. If you are using a cloud platform, check on their documentation, or ask the administrator about the steps to do this.\n2. Change the node selector in the CSPC YAML (next section describes how to do this).\n\n![](https://lh4.googleusercontent.com/XTwKu6lE3lyoZ3cHRO9HNJGUaTOoGfE-OWGuscrmukbxEKJNPSaEqxUPbbNnnc3dcD-Aybc2_AF0y2Scf0QBxSDG_f9QZWRu67sXZjoMKO6nymhgelEWfDzPjfGKi4D9UwLBaN0D)\n\n**Existing setup**:\n\nI have a three-node cluster with CSPC and CSI volumes already provisioned(To create CSPC pools and CSI volume click [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md#quickstart)). Here is detailed information:\n\n**Cluster details**:\n\n    Kubernetes Cluster: AWS\n    Kubernetes Version: v1.15.9\n    OpenEBS Version: 2.2.0 \n\n****Node and BlockDevice details**: **Attached three disks to three nodes(each node has one disk)\n\n    Kubectl get nodes\n    \n    NAME                STATUS   ROLES    AGE   VERSION\n    ip-192-168-29-151   Ready    <none>   16m   v1.15.9\n    ip-192-168-36-89    Ready    <none>   8h    v1.15.9\n    ip-192-168-74-129   Ready    <none>   8h    v1.15.9\n    \n    Kubectl get bd -n openebs\n    NAME                                           NODENAME          SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-36-89  10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-74-129 10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-29-151 10737418240   Claimed      Active\n\n****CSPC Manifest**: **Applied following CSPC manifest to provision cStor pools\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-74-129\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-36-89\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-29-151\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nAfter applying the above CSPC manifest, the following three CStorPoolInstances(CSPI) were created.\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-74-129 24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-36-89  24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-29-151   24100M   24113200k   false     ONLINE   8h\n\nNow everything looks good. After some time, the cluster has been scaled down **0** nodes and scaled back to **3** nodes. So after scaling operations following are new nodes in the cluster.\n\n    Kubectl get nodes\n    \n    NAME               STATUS   ROLES    AGE     VERSION\n    ip-192-168-14-90   Ready    <none>   118s    v1.15.9\n    ip-192-168-49-43   Ready    <none>   5m55s   v1.15.9\n    ip-192-168-94-113  Ready    <none>   4m6s    v1.15.9\n\nAttached old disks that participated in pool creation to new nodes, and the following is blockdevice output.\n\n    Kubectl get bd -n openebs\n    \n    NAME                                           NODENAME            SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-49-43    10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-94-113   10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-14-90    10737418240   Claimed      Active\n\nFrom the above and previous output following are blockdevice mappings with zn old node and new node:\n\n    Blockdevice  Name                                    Old Node            New Node \n    blockdevice-7d311a98255a454a717427b5c2d38426    ip-192-168-36-89        ip-192-168-49-43\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b    ip-192-168-74-129       ip-192-168-94-113\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3    ip-192-168-29-151       ip-192-168-14-90\n\nOpenEBS **NodeDiskManager**(NDM) will automatically update the details in blockdevice CRs when the disks migrate to a new node. Based on the above output, update the CSPC manifest with new **nodeSelector** values.\n\n****Updated CSPC Manifest**:**\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-94-113\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-49-43\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-14-90\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nOnce the CSPC manifest is updated then CSPIs will automatically migrate to the new node (which can be verified using ****kubectl get cspi -n openebs****).\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-94-113   24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-49-43    24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-14-90    24100M   24113200k   false     ONLINE   8h\n\n**Note:** Along with CStorPoolInstance migration, CStorVolumeReplicas belongs to CSPI will also migrate automatically.\n","slug":"migrate-cspis-to-a-different-node-by-moving-the-disks"},{"id":11,"title":"OpenEBS Backup/Restore for ZFS-LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"27-10-2020","tags":["OpenEBS"],"excerpt":"Overview of how to use Velero Backup/Restore plugin for ZFS-LocalPV to protect it against data loss.","content":"\n## Overview: OpenEBS Backup/Restore for ZFS-LocalPV\n\n**Backup** is the process of copying the data to a different/remote location to protect against accidental or corruption or any other type of data loss. Restore is the process of getting back the data from the backup. In this blog, I will discuss how we can use *Velero Backup/Restore* plugin for ***ZFS-LocalPV*** to protect it against data loss.\n\n### Pre-requisites\n\nWe should have installed the ZFS-LocalPV 1.0.0 or later version for Backup and Restore, see my previous[ blog](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d) for the steps to install the ZFS-LocalPV driver.\n\n### Setup\n\n**1.Install Velero CLI**\n\nDownload the 1.5 or later binary for ZFS-LocalPV. For Linux on amd64, we need to download below\n\n    wget\n    https://github.com/vmware-tanzu/velero/releases/download/v1.5.1/velero-v1.5.1-linux-amd64.tar.gz\n\nExtract the tarball:\n\n    tar -xvf velero-v1.5.1-linux-amd64.tar.gz\n\nMove the extracted velero binary to somewhere in your $PATH (/usr/local/bin for most users).\n\nSee the detailed steps[ here](https://velero.io/docs/v1.5/basic-install/).\n\n**2.Deploy Velero**\n\nWe will be using minio for storage purpose in this blog, we need to setup the credential file first\n\n    $ cat /home/pawan/velero/credentials-minio\n    [default]\n    aws_access_key_id = minio\n    aws_secret_access_key = minio123\n\nWe can install Velero by using below command\n\n    $ velero install --provider aws --bucket velero --secret-file /home/pawan/velero/credentials-minio --plugins velero/velero-plugin-for-aws:v1.0.0-beta.1 --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://minio.velero.svc:9000 --use-volume-snapshots=true --use-restic\n\nWe have to install the velero 1.5 or later version of velero for ZFS-LocalPV.\n\n**3.Deploy MinIO**\n\nDeploy the MinIO for storing the backup:-\n\n    $ kubectl apply -f\n    https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/sample/minio.yaml\n\nThe above MinIO uses tmp directory inside the pod to store the data for the demonstration purpose, so when restart happens, the backed up data will be gone. We should change the above YAML to use persistence storage to store the data when deploying it for the production.\n\nCheck the Velero Pods are UP and Running\n\n    $ kubectl get po -n velero\n    NAME                      READY   STATUS      RESTARTS   AGE\n    minio-d787f4bf7-xqmq5     1/1     Running     0          8s\n    minio-setup-prln8         0/1     Completed   0          8s\n    restic-4kx8l              1/1     Running     0          69s\n    restic-g5zq9              1/1     Running     0          69s\n    restic-k7k4s              1/1     Running     0          69s\n    velero-7d9c448bc5-j424s   1/1     Running     3          69s\n\n**4.Setup OpenEBS Plugin**\n\nWe can Install the Velero Plugin for ZFS-LocalPV using the below command\n\n    velero plugin add openebs/velero-plugin:2.2.0\n\nWe have to install the velero-plugin 2.2.0 or later version, which has the support for ZFS-LocalPV. Once the setup is done, we can go ahead and create the backup/restore.\n\n**5.Create the VSL**\n\nThe VSL(Volume Snapshot Location) has information about where the snapshot should be stored. To create the Backup/Restore, we can create the Volume Snapshot Location by applying the below YAML:\n\n    apiVersion: velero.io/v1\n    kind: VolumeSnapshotLocation\n    metadata:\n     name: default\n     namespace: velero\n    spec:\n     provider: openebs.io/zfspv-blockstore\n     config:\n       bucket: velero\n       prefix: zfs\n       namespace: openebs # this is the namespace where ZFS-LocalPV creates all the CRs, passed as OPENEBS_NAMESPACE env in the ZFS-LocalPV deployment\n       provider: aws\n       region: minio\n       s3ForcePathStyle: \"true\"\n       s3Url: http://minio.velero.svc:9000\n\nHere, we have to provide the namespace, which we have used as OPENEBS_NAMESPACE env while deploying the ZFS-LocalPV. The ZFS-LocalPV Operator yamls uses “openebs” as the default value for OPENEBS_NAMESPACE env. Verify the volumesnapshot location:\n\n    kubectl get volumesnapshotlocations.velero.io -n velero\n\n### Create Backup\n\nWe can use the below Velero command to create the backup:\n\n    velero backup create my-backup --snapshot-volumes --include-namespaces=<backup-namespace> --volume-snapshot-locations=default --storage-location=default\n\nwe can add all the namespaces we want to be backed up in a comma-separated format in --include-namespaces parameter. We have to provide the VSL that we have created in --volume-snapshot-locations parameter.\n\nWe can check the backup status using the velero backup get command:\n\n    $ velero backup get\n    NAME        STATUS       CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR\n    my-backup   InProgress   2020-09-14 21:09:06 +0530 IST   29d       default            <none>\n\nThe status InProgress means that the backup is in progress. Wait for it to be Completed.\n\nWe can also create a scheduled backup which will take the backup periodically. For example, to take the full backup at every 5 min, we can create the below schedule :\n\n    velero create schedule schd --schedule=\"*/5 * * * *\" --snapshot-volumes --include-namespaces=<backup-namespace1>,<backup-namespace2> --volume-snapshot-locations=default --storage-location=default\n\n### Restore\n\nIf the application and its PVC has been deployed in a namespace, then we can use the below Velero command to create the backup of the entire namespace:\n\n    velero restore create --from-backup my-backup --restore-volumes=true --namespace-mappings <source-ns>:<dest-ns>\n\nThe above command will create the backup of everything that is there in the namespace provided as --include-namespaces argument. We can provide the namespace mapping if we want to restore in a different namespace as --namespace-mappings parameter. If namespace mappings are not provided, it will restore in the source namespace only where the original pod and pvc was present. Now we can check the restore status:\n\n    $ velero restore get\n    NAME                       BACKUP      STATUS       WARNINGS   ERRORS   CREATED                         SELECTOR\n    my-backup-20200914211331   my-backup   InProgress   0          0        2020-09-14 21:13:31 +0530 IST   <none>\n\nOnce the Status is Completed, we can check the pods in the destination namespace and verify that everything is up and running. We can also verify that the data has been restored.\n\n### Summary\n\nAs demonstrated in this blog, OpenEBS makes it easy to take the backup of the Kubernetes applications, which we can use to Restore as part of disaster recovery. In my next blog, I will talk about how we can take the incremental backup of the volumes, which is space optimized backup for ZFS-LocalPV\n\n## Important links\n\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n[https://velero.io/docs/](https://velero.io/docs/v1.5/basic-install/)\n","slug":"openebs-backuprestore-for-zfslocalpv"},{"id":12,"title":"OpenEBS 2.2.0 - Enhancements And New Storage Capabilities","author":"Ashutosh Kumar","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut","date":"20-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS 2.2.0 is here! Read this post to learn about the new updates.","content":"\n### **OpenEBS 2.2.0 is here**\n\nWe are excited to announce yet another ***OpenEBS*** release that comes with new storage capabilities, control plane enhancements, bug fixes, and new APIs for the world’s fastest storage engine built on RUST, also known as Mayastor.\n\nOpenEBS has seen a wider adoption among the users, thanks to the vibrant and growing community. Like in most of the OpenEBS releases, this release responds to the feedback received in the community. If you want to learn more about the project roadmap, please browse the following link:\n[https://github.com/openebs/openebs/blob/master/ROADMAP.md](https://github.com/openebs/openebs/blob/master/ROADMAP.md)\n\nIncremental Backup and Restore in ZFS local PV and pool and volume migration in cStor are the major release milestones made into the release. The pool migration in cStor solves the use-case of replacing a bad node with a new node or sending a node for maintenance on on-premise clusters. The migration feature provides great value in cloud-managed Kubernetes clusters, too, e.g., GKE, where node reboots or voluntary scale down of nodes can cause the disks to get removed. \n\nThis release is also special due to the [*Hacktoberfest*](https://hacktoberfest.digitalocean.com/) festival and would like to give a shout out to first-time contributors [@didier-durand](https://github.com/didier-durand), [@zlymeda](https://github.com/zlymeda), [@avats-dev](https://github.com/avats-dev), and many more.\n\n### **Key Highlights of OpenEBS 2.2.0 Release:**\n\n- Mayastor aims to be the world’s fastest container attached storage and is currently in alpha. The release introduced block device enumeration feature via the gRPC API and enhancement around storage pool finalizers.\n- ZFS local PV has become a popular storage engine built on local storage design and provides powerful storage features like snapshots and clones, raw block volume, etc. It also supports day two operations like volume resize and backup and restore via the pluggable Velero interface.\nSupport for Incremental Backup and Restore by enhancing the OpenEBS Velero Plugin has been a significant highlight for ZFS local PV release. \nTo learn more about this, please refer to the document [here](https://github.com/openebs/zfs-localpv/blob/master/docs/backup-restore.md).\n- OpenEBS Velero plugin connects the Velero interface to the OpenEBS storage engines to deliver backup/restore functionality. Velero Plugin has been enhanced to restore ZFS Local PV into a different cluster or a different node in the cluster and use custom certificates for S3 object storage.\n- CStor went into beta in 2.0 and has been enhanced to migrate the storage pool from one node to another node. This will help with scenarios where a Kubernetes node can be replaced with a new node but can be attached with the block devices from the old node that contain cStor Pool and the volume data.\n- OpenEBS node disk manager helps in block device discovery and management in a Kubernetes cluster and powers storage engines like cStor. Support to exclude multiple devices that could be mounted as host filesystem directories has been added.\nAn issue where NDM could cause data loss by creating a partition table on an uninitialized iSCSI volume has also been fixed.\n\n### **Useful Links and Summary:**\n\nIf you are interested in knowing more details regarding the changes that made to this release, please visit the release note [link](https://github.com/openebs/openebs/releases/tag/v2.2.0). To try out OpenEBS, you can visit [https://docs.openebs.io/](https://docs.openebs.io/) and follow the user guides.\n\nYou can visit the following link to learn more or experiment with Mayastor\n[https://github.com/openebs/mayastor](https://github.com/openebs/mayastor)\n\nYou can visit the following link to learn more or experiment with ZFS local PV\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n\nTo learn more about the new cStor CSPC API, please visit the following link:\n[https://github.com/openebs/cstor-operators](https://github.com/openebs/cstor-operators)\n\nIf you have any feedback, questions, or suggestions — please reach out to the community on the #openebs channel in the Kubernetes workspace or consider opening a relevant issue at [Github](https://github.com/openebs/openebs).\n","slug":"openebs-220-enhancements-and-new-storage-capabilities"},{"id":13,"title":"Scaling up cStor Volume Replica","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"07-10-2020","tags":["OpenEBS"],"excerpt":"OpenEBS provides volume replication through different storage engines. Learn how to scale up cStor Volume Replica.","content":"\nEven if a cluster is reliable, nodes can and do fail. Rebooting a node does not simulate a crash. There can be many reasons, such as catastrophic hardware failure, Operating System failure, or communication failure among the nodes. To overcome this hazardous situation, the Replication of volume becomes necessary.\n\nReplication is the process by which one or more volumes can be copied to maintain the significance of a cluster and to avoid data loss. OpenEBS provides volume replication through different storage engines. One of them is cStor Volume Replication.\n![Synchronous replication of data](https://lh5.googleusercontent.com/ijS24Ywabw-QkWWYbSLoOshGTi2SHZhdEFATaHIYbkNGK8lUq5SJrct6fNHfPjWcPTHGyvByS7uD1vYct2m5D6-HdRC2ZoMpS_c4Crw-9sREhPU-tXE8KAt-nWj7vYw99Ee_s1pE)\n#### Prerequisite for scaling up the replicas of cStor volume:\n\n- A cStor pool should be available, and replicas of this cStor volume should not be present on this cStor pool.\n- The OpenEBS version should be 1.3.0 or more.\n\n### Please follow the below steps for cStor Volume Replication:\n\nGet the StorageClass name using the following command:\n\n    kubectl get sc\n\nExample Output:\n![](https://lh5.googleusercontent.com/lTma7ZqsAavmXEzGG_b4BXDMUEYXjFXf0xxnWgE70znfR_EzP3IorVFp0evkKoLMsBQ0D7gwOQxivB_bZxEcv2vhYZOe17k7mNyDBaPewTgiUdusrd3ow12ClBeQvZVmVzjDrdsI)\nThe storage class for cStor is ***openebs-sc-cstor***. Perform the following command to get the details of the corresponding StorageClass, which is used for creating the cStor volume :\n\n    Kubectl get sc openebs-sc-cstor\n\nWe will get the Yaml file of the corresponding StorageClass ***openebs-sc-cstor***.\n![](https://lh5.googleusercontent.com/81DQJ-DhT3AKseMRfCZ4NpkmOPl2Tckm76jrUxE2eECY7lrejvNz3OjomFWmNiCRwm0L2seAWzmJJhe-8xcqFirBsEUedf2xzPN4NHq2RM2YYEZZv-iKpsE03j06EQi_D5kqnDCi)\nIn the Yaml above, We can see the Replica count Value is 1.\n\nGet the volume name using the following command:\n\n    Kubectl get pvc\n\nGet the VOLUME name and use it in the following command to get the details of corresponding cStor volume. All commands are performed by considering the above PVC.\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=<Vol-name>\n\nExample output:\n![](https://lh4.googleusercontent.com/FIOJchscq3lm7UJLwnk7i1oNne_RxhjIJzI3FMANxxkRhz4yWZAue-Wu1jD03ii2aMjtdDu3zr9C-0ZGaeazkvxb_JkGnxBBDza605w_p-v9BY1ER40f6DityHwimJvhvuAR8FcT)\nGet the details of existing cStor Volume Replica details using the following command:\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nExample output:\n![](https://lh3.googleusercontent.com/68NvgkfD7audTNZN1QLt6SVw4OvN_B3MIlnFnWm8MfgDziiexFX2qeI3tX6H1TCJJgrCA8b-nZQJoM6hx1QoYWOv4q74tKwB7nrZLc9xdluXRCvWTpj-sU6sIv7aJ0AMgL3rr1AR)\nPerform the following command to get complete details of the existing cStor volume replica:\n\n    kubectl get cvr -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nGet the available cStor Pools for creating new cStor volume replica. The following command will get the other associated cStor pools details:\n\n    kubectl get csp -l openebs.io/storage-pool-claim=cstor-disk-pool | grep -v cstor-disk-pool-hgt4\n\nExample Output:\n![](https://lh6.googleusercontent.com/lcbO830nSZgValr-I4ci7FHRa6Qvqf3eG-bycWHHAniRD8mb8dwRHOwxeVObFqj4FqvXbNkb_oZUdWhMgAQuHvU1pYDecvWXhDetYGdJADBQhWfzMuwJm4d9Ywgg6bAKkj-Sd79a)\nFrom the above example output, there are 2 cStor pools available, i.e., ***cstor-disk-pool-2phf*** and ***cstor-disk-pool-zm8l***. So it is possible to scale up the current volume replica count to 3 from 1. If there are no cStor pools available to perform volume replica scale-up, then follow the [steps](https://docs.openebs.io/docs/next/ugcstor.html#expanding-cStor-pool-to-a-new-node) to create a new cStor pool by updating existing SPC configuration.\n\nPerform the following command to get the details of the cStor Pool where new replica will be created:\n\n    kubectl get csp -n openebs cstor-disk-pool-2phf -oyaml\n\nNote down following parameters from the output:\n\n- metadata.labels.cstorpool.openebs.io/name\n- metadata.labels.cstorpool.cstorpool.openebs.io/uid\n- metadata.annotations.cstorpool.openebs.io/hostname\n\nThe sample CVR Yaml is provided below:\n![](https://lh3.googleusercontent.com/JePqVqyIryf396SEkCf9NoS3kmPDXM0huqehkN3kX5f-eE7nX3-mCr42xriJeDKSNRgfVxSeQG_SUHkbqEZS4ktIzzcJ8VKCsFXuz4VhtdXpikLADE3eJdkgwH3zFd5PXRPfYc70)\nApply the updated CVR YAML spec to create the new replica of cStor volume using the following command:\n\n    kubectl apply -f cvr.yaml\n\nExample Output:\n![](https://lh5.googleusercontent.com/JElB0d8zFXHoUh6wM0QpAshOmYbVXOvH5RIR9UjJ_svM67ZR2pq6cQ4ckrq0Qw6ACpRnOqO-6nUbvLUrDhFKvgZxjrh-ke0VHnKW-pR2oyzkgXdQuRATSwy9EVN19G458ZyR_9Xd)\nVerify if new CVR is created successfully using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh4.googleusercontent.com/ql9j6Zcod6DT1vKhJrlJJaxk4YUN8Mf_o7LT3e-fBjjoybINByEwwDS5fln6K5BEJGW6vFfE8h2JA_2tFvQY5PQKo62eJvQfTE5j5JwECIz2oO3u_ypKHWRylL3gmU4KYlo4axtU)\nFrom the above output, a new replica of the cStor volume is created, and STATUS is showing as Offline.\n\nUpdate Desired Replication Factor in cStor volume with a new replica count. This can be updated by editing corresponding cStor volume CR YAML.\n\n    kubectl edit cstorvolume pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8 -n openebs\n\nThe following is the snippet of updated cStor volume CR YAML:\n![](https://lh3.googleusercontent.com/lAisXwgequP2MyeCw1cVuwUYFG9G9L5U88olJ2CjbjIOpHjlMwn-K8p11ktaCjQfxK-u5EL-ebpZofD0W_LOKmfFa-wW3eTLtBpqSt7EPYvz5rQciYeaFdT6_7PCsJkdxPVHZCVg)\n\nIn the above snippet, the desiredReplicationFactor is updated to 2 from 1. Example output:\n![](https://lh6.googleusercontent.com/uBkJft958gfjATk070ZFZOMXaq7Sb1xnd5lBVMa2sKuXo-nxwrRxQS58TPgdpoLjMuMHvT4LwPscxPdT6kgwpaDVSraLmsNwWhfanMUrNVO72K8WgxwT3_or4EdzqQkWBgI-Ka84)\nVerify if the rebuilding has started on the new replica of the cStor volume. Once rebuilding has been completed, it will update its STATUS as Healthy. Get the latest status of the CVRs using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh6.googleusercontent.com/1KjmeLgtvoFcBh0vVmB0iwj_gjo-Tkd3vVTTmaw3OaREY9KbvDUQLqyEu0Hj_aYKDpTIRSDVG2sOrTPMczJAPASlzFitSHDyocPV4Bb6IgajW-ArUpDKhi8StFesnHYZrUc3X9DJ)\n","slug":"scaling-up-cstor-volume-replica"},{"id":14,"title":"\"Hacktoberfest 2020 - Contribute to OpenEBS\"","author":"MayaData Marketing","author_info":"Mayadata Marketing Team","date":"30-09-2020","tags":["OpenEBS"],"excerpt":"Hacktoberfest 2020 is almost here. Contribute to open source project, OpenEBS, to win exciting swag.","content":"\n### Hacktoberfest returns! Contribute to OpenEBS and win exciting swag\n\nThe seventh annual [***Hacktoberfest ***](https://hacktoberfest.digitalocean.com/) celebration is almost here, and we at *OpenEBS* are happy to be participating in the contest once again. In August 2017, the OpenEBS community began growing and building a strong foundation for an open source project.\n\nWe were first introduced to *Hacktoberfest* by friends and peers at the DigitalOcean Bangalore Meetup and were immediately interested in participating. We enlisted OpenEBS as one of the projects participating in Hacktoberfest 2017. We were pleasantly surprised by the participation and enthusiasm that Hacktoberfest attracts from developers around the world. The PRs have been at their peak during Hacktoberfest.\n![](https://lh4.googleusercontent.com/Og_t8KLCiRni_LS66bpJsonSXMjcoAX671c8a2LD7ZjbkVdYZgZCRFq47sDC7hsEZt6qcaoCJPZi_gm2FnKmuzMvlg4UZAQKofU0agH2Z11TRmw6vBCQ8u3ssGfre75BN9OV-vOO)\n### Get started with OpenEBS this Hacktoberfest\n\nFollowing the smashing success we had when we participated in the event last few years, we’re going to do the same this year! MayaData makes it more exciting to participate in **Hacktoberfest **by running multiple Meetups throughout the month and helping contributors to get started with their favorite areas (in any of the programming languages) like website development and documentation enhancements. \n\nTo top it all, there are exciting prizes to be won and every contribution deserves an additional swag from MayaData. Read [this blog](https://blog.mayadata.io/openebs/experience-with-openebs-in-this-hacktoberfest) by Aswath K, one of last year’s weekly winners, who writes about his experience with OpenEBS in Hacktoberfest 2019.\n![](https://lh6.googleusercontent.com/2POqPppb7pyGM0OWwl_LlkHzwz-DSWXMMggxIeNCXvsU6EVVmNHdiIzIoTw23-ceK9R5iBleFMGiK-lw9JLtCP5VVjFGQS1QhIOXbpQhtvku5Gp5aCw4Eul_r6JcM-o0WuVZRZmj)\n### How do I contribute to OpenEBS?\n\nThat is an excellent question! OpenEBS is a Kubernetes native Container Attached Storage (CAS) that simplifies running Stateful workloads on Kubernetes. It is built on Microservices architectural patterns, fully automated development, and build pipelines.\n\nOpenEBS has several components that need your help from simple fixes like adding GitHub issue templates, to enhancing the components. These are developed using Go, Rust, Python, Javascript, Ansible, and many more interesting tools. OpenEBS is also a great way to start your journey into the exciting world of storage, containers, and Kubernetes.\n\nThe [architecture overview document ](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) is a great place to start learning and picking up a component that speaks to your passion. You could start your first contribution by enhancing that document itself for providing more clarity.\n\nThere are many other [good first issues](https://github.com/search?q=org%3Aopenebs+is%3Aissue+label%3A%22good+first+issue%22) to pick from.\n\nContributions can be anything from creating issues, improving user and contributor documents, enhancing build and docker tools, fixing and enhancing code, or unit tests and e2e tests. If you are unsure where to start, begin a discussion with the contributors on [GitHub Discussions](https://github.com/openebs/openebs/discussions) or by joining [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).\n\n### Will there be swag?\n\nYes. A big fat YES!\n\nThe official [Hacktoberfest](https://hacktoberfest.digitalocean.com/) will be giving away free t-shirts to every person making four pull requests to open source repositories during October, as well as limited-edition Hacktoberfest stickers to everyone who participates.\n\nOn top of this, you will also be able to get some exclusive and limited OpenEBS swag. When your PR to any OpenEBS repository is merged, we will contact you to fill out a form to send a special edition swag designed for Hacktoberfest.\n\nNot only this but by becoming a top weekly contributor, you’ll be able to grab even more swag.\n\nPrizes will be sent to quality contributions. The best PR will win a grand prize. Stay tuned to find out more.\n\nSo, what are you waiting for! Go get your git on and start contributing - we can’t wait to receive your PR.\n\nHappy hacking!\n\n### Getting Started:\n\n1. [https://hacktoberfest.digitalocean.com/](https://hacktoberfest.digitalocean.com/)\n2. Join [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F)\n3. Checkout the [OpenEBS Contributing guide](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md)\n4. Learn about the [architecture and components](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) of OpenEBS\n5. Create new issues for your contribution or pick one of the existing issues from [https://github.com/openebs/openebs/issues](https://github.com/openebs/openebs/issues)\n","slug":"hacktoberfest-2020-contribute-to-openebs"},{"id":15,"title":"Provisioning Google Cloud with k8s using it’s in-house tool, KOPS","author":"Harshvardhan Karn","author_info":"Harshvardhan Karn works at MayaData Inc. He is a public speaker, has talked in few local meetups and at two major conferences. In his free time, he likes to play Guitar, Netflix.","date":"14-08-2018","tags":["Docker"," Kubernetes"," Openebs"," Kops"],"excerpt":"Setting up and using a cluster in GCP offers a few significant advantages over using GKE. For instance, using GCP gives the user the liberty to use their custom binaries or a pure Open Source Kubernetes.","content":"\nI am very excited for this post, as I have been working on this content for a few weeks. I might sound naive throughout this, mainly because I am, to be honest. Setting up and using a cluster in _GCP_ offers a few significant advantages over using _GKE_. For instance, using GCP gives the user the liberty to use their _custom binaries_ or a _pure Open Source Kubernetes_. Also, _GKE_ does not support modification or access to the master node, whereas a manually setup-ed k8s cluster over _VMs_ does.\n\nTo gain the full understanding of Kubernetes, some people like to get their hands dirty for a course of interval. Luckily, we have a few more tools to get a Kubernetes cluster up and running in VM instances of **Google Cloud**. I find that tools like _kubernetes-incubator/kubespray , crosscloudci/cross-cloud_ and kops, are not very straightforward to use, but _kops, kubespray_ is somewhat close. _Cross-cloud_ on the other hand, has poor documentation and is not very stable. _kops_ here stands for ‘_Kubernetes Operations._’ To be honest, I find this to be a good tool to deploy the Cluster over Google Cloud Platform (**GCP**) or Amazon Web Services (**AWS**). I certainly would not say it is the best, but this tool is documented to the extent that one can use it. The original idea of KOPS was to create user a production ready cluster in **AWS**. Allowing it to provision the GCP is luxury since GCP already provides with GKE and AWS does not.\n\n### **Requirements**\n\nThese items are required to deploy the production-ready k8s cluster in GCP:\n\n- **KOPS**\n\n```\nwget -O kops\nhttps://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '\"' -f 4)/kops-linux-amd64\n\nchmod +x ./kops\n\nsudo mv ./kops /usr/local/bin/\n```\n\n- **GCloud**\n\n[https://cloud.google.com/sdk/](https://cloud.google.com/sdk/)\n\nOnce you are done installing GCloud SDK, you must run _gcloud init_. This will configure your gcloud with your existing GCP project.\n\n- **kubectl**\n\nFrom the [official kubernetes kubectl release:](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\n\n```\nwget -O kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl\nchmod +x ./kubectl\nsudo mv ./kubectl /usr/local/bin/kubectl\n```\n\n- A little patience …\n\n## Let’s Begin!\n\nA quick note: every time you create a cluster, it also creates a _Virtual Private Cloud _(**VPC**), per se. Google Cloud allows you to create only a maximum of 5 VPC’s in one project, and a total of only 5 clusters. So, to resolve this problem, we can create a **VPC** explicitly and use it as a common Network for the rest of the clusters.\n\n### Create a VPC\n\nHere I am using subnet-mode as auto, and it will create a VPC _openebs-e2e_ with a subnet in every zone.\n\n```\ngcloud compute networks create openebs-e2e --project=openebs-ci --subnet-mode=auto\n```\n\n### Create a Bucket\n\nKops needs a State Store to hold the configuration of our cluster. In our case, it is Google Cloud Storage Buckets. So, let’s create one empty Bucket using the following:\n\n```\ngsutil mb gs://openebs-dev/\n```\n\nNow, since we are ready with the Bucket, we can populate it with our cluster’s State Store, i.e. Cluster object and InstanceGroup object.\n\n**Create the Cluster & InstanceGroup Objects in Our State Store**\n\n_kops create cluster_, creates the Cluster object and InstanceGroup object. Here, we’ll be working within kops.\n\n```\nPROJECT=`gcloud config get-value project`\nexport KOPS_FEATURE_FLAGS=AlphaAllowGCE # to unlock the GCE features\nkops create cluster openebs-dev.k8s.local --zones us-central1-a\n--state gs://openebs-dev/ --project=${PROJECT}\n--kubernetes-version=1.11.1 --node-count 3\n```\n\nNow we can list the Cluster objects in our kops State Store (the GCS bucket we created):\n\n```\nkops get cluster --state gs://openebs-dev/\nNAME                     CLOUD        ZONES\nopenebs-dev.k8s.local    gce          us-central1-a\n```\n\n**NB:** It is not necessary to use the same name for the Bucket and Cluster; you are free to use whatever name you wish.\n\n### Create a Cluster\n\nWe are now ready with all of the changes and the cluster configuration, so we will proceed with the creation of the cluster. _kops create cluster_ created the Cluster object and the InstanceGroup object in our State Store, but it did not actually create any instances or other cloud objects in GCE. To do that, we’ll use _kops update cluster_.\n\n_kops update cluster_ without _--yes_ will show us a preview of changes that will be made. It comes handy in case we want to see or verify the specs before creation.\n\n```\nkops update cluster openebs-dev.k8s.local --state gs://openebs-dev/ --yes\n```\n\nCheers!\n\nWe have now deployed the Kubernetes cluster on GCP. If you go to the _Compute Engine_ in _Google Cloud Platform_, you will find 4 new nodes, where 1 is the master and the rest are worker nodes. Just to save your day, if you are wondering why you could not find your nascent cluster inside _Google Kubernetes Engine_, this is not a mistake or error because it is not a GKE Cluster. All GzCP knows is that there are 4 VMs running in the project, which we know is a K8s cluster.\n\n## Out-of-the-Box\n\nWe are now ready with the cluster, but is it ready for the deployments? Once the kops is finished creating the cluster, we can validate its readiness using the following:\n\n```\nkops validate cluster --state gs://openebs-dev/\n\n\nI0808 12:34:10.238009   25907 gce_cloud.go:273] Scanning zones: [us-central1-c us-central1-a us-central1-f us-central1-b]\nINSTANCE GROUPS\nNAME                 ROLE   MACHINETYPE    MIN MAX SUBNETS\nmaster-us-central1-a Master n1-standard-1  1   1   us-central1\nnodes                Node   n1-standard-2  3   3   us-central1\nNODE STATUS\nNAME                       ROLE   READY\nmaster-us-central1-a-067f  master True\nnodes-6rt6                 node   True\nnodes-lvs5                 node   True\nnodes-wbb8                 node   True\nYour cluster openebs-dev.k8s.local is ready\n```\n\nIf you find that the cluster not ready, wait for a few minutes as it takes some time to configure the cluster. You can even check using _kubectl_ from your control machine:\n\n```\nkubectl get nodes\n```\n\nYou will see the node counts once your Cluster is up, viz. _kubelets_ are configured. If you are wondering how you got your _kubectl_ configured to this cluster, _kops_ does that for you. It exports a kubecfg file for a cluster from the state store to your _~/.kube/config_ local machine where you are running _kops_. If you want to export this config to some other path, you can the following:\n\n```\nkops export kubecfg openebs-dev.k8s.local\n```\n\nI wrote an Ansible playbook for [Litmus](https://github.com/openebs/litmus/), which is actually a wrapper for all of these to bring up the cluster on GCP. You can check it out here:\n\n[https://github.com/openebs/litmus/tree/master/k8s/gcp/k8s-installer](https://github.com/openebs/litmus/tree/master/k8s/gcp/k8s-installer)\n\nThe playbook also checks the cluster availability implicitly using a python script. This will hold the playbook from termination until the cluster is ready to use. _kops validate_ works well, but **not** for **k8s version < 1.9,** up to the day of writing this post.\n\nGodspeed!\n","slug":"provisioning-google-cloud-with-k8s-using-its-inhouse-tool-kops"},{"id":16,"title":"How to start contributing to mayactl","author":"Sumit Lalwani","author_info":"Sumit Lalwani is a Software Engineer at Mayadata. He is a Kubernetes enthusiast and passionate about open source, containers, cloud, and arm. He loves to learn and code.","date":"14-08-2018","tags":["Docker"," Openebs"," Kubernetes"],"excerpt":"mayactl is the command line tool for interacting with OpenEBS volumes. mayactl is not used/required while provisioning or managing the OpenEBS volumes, but it is currently used while debugging and troubleshooting.","content":"\n## What is mayactl?\n\n- mayactl is the command line tool for interacting with OpenEBS volumes. mayactl is not used/required while provisioning or managing the OpenEBS volumes, but it is currently used while debugging and troubleshooting.\n- mayactl is the client like kubectl which requests to maya-apiserver to get specific information whereas kubectl requests to Kubernetes apiserver to get specific information.\n- mayactl helps retrieve storage related information for debugging/troubleshooting storage related issues. mayactl provides various commands to create volume, get volume details and create, list and revert snapshot and many more.\n\nTo know more about the mayactl visit:\n\n[https://docs.openebs.io/docs/next/mayactl.html](https://docs.openebs.io/docs/next/mayactl.html)\n\n## OpenEBS Architecture\n\n![OpenEBS Architecture](/images/blog/openebs-architecture.png)\n\nTo know about the OpenEBS visit: [https://docs.openebs.io/docs/next/introduction.html](https://docs.openebs.io/docs/next/introduction.html)\n\n### These few things are required to be installed in your system (with Ubuntu host) to run mayactl\n\n1. **Docker**\n\n- To install docker run these commands\n\n```\nsudo apt-get update\nsudo apt-get install apt-transport-https ca-certificates curl software-properties-common\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \\\n  \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) \\\n  stable\"\nsudo apt-get update\nsudo apt-get install docker.io\n```\n\n- Or you can visit the official docker website to install docker\n\n[https://docs.openebs.io/docs/next/mayactl.html](https://docs.openebs.io/docs/next/mayactl.html)\n\n2. **open-iscsi package**\n\n- To install open-iscsi package run these commands\n\n```\nsudo apt-get update\nsudo apt-get install open-iscsi\nsudo service open-iscsi restart\n```\n\n3. **Golang**\n\n- To install golang, visit the official golang website: [https://golang.org/doc/install](https://golang.org/doc/install)\n\n4. **Minikube**.\n\n- To install minikube, run these commands:\n\n```\n# minikube requires virtualbox to be installed as a dependency\n\nsudo apt-get install virtualbox virtualbox-ext-pack\nsudo apt-get update\n\n# minikube version 0.24.0\n\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.24.0/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/\n```\n\n5. **Kubectl**.\n\n- Run these commands to install Kubectl:\n\n```\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/v1.8.0/bin/linux/amd64/kubectl\nchmod +x ./kubectl\nsudo mv ./kubectl /usr/local/bin/kubectl\n```\n\n### How do I run mayactl in a local machine for development purposes?\n\n1. Open the openebs repo ( [https://github.com/openebs/openebs](https://github.com/openebs/openebs)) and star the openebs repo.. 😄 (Not Mandatory)\n\n2. Fork the openebs/openebs and openebs/maya repositories into your GitHub account.\n\n- Visit and click on the fork option (both repositories)\n\n[a) openebs/openebs](https://github.com/openebs/openebs)\n\n[OpenEBS is containerized block storage written in Go for cloud native and other environments w/ per container (or pod)…](https://github.com/openebs/openebs)[github.com](https://github.com/openebs/openebs)\n\n[b) openebs/maya](https://github.com/openebs/maya)\n\n[maya — OpenEBS Maya extends Kubernetes capabilities to orchestrate CAS containers.](https://github.com/openebs/maya)[github.com](https://github.com/openebs/maya)\n\n3. Clone the openebs and maya repositories inside your gopath. Then run these commands to clone:\n\n```\n# if directories not present create the directories in same hierarchy\n\ncd $GOPATH/src/github.com/openebs\ngit clone https://github.com/<your-github-username>/openebs.git\ngit clone https://github.com/<your-github-username>/maya.git\n```\n\n4. Run the single node cluster using the minikube command.\n\n```\nminikube start --vm-driver=none\n\n# To check whether minikube is configured and running\n\nminikube status\n```\n\n5. Install OpenEBS by executing these commands:\n\n```\ncd $GOPATH/src/github.com/openebs/openebs/k8s/\nkubectl apply -f openebs-operator.yaml\nkubectl apply -f openebs-storageclasses.yaml\n```\n\n![kubernetes commands](/images/blog/install-openebs-by-commands.png)\n\n6. Now we have the openebs-provisioner and maya-apiserver running as a pod in the Kubernetes (minikube) cluster.\n\n- To get the pods, run this command:\n\n```\nkubectl get pods\nNAME READY STATUS RESTARTS AGE\nmaya-apiserver-7b8d5496cc-kgmnn 1/1 Running 0 3m\nopenebs-provisioner-6797d44769-phnnc 1/1 Running 2 3m\n```\n\n7. To run/access mayactl, you will need to login/execute into the maya-apiserver pod on Kubernetes.\n\n- Find out the name of the maya api-server pod by running the following commands:\n\n```\nkubectl get pods\n\n# It will access the bash shell inside the pod\n\nkubectl exec -it <maya-apiserver-podname> /bin/bash\n```\n\n8. Now you can run all mayactl commands as you are inside the maya-apiserver pod.\n\n- Try running these commands after exececute/login into the pod.\n\n```\nmayactl -help\n```\n\nGo through the issues ([https://github.com/openebs/maya/issues](https://github.com/openebs/maya/issues)) and start modifying the mayactl code, located in $GOPATH/src/github.com/openebs/maya/cmd/mayactl, and start contributing to OpenEBS. Also, you can start contributing by writing a small unit test code in mayactl. For every PR you raise, you will also receive goodies from the OpenEBS team. 😃\n\n**How do I test the changes made in mayactl?**\n\n1. After modifying the mayactl code, go into the maya directory, i.e $GOPATH/src/github.com/openebs/maya, and run these commands:\n\n```\n# run this if not currently in maya directory\n\ncd $GOPATH/src/github.com/openebs/maya\n\n# this will create the mayactl binary into the bin folder inside maya directory\n\nmake mayactl\n```\n\n2. After the build has been completed, copy the mayactl binary from the bin folder to the maya-apiserver pod using the command:\n\n```\nkubectl cp $GOPATH/src/github.com/openebs/maya/bin/maya/mayactl <maya-apiserver-podname>:/tmp/\n```\n\n3. Login/execute into the maya-apiserver pod to run the mayactl binary.\n\n```\nkubectl exec -it <maya-apiserver-podname> /bin/bash\ncd /tmp/\n```\n\n4. Here the mayactl binary you copied is shown.\n\n- To run that binary, use the following command:\n\n```\n./mayactl -help\n```\n\nNow you can easily see the changes you made in the mayactl command line tool. You are also now ready to raise the PR’s. 😃\n\n**Reference:**\n\n- [https://www.youtube.com/watch?v=yzMEYT-yzRU](https://www.youtube.com/watch?v=yzMEYT-yzRU)\n- [https://docs.openebs.io/docs/next/introduction.html](https://docs.openebs.io/docs/next/introduction.html?__hstc=216392137.2d2e61b1b8f85b3675bfaef604437f8a.1580205967521.1580205967521.1580205967521.1&__hssc=216392137.1.1580205967522&__hsfp=2262740235)\n","slug":"how-to-start-contributing-to-mayactl"},{"id":17,"title":"Setting up WordPress and SQL with OpenEBS","author":"Ashish Ranjan","author_info":"An enthusiastic person when it comes to software & computers. I don't mind getting out of my comfort zone when things related to computing need to be done at the spur of the moment.","date":"14-08-2018","tags":["Openebs"," Kubernetes"," Cloud Native Storage"," Open Source"," State Department"],"excerpt":"Wordpress is a well-known blogging platform. New bloggers are often surprised when they find out how easy it is to get set up and start their first piece in this popular tool.","content":"\n[Wordpress](https://en.wikipedia.org/wiki/WordPress) is a well-known blogging platform. New bloggers are often surprised when they find out how easy it is to get set up and start their first piece in this popular tool. In this blog, we will show how to deploy WordPress and MySQL on OpenEBS in their Kubernetes cluster.\n\n## What is OpenEBS?\n\nOpenEBS offers containerized persistent block storage using Docker containers. Those blocks are often referred to as Virtual Storage Machines (similar to K8s pods). OpenEBS seamlessly provides scalable storage volumes and manages them effortlessly. For more information, you can visit [https://openebs.io/join-our-slack-community](https://openebs.io/join-our-slack-community?__hstc=216392137.b7acacf689e0cc4579eea008f86d0c72.1579857743065.1579857743065.1579857743065.1&__hssc=216392137.1.1579857743066&__hsfp=3765904294).\n\n### Prerequisites:\n\n- A k8s cluster with at least one minion.\n- Basic knowledge of writing services, deployment in k8s.\n- Kubectl, already configured.\n- A code editor for writing a yamls.\n- Brains.\n\nLet’s get started!\n\n## Setting up OpenEBS\n\nBefore starting with WordPress, we need to set up OpenEBS. For this article, I will be using OpenEBS v0.6 (you are free to use newer versions if you wish).\n\nWhen setting up OpenEBS, you need to apply the following yamls:\n\n```\nkubectl apply -f https://raw.githubusercontent.com/openebs/openebs/v0.6/k8s/openebs-operator.yaml\nkubectl apply -f https://raw.githubusercontent.com/openebs/openebs/v0.6/k8s/openebs-storageclasses.yaml\n```\n\nThe first yaml is for the openebs-operator, and the second one is for openebs-storage-classes. For more information look [here](https://docs.openebs.io/?__hstc=216392137.b7acacf689e0cc4579eea008f86d0c72.1579857743065.1579857743065.1579857743065.1&__hssc=216392137.1.1579857743066&__hsfp=3765904294). After applying the above yamls, the output of kubectl get pods — all-namespaces will look like this:\n\n```\n$ kubectl get pods --all-namespaces\nNAMESPACE NAME READY STATUS RESTARTS AGE\nkube-system event-exporter-v0.2.1-5f5b89fcc8-bhv7r 2/2 Running 0 16m\nkube-system fluentd-gcp-scaler-7c5db745fc-tb2zw 1/1 Running 0 16m\nkube-system fluentd-gcp-v3.0.0-wqgzx 2/2 Running 0 14m\nkube-system heapster-v1.5.3-77c6fcd568-q8txc 3/3 Running 0 15m\nkube-system kube-dns-788979dc8f-4lgsf 4/4 Running 0 16m\nkube-system kube-dns-autoscaler-79b4b844b9-jldbr 1/1 Running 0 16m\nkube-system kube-proxy-gke-ashish-ranjan-default-pool-b3a38b91-cv5d 1/1 Running 0 16m\nkube-system l7-default-backend-5d5b9874d5-hvrgb 1/1 Running 0 16m\nkube-system metrics-server-v0.2.1-7486f5bd67-hls82 2/2 Running 0 15m\nopenebs maya-apiserver-68c98fdb76-vbslv 1/1 Running 0 1m\nopenebs openebs-provisioner-5569654c96-hmhb5 1/1 Running 0 1m\nopenebs openebs-snapshot-operator-5f7c4d9bd8-7fnfv 2/2 Running 0 1m\n```\n\nWait until all openebs namespaced pods move into a running state. Once this is completed, we’ll start by creating a secret for sql.\n\n## Creating a Secret\n\n```\nkubectl create secret generic mysql-pass --from-literal=password=w0rdPres5\n```\n\nRun the above kubectl command to create a mysql password.\n\n## Wordpress Deployment\n\nNow, let's start writing the WordPress deployment yaml. Copy and save the above into a Wordpress.yaml file and execute a kubectl apply on it. Once this is done, the output of kubectl get pods,svc,pvc — all-namespaces will look similar to this:\n\n```\n$ kubectl get pods,svc,pvc --all-namespaces\nNAMESPACE NAME READY STATUS RESTARTS AGE\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-766678794-jtltg 2/2 Running 0 2m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-2pkt4 1/1 Running 0 2m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-htdxh 1/1 Running 0 2m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-rdtlk 1/1 Running 0 2m\ndefault pod/wordpress-7bdfd5557c-5b4nh 1/1 Running 2 2m\nkube-system pod/event-exporter-v0.2.1-5f5b89fcc8-wprbm 2/2 Running 0 8m\nkube-system pod/fluentd-gcp-scaler-7c5db745fc-s9mp9 1/1 Running 0 8m\nkube-system pod/fluentd-gcp-v3.0.0-49vq6 2/2 Running 0 5m\nkube-system pod/fluentd-gcp-v3.0.0-kfjsx 2/2 Running 0 5m\nkube-system pod/fluentd-gcp-v3.0.0-tg5hh 2/2 Running 0 5m\nkube-system pod/heapster-v1.5.3-76f7f5f544-z7xk9 3/3 Running 0 6m\nkube-system pod/kube-dns-788979dc8f-2chf4 4/4 Running 0 8m\nkube-system pod/kube-dns-788979dc8f-ls4ln 4/4 Running 0 7m\nkube-system pod/kube-dns-autoscaler-79b4b844b9-8745z 1/1 Running 0 8m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8866 1/1 Running 0 7m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8fh5 1/1 Running 0 7m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-9jjf 1/1 Running 0 8m\nkube-system pod/l7-default-backend-5d5b9874d5-k9mn8 1/1 Running 0 8m\nkube-system pod/metrics-server-v0.2.1-7486f5bd67-wlnlg 2/2 Running 0 6m\nopenebs pod/maya-apiserver-68c98fdb76-5bt2z 1/1 Running 0 4m\nopenebs pod/openebs-provisioner-5569654c96-4n4hp 1/1 Running 0 4m\nopenebs pod/openebs-snapshot-operator-5f7c4d9bd8-shk58 2/2 Running 0 4m\nNAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\ndefault service/kubernetes ClusterIP 10.55.240.1 <none> 443/TCP 8m\ndefault service/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.253.18 <none> 3260/TCP,9501/TCP 2m\ndefault service/wordpress LoadBalancer 10.55.253.170 104.154.224.12 80:31392/TCP 2m\nkube-system service/default-http-backend NodePort 10.55.243.156 <none> 80:30045/TCP 8m\nkube-system service/heapster ClusterIP 10.55.248.200 <none> 80/TCP 8m\nkube-system service/kube-dns ClusterIP 10.55.240.10 <none> 53/UDP,53/TCP 8m\nkube-system service/metrics-server ClusterIP 10.55.244.66 <none> 443/TCP 8m\nopenebs service/maya-apiserver-service ClusterIP 10.55.240.121 <none> 5656/TCP 4m\nNAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\ndefault persistentvolumeclaim/wp-pv-claim Bound pvc-7030ae5f-9d40-11e8-afcb-42010a800179 20Gi RWO openebs-standard 2m\n```\n\n## MySql deployment\n\nFollow the same procedure as done for WordPress deployment and execute a kubectl apply on it. The output of kubectl get pods,svc ,pvc — all-namespaces will look similar to this:\n\n```\n$ kubectl get pods,svc,pvc --all-namespaces\nNAMESPACE NAME READY STATUS RESTARTS AGE\ndefault pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-ctrl-b5c4f588f-lrl2l 2/2 Running 0 2m\ndefault pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-2jcgx 1/1 Running 0 2m\ndefault pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-j5tsk 1/1 Running 0 2m\ndefault pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-q9kww 1/1 Running 0 2m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-766678794-jtltg 2/2 Running 0 6m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-2pkt4 1/1 Running 0 6m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-htdxh 1/1 Running 0 6m\ndefault pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-rdtlk 1/1 Running 0 6m\ndefault pod/wordpress-7bdfd5557c-5b4nh 1/1 Running 4 6m\ndefault pod/wordpress-mysql-bcc89f687-zlt5q 1/1 Running 0 2m\nkube-system pod/event-exporter-v0.2.1-5f5b89fcc8-wprbm 2/2 Running 0 11m\nkube-system pod/fluentd-gcp-scaler-7c5db745fc-s9mp9 1/1 Running 0 11m\nkube-system pod/fluentd-gcp-v3.0.0-49vq6 2/2 Running 0 9m\nkube-system pod/fluentd-gcp-v3.0.0-kfjsx 2/2 Running 0 9m\nkube-system pod/fluentd-gcp-v3.0.0-tg5hh 2/2 Running 0 9m\nkube-system pod/heapster-v1.5.3-76f7f5f544-z7xk9 3/3 Running 0 10m\nkube-system pod/kube-dns-788979dc8f-2chf4 4/4 Running 0 11m\nkube-system pod/kube-dns-788979dc8f-ls4ln 4/4 Running 0 10m\nkube-system pod/kube-dns-autoscaler-79b4b844b9-8745z 1/1 Running 0 11m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8866 1/1 Running 0 11m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8fh5 1/1 Running 0 11m\nkube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-9jjf 1/1 Running 0 11m\nkube-system pod/l7-default-backend-5d5b9874d5-k9mn8 1/1 Running 0 11m\nkube-system pod/metrics-server-v0.2.1-7486f5bd67-wlnlg 2/2 Running 0 10m\nopenebs pod/maya-apiserver-68c98fdb76-5bt2z 1/1 Running 0 7m\nopenebs pod/openebs-provisioner-5569654c96-4n4hp 1/1 Running 0 7m\nopenebs pod/openebs-snapshot-operator-5f7c4d9bd8-shk58 2/2 Running 0 7m\nNAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\ndefault service/kubernetes ClusterIP 10.55.240.1 <none> 443/TCP 12m\ndefault service/pvc-082a54c8-9d41-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.251.84 <none> 3260/TCP,9501/TCP 2m\ndefault service/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.253.18 <none> 3260/TCP,9501/TCP 6m\ndefault service/wordpress LoadBalancer 10.55.253.170 104.154.224.12 80:31392/TCP 6m\ndefault service/wordpress-mysql ClusterIP None <none> 3306/TCP 2m\nkube-system service/default-http-backend NodePort 10.55.243.156 <none> 80:30045/TCP 11m\nkube-system service/heapster ClusterIP 10.55.248.200 <none> 80/TCP 11m\nkube-system service/kube-dns ClusterIP 10.55.240.10 <none> 53/UDP,53/TCP 11m\nkube-system service/metrics-server ClusterIP 10.55.244.66 <none> 443/TCP 11m\nopenebs service/maya-apiserver-service ClusterIP 10.55.240.121 <none> 5656/TCP 7m\nNAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\ndefault persistentvolumeclaim/mysql-pv-claim Bound pvc-082a54c8-9d41-11e8-afcb-42010a800179 20Gi RWO openebs-standard 2m\ndefault persistentvolumeclaim/wp-pv-claim Bound pvc-7030ae5f-9d40-11e8-afcb-42010a800179 20Gi RWO openebs-standard 6m\n```\n\nIf all of the pods are running, check the external IP of the WordPress load balancer. For example, in my case it is **104.154.224.12**. Open the your web browser IP if you are redirected to your WordPress setup page. Congratulations! Your WordPress is now ready for you to start your blog!\n\nHappy blogging!\n\n### Proof:\n\n![wordpress](/images/blog/wordpress.png)\n","slug":"setting-up-wordpress-and-sql-with-openebs"},{"id":18,"title":"ARMing Kubernetes with OpenEBS \\#1","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"02-08-2018","tags":["Arm64"," Kubernetes"," Lepotato"," Owncloud"," Solutions"],"excerpt":"Running stateful containers on Le Potato. Why not! It’s fun and extremely efficient! I know many people (including me) used to run ownCloud on their desktop computers.","content":"\n## Running stateful containers on Le Potato\n\nWhy not! It’s fun and extremely efficient! I know many people (including me) used to run ownCloud on their desktop computers. I have finally decided to retire my old desktop computer and was looking ways to keep my ownCloud instance alive and maybe even improve it a bit.\n\nFirst, I ran **ownCloud** on GKE Kubernetes cluster and came to a decison quickly that it’s not what I needed:\n\n- I am used to the speed of USB 3.0 for large uploads when needed. I wanted to keep the option of (50MB+/sec) using USB. Which means, if I choose a budget ARM SoC route, then the board should have **non-shared bandwidth** for LAN and USB.\n- 4 node GKE cluster using n1-standard-1 + 200GB storage costs ~$225/month, I would rather use Dropbox for $20/month = 240$/year (still doesn’t give me what I need).\n- **Low-power**, possibly solar-powered. I’ll share my power consumption findings in the series of blog articles.\n- Everything on **Kubernetes** is more fun, right?\n\nI was looking into [Raspberry Pi 3 Model B](http://amzn.to/2GMjYt4) option and after a quick trial realized that shared USB/Ethernet bandwidth and lack of MicroSD UHS support is not going to give me the performance I need and found the **AML-S905X-CC Le Potato** board.\n\nLibre Computer Board, code name Le Potato, is designed as a drop in hardware replacement for the Raspberry Pi 3 Model B (In fact it has the exact same form factor and port locations) and offers faster performance, more memory, lower power, higher IO throughput, 4K capabilities, open market components, improved media acceleration and removal of the vendor locked-in interfaces. This platform uses the latest technologies and is built upon proven long-term available chips. It is supported by upstream Linux and has a downstream development package based on Linux 4.9 LTS that offers ready-to-go 4K media decoding, 3D acceleration, and more.\n\nMost importantly, Le Potato has almost double the performance of RPi 3 with 2GB memory and 50% faster CPU and GPU. It also has non-shared bandwidth for LAN and USB and MicroSD UHS support. I was able to get over 70MB/s read&write performance vs ~15–20MB/s on RPi 3. I also noticed that even under heavy load Le Potato has lower power consumption compared to Rpi 3.\n\nIt sounds too good to be true, right? Since Le Potato is new, I’ve decided to run both side-to-side and publish my experience.\n\nIn this blog post, I will focus on setting up a Kubernetes on a Le Potato Clusters, install ownCloud on top, and compare it to Rpi 3.\n\n## Prerequisites\n\n### Hardware\n\n- 4 x [Libre Computer Board AML-S905X-CC (Le Potato) 64-bit (2GB)](http://amzn.to/2ptxGJS) $45\n- 4 x 32GB MicroSD Card ([Samsung 32GB 95MB/s MicroSD](http://amzn.to/2uayTe4) $9.99)\n- 4 x 128GB USB Drive ([Samsung 128GB USB 3.0 Flash Drive Fit (MUF-128BB/AM)](http://amzn.to/2psgFPC) $39)\n- 1 x Desktop Switch ([TP-link 5-Port Gigabit Desktop Switch](http://amzn.to/2u3TCQN) $29.99)\n- 1 x Active USB Hub ([Generic 7-Port USB Hub with ON/OFF Switch](http://amzn.to/2IBIZaO) $5.64)\n- 4 x short USB to Micro USB cable ([ZiBay Micro USB Short Sync Cable for Select Models/Device, 7-Inch — Pack of 5](http://amzn.to/2G8Doub) $6.99)\n- For comparison: 4 x [Raspberry Pi 3 Model B](http://amzn.to/2GMjYt4) $34.62\n\n### Optional:\n\n- Short cables make it look clean and nice:\n  6-inch CAT6 flat network cables ([5-PACK 6-inch CAT6 Network UTP Ethernet RJ45 Flat-Design](http://amzn.to/2GcT5AV) $12.48)\n- One touchscreen to access the cluster when nothing else available:\n  1x 3.5 inch TFT Touch Screen ([kuman 3.5 Inch 480×320 TFT Touch Screen Monitor for Raspberry Pi](http://amzn.to/2pwR9tt) $19.39)\n- I also build a mobile version to run in my car using this with a Tmobile line ([SIM800 Module GSM GPRS Expansion Board UART V2.0](http://amzn.to/2GLBeyE) $25.99)\n\n### Software components used\n\n- [Armbian 5.38 Ubuntu Xenial](https://dl.armbian.com/lepotato/) (for Le Potato)\n- [Raspbian Stretch Lite](https://www.raspberrypi.org/downloads/raspbian/) 2017–11–29 (for Rpi 3)\n- [Etcher](https://etcher.io/) v1.3.1\n- Kubernetes v1.9.2+\n- OpenEBS 0.5.3 arm64\n- ownCloud\n\nI will start with Le Potato and compare against Raspberry Pi 3 on my next blog.\n\n### Flash Le Potato Armbian image on SD Cards\n\n**Armbian** provides Debian and Ubuntu based builds for ARM development boards. Armbian Ubuntu is pretty much same as Ubuntu, except the desktop interface. Armbian uses the Xfce desktop environment, which is a lighter than Gnome or KDE. Its main advantage is its speed, and it’s ideal for systems with 256 MB to 512 MB of RAM. And, I plan to disable desktop anyways.\n\nDownload the [Armbian Ubuntu image](https://dl.armbian.com/lepotato/Ubuntu_xenial_next_desktop.7z) from the link [here](https://dl.armbian.com/lepotato/), extract and burn it to your SD cards using Etcher.\n\n![Etcher flashing](https://cdn-images-1.medium.com/max/800/0*XI8xSg4dCl_IWvbz.png)\n\nPlug the SD card into your Le Potato board and power on.\n\n![Terminal Window](https://cdn-images-1.medium.com/max/800/0*ojAbBScZY7giAV7b.jpg)\n\nLogin as `root` and use password `1234`. You will be prompted to change this password at first login. Next, you will be asked to create a normal user account that is sudo enabled.\n\n### Prepare Armbian host\n\nAfter reboot, you will auto login to your host with the new user you have created.\n\n![Armbian Le Potato](https://cdn-images-1.medium.com/max/800/0*UOLgX8I0Oz9hw7I8.jpg)\n\nChange the hostname and set static IP by using armbian-config utility:\n\n`sudo armbian-config`\n\n![armbian-config utility](https://cdn-images-1.medium.com/max/800/0*s8fjc1-L-9pkDzRE.png)\n\nDisable swap by running the following commands:\n\n```\nsudo systemctl disable zram-configsudo swapoff -a\n```\n\nAnd also comment out the reference to swap in /etc/fstab file:\n\n```\nsudo vi /etc/fstab\n```\n\nAfter reboot, confirm that swap space is disabled by running the following command. It should return empty.\n\n```\nsudo swapon — summary\n```\n\nInstall Golang 1.10:\n\n```\nwget https://dl.google.com/go/go1.10.linux-arm64.tar.gz\nsudo tar -C /usr/local -xzf go1.10.linux-arm64.tar.gz\nexport PATH=$PATH:/usr/local/go/bin\nmkdir go\nexport GOPATH=”$HOME/go”\ngo get github.com/kubernetes-incubator/cri-tools/cmd/crictl\n```\n\nRepeat all the steps above on all your nodes.\n\n#### Install Docker on Armbian Ubuntu (arm64)\n\nRun the following command to install Docker on all nodes. The second line is to use Docker as a non-root user, use your username instead of mine below (murat):\n\n```\ncurl -sL https://get.docker.com | sh\nsudo usermod murat -aG docker\n```\n\nSuccessful installation would look like below:\n\n```\nmurat@kubenode1:~$ curl -sL https://get.docker.com | sh\n # Executing docker install script, commit: 02d7c3c\n + sudo -E sh -c apt-get update -qq >/dev/null\n + sudo -E sh -c apt-get install -y -qq apt-transport-https ca-certificates curl >/dev/null\n + sudo -E sh -c curl -fsSL “https://download.docker.com/linux/ubuntu/gpg\" | apt-key add -qq →/dev/null\n + sudo -E sh -c echo “deb [arch=arm64] https://download.docker.com/linux/ubuntu xenial edge” > /etc/apt/sources.list.d/docker.list\n + [ ubuntu = debian ]\n + sudo -E sh -c apt-get update -qq >/dev/null\n + sudo -E sh -c apt-get install -y -qq — no-install-recommends docker-ce >/dev/null\n + sudo -E sh -c docker version\nClient:\n Version: 18.02.0-ce\n API version: 1.36\n Go version: go1.9.3\n Git commit: fc4de44\n Built: Wed Feb 7 21:11:48 2018\n OS/Arch: linux/arm64\n Experimental: false\n Orchestrator: swarm\nServer:\n Engine:\n Version: 18.02.0-ce\n API version: 1.36 (minimum version 1.12)\n Go version: go1.9.3\n Git commit: fc4de44\n Built: Wed Feb 7 21:09:57 2018\n OS/Arch: linux/arm64\n Experimental: false\nIf you would like to use Docker as a non-root user, you should now consider\nadding your user to the “docker” group with something like:\nsudo usermod -aG docker murat\nRemember that you will have to log out and back in for this to take effect!\nWARNING: Adding a user to the “docker” group will grant the ability to run\n containers which can be used to obtain root privileges on the\n docker host.\n Refer to https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\n for more information.\n```\n\nRepeat all the steps above on all your nodes.\n\n#### Install Kubernetes on Armbian for Le Potato\n\nRun the following command to install Kubeadm on all nodes:\n\n```\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add — && \\\n echo “deb http://apt.kubernetes.io/ kubernetes-xenial main” | sudo tee /etc/apt/sources.list.d/ kubernetes.list && \\\n sudo apt-get update -q && \\\n sudo apt-get install -qy kubeadm\n```\n\nRepeat all the steps above on all your nodes.\n\n#### Initialize Kubernetes master node\n\nInitialize your master K8s node:\n\n```\nsudo kubeadm init — pod-network-cidr=10.20.0.0/24 — apiserver-advertise-address=10.10.0.131\n```\n\nBy default, token expires in 24h. If you need it longer, then you can add `— token-ttl=0` to the end of the command above to generate token that does not expire.\n\nThis step may take around 10 minutes and after that, you will see a summary like below:\n\n```\n…\nYour Kubernetes master has initialized successfully!\nTo start using your cluster, you need to run the following as a regular user:\nmkdir -p $HOME/.kube\n sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n sudo chown $(id -u):$(id -g) $HOME/.kube/config\nYou should now deploy a pod network to the cluster.\n Run “kubectl apply -f [podnetwork].yaml” with one of the options listed at:\n https://kubernetes.io/docs/concepts/cluster-administration/addons/\nYou can now join any number of machines by running the following on each node\nas root:\nkubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n```\n\nRun the following:\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nDeploy a pod network to the cluster. I used flannel, you can see your other options [here](https://kubernetes.io/docs/concepts/cluster-administration/addons/).\n\n```\nsudo sysctl net.bridge.bridge-nf-call-iptables=1\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\nBy default, pods cannot be scheuled on the master node. If you want to be able to schedule pods on the master, e.g. for a single-machine Kubernetes cluster for development, run:\n\n```\nkubectl taint nodes — all node-role.kubernetes.io/master-\n```\n\nAs soon as the pod network has been installed, you can continue by joining your nodes.\n\nTo confirm that kube-dns pod is up run the command below and check the output:\n\n```\nmurat@kubenode1:~$ kubectl get pods — all-namespaces\n NAMESPACE NAME READY STATUS RESTARTS AGE\n kube-system etcd-kubenode1 1/1 Running 0 1m\n kube-system kube-apiserver-kubenode1 1/1 Running 0 1m\n kube-system kube-controller-manager-kubenode1 1/1 Running 0 1m\n kube-system kube-dns-6448b967fc-bc58z 3/3 Running 0 1m\n kube-system kube-proxy-h7p6s 1/1 Running 0 1m\n kube-system kube-scheduler-kubenode1 1/1 Running 0 1m\n [/cce_bash]\n```\n\nNote: If kube-dns is stuck in the Pending state. Follow the steps below to fix it and re init your master. This issue and the solution was mentioned [here](https://github.com/kubernetes/kubernetes/issues/43815).\n\n```\nkubeadm reset\nsudo nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n```\n\nRemove the `$KUBELET_NETWORK_ARGS` entry from the ExecStart, save the file, and reload systemd and kube services.\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n```\n\nInitialize your master K8s node again.\n\n## Join Kubernetes nodes to the cluster\n\nYou can now join any number of nodes by running the command with the token generated during the K8s master initialization:\n\n```\nmurat@kubenode2:~$ kubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n [preflight] Running pre-flight checks.\n [preflight] Some fatal errors occurred:\n [ERROR IsPrivilegedUser]: user is not running as root\n [preflight] If you know what you are doing, you can make a check non-fatal with ` — ignore-preflight-errors=…`\n murat@kubenode2:~$ sudo kubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n [preflight] Running pre-flight checks.\n [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.03.0-ce. Max validated version: 17.03\n [discovery] Trying to connect to API Server “10.10.0.131:6443”\n [discovery] Created cluster-info discovery client, requesting info from “https://10.10.0.131:6443\"\n [discovery] Requesting info from “https://10.10.0.131:6443\" again to validate TLS against the pinned public key\n [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server “10.10.0.131:6443”\n [discovery] Successfully established connection with API Server “10.10.0.131:6443”\nThis node has joined the cluster:\n * Certificate signing request was sent to master and a response\n was received.\n * The Kubelet was informed of the new secure connection details.\n```\n\nRun `kubectl get nodes` on the master to see this node join the cluster.\n\nIf you forgot the cluster token, you can generate a new one with the command:\n\n```\nkubeadm token generate\n```\n\nRepeat all the steps above on all your nodes.\n\n## Install OpenEBS on ARM (Le Potato)\n\nSimilar to most of the arm based hobby boards, Le Potato doesn’t provide any additional redundancy. Even using a RAID protected external USB device wouldn’t give me protection against node failure unless it’s some form of a shared network storage. They are both way over my affordability requirement. All I need is a replicated block device, so my container can survive a node or USB device failures.\n\nOpenEBS provides a great solution for modern x64 architecture but currently doesn’t have a build for [arm64](https://en.wikipedia.org/wiki/ARM_architecture#64/32-bit_architecture) (armv8) architecture. Therefore, I’ve opened an issue [here](https://github.com/openebs/openebs/issues/1295) and started working on it myself. I did successfully build OpenEBS images for arm64 architecture from the repo base on the 0.5.3 release and uploaded custom images to my personal docker registry [here](https://hub.docker.com/u/muratkarslioglu/). So, it is work in progress and please use it at your own risk, until it’s merged.\n\n```\nsudo apt-get install -y curl open-iscsi\nkubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/openebs-operator-arm64.yaml\nkubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/openebs-storageclasses.yaml\n```\n\nNow, get the list of storage classes using the below command:\n\n```\n$ kubectl get sc\n NAME PROVISIONER AGE\n openebs-cassandra openebs.io/provisioner-iscsi 1h\n openebs-es-data-sc openebs.io/provisioner-iscsi 1h\n openebs-jupyter openebs.io/provisioner-iscsi 1h\n openebs-kafka openebs.io/provisioner-iscsi 1h\n openebs-mongodb openebs.io/provisioner-iscsi 1h\n openebs-percona openebs.io/provisioner-iscsi 1h\n openebs-redis openebs.io/provisioner-iscsi 1h\n openebs-standalone openebs.io/provisioner-iscsi 1h\n openebs-standard openebs.io/provisioner-iscsi 4d\n openebs-zk openebs.io/provisioner-iscsi 1h\n```\n\n**Voila…!**\n\n`openebs-standard` storage class creates 3 replicas. That’s what I will use for my application.\n\nTo test the OpenEBS installation you can try my Jenkins example here:\n\n```\nkubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/demo/jenkins/jenkins-arm64.yaml\n```\n\n## Next — Installing containerized OwnCloud on OpenEBS\n\nFinding right container images to run on arm64 architecture is challenging. On the next article, I will build an OwnCloud container image running on Postgres database and both containers will store their data on OpenEBS persistent volumes.\n\nMy final goal is to build a mobile OwnCloud cluster installed in my family van, where storage is replicated to another cluster in my home lab.\n\nStay tuned!\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/arming-kubernetes-with-openebs-1/)_._\n","slug":"arming-kubernetes-with-openebs-1"},{"id":19,"title":"Recap of Google Next’18","author":"Murat Karslioglu","author_info":"No author information","date":"01-08-2018","tags":["Cloud Services Platform"," Knative"," Google Next18"," Istio"," Openebs"],"excerpt":"This year I have attended a number of tech events and in terms of size, organization, and especially the content — Next ’18 is so far my favorite.","content":"\n![You know that you are at the right event when you see a familiar face like Mr. Hightower :)](https://lh3.googleusercontent.com/iBQD9nOCN5cmrzn73zLeMoHDdhbTZWa3d4sSC1k1wkudXXL0L0912hrjUe2Bxr3MBTLOM_-LDC-ZrA-zNq8arcTJfD_V6e0pc_A9_oKcm6tAsBnIfqXdTfEbnmb8Qu_PoSyBZkVN)\n\nThis year I have attended a number of tech events and in terms of size, organization, and especially the content — Next ’18 is so far my favorite.\n\nNext ’18 was an excellent representation of Google as a company and their culture. Sessions were mostly in Moscone West, but the whole event was spread across Moscone West, the brand new South building, and six other buildings.\n\n![Next ’18 Event Map](https://lh4.googleusercontent.com/3ojmOPqqjEieE6GxfEjgFxRRv4sIzQpA_x21hFRpj3IRrmy6i7HL4k5FO2zztbwf9b5HJlrzO8BP3bWkOM34gZQdKS5lmLqR0FjmHJr96VIToFfc-SWdIKmlLcMJLz2y_tWPbERn)\n\nThe floor plan was fun and casual; catering was of “Google Quality” and the security was insane, with metal detectors, police, K9 search dogs, and cameras everywhere. And of course games, fun, and even “Chrome Enterprise Grab n Go” were there in case you needed a loaner laptop to work on — see some pictures at the end. :)\n\n### **What I learned at the Next ’18 conference**\n\nFirst of all, a big shout out to all involved in the [**Istio** project](https://istio.io/). It is not a surprise that we see great advocate marketing and support for the Istio 1.0 GA release on social media last week. Istio is a big part of the [**Google’s Cloud Services Platform**](https://cloud.google.com/solutions/cloud-services-platform/)(**CSP**) puzzle.\n\n![GCSP Dashboard — After deploying my first app in less than 30 seconds.](https://lh4.googleusercontent.com/taoSgNELqkMCnfsqUd84nPfbIATkjucboLYdbzMUWKct5ZFiXb_PZFjoU5KFBc5LZNBz6mhuwHXEpMs49tREabCzrMDCuNTrKniQ4UYuk_i1pNxR08pUHOEjtZ3nxfUOZswcA_xe)\n\nLater this year, Google is targeting to make all components of their CSP available (in some form). CSP will combine **Kubernetes**, **GKE**, **GKE On-Prem**and **Istio **with Google’s infrastructure, security, and operations to increase velocity, reliability and manage governance at scale.\n\nCloud Services Platform will be extensible through an open ecosystem. **Stackdriver Monitoring** and **Marketplace** are the extensions to platform services. [Marketplace](https://console.cloud.google.com/marketplace/browse?filter=solution-type:k8s) already has 27 Kubernetes apps including commonly used components of many environments such as Elasticsearch and Cassandra.\n\n![CSP Marketplace](https://lh3.googleusercontent.com/esTW1l0iBV-Wvleoosxha1W5KqmA5BQLZ-4jyfb3e0W2j_S5rzqtncJCFA8t6brQc_ZJdF2eVqaXAdhHASBlTq9izYO85SLSZRyE8mbwoB1EiFHTmQdwDHsnTdFm2EDb0i4yefVA)\n\nUsers will be able to deploy a unified architecture, that spans from their private cloud, using Google CSP to Google’s public cloud. Again, the two most important pieces to this puzzle are managed versions of the open source projects Kubernetes and Istio. To me, the rest of it still feels mostly to be DIY-like quality.\n\nKnative, Cloud Build, and CD are other significant solutions announced at Next’18.\n\n### **A new cloud availability zone, this time in your datacenter — which might be in your garage**\n\nAt first,** GKE on-prem** got me interested. But, after talking to a few Google Cloud Experts again, I felt it’s very early to be seriously considered. You can read others’ thoughts here on [Hacker News](https://news.ycombinator.com/item?id=17602555).\n\n![Discussions on GKE on-prem](https://lh5.googleusercontent.com/q_0yHazRpRZ9bLptYCw1_GQsmdM8TpbM7xXmZ8nL8nejR3uhVg79bvJokA_BrQ91VfzYYl8OLtQ1Evl5VNJqDwJM3EKwqKFsn_jr99N91hCEa1lkazjMZE3aphRbr21LEc0atqTr)\n\nGKE on-prem alpha will support **_vSphere 6.5_** only, no bare-metal for now!\n\nFailover from on-prem -> GKE is something Google team is working on. This means GKE on-prem instance will look like another availability zone (AZ) on a Google Cloud dashboard.\n\nOther than vSphere dependency, the idea of being able to have an availability zone, local in your data center is really compelling. It is also a very common use-case for [**OpenEBS**](https://openebs.io/) since there is no cloud vendor provided, a cloud-native way of spreading your cloud volumes, EBS, etc. across AZs — we see many community users running web services today using OpenEBS to enable that.\n\n### **Github and Google Partnership to provide a CI/CD platform**\n\n**Cloud Build** is Google’s fully managed CI/CD platform that lets you build and test applications in the cloud. Cloud Build is fully integrated with GitHub workflow, simplifies CI processes on top of your GitHub repositories.\n\n![Me deploying myself on Serverless Cloud Maker :)](https://lh3.googleusercontent.com/Vid2Mpm0eaSATtriAt3eLoDdBvvRcv7WCJeNBKxe_VOhVcbdrmh_nJIn5aiQlnMfEOpywRMhHF7Gnv58Nyu_5MQHoWWfxMCmPYdfDlYlKkiQPldJvHxEk9Qa5BOQBuDQNW-YZ0dc)\n\nCloud Build features;\n\n**Multiple environment support** lets developers build, test, and deploy across multiple environments such as VMs, serverless, Kubernetes, or Firebase.\n\n**Native Docker support** means that deployment to Kubernetes or GKE can be automated by just importing your Docker files.\n\n**Generous free tier**— 20 free build-minutes per day and up to 10 concurrent builds may be good enough for many small projects.\n\n**Vulnerability identification** performs built-in package vulnerability scanning for Ubuntu, Debian, and Alpine container images.\n\n**Build locally or in the cloud** enables more edge usage or GKE on-prem.\n\n### Serverless — here we are again\n\n**Knative** is a new open-source project started by engineers from Google, Pivotal, IBM, and a few others. It’s a K8s-based platform to build, deploy, and manage serverless workloads.\n\n_“The biggest concern on Knative is the dependency on Istio.”_\n\nTraffic management is critical for serverless workloads. Knative is tied to Istio and can’t take advantage of the broad ecosystem. This means existing external DNS services and cert-managers cannot be used. I believe, Knative still needs some work and not ready for prime-time. If you don’t believe me, read the installation YAML file — I mean the 17K lines “human readable” configuration file ([release.yaml](https://github.com/knative/serving/releases/download/v0.1.0/release.yaml)).\n\n![](https://lh6.googleusercontent.com/0qn1GCe8B-15DIr5G7eqqbg3FfnOcm58iQ08ZUobrKJ82xIArtNjnSuFS2KOkkEhyGfyTH8pz5_NXZOk87EllIjN4rSVYlyxxmN6iDemZ0AgM_Yd-FMZzMR-nQdCHpFPTIL84hwS)\n\n### **My take on all of the above — Clash of the Cloud Vendors**\n\nIf you have been in IT long enough, you could easily see the pattern and predict why some technologies will become more important and why will the others be replaced.\n\n_“What is happening today in the industry is the battle to become the “Top-level API” vendor.”_\n\n20–25 years ago hardware was still the king of IT. Brand-name server, network, and storage appliance vendors were ruling in the datacenters. Being able to manage network routers or configure proprietary storage appliances were the most wanted skills. We were talking to hardware…\n\n20 years ago (in 1998), VMware was founded. VMware slowly but successfully commercialized hypervisors and virtualized the IT. They became the new API to talk to, everything else under that layer became a commodity. We were suddenly writing virtualized drivers, talking software-defined storage and networking — the term “software-defined” was born. Traditional hardware vendors lost the market and momentum!\n\n12 years ago, the AWS platform was launched. Cloud vendors became the new API that developers wanted to talk to, hypervisors became a commodity. CIO and enterprises that are sucked into the cloud started worrying about the cloud lock-in. Just like the vendor lock-in or hypervisor lock-in, we have experienced before. Technology might be new, but concerns were almost the same.\n\n4 years ago, Kubernetes was announced and v1.0 released in mid-2015. Finally, an open-source project that threatens all previous, proprietary, vendor managed “Top-level API” that we were using became a majorly adopted container orchestration technology. Although it came from Google, it took off after it got open-sourced and probably would be right to say that so far financially, Red Hat profited most from Kubernetes with their Red Hat OpenShift platform. And now we see somewhat of a battle over APIs to be used in operating applications on Kubernetes, with the RedHat / CoreOS operator framework and other projects including one supported by Google and others such as Rook.io emerging to challenge or extend the framework.\n\nGoogle Container Engine (**GKE**), Microsoft Azure Container Service (AKS**)**, Amazon Elastic Container Service (**EKS**), IBM Cloud Container Service (**CCS**), and Rackspace Kubernetes-as-a-Service (**KaaS**) are all competing in the hosted Kubernetes space (new vendors expected here).\n\nThere is enough space to grow in the self-hosted Kubernetes space. GKE on-prem is the validation from Google.\n\n**Hardware>Virtualization>Cloud>Containers>Serverless???**\n\nMany of us see **Serverless** as the next step, but it might be too granular to support larger adoption and current limitations validate the claims. It doesn’t scale well for intense workloads.\n\nOne size doesn’t fit all, there are still traditional use cases that even run on bare-metal and VMs. Same might be true for Serverless. It is not for every workload. Modernizing existing workloads will take time, and we will see who will become the leader of the next “Top-level API”.\n\nWhat do you think? Who is going to win the clash of the titans? What did you think about Next’18 and Google’s strategy?\n\nThanks for reading and for any feedback.\n\n### **Some Next’18 moments from my camera**\n\n![](https://lh4.googleusercontent.com/ARfwggxkEIm1I-QXUGinQGV0zVQLzaTaQ9WxUEC4nN-xuTUsK0I-Bi4JO9kwyIi6MQYxnu0hBQDxdbkVy5nsTd5oQMEl-JCXRvdWWVhcrbCK3EfM8EegXImT2_Kn0kXeZoHbfLmK)\n\n![](https://lh5.googleusercontent.com/bUCoD0IKci0QEETmHlcrUN-wOSLFSYsIuR4aG96D3QtZo23_gm10SfBqMzUtHVduFt-XzA4m9mI-sae4ktxJRIG9m9aBUt9VUtG0ytYyjFoh-Q2GbFNlQC7Ry0iBiTiaKUNuKsFd)\n\n![](https://lh3.googleusercontent.com/Vdr19dKixjLs64xGxB_thJ3D8_-cnMihbC-gH50S5FuFJ13y2UMb42zSQy9Rp2LT9olLP5TPSRb4WPoW71l71NMJoBeK70SiFtYgsDs1l2k2tmLTiqJTlo9ajj0F0xTp4JlkQuF2)\n\n![](https://lh4.googleusercontent.com/GGkcm_nFqb_gDKJuBJISMI3mueZx6xiBE6R8diM84xEOnYmcSDQVNPaRTbIFgBf-fh1Y_8JcioxxP8g8RzrxYEUJ4Xhw51RMRdXw3aS3fVpbH_mjc_kPUC0pXL3WxXZNlgR3baCb)\n\n![](https://lh4.googleusercontent.com/seBUEu7ltrIHW3VxY_V5rqekHkLXfLYhR0dZZbsyr8MC-vww-_rGvQA3rPz0kfbqudV-LNAi292BTwNrGIe_KG56Vqr-sHSv-mPlIy8nhnJDQPQKnUj7ohg3uql67RVvqTf-earr)\n\n![](https://lh6.googleusercontent.com/2BPdWJYXZizBdmFra0GYqedeArDGynas8VsxPkC0FWhyCjUm8A7TYLpPN06hPMmQ1UQ_yPoG8mH91eRjAyQE6sbw4Jo2wjPlsqDVTLEohowMOtSQaEuSWZO0lIntDOeMip75K20P)\n\n![](https://lh3.googleusercontent.com/esI-PdVDc9sEqPoOkwG4nQhcD_FYSxs8Z1eBiHW9UTBDNO9bbd145X9vwnQgijXHTiz6DUD_bgkz9ViC1C2ukDYtjLaHVAIFlEMPcHmQEWjpKeq3pvEy4HyWXeK65oe61LUMTZ1-)\n\n![](https://lh5.googleusercontent.com/KtS0m1tRBvjWehJSCSFItgtvDK5IiAEU20aa3GfSK6TmlyPVWjQpjnq_z5OAxsa1-L7PQuNRuiK2ZRX1It-1CrDlqzv1ubwrYaZA_gQQGxsb2rXJCAiQPjZ9GLiqXHZsCess6dYz)\n\n![](https://lh6.googleusercontent.com/Uee-fb3QJewe05s4AWM2bF6b7MuRI8XgU9r3KfX72RNwVYYecjt5UX15vw1jhk0LoqvgL1MN5yKT5t9Mei6QzI7bohUAKtoQthG02YCr1VXiM4HFB-RRmQB29uuANQNDiq1sGKGe)\n\n![](https://lh6.googleusercontent.com/OXx7ZGSWDI5z2UnqunkcWtB1MWY5ZtXs3EmruVAqfZo4JiLzhd00hmRkKZi_y2Icv6FV4CJRJW68HK1laKNXCKnGI5A9Z1l53R1BtOiM6dLzjDvecuWLgzPIgir3Q89qxkHt50yo)\n\n![](https://lh4.googleusercontent.com/LUlB3APRP1t0gEEzaXmPbUxZFKGD1nVHRtdNMoKp7iSTLAZAHXOF3W_VPaZs9-XsLdw54GC2TnjnxGyR_spqek8X5ZLFkWICZpP4oXEzATj4n_vfvLQtr0FNceiT3lKzGKg7oh1f)\n\n![](https://lh4.googleusercontent.com/AZP7UsS_i0gXvSBRuoDas6D48cBdU9JD3N39C53YEIdJwXARCyEg2sXRSuvOGUSa07o0xZ2UzQc8mLgZxj6EQm8uRLZ3JXVDzEwx6kTT3Vq-eia5OV865zc0q3bq3htEDZxUiIX1)\n\n![](https://lh4.googleusercontent.com/GkXUs0HYRwS66hSMex7NDDT6Ck0NaxO4VrIHW23GzjrQbRMWDDA4EGwIOwSsg3O8tL_iNuISRywMDuF1u61rZm4fzaBisfUkyo-aPIcCcTk3KwUPunnPwgrV6-oRca0td-eYHxss)\n\n![](https://lh3.googleusercontent.com/EPOoqoV_b11WJCV9cNJFgAtGfuRyqF3xZpKKoJ46J54wNsrE0kFFp82WFZn_gRoRTSLYPAkFHdFcizdOOBYwk_pL6pUZiy9ld24o-xBHIJZWcLmz_tMSFav77_9fbc2pPbwgnObR)\n\n![](https://lh5.googleusercontent.com/cbuvmjdXzUEgiSf6BL6jC3-TKAbwf1WASiNfypDXQcmeXLrr6OPhITsEjeEUo1dXtg3OW3YTPNez3XxjaRxeAV_Ox6dTq9XpbwNDqh2-iWiXqWhrgn2o1VIe45xKPGYsxxPluLkw)\n\n![](https://lh5.googleusercontent.com/wskI0Jy2g9icXoitcNDIp9VChhWlxu9fIDwepnqd0ds_Oq1m8Yt7ZHY8GZ_DvfS8IQcNfsJyBanCPIpp_GUznnzK3b3YBP7F2oV9gsi9k9WyKfwmWGCI4um2SKeNveXy2uaeD-sd)\n\n![](https://lh5.googleusercontent.com/zeDLw8eZvkjgSfWnUwOkIG_Ze3GmKAwrTH59o37K8XEMXDMcAOtUsOSzfEwP8qF7qgVHEbgCs6YbXyE9loDTZOX4q5JeRe2J4JMMufrD0H6wr-ADk9sMBzRRwgi3iRVjhTCLh0Uy)\n\n### **Check-out the popular hashtags :**\n\n[#next18](https://twitter.com/search?q=next18)[#googlenext18](https://twitter.com/search?q=googlenext18)[#knative](https://twitter.com/search?q=knative)[#kubernetes](https://twitter.com/search?q=kubernetes)[#istiomesh](https://twitter.com/search?q=istiomesh)\n\nAlso check out the keynotes:Keynotes from last week’s[ #GoogleNext18](https://twitter.com/hashtag/GoogleNext18?src=hash) here →[ http://g.co/nextonair](https://t.co/mVuwk0hw4i)\n","slug":"recap-of-google-next18"},{"id":20,"title":"Designating OpenEBS pods to run on specific K8S Nodes","author":"Ajesh Baby","author_info":"Product Manager at MayaData","date":"30-07-2018","tags":["Openebs"," Kubernetes"," Solutions"," Scheduler"," Scheduling"],"excerpt":"OpenEBS does not have a separate scheduler used to manage scheduling pods. Instead, it uses the Kubernetes scheduler for managing the scheduling needs of an administrator.","content":"\nOpenEBS does not have a separate scheduler used to manage scheduling pods. Instead, it uses the Kubernetes scheduler for managing the scheduling needs of an administrator. Kubernetes provides the following methods for controlling the scheduling pods on cluster nodes:\n\n- [nodeSelector](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector)\n- [Taints and Tolerations](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)\n\nFor more details and information about these features, you can refer to the Kubernetes documentation.\n\nIn this post, I would like to cover the different aspects of how to restrict/control the OpenEBS pods scheduling to a set of specific nodes in the Kubernetes cluster.\n\nOpenEBS deals with many types of Kubernetes pods throughout its life cycle. These can be broadly categorized into two types, control plane pods and data plane pods. Control plane pods are installed as part of installation of the following OpenEBS components:\n\n- OpeEBS API Server\n- OpenEBS Provisioner\n- OpenEBS Snapshot Controller\n\nData plane pods are installed as part of volume provisioning:\n\n- Target Pod\n- Replica Pods\n\nFor details on the exact steps of scheduling, see the configuration section [here](https://docs.openebs.io/docs/next/scheduler.html?__hstc=216392137.e7b2938c542eaf0f98426e5d8be4aa84.1579859056424.1579859056424.1579859056424.1&__hssc=216392137.1.1579859056424&__hsfp=3765904294).\n\nUse case: Let’s consider a scenario in which you have 20 nodes named Node1, Node2 ... Node20. You may want to designate Node1, Node2, Node3 as storage nodes so that all storage pods are scheduled only on these nodes.\n\nSolution: You can use Kubernetes scheduling methods to achieve this. Below are some of the possible options and their effect on scheduling pods to respective nodes.\n\n![Storage Pods](/images/blog/storage-pods.png)\n\nYou may select and use any of the above options based on your unique requirements.\n\nOption 2 does not necessarily guarantee storage pod scheduling on Node1, Node2 and Node3.\n\nOption 1, Option 3, and Option 4 will limit the scheduled OpenEBS pods to Node1, Node2 and Node3. Option 3 is my preferred choice, for the following reasons:\n\n- Other application pods will not be scheduled on my storage nodes, whereas Option 1 does present the possibility of other application pods being scheduled on Node1, Node2, and Node3.\n- While scaling the cluster for application deployments, I do not have to worry about changing the policy for storage. If I use option4, I must taint the new nodes with respective applications.\n- In this scenario, I am worried only about storage nodes, as these have local disks attached to them. I am not restricted to schedule an application pod deployment on any nodes other than storage nodes.\n","slug":"designating-openebs-pods-to-run-on-specific-k8s-nodes"},{"id":21,"title":"OpenEBS 0.6 serves IOs amidst Chaos and much more","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"20-07-2018","tags":["DevOps"," Kubernetes"," Openebs"," Statefulcontainers"," Storage"],"excerpt":"We are very excited to announce the availability of OpenEBS version 0.6. I would like to take a few minutes to talk about what has been keeping us busy in making it GA.","content":"\nWe are very excited to announce the availability of OpenEBS version 0.6. I would like to take a few minutes to talk about what has been keeping us busy in making it GA. We have been making a number of additions to both the design and code in the last few months. In this blog I’ll talk about:\n\n- Quality leveraging Chaos Engineering\n- Framework (CAS Templates) for supporting multiple storage engines\n\nI won’t talk about our new Storage Engine (cStor) — written in C — which is _almost_ ready. I’ll save that for a later blog.\n\nBefore going into specifics, I would like to express my sincerest gratitude to the OpenEBS community users and developers who are helping to make OpenEBS the most simple and easy to setup containerized attached storage (CAS) solution available for Kubernetes today — and the most popular open source one as well.\n\nSince the OpenEBS 0.5 release we have seen so many ways users have deployed OpenEBS many of which we had not envisioned when we started OpenEBS back in 2016. We are working hard to listen to the growing user community — and of course MayaOnline is helping us a bit as well as we learn something from MayaOnline users who are using this free SaaS monitoring and ChatOps integration of their stateful workloads. Along these lines, we have a survey that is running through the end of July that takes 2–3 minutes that has proven helpful; please do fill it out if you have not already and we will even send you some swag: [https://www.surveymonkey.com/r/BRDCCWY](https://www.surveymonkey.com/r/BRDCCWY)\n\nThe timing of OpenEBS 0.5 was perfect in that it coincided with a take-off in interest in stateful workloads on Kubernetes. Some deployment patterns I’ve encountered just in the last few weeks include:\n\n- GitLab for internal IT teams\n- Kube weekly just featured a step by step blog on this subject: [https://blog.openebs.io/git-freedom-on-kubernetes-3a491dd37cdf](https://blog.openebs.io/git-freedom-on-kubernetes-3a491dd37cdf)\n- Data Science training sessions\n- Here we are seeing hundreds of pods with stateful workloads spun up and destroyed repeatedly — really a great use case for container attached storage\n- Running Minio on OpenEBS which some users have called a happy marriage between OpenEBS block and Minio S3\n- We remain huge fans of Minio and are looking forward to more community led collaboration with our almost neighbors\n- OpenEBS being deployed as a basic part of DBs on kubernetes; in particular we are seeing a good amount of NuoDB on OpenShift for example\n- The elastic SQL technology of NuoDB seems to resonate with lots and lots of users; we’re pretty proud that using OpenEBS underneath is becoming a common pattern\n- And of course many Containers as a Service offerings now include OpenEBS as a default option with more to be announced shortly\n\nAnd all this adoption means heterogeneity and dynamism.\n\n## Challenge 1: Kubernetes is resilient amidst Chaos and so must be storage\n\nBecause OpenEBS is deployed on so many varieties of Kubernetes and our fundamental job is to keep the data safe no matter what — we have been investing heavily in our ability to create these varied environments and their behaviors and to then measure and validate the resilience of OpenEBS as these environments respond to outages and increased load and so forth. We are seeing OpenEBS deployed across lots of varieties including:\n\n- Native Kubernetes or using Rancher, OpenShift, IBM Cloud Private, GKE, Tectonic, StackPoint Cloud, and others\n- Operating Systems -Ubuntu, CentOS, CoreOS and others\n- Pod Networking of all types, with Flannel being a favorite\n- Various cloud services — AWS EC2 remains the preferred option, with GCE growing in adoption amongst OpenEBS users\n\nEach combination comes with nuances that are unique and sometimes annoying as well. For example, recently a user on a Cloud Provider saw their nodes shut down frequently and occasional high network latency or packet drops in inter pod networking. Anyone with experience working with Storage Systems knows how detrimental these situations can be for latency-sensitive Stateful Applications.\n\nWe consciously chose the well-understood and widely used iSCSI protocol as the underlying storage connectivity used by Applications to connect to OpenEBS Volumes. There are many benefits to this architecture, but I will not address those here.\n\nThere are some annoying pieces when running iSCSI at scale as well. For example, depending on the response from the iSCSI targets and your operating system, there are some quirky things that can happen with iSCSI. The most notorious of these happens when iSCSI backed volumes move into read-only if you are using ext4 under certain conditions. You must then go through the steps for manually recovering the volumes. To address this, we have put together a troubleshooting guide that you can access [here](https://docs.openebs.io/docs/next/readonlyvolumes.html?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294).\n\nHowever, we wanted to solve as many of these issues as possible with the right approach. We stepped up our use of chaos engineering in our OpenEBS development process. We also extended and open sourced our in-house tooling, and we are starting to see it used more and more by engineers deploying stateful workloads on Kubernetes — whether or not OpenEBS is the underlying storage.\n\n## Solution : Chaos Engineered OpenEBS, the birth of Litmus.\n\nIf you would like an introduction to the Litmus project, which we open sourced at KubeCon in Denmark, visit the following link: [https://openebs.io/litmus](https://openebs.io/litmus?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294) or [https://github.com/openebs/litmus](https://github.com/openebs/litmus)\n\nWe are also working on operators to add additional autonomic function into OpenEBS, leveraging improved metrics and advancements in CSI around node daemonsets and the mount-propagation feature. In the meantime, we use Litmus to increase automated real-world scenario testing to ensure improvements in every release. In this regard, a lot of effort has gone towards beefing up the tests that can simulate Chaos at Node, Network, Storage, RAM, and CPU. These typically contribute to Volume Pods switching nodes and, if not careful, interrupted IOs.\n\nOf course, this Chaos for Storage Application is something we believe should be applied to stateful workloads and underlying storage both during testing and as a part of a healthy chaos engineering practice. This is what led us to Open Source Litmus.\n\nOne outcome of our improved chaos engineering and testing is improvements to the resiliency of intra OpenEBS deployment communication. Specifically, we added enhancements to the responses sent by the iSCSI Target to the initiator; overall, this makes OpenEBS more resilient even when Pods are rescheduled unexpectedly and when the environment otherwise changes. You can learn more about these issues in the [release notes](https://github.com/openebs/openebs/releases/tag/v0.6).\n\nWe expect that the incidence of read-only issues will decrease greatly for the tested scenarios. We are constantly adding more scenarios, workloads and other tooling into Litmus to bolster the Jiva storage engine and other engines to come. Contributions to Jiva are of course always welcome!\n\n## Challenge 2: The evolving state of the State in Kubernetes!\n\nIf you regularly monitor storage developments, you will notice that Kubernetes is moving towards CSI and Snapshots are beginning to become a standard. There are enhancements to support Block Volumes and Topology aware Scheduling for Stateful Applications powered by Local PVs, which also benefits other PV types like OpenEBS.\n\nTo give an example, OpenEBS strongly prefers the case when the OpenEBS Controller Pod (and the application Pod) schedule on nodes where the OpenEBS Replica Pod resides. Currently, we achieve this via Pod/Node Affinity parameters. However, with Topology Aware scheduling, the constructs of pinning are efficiently done via the PV topology parameters.\n\nThat is just one example of new capabilities that we must now embrace. Features in Kubernetes now transition “quickly” from alpha to beta and the new paradigms/patterns that enter into Kubernetes must be adopted, or you will soon become outdated like the Third Party Resources (TPRs). However, we are not complaining about the pace of progress and continually contribute upstream to Kubernetes itself. We always seek to lend a hand to make Kubernetes an even better platform for storage and stateful workloads.\n\nNonetheless, the challenge remains. After all, the core of the Orchestration layer in OpenEBS is to deploy and operate the Container Attached Storage solution using Kubernetes native constructs. And the constructs just keep changing!\n\nLooking at the situation, we decided to step back and think about an architecture that would allow us to minimize the need to make code changes every time Kubernetes changes. For example, some users want to deploy their OpenEBS by specifying Pod Disruption Budges (PDBs) or setting specific Resource Limits for PVs in certain namespaces/users etc. We wondered: how can we embrace these new knobs, settings, and advances without endless code churn? This type of work — effectively upgrading the transmission of the underlying orchestration of OpenEBS — is not easy to do unless you really understand the architecture of OpenEBS. That’s not good — what’s the point of being open source if the code itself is too hard to work with and adjust? Fortunately, Kubernetes has CRDs, which provides a way forward.\n\n## Solution : Provide templates to Cluster Owners to define and manage the storage infrastructure.\n\nIn the OpenEBS 0.6 release, we have utilized the power of Kubernetes CRDs to provide a workable solution to introduce pluggable storage engines. OpenEBS now provides a complete workflow for developers and cluster administrators to choose the right storage software and hardware for their unique requirements. The control of the storage infrastructure stays with the cluster owner, and the ability to address a given need in storage lies with the developer. OpenEBS 0.6 brings the initial version of CAS Templates, which are YAMLs that can be scripted by cluster owners, fit into your GitOps, and are associated with Storage Classes.\n\nWe like the way OpenEBS CAS Templates are shaping up, and we can see many of the cluster owners’ needs being met over time, including enforcing of policies using tools like OPA. I will share more on this in upcoming blogs, but you can glance at them by reading this introductory documentation [here](https://docs.openebs.io/docs/next/storageengine.html?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294). We intend to build upon this improved architectural pattern to do even more than the pluggability of storage engines. As always, we would especially welcome your feedback and use cases.\n\n### And there is more…\n\nYou will notice when you look at the release notes or try OpenEBS 0.6 that there are many other enhancements, including:\n\n- Configuring of OpenEBS for running stateful workloads that span across Availability Zones\n- Enabling the management of Snapshots and Clone from kubectl\n- Enhancement to mayactl to display volume status\n- Improved Integration and Unit Testing coverage\n- Enhanced Contributor Guides\n\nAnd, most importantly, product documentation has been overhauled to provide accessible insights about OpenEBS as well as a process to provide feedback.\n\nAs mentioned above, our next release also enables users to try out _cStor — a storage engine_ that is more efficient in terms of performance and capacity management. It also reduces the number of containers required to run OpenEBS. If you are interested in taking a look, please get in touch as we have some alpha users of cStor now.\n\nWith its strong community of users, developers, and partners building us into their solutions, it feels like OpenEBS is nearly unstoppable. As always, we look forward to your feedback and suggestions on this release and the direction that you want to see OpenEBS move going foward. Please reach out to us on Slack or add comments below. [https://slack.openebs.io](https://slack.openebs.io/?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294)/\n\nFinally, if you have not done so yet, claim your free access to [MayaOnline](https://mayaonline.io/). You will be surprised by how easy it can be to visualize and manage your storage needs.\n\n[Public domain](https://creativecommons.org/publicdomain/mark/1.0/).\n","slug":"openebs-06-serves-ios-amidst-chaos-and-much-more"},{"id":22,"title":"How do I run a litmus test to compare storage performance on Kubernetes","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"16-07-2018","tags":["Benchmarking"," Kubernetes"," Litmus"," Openebs"," Solutions"," Chaos Engineering"],"excerpt":"Ever so often, developers and devops engineers building or managing stateful applications on Kubernetes are on the lookout for for suitable storage options which serves their application’s specific needs.","content":"\nThis article belongs to a #HowDoI series on Kubernetes and Litmus\n\nEver so often, developers and devops engineers building or managing stateful applications on Kubernetes are on the lookout for for suitable storage options which serves their application’s specific needs. The emphasis could be on high-availability, provisioning ease, performance etc.., **Litmus **(as detailed in this [article](https://blog.openebs.io/litmus-release-a-chaos-monkey-on-your-kubernetes-stateful-workloads-6345e01b637d)), is an attempt to arm them with the necessary info to make the right choice. One of the important storage tests is to simulate application workloads or multiply its effect using synthetic workload generators like fio. In this article, we list the steps to run a fio-based benchmark test using litmus\n\n![Evaluating storage performance w/ Litmus](https://cdn-images-1.medium.com/max/800/1*zRIZ9WjL7S0wq6Sp_IbzCw.png)\n\n## PRE-REQUISITES\n\n- At least a single-node Kubernetes cluster with the necessary disk resources, mounted on the node. (**_Note_**: _Certain storage solutions need minimum Kubernetes versions from which they are supported. For ex: Local PVs are beta from 1.10, OpenEBS needs 1.7.5+_)\n- Storage operator installed (typically, this includes control-plane elements like the static/dynamic provisioners, storage classes and other elements) with appropriate references to the node & disk resources (**_For example_**: _This may involve storage pool creation OR updating disk and node details in the static provisioners etc.,_)\n\n## STEP-1: Setup Litmus essentials on the Kubernetes cluster\n\n- Obtain the Litmus Git repository via a Git Clone operation on the Kubernetes master/Control machine used to manage cluster & set up the Litmus namespace, service account & clusterrolebinding by applying _rbac.yaml_\n\n```\nkarthik_s@cloudshell:~ (strong-eon-153112)$ git clone https://github.com/openebs/litmus.git\n\nCloning into 'litmus'...\n\nremote: Counting objects: 2627, done.\n\nremote: Compressing objects: 100% (16/16), done.\n\nremote: Total 2627 (delta 2), reused 9 (delta 2), pack-reused 2609\n\nReceiving objects: 100% (2627/2627), 10.50 MiB | 4.23 MiB/s, done.\n\nResolving deltas: 100% (740/740), done.\n\nkarthik_s@cloudshell:~ (strong-eon-153112)$ cd litmus/\n\nkarthik_s@cloudshell:~/litmus (strong-eon-153112)$ kubectl apply -f hack/rbac.yaml\n\nnamespace \"litmus\" created\n\nserviceaccount \"litmus\" created\n\nclusterrole \"litmus\" created\n\nclusterrolebinding \"litmus\" created\n```\n\n- Create a configmap resource out of the cluster’s config file, typically at _~/.kube/config_, _/etc/kubernetes/admin.conf_ or elsewhere depending on the type of cluster or setup method\n\n(**Note**: _Copy the config file to admin.conf before creating the configmap out of it, as the litmus job expects this path_)\n\n```\nkarthik_s@cloudshell:~ (strong-eon-153112)$ kubectl create configmap kubeconfig --from-file=admin.conf -n litmus\n\nconfigmap \"kubeconfig\" created\n```\n\n## STEP-2: Update the Litmus test job as per need\n\nThe litmus fio test job allows the developer to specify certain test parameters via ENV variables, such as the following:\n\n- The litmus fio test job allows the developer to specify the storage provider (PROVIDER_STORAGE_CLASS) and the node on which to schedule the application. (APP_NODE_SELECTOR)\n- The desired fio profile can also be specified. Currently, litmus supports simple [test-templates](https://github.com/ksatchit/litmus/tree/fio_test/tools/fio/templates), and is expected to grow to include multiple standard profiles. (FIO_TEST_PROFILE)\n- Certain simple test parameters such as the size of the test file (FIO_SAMPLE_SIZE) and duration of I/O (FIO_TESTRUN_PERIOD) can be specified as well, while the core I/O params continue to be housed in the templates.\n- The developer can choose to specify a comma-separated list of pods whose logs need to be collected for analysis of results, as well as the logs’ location on the host in the spec for the logger.\n\n```\nkarthik_s@cloudshell:~ (strong-eon-153112)$ cd litmus/tests/fio/\n\nkarthik_s@cloudshell:~/litmus/tests/fio (strong-eon-153112)$ cat run_litmus_test.yaml\n\n***\n\napiVersion: batch/v1\n\nkind: Job\n\nmetadata:\n\nname: litmus\n\nnamespace: litmus\n\nspec:\n\ntemplate:\n\n      metadata:\n\n        name: litmus\n\n      spec:\n\n        serviceAccountName: litmus\n\n        restartPolicy: Never\n\n        containers:\n\n        - name: ansibletest\n\n          image: openebs/ansible-runner\n\n          env:\n\n            - name: ANSIBLE_STDOUT_CALLBACK\n\n              value: log_plays\n\n\n            - name: PROVIDER_STORAGE_CLASS\n\n              value: openebs-standard\n\n\n\n            - name: APP_NODE_SELECTOR\n\n              value: kubeminion-01\n\n\n            - name: FIO_TEST_PROFILE\n\n              value: standard-ssd\n\n\n            - name: FIO_SAMPLE_SIZE\n\n              value: \"128m\"\n\n\n            - name: FIO_TESTRUN_PERIOD\n\n              value: \"60\"\n\n\n          command: [\"/bin/bash\"]\n\n          args: [\"-c\", \"ansible-playbook ./fio/test.yaml -i /etc/ansible/hosts -v; exit 0\"]\n\n          volumeMounts:\n\n            - name: logs\n\n              mountPath: /var/log/ansible\n\n          tty: true\n\n        - name: logger\n\n          image: openebs/logger\n\n          command: [\"/bin/bash\"]\n\n          args: [\"-c\", \"./logger.sh -d 10 -r fio,openebs; exit 0\"]\n\n          volumeMounts:\n\n            - name: kubeconfig\n\n              mountPath: /root/admin.conf\n\n              subPath: admin.conf\n\n            - name: logs\n\n              mountPath: /mnt\n\n          tty: true\n\n        volumes:\n\n          - name: kubeconfig\n\n            configMap:\n\n              name: kubeconfig\n\n          - name: logs\n\n            hostPath:\n\n              path: /mnt\n\n              type: Directory\n```\n\n## STEP 3: Run the Litmus fio test job.\n\nThe job creates the Litmus test pod, which contains both the test runner as well as the (stern-based) logger sidecar. The test runner then launches an fio test job that uses a persistent volume (PV) based on the specified storage class.\n\n```\nkarthik_s@cloudshell:~/litmus/tests/fio (strong-eon-153112)$ kubectl apply -f run_litmus_test.yaml\n\njob \"litmus\" created\n```\n\n## STEP 4: View the fio run results.\n\nThe results can be obtained from the log directory on the node in which the litmus pod is executed (By default, it is stored in _/mnt_). The fio & other specified pod logs are available in a tarfile (\\_Logstash*<timestamp>*.tar\\_\\_).\n\n```\nroot@gke-oebs-staging-default-pool-7cc7e313-bf16:/mnt# ls\n\nLogstash_07_07_2018_04_10_AM.tar  hosts  systemd_logs\n```\n\nThe fio results are captured in JSON format with job-specific result sections. Below is a truncated snippet reproduced from the log for a sample basic rw run:\n\n```\n{\n  \"jobname\": \"basic-readwrite\",\n  \"groupid\": 0,\n  \"error\": 0,\n  \"eta\": 0,\n  \"elapsed\": 61,\n  \"read\": {\n    \"io_bytes\": 28399748,\n    \"bw\": 473321,\n    \"iops\": 118330.31,\n    \"runtime\": 60001,\n    \"total_ios\": 7099937,\n    \"short_ios\": 0,\n    \"drop_ios\": 0,\n    \"slat\": {\n      \"min\": 0,\n      \"max\": 0,\n      \"mean\": 0,\n      \"stddev\": 0\n    },\n    \"write\": {\n      \"io_bytes\": 28400004,\n      \"bw\": 473325,\n      \"iops\": 118331.38,\n      \"runtime\": 60001,\n      \"total_ios\": 7100001,\n      \"short_ios\": 0,\n      \"drop_ios\": 0,\n      \"slat\": {\n        \"min\": 0,\n        \"max\": 0,\n        \"mean\": 0,\n        \"stddev\": 0\n      }\n    }\n  }\n}\n```\n\n## CONCLUSION\n\nHow is this different from doing an fio package installation on the kubernetes nodes and running tests?\n\n- Running an fio kubernetes job will offer better control to simulating actual application loads when used with resource limits.\n- The litmus fio jobs with various profiles can be included as part of a larger suite using the executor framework, thereby obtaining results for different profiles.\n- Litmus (as it continues to mature) will provide jobs that perform Chaos tests against storage while running different types of workloads. Running a fio job lends itself to that model.\n- Finally, it is a more “Kubernetes” way of doing things!\n\nLet us know your experience with using fio-based performance tests with Litmus. Any feedback is greatly appreciated!\n","slug":"how-do-i-run-a-litmus-test-to-compare-storage-performance-on-kubernetes"},{"id":23,"title":"Kubernetes storage extensions to Weave Scope","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"28-6-2018","tags":["Open Source"," Weave Scope"," Node Disk Manager"," Persistent Volume"," Kubernetes"],"excerpt":"It was in Austin KubeCon 2017 that I first got a deep look at Weave Scope, and could not stop falling in love with it. The visualisation Scope provides into Kubernetes resources is simply amazing.","content":"\nIt was in Austin KubeCon 2017 that I first got a deep look at Weave Scope, and could not stop falling in love with it. The visualisation Scope provides into Kubernetes resources is simply amazing. It greatly simplifies the tasks of an Administrator in dealing with the clutter of Kubernetes components and helps directly go to the component of interest and start observing and managing it.\n\nBeing tasked with the goal of simplifying storage management for Kubernetes, my immediate thought was, why can’t we use Scope for Kubernetes storage? Of course, storage in Kubernetes is a developing area and new features are always coming but the existing adoption of Kubernetes persistent storage volumes(PVs) concept was already pretty large and we thought it warranted extensions to Scope to include PVs.\n\nSo we got to and with the help of [Alexis](https://twitter.com/monadic) and the Weave team — we started coding!\n\nWe set out multiple milestones for this journey:\n\n- The first one — get the persistent volumes (PVs), persistent volume claims (PVCs) and Storage Classes (SCs) into Scope\n- The second one — add snapshot/clone support and start monitoring the volume metrics\n- The third one — bring in the disk or SSD or similar as a fundamental resource that is being managed by the Administrator just like they might want to sometimes take a look at CPU and Memory\n\n## Persistent Volumes (PVs)\n\nMost of the time, Persistent Volume Claims (PVCs) are the entry points to increasing the storage. The number of PVCs will be about the same as the number of pods, or slightly less in a reasonably-loaded Kubernetes cluster. The administrator will benefit from having visibility of which POD is using which PVCs and the associated storage classes and PVs. This is especially true if they are using the storage capacity of the Kubernetes clusters themselves. Adding this visibility is precisely is what we did to start.\n\n![PVC-PV-SC-POD Relationship on Scope](/images/blog/pvc-pv-sc-pod.png)\n\nYou can see this new visibility in Scope by using the newly-created filter “Show storage/Hide storage” under the PODs section. This filter puts the storage components in perspective with the remaining pods and associated networked-data connections. Users can **Hide storage** when not interested, or to reduce clutter.\n\nWe received an enthusiastic welcome to the Scope community from the Weaveworks team. We also found encouragement from [Alexis](https://twitter.com/monadic) and plenty of technical help from [Bryan](https://twitter.com/bboreham) at Weaveworks. The first pull request (PR) was really about adding PV, PVC and Storage Class support, and was merged into the Weave Scope master recently ([https://github.com/weaveworks/scope/pull/3132](https://github.com/weaveworks/scope/pull/3132) ).\n\n![PV-PVC-SC Integration into Scope](https://blog.mayadata.io/hubfs/0_iYXgl-m8oxyXVs1s.gif)\n\n## Future work:\n\n### Snapshots and Clones\n\nCI/CD pipelines are the most active areas in which DevOps are finding stateful applications on Kubernetes to be immediately applicable. Storing the state of a database at the end of each pipeline stage, and restoring them when required, is a commonly performed task. The state of the stateful application is stored by taking snapshots of its persistent volumes and is restored by creating clones of persistent volumes. We believe that offering visibility and administrative capabilities to manage snapshots and clones in Scope is a natural next step.\n\n### Disk Management and Monitoring\n\nHyper-converged Infrastructure (HCI) has yet to find its rhythm with Kubernetes, largely due to a lack of fully-developed tools for disk management and monitoring. Kubernetes now has a well-accepted method to provision and manage volumes and attach them to disk management. Therefore, the enabling of HCI for Kubernetes will be improved by new tools such as [Node Disk Manager (NDM)](https://github.com/openebs/node-disk-manager), to which, incidentally (humble brag), we are also contributing. With Disk being the fundamental component for storage and the main participant in the chaos engineering of storage infrastructure, it helps to have it visualised and monitored in a proper way. In large Kubernetes clusters (100+) nodes, the disks will be in the thousands. Scope’s resource utilisation panel is a powerful tool that brings in the visibility of CPU and Memory utilisation at the Host, Container and Process level. This is a natural extension to add Disk Capacity, Disk performance (IOPS and throughput) to this resource utilisation tool. Our view is shown in the figure below, that Disk performance can be added.\n\n![Current View of the Resource Utilisation Tool on Scope](https://blog.mayadata.io/hubfs/0_9SozVWeQ2F69fDQO.gif)\n\nAnother important aspect of disk management is simply browsing from the application volume all the way to the disk where the data is stored. It is not possible to locate the actual disk of a persistent volume if the underlying storage is a cloud-disk such as EBS or GPD, but if it is a Kubernetes local PV or OpenEBS volume, the volume data vs. physical disks relationship can be identified. This will be useful while managing the hyper-converged infrastructure on Kubernetes.\n\n![(Future work) PODs/Disks and Nodes Relationship at Scope](https://blog.mayadata.io/hubfs/0_WJA8ii6NlaBoS94H.gif)\n\nThe above screens are a dirty implementation on a dev branch that is still in process. However, it provides a good, quick glimpse of how a POD’s volume is linked to the associated disks.\n\n_Weaveworks team recently started community meetings led by [Fons](https://twitter.com/2opremio), and it appears to be a great beginning of broader community involvement into the development of Scope. You can access the public meeting notes at_\n\n_[https://docs.google.com/document/d/103_60TuEkfkhz_h2krrPJH8QOx-vRnPpbcCZqrddE1s/edit?usp=sharing](https://docs.google.com/document/d/103_60TuEkfkhz_h2krrPJH8QOx-vRnPpbcCZqrddE1s/edit?usp=sharing)_\n\n## Summary:\n\nWeave Scope is a very useful tool for Kubernetes administrators for visualising and basic administration. With the addition of extensions being added, and a wider community being formed, Scope’s adoption will certainly increase and benefit the Kubernetes eco-system. We are looking forward to being an active contributor to this excellent visualisation tool.\n\nPlease provide any feedback here or in the next Scope community meeting. We will be there!\n\nThanks to [Akash Srivastava](https://medium.com/@srivastavaakash?source=post_page) and [Satyam Zode](https://medium.com/@satyamz?source=post_page).\n","slug":"kubernetes-storage-extensions-to-weave-scope"},{"id":24,"title":"OpenEBS announces the availability of version 1.0","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"24-06-2018","tags":["Cncf"," Kubernetes"," Openebs"," Storage"],"excerpt":"In this blog, I will touch upon what I have learned from users about Open Source CAS solutions like OpenEBS at KubeCon EU 19, followed by a quick note on the major changes in 1.0 and what is in the immediate roadmap.","content":"\nCongratulations and thanks to each one of you from the OpenEBS community for reaching this significant milestone!\n\nIn this blog, I will touch upon what I have learned from users about Open Source CAS solutions like OpenEBS at KubeCon EU 19, followed by a quick note on the major changes in 1.0 and what is in the immediate roadmap.\n\nBeing an active member of the OpenEBS Slack channel and from the usage statistics, I was cognizant of the vibrant user community. For instance, a recent usage report generated by MayaData since 0.8 was released, OpenEBS is running on — 340 different flavors of Operating Systems, 90 different flavors of Kubernetes and across 75 different countries.\n\n![OpenEBS Usage Report](https://cdn-images-1.medium.com/max/800/0*QKRCQN6eguXuHH6u)\n\nKubeCon EU 19, was by far the most interesting for me — to interact with some of the above users who are already running OpenEBS in production or in the process of evaluation. For those of you, curious about the kind of views expressed from users and the partner community about OpenEBS and Kubernetes Storage at large, here are some interesting ones:\n\n**Feedback from Users running OpenEBS in production. **The choice to adopt OpenEBS was made after evaluating and comparing other available solutions as can be seen from several stories shared by the users:\n\n![User feedback about adoption of OpenEBS](/images/blog/slack-snnipets.png)\n\nThis growing adoption is attributed to the following:\n\n- The major one being the architectural superiority of using Kubernetes to build highly portable distributed systems — and **not locking** all the applications into a single point of failure — by making them write into storage system run by some other group or provider. OpenEBS helps to build a storage solution where each application gets its own storage controllers. This is a perfect validation of the Container Attached Storage Category, which is explained in more detail at a [CNCF Blog](https://www.cncf.io/blog/2019/05/16/a-year-later-updating-container-attached-storage/).\n- Containerized distributed applications are much smarter than their legacy server-based counterparts and these new containerized applications don’t have the same dependency on the storage system as before. What applications need are **ala-carte** of Storage Solutions that OpenEBS offers as Storage Engines. Depending on the application needs, cluster administrators can decide what components of OpenEBS are really deployed. For example — does the cluster need to only have Local PVs or a full-fledged storage solution like cStor.\n- Of course the fact the OpenEBS itself is completely developed in user space and just runs on any platform easily. **No kernel taints required.** Yes, currently with 1.0 — there is a performance hit, but there are enough use cases where the current performance is good enough.\n\nWords just can’t express the joy of hearing directly from users on how OpenEBS has helped them. It is just amazing to see the diversity of users as well; from universities to financial corporations, startups to enterprises, fresher to seasoned SREs.\n\nPersonally, the most humbling moment for me at the KubeCon EU 2019, was when an end-user approached me just to thank for the efforts we have put into OpenEBS. He works at a University as a SysAdmin and he mentioned that using OpenEBS — he is able to spin up a self-contained Kubernetes Cluster with host storage that can be used by the stateful applications. This has helped in the number of support calls he receives from the University IT department when rolling out Stateful Applications that needed some hand-holding to provide the PVs.\n\nA similar sentiment is being expressed by large enterprises where the Infra team is supposed to roll out services to 100s of there application teams, in a more agile and uniform way than before. Some of the enterprises run Big Data pipelines at mammoth scale and have found OpenEBS to contains the right set of abstractions that can be extended and used.\n\n**Feedback from the growing community and partner ecosystem** that comprises of individual contributors, home users, enterprise solution architects, technology enthusiasts to hardware vendors included:\n\n- Solution Architects, DevOps, SREs >> I have put together a few scripts to make backups and restores with the Velero plugin for cStor volumes a little easier, since there are some parameters to remember and some additional steps required for both backups and restores other than using the basic Velero commands. I created a tool for [velero openebs](https://github.com/vitobotta/velero-openebs-backup) — with a few notes in a comment, in case anyone is interested\n- Storage Solution Engineers >> Hey, I know OpenEBS was not meant for this — but I think I made some changes can now serve Volumes from Kubernetes Cluster to Virtual Machines. A custom SDS, if you will, that is developed using OpenEBS.\n- Storage Vendors >> We are a storage devices company and OpenEBS can be used to run in an optimized way and help us shift storage boxes.\n- Kubernetes Managed Service Providers >> It will be cool to have OpenEBS available via the Operator Hub/Marketplace.\n\nBy the way, it is hard to gauge how much of the above discussions were really made possible by OpenEBS becoming part of the CNCF family. However, a major shift that I have observed since becoming a CNCF project, is that both end users and partners are more forthcoming to share their stories and integrate OpenEBS into their portfolio. _For anyone considering donating their projects to CNCF, I highly recommend it **—** there is a steep learning curve that helps with Governance of the project, by just being part of the efforts to propose the project into CNCF._\n\nClearly, these days the discussions at KubeCon EU are not around What or Why OpenEBS? but around When a specific feature is going to be made available. While the top requests with regards to missing features were around CSI support, automation of the operations like — disk provisioning and capacity expansion and performance improvements — they were really not blocking users from running OpenEBS in production. There are lots of users out there, that have found the current performance offered by the OpenEBS Data Engines was good enough for their use cases, and they have gone ahead and implemented playbooks and tools for performing maintenance and monitoring operations.\n\nPost KubeCon, having known and also met in person some of these early adopters that are running OpenEBS in production with a set of home-grown solutions, we felt a sense of responsibility to release 1.0 at the earliest and promise to provide long term support on the current feature set. As we progress with implementing additional functionality around operators, CSI, supporting the latest from Kubernetes Storage, and so forth we are also making a commitment that the current version will be supported.\n\nHence, for 1.0 — we changed our gears a bit to focus on helping address the feedback received on the existing feature sets for all the three data engines now supported by OpenEBS and deployed in production- Jiva, cStor Data Engines and Local PV.\n\nSome significant changes in 1.0 are as follows:\n\n**Enhanced Lifecycle Management of Block Devices**. The component of OpenEBS — NDM — Node Disk Manager or Node (Storage) Device Manager as we call it now, has been enhanced to support Block Device Claim (BDC). A new NDM Operator has been introduced in 1.0, that helps to request and reserve a Block Device before using that for either creating Local PV or cStor Pool. NDM is also being used independently of OpenEBS Storage Engines, and the ability to claim a Block Device — similar to PVC — enables the sharing of the block devices without stepping on each other.\n\nBlock Device(BD) is a new CR — which is a preferred way to represent a storage device than a Disk CR ( which was used in earlier releases.) Disk CR are also present — to allow for backward compatibility. The cStor Data engines and Local PVs that typically use block devices have been enhanced to use BDC/BD in place of Disk.\n\nWhen a BDC is deleted, the BD is released. And before it can be claimed by another BDC, the NDM takes care of deleting the data that has been written from the previous consumer. The cleaner utility used is derived from the Kubernetes Local PV cleaner jobs.\n\n**Enhance the OpenEBS Local PV to be used with Block Devices.** In the previous release, we introduced Local PVs that can be used with a hostpath, in this release, we have added support to create a Local PV directly on a Block Device (discovered by NDM). The Block Device can either be a raw block device (Example: GPD) — in which case it will be formatted (Example: Local SSDs on GKE) with the requested filesystem type or already mounted block device.\n\nAlso included in this release are:\n\n- Bug fixes reported around the cStor and Jiva data engines that surface after running OpenEBS on nodes that experience frequent reboots.\n- Additional debugging tools for cStor and Jiva engines, jivactl being the significant one that will help with clearing up of older snapshots. This tool has to be used to clear older snapshots to avoid hitting a cap limit of 255 snapshots in older releases.\n- Added few more Prometheus monitoring metrics\n- Added several e2e tests and included more applications into the OpenEBS CI pipeline maintained by [MayaData](https://mayadata.io/) at [openebs.ci](https://openebs.ci/)\n\nFor detailed changes summary, please check the [OpenEBS 1.0 Changelog](https://github.com/openebs/openebs/wiki/Change-Summary----v1.0).\n\nPlease refer to the[ OpenEBS Documentation](https://docs.openebs.io/?__hstc=216392137.ed92f0691adfb1cbf08ea329504224a3.1580116629364.1580116629364.1580116629364.1&__hssc=216392137.1.1580116629364&__hsfp=3765904294) to get started.\n\nOpenEBS 1.0 — ships with multiple Data Engines to choose from depending on your application needs:\n\n- OpenEBS Jiva PVs — can be used if your kubernetes nodes don’t have the capability to add raw block devices, but have extra capacity available on the host filesystem. This is the first and the longest running in production with lots of Kubernetes tunables available like — to customize the location where data is saved, the specific nodes on which data needs to be replicated — within or across availability zones, setup the volumes for thin provisioning, and so forth.\n- OpenEBS cStor PVs — is the preferred option when your nodes have raw block devices. cStor Data Engine continues to be a preferred solution for use cases that require instant snapshot and clone of volumes.\n- OpenEBS Local PVs — best suited for applications that can do their own replication and require high performance. OpenEBS Local PVs can work with either hostpath or with block devices that are already attached to the nodes.\n\nThere are a lot of options available to customize from the type of block devices that can be used for OpenEBS volumes to customizing the resources allocated to the Storage Pods.\n\nOpenEBS has turned a new leaf in its journey by releasing version 1.0. Thank you for all the support and love that you have shown along this journey. We are forever more committed to learn from you and help you realize the Data Agility that Cloud Native promises to offer.\n\nOur immediate focus is on getting OpenEBS ready for CSI and enhancing the OpenEBS Operators — for managing the Day 2 operations like dealing with Kubernetes upgrades, ASG, expansion of cStor Pool capacity or migrating them to new nodes and so forth. Development on these items is being tracked in the Kubernetes style at [Product Planning Sheet](https://docs.google.com/spreadsheets/d/1bbphUqbxShBhgr1VHaEQUzIGMaJJacPNKc1ckNXU1QE/edit).\n\nThanks to CNCF, we have the following mailing lists to connect apart from the [Slack](https://openebs.org/community).\n\n- For OpenEBS project updates — subscribe to [https://lists.cncf.io/g/cncf-openebs-announcements](https://lists.cncf.io/g/cncf-openebs-announcements)\n- For interacting with other OpenEBS users, you can either join the [Slack](https://openebs.org/community), raise issues on [Github](https://github.com/openebs/openebs/issues) or send an email to [https://lists.cncf.io/g/cncf-openebs-users](https://lists.cncf.io/g/cncf-openebs-users)\n\nAs always, I am eager to learn from you. Please hit me up on [twitter (@kiranmova)](https://twitter.com/kiranmova), [slack](https://openebs.org/community) or on here in the comments.\n\nThanks to [Murat Karslioglu](https://medium.com/@muratkarslioglu?source=post_page). [Public domain](https://creativecommons.org/publicdomain/mark/1.0/).\n","slug":"openebs-announces-the-availability-of-version-10"},{"id":25,"title":"Git freedom on Kubernetes","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"05-06-2018","tags":["DevOps"," Git"," Gitlab"," Kubernetes"," Openebs"],"excerpt":"Here is one of the fastest ways to get your private repository with Gitlab up and running on your Kubernetes environment — Let’s “Make DevOps lifecycle private again”","content":"\n#### Steps to easily run GitLab\n\nAfter Microsoft announced the acquisition of GitHub, many developers raised concerns on social media about Microsoft’s history of unsuccessfully running the acquired businesses like Skype, Nokia’s handset business, Navision and other 150 companies (you probably haven’t noticed) they have swallowed up over the years.\n\nOther than keeping the developer’s life-support plugged, one of the biggest concern is that MS would use its power on GitHub repositories to analyze trends among software development in order to launch competing products. Fears that GitHub privacy may be in jeopardy have already led many developers to jump off the ship or consider alternatives. GitLab’s publicly available [status graphs](https://t.co/svpWpI0Rb2) show spikes of 70x increase in imported repositories (average 100 vs 7.5K), a validation of increased user apprehension.\n\nHere is one of the fastest way to get your private repository with Gitlab up and running on your Kubernetes environment — Let’s “**Make DevOps lifecycle private again**” ©\n\nCurrently, the easiest and recommended way to install GitLab on Kubernetes is using the [Gitlab-Omnibus](https://docs.gitlab.com/ee/install/kubernetes/gitlab_omnibus.html) Helm charts.\n\nGitlab-Omnibus deploys every feature a small deployment would require including the [Container Registry](https://docs.gitlab.com/ee/user/project/coThis year I have attended a number of tech events and in terms of size, organization, and especially the content — Next ’18 is so far my favorite.ntainer_registry.html#gitlab-container-registry), [load balancer (NGINX)](https://github.com/kubernetes/ingress/tree/master/controllers/nginx), [Mattermost](https://docs.gitlab.com/omnibus/gitlab-mattermost/), and [Runner](https://docs.gitlab.com/runner/).\n\n#### **Prerequisites**\n\nMinimum requirements for a multi-node cluster:\n\n**Hardware**\n\n- **Boot node:** 1x 1+ core(s) >= 2.4 GHz CPU, 4GB RAM, >=100 GB disk space\n- **Master node:** 1 or 3x 2+ cores >= 2.4 GHz CPU, 4+GB RAM, >=151 GB disk space\n- **Worker node:** 3x 2+ cores >= 2.4 GHz CPU, 4+GB RAM, >=100 GB disk space\n\nSince I’m not planning to run anything heavy, I’ll be using 3 nodes, and will install Master, Proxy, and Workers an all 3.\n\n**Software**\n\n- [Ubuntu 16.04 LTS](https://www.ubuntu.com/download/server) (RHEL 7.x is also supported)\n- Docker 1.12 to 17.03\n- Kubernetes 1.7+ Cluster (You can use [IBM Cloud Private 2.1.0.2](http://containerized.me/how-to-install-openebs-on-ibm-cloud-private/) or [Red Hat OpenShift Origin](http://containerized.me/how-to-install-openebs-on-openshift/))\n- [kubectl](https://github.com/kubernetes/kubectl)\n- Helm client\n- A [GitLab Omnibus](https://docs.gitlab.com/omnibus/) Pod, including Mattermost, Container Registry, and Prometheus\n- An auto-scaling [GitLab Runner](https://docs.gitlab.com/runner/) using the Kubernetes executor\n- [Redis](https://github.com/kubernetes/charts/tree/master/stable/redis)\n- [PostgreSQL](https://github.com/kubernetes/charts/tree/master/stable/postgresql)\n- [NGINX Ingress](https://github.com/kubernetes/charts/tree/master/stable/nginx-ingress)\n- [OpenEBS](https://github.com/openebs/openebs) persistent volumes for Data, Registry, Postgres, and Redis\n\nThe Kubernetes instructions described below using Helm are generic and should work on all other platforms.\n\n**Installing GitLab and OpenEBS using the Helm Chart**\n\nGitLab depends on stateful applications like Redis and PostgeSQL, and requires persistent volumes for its data and the registry. Here, I will simplify the storage provisioning using OpenEBS.\n\nFirst, install OpenEBS using the chart.\n\n```\nhelm install — name ‘openebs-gitlab-test’ stable/openebs\n```\n\nOptional: If you would like to customize your OpenEBS installation you can also use a copy of the [value.yaml](https://raw.githubusercontent.com/kubernetes/charts/master/stable/openebs/values.yaml) file from the OpenEBS chart and modify parameters listed [here](https://github.com/kubernetes/charts/tree/master/stable/openebs).\n\n```\nhelm install — name ‘openebs-gitlab-test’ -f values.yaml stable/openebs\n```\n\nNext, add the predefined storage classes.\n\n```\nkubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml\n```\n\nThere are many ways to enable OpenEBS for use by GitLab. The fastest is by making one of the OpenEBS storage classes a default StorageClass:\n\nList available OpenEBS storage classes in your cluster.\n\n```\nmurat@icpnode1:~$ kubectl get sc\nNAME PROVISIONER AGE\nopenebs-cassandra openebs.io/provisioner-iscsi 18d\nopenebs-es-data-sc openebs.io/provisioner-iscsi 18d\nopenebs-jupyter openebs.io/provisioner-iscsi 18d\nopenebs-kafka openebs.io/provisioner-iscsi 18d\nopenebs-mongodb openebs.io/provisioner-iscsi 18d\nopenebs-percona openebs.io/provisioner-iscsi 18d\nopenebs-redis openebs.io/provisioner-iscsi 18d\nopenebs-standalone openebs.io/provisioner-iscsi 18d\nopenebs-standard openebs.io/provisioner-iscsi 18d\nopenebs-zk openebs.io/provisioner-iscsi 18d\n```\n\nEither create your StorageClass or pick one of the predefined classes. _openebs-standard_ creates 3 replicas and is an ideal candidate here to be used for most of the stateful workloads. Let’s mark this StorageClass as default.\n\n```\nkubectl patch storageclass openebs-standard -p ‘{“metadata”: {“annotations”:{“storageclass.kubernetes.io/is-default-class”:”true”}}}’\n```\n\nNo verify that your chosen StorageClass is indeed the **default**.\n\n```\nmurat@icpnode1:~$ kubectl get sc\nNAME PROVISIONER AGE\nopenebs-cassandra openebs.io/provisioner-iscsi 18d\nopenebs-es-data-sc openebs.io/provisioner-iscsi 18d\nopenebs-jupyter openebs.io/provisioner-iscsi 18d\nopenebs-kafka openebs.io/provisioner-iscsi 18d\nopenebs-mongodb openebs.io/provisioner-iscsi 18d\nopenebs-percona openebs.io/provisioner-iscsi 18d\nopenebs-redis openebs.io/provisioner-iscsi 18d\nopenebs-standalone openebs.io/provisioner-iscsi 18d\nopenebs-standard (default) openebs.io/provisioner-iscsi 18d\nopenebs-zk openebs.io/provisioner-iscsi 18d\n```\n\nNext, we can install the GitLab-ce chart. It is recommended to save your configuration options in a values.yaml file for future use.\n\n```\nwget https://raw.githubusercontent.com/kubernetes/charts/master/stable/gitlab-ce/values.yaml\n```\n\nEdit the _values.yaml_ file and at minimum, add the **externalUrl** field. Otherwise, you’ll end up with a non-functioning release.\n\nHere is how my _values.yaml_ file looks like after these changes:\n\n```\nimage: gitlab/gitlab-ce:9.4.1-ce.0\nexternalUrl: http://containerized.me/\nserviceType: LoadBalancer\ningress:\nannotations:\nenabled: false\ntls:\nurl: gitlab.cluster.local\nsshPort: 22\nhttpPort: 80\nhttpsPort: 443\nlivenessPort: http\nreadinessPort: http\nresources:\nrequests:\nmemory: 1Gi\ncpu: 500m\nlimits:\nmemory: 2Gi\ncpu: 1\npersistence:\ngitlabEtc:\nenabled: true\nsize: 1Gi\nstorageClass: openebs-standard\naccessMode: ReadWriteOnce\ngitlabData:\nenabled: true\nsize: 10Gi\nstorageClass: openebs-standard\naccessMode: ReadWriteOnce\npostgresql:\nimageTag: “9.6”\ncpu: 1000m\nmemory: 1Gi\npostgresUser: gitlab\npostgresPassword: gitlab\npostgresDatabase: gitlab\npersistence:\nsize: 10Gi\nstorageClass: openebs-standard\naccessMode: ReadWriteOnce\nredis:\nredisPassword: “gitlab”\nresources:\nrequests:\nmemory: 1Gi\npersistence:\nsize: 10Gi\nstorageClass: openebs-standard\naccessMode: ReadWriteOnce\n```\n\nNow, install the chart.\n\n```\nhelm install — name gitlab-test -f values.yaml stable/gitlab-ce\n```\n\nList the pods and confirm that all pods are ready and running.\n\n```\n$ kubectl get pods\nNAME READY STATUS RESTARTS AGE\ngitlab-test-gitlab-ce-dd69cdf4b-69vmb 1/1 Running 0 11m\ngitlab-test-postgresql-75bf9b667d-lwj2b 1/1 Running 0 11m\ngitlab-test-redis-998998b59-hzztj 1/1 Running 0 11m\nopenebs-gitlab-test-apiserver-68fc4488fd-jf8gz 1/1 Running 0 1h\nopenebs-gitlab-test-provisioner-7dfdf646d8–9wpmg 1/1 Running 0 1h\npvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-ctrl-74d4b59c9f-bjtg2 2/2 Running 0 11m\npvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-6ds26 1/1 Running 0 11m\npvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-99mbh 1/1 Running 0 11m\npvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-d8d4z 1/1 Running 0 11m\npvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-ctrl-bd7cff65f-ph8dr 2/2 Running 0 11m\npvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997–2lm4x 1/1 Running 0 11m\npvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997-jldjs 1/1 Running 0 11m\npvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997-kzlrc 1/1 Running 0 11m\npvc-cb111261–6904–11e8–9f57–06a0a9acf800-ctrl-668f5988c5-hv8vb 2/2 Running 0 11m\npvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-hsn49 1/1 Running 0 11m\npvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-lj64g 1/1 Running 0 11m\npvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-z6kfd 1/1 Running 0 11m\npvc-cb11a791–6904–11e8–9f57–06a0a9acf800-ctrl-585cf7c97d-58pnq 2/2 Running 0 11m\npvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-5bzn6 1/1 Running 0 11m\npvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-9dz5f 1/1 Running 0 11m\npvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-snkfb 1/1 Running 0 11m\n```\n\nGet the list of persistent volumes.\n\n```\n$ kubectl get pv\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\npvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-postgresql openebs-standard 17m\npvc-cb1064ee-6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-redis openebs-standard 17m\npvc-cb111261–6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-gitlab-ce-data openebs-standard 17m\npvc-cb11a791–6904–11e8–9f57–06a0a9acf800 1Gi RWO Delete Bound default/gitlab-test-gitlab-ce-etc openebs-standard 17m\n```\n\nYou can see above that four persistent volumes were created (**postgresql, redis, gitlab-ce-etc, gitlab-ce-data**), and each volume is protected by 3 replicas.\n\nNow go to the external endpoint address you have defined and start using GitLab after you set your new password.\n\n![](https://lh4.googleusercontent.com/9UnAe3ZuKt_weq1IbxOrgA_JQMpXE2ZCd80PgDxIodeUdFslr-wCt2DUjbWyoERYWa6RKht8JYvihV-_dQS0EYArc4dJhkPPtN0cGPNfYcDsiHgtjS7unCLOW9MTDre79AjZ660xm6IN94OPew)\n\nNow click on **Create a project**, then import your existing project from GitHub and start using GitLab.\n\n![](https://lh4.googleusercontent.com/CDe7SDXnBmCL5IGVTIOYATjzjZN2iMPsZaVBmuY3-l6qXFX8xReeU6M234eX0ELY1Pips6JfR1FJb4rzfL_d53KLDon0MrzBKqQvuBslQDboCw1yPehiKrSf771PMy79ckmPdLGWnhmijDFkVg)\n\n![](https://lh6.googleusercontent.com/AFqy2l5MohpC1kCk5k2yFoZA90qJGabfUymqmMmI0kFqcpgqXnrapoYCs1dMfrFDqKj-37ncNvoCe7Kf8UfCQq6VRvmFMK742abC58ju6TiRSUk2yeq1OtMBZWPMd3pqyQWawBDgUcSpSZ8Djg)\n\n---\n\nHopefully this helps anyone who is motivated to reexamine their approach to Git to quickly and easily start running GitLab on Kubernetes. Thank you for reading, and please provide any feedback below or via twitter — [**@**muratkarslioglu](https://twitter.com/muratkarslioglu)_Originally published at _[_Containerized Me_](http://containerized.me/git-freedom-on-kubernetes/)_._\n","slug":"git-freedom-on-kubernetes"},{"id":26,"title":"Berlin K8s meetup retrospect","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"31-05-2018","tags":["Openebs"," Kubernetes"," DevOps"],"excerpt":"Last week, I was invited to give a talk about OpenEBS during the Kubernetes meetup in Berlin. The event was hosted by the friendly folks at Profitbricks, who once again I want to thank for the lovely venue and experience.","content":"\nLast week, I was invited to give a talk about OpenEBS during the Kubernetes meetup in Berlin. The event was hosted by the friendly folks at Profitbricks, who once again I want to thank for the lovely venue and experience. Matt Baldwin, from our friends at StackPoint Cloud, was once again an organizer — thank you Matt for your ongoing support of the community (and of OpenEBS as well).\n\nAs we went over some of the nitty-gritty details on how we are building OpenEBS, I received a few questions that I thought deserved an extended response. I will address one of those here.\n\nA common question was: “If I’m running on an _<insert cloud vendor>_ system, what is the benefit of OpenEBS?”\n\n**_So, let’s dive into one of the biggest questions— what if you are running on AWS and you are using EBS volumes, why use OpenEBS on top?_**\n\nFirst of all, we already made the implicit assumption that if you were to run an application managed by Kubernetes, you are using EBS volumes. But, this assumption does not have to be true. In fact, if you want fast and performant storage, AWS suggests that you use optimized storage instances, meaning _not using EBS_ volumes at all.\n\nThe EBS volumes are not the fastest thing you can get from AWS, but they do provide replication across zones and snapshots. This brings me to the second part, a snapshot, in AWS, is stored in S3. That bill (depending on dataset size) can quickly and easily pile up with the number of snaps. With OpenEBS, we store the snapshot locally on the volume itself, and we don’t require you to “copy” this into S3 or a similar location. Also, consider the amount of time it takes for a snapshot to be created in AWS; it can take hours and the snapshot restores require you to attach a new EBS volume. Moreover, if you do these types of things, you have to “fiddle” with the OS to get it attached, something that OpenEBS handles for you, making snapshots instantly and allowing you to rollback immediately.\n\nThere is also the matter of granularity; with OpenEBS, you can control everything per application or even per workload. You can fine-tune the replication factors (or not have it all) and you can use just one EBS volume for all your apps since OpenEBS handles the slicing and dicing for you.\n\nSo, this was about using EBS volumes, I hope the advantages are apparent and easy to understand. This brings data agility to your applications, not just in AWS, but also across clouds: public, private or hybrid. The developer does not have to make any changes to his or her YAML, and can write once and run everywhere, precisely what containers are supposed to do. Do not let others take that freedom away from you =)\n\nBack to the non-EBS volumes, what AWS refers to as “instance store.” More information from Amazon:\n\n![Instance stores](/images/blog/instance-stores.png)\n\nAs the docs point out, when you use this, you get high speed with zero features. With OpenEBS, you get high speed and all of the features if you delegate control of the “instance store” to OpenEBS. An interesting note, the instance store comes with the price of the machine instance itself, so there are no extra charges on your bill.\n\nIn a future blog I’ll cover some other common questions that arose — and I’m also going to continue talking about the shift of IO and so forth to the user space, and what it may mean for Container Attached Storage and running IO intensive workloads in general.\n\nFeel free to ask any questions below, or maybe I’ll see you on the [OpenEBS slack community](https://slack.openebs.io/?__hstc=216392137.c2ca19ae0ec72f00a9ae3bf6f8a512a3.1579861713935.1579861713935.1579861713935.1&__hssc=216392137.1.1579861713935&__hsfp=3765904294) where we are discussing many related subjects.\n","slug":"berlin-k8s-meetup-retrospect"},{"id":27,"title":"Container Attached Storage (CAS) — Taking off nicely","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"28-05-2018","tags":["Cas"," Kubernetes"," Stateful Applications"," Openebs"," Mayaonline"],"excerpt":"I had the fortune of presenting to a group of brilliant folks at SNIA India SDC event last week. This event being in Bangalore, I could sense the heat emanating from technology savvy brains mostly from the storage companies like DELL-EMC, NetApp, RedHat storage, HP storage etc","content":"\nI had the fortune of [presenting](https://www.slideshare.net/OpenEBS/openebs-cas-sdc-india-2018) to a group of brilliant folks at SNIA India SDC event last week. This event being in Bangalore, I could sense the heat emanating from technology savvy brains mostly from the storage companies like DELL-EMC, NetApp, RedHat storage, HP storage etc and the questions at the end of the presentation were a proof of it. Lots of great questions on the lines of “Nice architecture, I never knew storage can be run completely in user space”, “CAS — great topic, I understand the value and benefits, but are not you adding too many containers to the equation?”. In the interest of answering those questions in detail, I thought let me take the most commonly asked ones and answer them in this short article.\n\n## Just a quick recap on CAS:\n\n[Container Attached Storage (CAS)](https://docs.openebs.io/docs/next/conceptscas.html) is a new storage architecture to run the entire storage software in containers and hence in user space. This architecture has many benefits, primary one being “a dedicated storage controller per application” and bring in the possibility of hardening the storage controller for a given application workload. Read more on the benefits at the [CNCF blog](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/). A typical CAS architecture example is shown below.\n\n![CAS architecture with controller and replica pods for each application](https://cdn-images-1.medium.com/max/800/1*4dJDmPbxxrP-fZK7NZZmYg.png)\n\nNow back to the CAS FAQ, here are a couple:\n\n### Q1: Well, how can you run entire storage in user space? I thought it can never be run in user level because of performance reasons.\n\nFor more technical answer, read our [CTO’s blog](https://blog.openebs.io/the-mule-and-the-flash-going-for-a-run-b104acbc74a2) on this precise topic 🙂\n\nShort answer is, we think storage should take advantage of container technology, so in CAS, we run storage as a microservice. The performance will be taken care by using technologies like SPDK, VPP and also taking advantage of the abundant availability of compute cores on the node.\n\nReality is that, linux kernel, as it is today, cannot deliver all the IOPS from the underlying NVMe flash disks. Do we think kernel can deliver 12 Million IOPS from the 24 NVMe disks ? Of course not, not today !!\n\nIn summary, higher performance can only be delivered using CAS architecture, SPDK, VPP and using more CPU cores.\n\n![CAS with SPDK leads to higher performance](https://cdn-images-1.medium.com/max/800/1*aKjepAaB5sIZF-hOq_dxIg.png)\n\n### Q2: In CAS, you are adding more containers to the cluster because of storage. Isn’t that increasing the compute needs of the Kubernetes cluster ?\n\nCAS enables native hyper convergence capability on Kubernetes. You don’t need an external storage array to manage the storage/data needs of applications on K8S, thats a lot of saving of CPU and hardware. With CAS, the overall TCO reduces as the additional storage (local disks), CPU and software (CAS) are provisioned on the same K8S cluster nodes and avoids the need of expensive external storage arrays.\n\nAs for the the question of dealing with large number of containers is concerned, there are nice tools like Weave Scope which you can use either on the local K8S or in a free service like MayaOnline. Check out [MayaOnline](https://www.mayaonline.io) where the storage extensions to Scope are put to use.\n\n![Application relationship with storage (PVC, PV, SC, and CAS)](https://cdn-images-1.medium.com/max/800/1*RQYjI0MdsXf1kj8AGqLJZA.png)\n\n## Conclusion:\n\nWe continue to say — With CAS, storage fades away as a concern !! Join our [slack community](https://slack.openebs.io) to find more !!\n","slug":"container-attached-storage-cas-taking-off-nicely"},{"id":28,"title":"My First Contribution to OpenEBS \\#OSS","author":"Vipul Gupta","author_info":"Enter a short bio? No, thank you. If you like to find me or my content, then I would be at http://mixstersite.wordpress.com/","date":"28-05-2018","tags":["Openebs"," Go"," Golang"," Summer Hackfest"," Open Source"],"excerpt":"Writing documentation for any project is tough, be it big or small, propriety or open-source. Rewriting and improving it is even tougher. Let no one tell you any different.","content":"\nWriting documentation for any project is tough, be it big or small, propriety or open-source. Rewriting and improving it is even tougher. Let no one tell you any different. Take it from someone who scoured through 6000+ lines of documentation written in Markdown spread across 20 or so files and been able to fix about 900 odd lines of them for a major open-source project. That’s how my story goes if you want to know about my first contribution to OpenEBS.\n\nHonestly, I have little experience in Go, I have never been inclined to use it much. As I am already comfortable, writing code in Python for about a year now. But that doesn’t stop me from learning new languages and technologies. Hence my utmost dedication to cure myself of the “Too Much too Learn” Syndrome. I went to the **Women Who Go meetup** in New Delhi, India for a [Go 101 workshop](https://twitter.com/vipulgupta2048/status/977893034808434689?s=09). And that’s how I got to know about the open-source project, OpenEBS, and their exciting Summer HackFest.\n\n[OpenEBS](https://openebs.io/) is an open source storage platform that provides persistent and containerized block storage for DevOps and container environments. OpenEBS is also tightly integrated with Kubernetes and is a part of Kubernetes-Incubator project. And works with all popular workloads such as PostgreSQL, Redis, Jenkins etc.\n\nNow, OpenEBS is still under active development from the team. Hence comes in, [Summer HackFest](https://openebs.io/hackfest). **Summer HackFest** is a unique opportunity for new contributors and people working with Go to develop and fix issues for OpenEBS and their projects such as [Maya](https://mayaonline.io/), [Litmus](https://openebs.io/litmus). By contributing to the Hackfest, you get community access, useful knowledge on working with new technologies, learn new skills and along the way win cool goodies, swag. Also, the chance to take home the grand prize, a laptop. HackFest starts out in April 2018. Being open-source, all contribution was needed to be submitted to [GitHub](https://github.com/openebs/openebs). I did and oh man, I had a good time writing code for OpenEBS. Sounds good. Want to contribute?\n\n---\n\n## Let’s get you started\n\nRefer to this [quick guide](https://github.com/search?utf8=%E2%9C%93&q=org%3Aopenebs+is%3Aissue+label%3Asummerhack+label%3Akind%2Funit-test&type=) to get started. You would also need to be familiar with the basics of Go, hence you can refer to the widely recommended tutorial [https://tour.golang.org/](https://tour.golang.org/), for the same. After that, make sure to join the OpenEBS Slack channel to resolve all doubts and questions that you might have. The link can be found here in the [contributing document](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md) on their repository. Read the document (I re-wrote it) And you are committed.\n\nGo to their website that I linked above, and figure out which section of issues you would like to contribute too. Once done. Head over there, and do your thing. Push the changes, make that PR and rest is history.\n\n## Well, sure thing but how was your experience?\n\n![Contributors to OpenEBS Hackfest](/images/blog/hackfest-contributors.png)\n\nMy experience has been great so far while contributing to OpenEBS (_I am still actively contributing to it_). Everything was a breeze. They have very flexible rules and easy guidelines, no hard checks with the CI. The reviewers are very helpful, and would assist you in every possible manner ( Shoutout to Kiran Mova !!) I have been working on solving issues in the documentation of OpenEBS and vagrant files that are being used in the project.\n\nEarlier, I also attended a webinar OpenEBS conducted on Introduction to contributing and solving issues of Maya and scope, which was very informative and helpful. Hence goes on to show their dedication to helping their contributors even further then most people would go. The codebase could be quite intimidating at first, but with time and the helpful answers provided by the very vibrant and active community will keep you going. I can tell you for a fact, that the journey is the reward here.\n\nI asked so many questions, and never got a blowback. I really appreciated all the support shown to me by the community. The environment is beginner-friendly and very welcoming, great for all new contributors. It couldn’t get any better with the incentives they add to it for contributing.\n\nI honestly had a lot of fun while contributing. One of the most notable [pull requests](https://github.com/openebs/openebs/pull/1511) of mine to Summer Hackfest was about rewriting and improving the documentation, which received a whopping 392 comments. They were sweet enough to put my name on the website with the fellow contributors and made me the star contributor of the week. Woohoo !! They also awarded me with a book as a token of their appreciation. Thanks, OpenEBS !!\n\nAnd that’s it for this time, I guess. For all my PR’s to Summer HackFest, [click here](https://github.com/search?utf8=%E2%9C%93&q=org%3Aopenebs+is%3Apr++label%3Asummerhack++author%3Avipulgupta2048+is%3Amerged&type=Issues). I will update the blog post with a picture of the goodies once I receive them (_So excited_). I highly recommend heading over to [https://openebs.io/hackfest](https://openebs.io/hackfest), to take part in this golden opportunity to contribute to such a brilliant project and being a part of their community.\n\n---\n\nVipul Gupta ([vipulgupta2048](http://www.letmegooglethat.com/?q=vipulgupta2048)) posts occasional on his blog, [Mixster](http://www.mixstersite.wordpress.com/). Check him out there for more updates like these.\n","slug":"my-first-contribution-to-openebs-oss"},{"id":29,"title":"Using Kubernetes Custom Resources for Microservices IPC","author":"Ganesh Kumar","author_info":"Gopher, Open Source Contributor, Thinker, Health enthusiast","date":"11-05-2018","tags":["Kubernetes"," Golang"," Openebs"," Microservices"],"excerpt":"This blog talks about why I used Custom Resources as a way for communication between different microservices (aka Kubernetes Pods).","content":"\nThis blog talks about why I used [Custom Resources](https://kubernetes.io/docs/concepts/api-extension/custom-resources) as a way for communication between different microservices (aka Kubernetes Pods).\n\nOpenEBS is a fully containerized storage solution running within Kubernetes. Infact [OpenEBS](https://docs.openebs.io/) extends the Kubernetes cluster functionality to manage storage and stateful workloads.\n\nOpenEBS has an operator (or orchestration component) called [Maya](https://github.com/openebs/maya) (magic) that relays Volume management operations to several storage engines. OpenEBS already supports [Jiva](https://github.com/openebs/jiva) based storage engine. The purpose is to plugin a more independent [cStor](https://github.com/openebs/cstor)based storage engine (making use of zfs on userspace).\n\nI essentially have a user interacting with OpenEBS Maya using PV, PVC, StorageClasses etc. and OpenEBS Maya interacts with cStor Pods. I will be focusing on the design considerations for interactions between OpenEBS Maya and cStor Pods.\n\n![Architecture](/images/blog/architecture.png)\n\n_1 — Shows user creating StoragePoolClaim (SPC) CR, with details like the number and type of pools to be created. Let us consider, SPC specifies a cStor pool should be created._\n\n_2 — Maya has a custom controller that watches for the SPC CR and it will go ahead and create the cStor Pods with a cstor-pool container and a side-car cstor-pool-mgmt that has a CLI interface for creating pools and volumes. Side-car container (following the Kubernetes Ambassador Pattern), helps in translating the Pool and Volume operations triggered by Maya into the corresponding CLI commands._\n\n_3 — Depending on the user’s request for creating a pool or a volume, Maya will create CStorPool and CStorVolumeReplica CRs respectively. Note that, I could have had the cstor-pool-mgmt container expose an API service that Maya could have invoked. Instead, I decided to use CRs and I will explain why in the following sections._\n\n_4 — cstor-pool-mgmt sidecar application watches for CRs of CStorPool and CStorVolumeReplica and performs pool — volume operations._\n\n**One of the core design constraint while deciding on inter-pod communication between Maya and CStor Pod is that:** _When the user requests for a Volume, the cluster state may not be fully ready to satisfy all the criteria — for example, User requests for 3 replicas but there are only 2 nodes running. The request should be cached and a third replica has to be provisioned whenever a new node gets added to the cluster._\n\nDevelopers normally go with an approach to make a REST/gRPC call to the receiver and store in a database, running in separate pod/statefulset. But OpenEBS thinks beyond that.\n\nNow consider, that I had used the traditional approach of using a REST/gRPC method of interactions between Maya and CStor Pods, then Maya would have to implement/consider cases like:\n\n- Where to store the state of current request, as the request can’t be serviced immediately depending on the cluster state. This is required to handle the case where the node running Maya can itself go down.\n- When working in a scaled environment, when there are multiple Maya pods, who gets to service the requests and when one of the pod goes down, should the other take it over or not?\n- How to handle the case where, Maya sends the request to the CStor container and then it goes boom (after all this is Kubernetes Cluster and they are supposed to handle all kinds of Chaos), who handles the results of the operation at CStor. In other words, how to implement a 2-phase commit?\n\n_However, if you look at my design constraint, doesn’t it sound similar to how a Kubernetes deployment with 3 replicas work?_ The user defines a desired state (in this case Maya) and the controllers make it happen eventually. So, why not just, be a roman when in rome.\n\n### Thats exactly what OpenEBS does!\n\nOpenEBS goes with `watch`-er approach. i.e., watch [**k8s custom resource definition**](https://kubernetes.io/docs/concepts/api-extension/custom-resources). If a pool (virtual disk) must be created on top of the actual disk, Maya creates a custom resource (named CStorPool), and a pod running cstor-pool-mgmt watcher gets an event for corresponding resource request and starts performing pool related operations. Cool, isn’t it?\n\n### Where does the custom resource get stored?\n\nkubernetes etcd. You pronounced it right, that’s `yetsed`, :-)\n\n### How is custom resource efficient?\n\n- Storing critical details in a separate pod-database, leads to pod level consistency. Storing in etcd leads to **cluster level consistency**.\n- Even if the **receiver is not running**, when the request is generated, the receiver-watcher gets an event, as and when it starts running.\n- Users can access the resources via **k8s cli** — `kubectl get <crd-name>`\n- Update the status of request on the same custom resource.\n\n### What is the problem with custom resource?\n\n- It is not suitable for transactional communication. (Say if an OTP request needs to be done within 20 seconds, it is not applicable to go with, “as and when up” approach).\n  Solution: Before making any transactional call, verify status of receiver and make a REST/gRPC API call. No other go, :-(\n- It is slightly complex to implement watcher.\n  Solution: My next blog will address an easy way to implement CRD watcher, how to solve issues with watcher design and different ways to implement watching controller. Practise, you become perfect; Follow us, you become fantastic :-)\n\nSupport and follow us [**@gkGaneshR**](https://twitter.com/gkGaneshR) and [**@openebs**](https://twitter.com/openebs) to get instant updates.\n\nThanks [Kiran](https://twitter.com/kiranmova) for your valuable support. We at OpenEBS are always looking for help and feedback from Community. Please join us on [Slack](https://slack.openebs.io/) or comment on the [design doc](https://docs.google.com/document/d/1Q5W3uHktHa-vOm8oGp-3kpAQ3V1tvyk5AYmxxtf57Rg/edit?usp=sharing) and related [Pull Request](https://github.com/openebs/maya/pull/284).\n\n**Summary**\n\n- K8s CRD becomes a good alternative to REST/gRPC API for “push to perform” operations.\n- Few more implementation details will be covered in upcoming blogs — Follow us for updates.\n","slug":"using-kubernetes-custom-resources-for-microservices-ipc"},{"id":30,"title":"Announcing MayaOnline — A SaaS platform for freeing data management from its traditional…","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"01-05-2018","tags":["Gitops"," Kubernetes"," Mayaonline"," Openebs"," Stateful Workloads"],"excerpt":"At this Kubecon, we, at MayaData, are thrilled to make couple of announcements. One of them is the launch of beta version of MayaOnline.","content":"\nAt this Kubecon, we, at MayaData, are thrilled to make couple of [announcements](https://www.prnewswire.com/news-releases/mayadata-releases-litmus---open-source-chaos-engineering-for-kubernetes--free-tier-of-mayaonline-681458381.html). One of them is the launch of beta version of [MayaOnline](https://mayaonline.io). MayaOnline provides **free** visibility, ChatOps and cross-cloud control for users running OpenEBS or just local disks on Kubernetes clusters.\n\nMayaOnline provides application developers, Kubernetes administrators and CIOs different variants of visibility into stateful applications data and helps these users to better manage data operations.\n\nIt has become an almost untold expectation that the modern era tools being built for easing / helping DevOps are built with easy integration into GitOps; change controlling configurations much in the way that code is managed has been identified as a key determinant of success. MayaOnline takes the GitOps philosophy into its design;configurations come from single source of truth — Git repositories.\n\nTalking about simple integrations — we also have made APIs first class citizens in the design of MayaOnline. Almost anything you can do via the GUI you can do via APIs.\n\nKubernetes’ stateful applications journey is still evolving. We observe two primary usage patterns.\n\n1. Perhaps the most common pattern is running stateful workloads with the help of open source storage that is easy to use and operate; if the open source storage delivering capabilities to microservices and containers is itself built from microservices and containers — all the better.. OpenEBS is a leading example of this pattern, with an architecture described as [CAS](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/) or container attached storage. In OpenEBS, data volumes are containerized and each workload has its own storage controller enabling teams to be fully in control of their storage without any central single point of failure (or latency)\n2. A second common pattern that we see is perhaps best characterized by NoSql workloads such as Cassandra, that manage the data operations themselves (replication, snapshotting and rebuilding) and therefore for which just raw storage underneath is good enough. This type of stateful workloads are starting to use Kubernetes Local PVs. However, the raw storage needs to be planned, monitoring and managed for Local PVs too otherwise your Cassandra and application engineers spend all their time trying to figure out why the ring is rebalancing again and again.\n\n**_MayaOnline is intended to be an all in one storage resource planning, monitoring and management solution for Kubernetes deployments across clouds; we do support the above patterns, allowing you to manage OpenEBS and Local PVs as the underlying storage choices._**\n\nMayaOnline is released as a beta version today and comes live with the following features. In this post, I discuss MayaOnline’s current capabilities and delve a bit into the vision as well.\n\n## Sifting through your PVCs and PVs:\n\nMicroservices architectures typically split applications into multiple kubernetes PODs. It is not uncommon to have a production Kubernetes cluster with hundreds of PODs, in some cases even thousands. Each POD can have multiple volumes claims (PVCs), derived from a combination of storage classes (SCs) and resulting in volumes (PVs). Thanks in large part to our newly released Weave Scope integration, MayaOnline provides an efficient way to view, debug and for some scenarios manage these PVC and PVs and their relationships.\n\nOne simple use case is sifting through the snapshots of a volume and creating a clone out of one.\n\n![Browse storage configuration of a cluster](https://cdn-images-1.medium.com/max/800/1*uEEzklDvtzepvdjGUIQdJQ.gif)\n\n## Managing hyper-convergence:\n\nThe same problem of sifting through hundreds of objects and their logical and physical relationships can arise while managing underlying storage media, including disks, cloud volumes, SSDs and more. MayaOnline helps here as well, simplifying disk monitoring and management, the pooling of disks, expansion of capacity . OpenEBS NDM is a key piece go get the hyper-convergence management right, you can refer to [this blog](https://blog.openebs.io/achieving-native-hyper-convergence-in-kubernetes-cb93e0bcf5d3) for more thoughts on contributing NDM to Kubernetes itself.\n\n![Browse disks relationship to a volume](https://cdn-images-1.medium.com/max/800/1*7w2jYA2KghNxT7c96snCxw.gif)\n\n## Visibility:\n\nPrometheus is a popular project applying a time series approach to monitoring. We use Prometheus in MayaOnline in a variety of ways. Thanks to Prometheus Developers, Operators and CIOs have readily customized dashboards for volume data and for storage resources data within and across clusters. MayaOnline makes it easy to aggregate Prometheus metrics from various clusters spread across multiple clusters and on-prem data centers. External API support, customization of Prometheus dashboards, and the creation of new dashboards are other favorite features of MayaOnline.\n\n![Comprehensive metrics of a volume, cluster and organization](https://cdn-images-1.medium.com/max/800/1*ZeFadSNW8zEQ9DWaotiOhA.gif)\n\n## ChatOps — Dedicated chatbot for automated operations:\n\nGetting useful alerts on time and be able to act on them is an integral part of data management operations. With MayaOnline, one can view and manage the alerts centrally by logging onto MayaOnline — or can just have them pop up in your chat thanks to our dedicated chatbot, which we call MuleBot. MuleBot is a [Slack application](http://slack.com/apps/A7XH78AAH-mulebot) that works hard to deliver alerts to the Slack channels you want while participating in your GitOps workflow by interacting with your teams end users, allowing them to storage infrastructure right from the slack channel.\n\n![MuleBot Slack Application](https://cdn-images-1.medium.com/max/800/0*U47i8j0o34sBq3AW.)\n\n## Looking into the future of MayaOnline:\n\n### Seamless cross cloud data movement:\n\nThough Kubernetes solves the problem of cloud lock-in with regard to application provisioning and management — by being a common orchestration framework and set of operations APIs across environments -, we still have the problem of lock-in caused by data gravity. MayaOnline’s cMotion feature — which we are working on actively and have demoed in the past — will help with seamless and policy based workload movements. cMotion APIs at MayaOnline will be used to automate workload movement across clouds or Kubernetes clusters right from the user’s DevOps platforms.\n\n### Learning workloads\n\nOne of the reasons we made MayaOnline freely available is to learn from users how they use OpenEBS and, more broadly, how they are managing stateful workloads on Kubernetes.\n\nIn the not too distant future we will use what we learn from MayaOnline to nudge users towards better approaches. For example, we are investigating how to suggest better storage policies based on our experience from many users. For example, certain workloads may benefit from larger block sizes and a replication approach optimized for videos — OpenEBS allows this kind of extreme customization thanks to its CAS architecture; with MayaOnline we intend to coach users towards better approaches.\n\n### It is free. Import your Kubernetes cluster today !\n\nMayaOnline follows a [freemium](https://en.wikipedia.org/wiki/Freemium) model. Using the free tier, one can manage certain number of Kubernetes clusters for free, forever.\n\nSign-up with your github credentials and import your Kubernetes cluster, we are eagerly looking for your feedback !!\n","slug":"announcing-mayaonline-a-saas-platform-for-freeing-data-management-from-its-traditional"},{"id":31,"title":"Litmus - Release a chaos monkey on your Kubernetes Stateful Workloads!","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"01-05-2018","tags":["Chaos"," Kubernetes"," Litmus"," Software Testing"," E2e"," Chaos Engineering"],"excerpt":"If you are a Kubernetes Enthusiast and working on stateful workloads, you may be asking yourself","content":"\n**In this blog we quickly talk about what led us to build Litmus and to open source it.**\n\nIf you are a Kubernetes Enthusiast and working on stateful workloads, you may be asking yourself:\n\n“With all the options I have to run Kubernetes — the permutations are endless — how can I be sure that my particular mix of options works well end to end at keeping my data safe and accessible?”\n\nYou are not alone, as can be seen by the ever increasing conversations on Kubernetes sig-storage slack channel and other forums like Reddit or Twitter. To just pick a few conversations:\n\n![Is it really recommended to run stateful workloads like MySQL on Kubernetes?](https://cdn-images-1.medium.com/max/800/1*6VJXdgFpuwD-fUkEKPo0GA.png)\n\n[Is it really recommended to run stateful workloads like MySQL on Kubernetes?](https://www.reddit.com/r/kubernetes/comments/88fxdg/is_it_really_not_recommended_to_run_stateful/)\n\n![What are the storage solutions offered in Kubernetes today? Which one will suit my workload](https://cdn-images-1.medium.com/max/800/1*5s60fO7nzhZfC3SFNiY0gA.png)\n\n[What are the storage solutions offered in Kubernetes today? Which one will suit my workload](https://twitter.com/rothgar/status/978694465975083009)\n\nAnd say, you somehow have made the journey to explore different solutions out there, mostly referring to product documentation and blogs, how can you be sure that the solution will continue to work in your enterprise environment ?\n\nAs enterprises move to DevOps and microservices, more and more of the infrastructure from policy engines through storage and everything in between such as DNS, tracing, logging and more are selected and operated by all in one teams. With this control and autonomy comes greater agility — and all too often, _stress_.\n\nMeanwhile, infrastructure vendors and projects are also (we know first hand) challenged to keep their end-to-end (e2e) and chaos engineering frameworks updated with the ever-increasing permutations of deployment scenarios. Kubernetes itself is changing, new providers emerge every day, workloads are changing, and all of it is increasingly simple to adopt and deploy. As a storage solution provider we simply cannot have the resulting explosion of “corner cases” go untested.\n\nThe solution providers can go one step ahead to open source their project, but it still doesn’t help the users to ensure that the selected Kubernetes stack works in their highly distributed and agile environments and they are not called to fight fires at 3 AM.\n\n![Fire-fighting production issues !!](https://cdn-images-1.medium.com/max/800/0*qX8CliW_E3gKMURn.)\n\n“What’s a person to do? Test, test, release the chaos monkeys, and test again!”\n\nThankfully, Kubernetes and containerization and Go and some software engineering we’re happy to share make it much easier to provide end to end validation in real world conditions !\n\n#### So — What is Litmus?\n\n**_Litmus is a community for e-2-e testing and chaos engineering for Kubernetes, focusing on stateful workloads._**\n\nThe primary objective of Litmus is to ensure a consistent and reliable behavior of Kubernetes for various persistent workloads and to catch hard-to-test bugs and unacceptable behaviors before users do. Litmus can detect many more real-world issues than relatively simple issues identified by unit and integration tests.\n\nLitmus can also be used to determine if a given Kubernetes deployment is suitable for stateful workloads. While Litmus tests and metrics were developed initially to test the resilience of container attached storage from OpenEBS and others — we realized that the use cases are broader and overall system resilience can be characterized, which is a major reason we are open sourcing our efforts and putting the time into starting the Litmus community.\n\nLitmus tests range from initial setup and configuration validation to deploying and running persistent workloads under various conditions and failures.\n\n_What sets Litmus apart is not just its intent of being an end to end testing framework that can be embedded into any CI/CD pipeline, but the ease with which different teams from product developers to customers can contribute to the tests. Litmus allows for defining scenarios using native language specifications (English !!) OR a set of easy-to-define/understand YAML templates which are internally converted into test scripts, with a simple Kubernetes manifest as the end-product._\n\nHere is a simple test, defined in plain English:\n\n![Simple test in plain english](https://cdn-images-1.medium.com/max/800/0*ar6cYX2rEJ7Nh_G2.)\n\n## How to get involved with Litmus?\n\nFirst, it might be useful to understand the basic pieces of Litmus. Litmus has the following major components:\n\n![Litmus: High level architecture](https://cdn-images-1.medium.com/max/800/1*CdBbpkSilx3aJnZA3tiAjQ.png)\n\n- **Deployments** that help in setting up different types of Kubernetes Clusters like on-premise, cloud, OpenShift, etc. The default is that the deployments provision and configure OpenEBS storage, however, these deployments are easily extended to support other storage and we are happy to help any user or storage vendor to build additional deployments.\n- **Facilitators** for test execution that aid: defining and running test suites, capturing logs and generating reports about the test runs, fault/error injection tools that help to perform chaos tests, examples that demonstrate how to integrate these test pipelines with Slack notifications\n- **Test modules** that are triggered from within a Kubernetes cluster. Think of these as containerized tests. For instance, the **_mysql-client_** can be launched as a pod to validate MySQL resiliency while the underlying nodes and the connected storage are subjected to chaos engineering.\n- **Tests** that themselves are written in easy to understand formats, either in plain English (thanks [Godog](https://github.com/DATA-DOG/godog)!) or in Ansible Playbooks. These tests primarily interact with the Kubernetes cluster via **_kubectl_**making them highly portable.\n\nLitmus can be used to test a given workload in a variety of Kubernetes environments, for example, a developer minikube or a GKE cluster with a specific storage solution or as a part of a full-fledged CI setup.\n\nLitmus is early and needs all the help you can provide to have it cover the ever-growing Kubernetes landscape. Checkout the [Litmus Project](https://github.com/openebs/litmus) on Github for more details or if you are at KubeCon EU, please join us for the talk this Friday on [End to End testing with Kubectl](https://kccnceu18.sched.com/event/DqwD/using-kubectl-to-run-your-end-to-end-tests-amit-kumar-das-uday-kiran-mayadata-intermediate-skill-level) to learn more about how we have built Litmus and a quic\n\n#### Conclusion:\n\nPlease welcome Litmus into the world! We’re pretty sure it addresses a set of needs being felt by everyone from developers and operators to service providers and cloud native open source projects such as OpenEBS. With Litmus we use microservices and containers and Kubernetes to test, validate and characterize environments end to end. Your feedback is welcome and needed. Thanks for reading!\n","slug":"litmus-release-a-chaos-monkey-on-your-kubernetes-stateful-workloads"},{"id":32,"title":"How do I create an OpenEBS storage pool on Google Persistent Disk","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"13-04-2018","tags":["Docker"," Openebs"," Solutions"," Google Cloud Platform"," Kubernetes"],"excerpt":"The OpenEBS volume replicas, which are the actual backend storage units of the OpenEBS iSCSI target currently store the data in a hostPath on the Kubernetes nodes.","content":"\nThis article belongs to #HowDoI series on Kubernetes and OpenEBS.\n\nThe OpenEBS volume replicas, which are the actual backend storage units of the OpenEBS iSCSI target currently store the data in a hostPath on the Kubernetes nodes. By default, a folder with the volume (PV) name is created on the root filesystem, in a parent directory (/var/openebs) & bind mounted into the container during the replica pod instantiation. This parent directory (also created if not already available), which is basically a persistent path to hold the individual volumes is referred to as a **_Storage Pool_**.\n\nNote: The notion of the storage pool described above is specific to the current default storage engine ,i.e., Jiva. Future releases may see availability of additional storage-engines which can consume block devices instead of hostdir to create storage pools\n\nFor various reasons, it may be desirable to create this storage pool on an external disk (GPD, EBS, SAN) mounted into specific locations on the Kubernetes nodes. This is facilitated by the **OpenEBS storage pool policy**, which defines the storage pool as a **_Kubernetes Custom Resource_** with the persistent path as an attribute.\n\nThis blog will focus on the steps to be followed to create the OpenEBS PV on Google Persistent Disks (GPD).\n\n## PRE-REQUISITES\n\n- 3-Node GKE cluster with the OpenEBS Operator installed (Refer: [https://docs.openebs.io/docs/cloudsolutions.html](https://docs.openebs.io/docs/cloudsolutions.html))\n- 3-Google Persistent Disks, one attached to each node of the cluster.This can be done using the **_gcloud compute disks create_** & **_gcloud compute instances attach-disk_** commands (Refer for console steps: [https://cloud.google.com/compute/docs/disks/add-persistent-disk#create_disk](https://cloud.google.com/compute/docs/disks/add-persistent-disk#create_disk))\n\n### STEP-1: Format the GPDs & Mount into desired path\n\nOn each node, perform the following actions :\n\n- Switch to root user _sudo su –_\n- Identify GPD attached _fdisk -l_\n\n```\nroot@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# fdisk -l\nDisk /dev/sda: 100 GiB, 107374182400 bytes, 209715200 sectors\nUnits: sectors of 1 \\* 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: dos\nDisk identifier: 0x635eaac1\n\nDevice Boot Start End Sectors Size Id Type\n/dev/sda1 \\* 2048 209715166 209713119 100G 83 Linux\n\nDisk /dev/sdb: 10 GiB, 10737418240 bytes, 20971520 sectors\nUnits: sectors of 1 \\* 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n```\n\n- Format the disk with, say ext4 fs (_mkfs.ext4 /dev/sd<>)_\n\n```\nroot@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mkfs.ext4 /dev/sdb\nmke2fs 1.42.13 (17-May-2015)\n/dev/sdb contains a ext4 file system\nlast mounted on /openebs on Fri Apr 13 05:03:42 2018\nProceed anyway? (y,n) y\nDiscarding device blocks: done\n  Creating filesystem with 2621440 4k blocks and 655360 inodes\nFilesystem UUID: 87d36681-d5f3-4169-b7fc-1f2f95bd527e\nSuperblock backups stored on blocks:\n32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632\n\nAllocating group tables: done\n  Writing inode tables: done\n  Creating journal (32768 blocks): done\nWriting superblocks and filesystem accounting information: done\n```\n\n- Mount the disk into desired mount point (_mount -o sync /dev/sd<> /mnt/openebs_)\n\n```\nroot@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mount -o sync /dev/sdb /mnt/openebs/\nroot@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mount | grep openebs\n/dev/sdb on /mnt/openebs type ext4 (rw,relatime,sync,data=ordered)\n```\n\n### STEP-2 : Create a storage pool custom resource\n\n- Construct a storage pool resource specification as shown below & apply it (Note that the custom resource definition for the storage pool is already applied as part of the operator install)\n\n```\napiVersion: openebs.io/v1alpha1\nkind: StoragePool\nmetadata:\nname: sp-mntdir\ntype: hostdir\nspec:\npath: \"/mnt/openebs\"\n```\n\n### STEP-3 : Refer the storage pool in a custom storage class\n\n```\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n    name: openebs-custom\nprovisioner: openebs.io/provisioner-iscsi\nparameters:\n  openebs.io/storage-pool: \"sp-mntdir\"\n  openebs.io/jiva-replica-count: \"3\"\n  openebs.io/volume-monitor: \"true\"\n  openebs.io/capacity: 5G\n```\n\n### STEP-4 : Use the custom storage class in an application’s PVC spec\n\n```\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: demo-vol1-claim\nspec:\n  storageClassName: openebs-custom\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5G\n```\n\n### STEP-5 : Confirm volume is created on the storage pool\n\n- Once the OpenEBS PV is created (_kubectl get pv, kubectl get pods_), list the contents of the custom persistent path mentioned in the storage pool custom resource. It should contain a folder with the PV name consisting of the sparse files (disk image files)\n\n```\nkarthik_s@strong-eon-153112:~$ kubectl get pv\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\npvc-556e7ab7-3ed9-11e8-8e6a-42010a800216 5G RWO Delete Bound default/demo-vol1-claim openebs-custom 59m\n\nroot@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# ls /mnt/openebs/\nlost+found pvc-556e7ab7-3ed9-11e8-8e6a-42010a800216\n```\n\n### GOTCHAS !!\n\n_Issue_: GPDs are detached in the event of a) Cluster resize (downscale/upscale) , b) upgrades & c) VM halts\n\n- No options to add “additional disks” during cluster creation\n- Instance templates are “immutable”, disks have to be added to instances separately\n\n_Workaround_: Perform a manual re-attach in above situations (Enlarged root disks are an option, but generally not recommended)\n","slug":"how-do-i-create-an-openebs-storage-pool-on-google-persistent-disk"},{"id":33,"title":"Using chaoskube with OpenEBS.","author":"Sudarshan Darga","author_info":"Senior Software Engineer at MayaData","date":"12-04-2018","tags":["Openebs"," Chaos Engineering"," Kubernetes"," Solutions"],"excerpt":"Chaos Engineering is the discipline of proving the reliability of any system by causing “chaos”. The work ‘Chaos’ means the state of confusion or failure caused due to unexpected reason.","content":"\n**Chaos Engineering** is the discipline of proving the reliability of any system by causing “chaos”. The work ‘Chaos’ means the state of confusion or failure caused due to unexpected reason.\n\n### Failures can be caused due to:\n\n- Power outages.\n- Software bugs.\n- Human Error.\n\n### Since failure is unavoidable.\n\n- Why not deliberately introduce failure to ensure the system can deal with the failure?\n- Chaoskube is one such tool, which can be used to introduce pod failures on Kubernetes Cluster.\n\n### Overview of Chaoskube:\n\n- Chaoskube is an open source Chaos Testing tool.\n- Written in GO language.\n- Can induce pod/controller failures on K8s Cluster.\n- Can kill pods by specifying the labels, namespaces.\n- Simple and easy to run.\n\n## Setup Chaoskube infrastructure on 3 node Kubernetes Cluster:\n\n```\nubuntu@kubemaster-01:~$ kubectl get nodes\nNAME            STATUS    ROLES     AGE       VERSION\nkubemaster-01   Ready     master    2d        v1.8.8\nkubeminion-01   Ready     <none>    2d        v1.8.8\nkubeminion-02   Ready     <none>    2d        v1.8.8\nkubeminion-03   Ready     <none>    2d        v1.8.8\nubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/e2e/ansible/playbooks/resiliency/test-ctrl-failure/chaoskube.yaml\ndeployment \"chaoskube\" created\nserviceaccount \"chaoskube\" created\nubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/e2e/ansible/playbooks/resiliency/test-ctrl-failure/rbac.yaml\nclusterrole \"chaoskube\" created\nclusterrolebinding \"chaoskube\" created\nubuntu@kubemaster-01:~$ kubectl get pods\nNAME                                   READY     STATUS    RESTARTS   AGE\nchaoskube-55fc8f5f6d-tb6hj             1/1       Running   0          32s\nmaya-apiserver-69f9db69-b9qxk          1/1       Running   0          2d\nopenebs-provisioner-77cb47986c-w6wbz   1/1       Running   1          2d\n```\n\n## Deploy Percona application on OpenEBS volume with Liveness probe:\n\n```\nubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/elves/master/e2e/percona-liveness/percona.yaml\ndeployment \"percona\" created\npersistentvolumeclaim \"demo-vol1-claim\" created\nservice \"percona-mysql\" created\nubuntu@kubemaster-01:~$ kubectl create configmap sqltest https://raw.githubusercontent.com/openebs/elves/master/e2e/percona-liveness/sql-test.sh\nconfigmap \"sqltest\" created\nubuntu@kubemaster-01:~$ kubectl get pods\nNAME                                                             READY     STATUS    RESTARTS   AGE\nchaoskube-55fc8f5f6d-tb6hj                                       1/1       Running   0          6m\nmaya-apiserver-69f9db69-b9qxk                                    1/1       Running   0          2d\nopenebs-provisioner-77cb47986c-w6wbz                             1/1       Running   1          2d\npercona-85b8997987-dg6jm                                         1/1       Running   0          1m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-vd8t5   2/2       Running   0          1m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-64rv5    1/1       Running   0          1m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-b5v25    1/1       Running   0          1m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-gs69w    1/1       Running   0          1m\n```\n\n## Induce controller failure using Chaoskube:\n\n- Induce failure on pod with label ‘openebs/controller=jiva-controller’ for duration of 60 seconds with interval of 20 seconds, which means it will induce controller pod failure for every 20 seconds for 3 times.\n\n```\nkubectl exec chaoskube-55fc8f5f6d-tb6hj -- timeout -t 60 chaoskube --labels 'openebs/controller=jiva-controller' --no-dry-run --interval=20s --debug\n```\n\n- Output should look something like this:\n\n```\ntime=\"2018-04-13T09:50:36Z\" level=info msg=\"terminating pod\" name=pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-vd8t5 namespace=default\ntime=\"2018-04-13T09:50:36Z\" level=debug msg=sleeping duration=20s\n```\n\n- Lets observe the failure induces by watching `kubectl get pods` for every 2 seconds.\n\n```\nEvery 2.0s: kubectl get pods Fri Apr 13 09:55:35 2018\nNAME READY STATUS RESTARTS AGE\nchaoskube-55fc8f5f6d-tb6hj 1/1 Running 0 16m\nmaya-apiserver-69f9db69-b9qxk 1/1 Running 0 2d\nopenebs-provisioner-77cb47986c-w6wbz 1/1 Running 1 2d\npercona-85b8997987-dg6jm 1/1 Running 7 12m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-nh5fk 2/2 Running 0 15s\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-64rv5 1/1 Running 0 12m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-b5v25 1/1 Running 0 12m\npvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-gs69w 1/1 Running 0 12m\n```\n\n- Observe that percona application pod with liveness probe is still running after inducing openebs controller pod failure using chaoskube. Hence, the system is reliable after causing ‘Chaos’.\n\n### Reference Links:\n\n- [https://github.com/linki/chaoskube](https://github.com/linki/chaoskube)\n- [https://docs.openebs.io/](https://docs.openebs.io/)\n","slug":"using-chaoskube-with-openebs"},{"id":34,"title":"How do I pin the OpenEBS Replica Pod(s) to the Kubernetes Nodes where they were scheduled?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"26-03-2018","tags":["Howdoi"," Kubernetes"," Openebs"," Storage"," Solutions"," Tutorials"],"excerpt":"A OpenEBS Volume comprises of a Controller pod and one or more Replica pod(s). Controller pod (also known as a Target pod) is the one to which the application can make an iSCSI connection.","content":"\nThis article belongs to #HowDoI series on Kubernetes and OpenEBS.\n\nA OpenEBS Volume comprises of a Controller pod and one or more Replica pod(s). Controller pod (also known as a Target pod) is the one to which the application can make an iSCSI connection. The Replica pods are the ones that access the underlying disk resources for storing the data.\n\n**Use Case #1: In my Kubernetes cluster, [_OpenEBS volume pods are scheduled on appropriate nodes_](https://blog.openebs.io/how-do-i-configure-openebs-to-use-storage-on-specific-kubernetes-nodes-361e3e842a78). This is all fine till the cluster experiences a disruption due to network partition. Kubernetes tries to evict & re-schedule these volume pods into newer nodes that does not have the underlying data. This results in volume getting into offline state. I want the OpenEBS volume pods to stick to the nodes they were originally placed.**\n\n**Solution**: Patch the Replica deployment with **nodeAffinity** property\n\nAs per Kubernetes docs, nodeAffinity allows you to constrain which nodes your pod is eligible to be scheduled on. It is based on labels on the node.\n\nThere are currently two types of node affinity:\n\n– `requiredDuringSchedulingIgnoredDuringExecution` &\n\n– `preferredDuringSchedulingIgnoredDuringExecution`\n\nThese node affinity types can be thought of “_hard_” vs. “_soft_” affinity respectively.\n\n- _Hard_ affinity states that pod will be scheduled only if the conditions are met.\n- _Soft_ affinity implies Kubernetes will make a best effort but the affinity may not be guaranteed.\n\nWe shall make use of `hard affinity` as this fits perfectly to the needs of Replica deployment.\n\nSteps required to patch the Replica deployment are summarised below:\n\n**Step 1**:- Replica pod(s) gets scheduled by Kubernetes default scheduler (via OpenEBS provisioner — a dynamic Kubernetes storage provisioner)\n\n**Step 2**:- Wait till replica pod(s) get into `Running` state\n\n**Step 3**:- Operator determines the node(s) on which the replica pod(s) are scheduled\n\n**Step 4**:- Replica deployment is patched with nodeAffinity\n\n```bash\n# REPLACE <namespace-where-openebs-pods-are-deployed> WITH ACTUAL NAMESPACE\n# REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n# TAKE A NOTE OF THE NODE NAME(S) TO BE USED IN THE PATCH.YAML\n\nkubectl get po -n <namespace-where-openebs-pods-are-deployed> \\\n  -o=custom-columns=NAME:metadata.name,NODE:spec.nodeName,STATUS:status.phase \\\n  | grep -E 'NAME|<name-of-persistentvolume>-rep'\n```\n\n```bash\n$ cat replica_patch.yaml\n```\n\n```yaml\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: kubernetes.io/hostname\n                    operator: In\n                    values:\n                      - nodename_where_replica_pod_1_got_scheduled\n                      - nodename_where_replica_pod_2_got_scheduled\n                      - nodename_where_replica_pod_3_got_scheduled\n```\n\n```bash\n# REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n\nkubectl patch deployment <name-of-persistentvolume>-rep \\\n  -p \"$(cat replica_patch.yaml)\"\n```\n\n```bash\n# VERIFY IF PODs ARE BACK TO `Running` AFTER PATCH\n# REPLACE <namespace-where-openebs-pods-are-deployed> WITH ACTUAL NAMESPACE\n# REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n\nkubectl get po -n <namespace-where-openebs-pods-are-deployed> \\\n  | grep -E 'NAME|<name-of-persistentvolume>-rep'\n```\n\nLearn more about nodeAffinity from Kubernetes docs at [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity).\n\nIf you want to understand more on kubectl patch operation, then go through [https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/](https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/).\n","slug":"how-do-i-pin-the-openebs-replica-pods-to-the-kubernetes-nodes-where-they-were-scheduled"},{"id":35,"title":"How do I configure OpenEBS to use storage on specific Kubernetes nodes?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"18-03-2018","tags":["Howdoi"," Openebs"," Solutions"," Kubernetes"," Tutorials"],"excerpt":"A OpenEBS Volume comprises of a Target pod and Replica pod(s). There can be one or more Replica pods. The Replica pods are the ones that access the underlying disk resources for storing the data.","content":"\nThis article belongs to **#HowDoI** series on [**Kubernetes**](https://kubernetes.io/) and [**OpenEBS**](https://openebs.io/).\n\n**Note: The approach mentioned in this article applies for OpenEBS version 6.0 or below. One can refer to this [link](https://github.com/openebs/community/pull/20) for OpenEBS version 0.8.0 and above.**\n\nA OpenEBS Volume comprises of a Target pod and Replica pod(s). There can be one or more Replica pods. The Replica pods are the ones that access the underlying disk resources for storing the data.\n\n**Use Case #1: In my Kubernetes Cluster, I have certain nodes that have disks attached. I call these as Storage Nodes. I want the OpenEBS Volume Replica Pods to be scheduled on these Storage Nodes.**\n\n**_Solution:_** Use Kubernetes “taints & tolerations” feature.\n\nAs per Kubernetes docs, taints allow a node to repel a set of pods. Taints and tolerations work together to ensure that pods are not scheduled onto inappropriate nodes.\n\n- You can apply `NoSchedule` & `NoExecute` taints to the node(s).\n- `NoSchedule` marks that the node should not schedule any pods that do not tolerate the taint.\n- `NoExecute` marks that the node should evict existing/running pods that do not tolerate this taint.\n- Tolerations are applied to pods, and allow the pods to get scheduled onto nodes with matching taints.\n- You need to set an ENV variable in maya API server Deployment specifications, which in turn ensures setting of above tolerations on the replica pods.\n- The ENV variable referred to here is `DEFAULT_REPLICA_NODE_TAINT_TOLERATION`\n\nFollowing are the instructions to do the same:\n\n````\n# Step 1  —  Taint the node(s)\n```bash\n# kubeminion-01 is the name of a Kubernetes node\n# The taint effects used here are `NoSchedule` and `NoExecute`\nkubectl taint nodes kubeminion-01 storage=ssd:NoSchedule storage=ssd:NoExecute\n```\n\n# Step 2  —  Maya API server should be deployed with below specs\n# This ensures the replica pods are set with appropriate tolerations\n```yaml\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: maya-apiserver\nspec:\n  replicas: 1\n  template:\n  metadata:\n    labels:\n    name: maya-apiserver\n  spec:\n    serviceAccountName: openebs-maya-operator\n    containers:\n    —  name: maya-apiserver\n      imagePullPolicy: Always\n      image: openebs/m-apiserver:0.5.3\n      ports:\n      —  containerPort: 5656\n      env:\n      —  name: DEFAULT_REPLICA_NODE_TAINT_TOLERATION\n        value: storage=ssd:NoSchedule,storage=ssd:NoExecute\n```\n````\n\n**Use Case #2:** In my Kubernetes Cluster, I have certain nodes that have disks attached. I call these as Storage Nodes. I want the OpenEBS Volume Replica Pods to be scheduled on these Storage Nodes. In addition, I want a better utilization of these nodes by being able to schedule my application Pods on these nodes as well.\n\n**Solution:** Use Kubernetes taints & tolerations feature. You may also want to try with `nodeAffinity` to achieve this. However, this solution focuses on use of tolerations.\n\n- You need to make use of `PreferNoSchedule` as the taint effect.\n- This can be thought of as a _soft version_ of `NoSchedule`.\n- In other words the system tries to avoid placing a pod that does not tolerate the taint on the node, but it is not mandatory.\n\nFollowing are the instructions to do the same:\n\n````\n# Step 1  —  Taint the node(s)\n```bash\n# kubeminion-01 is the name of a Kubernetes node\n# The taint effect used here is `PreferNoSchedule` i.e. a soft version of `NoSchedule` \n# the system tries to avoid placing a pod that does not tolerate the taint on the node,\n# but it is not mandatory.\nkubectl taint nodes kubeminion-01 storage=ssd:PreferNoSchedule\n```\n\n# Step 2  —  Maya API server should be deployed with below specs\n# This ensures the replica pods are set with appropriate tolerations\n```yaml\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: maya-apiserver\n  namespace: default\nspec:\n  replicas: 1\n  template:\n  metadata:\n    labels:\n    name: maya-apiserver\n  spec:\n    serviceAccountName: openebs-maya-operator\n    containers:\n    —  name: maya-apiserver\n      imagePullPolicy: Always\n      image: openebs/m-apiserver:0.5.3\n      ports:\n      —  containerPort: 5656\n      env:\n      — name: DEFAULT_REPLICA_NODE_TAINT_TOLERATION\n        value: storage=ssd:PreferNoSchedule\n  ```\n````\n\nIf you want to learn more on taints & tolerations, then go through [https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)\n\nI shall strive to put more such articles in future. Do let me know if you want any specific topics that I should explain.\n\n_Thanks to Kiran Mova._\n","slug":"how-do-i-configure-openebs-to-use-storage-on-specific-kubernetes-nodes"},{"id":36,"title":"Achieving native hyper convergence in Kubernetes","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"13-03-2018","tags":["Hyper Convergence"," Kubernetes"," Nutanix"," Openebs"," Persistent Storage"],"excerpt":"Hyper convergence has a lot of benefits — which is one reason it has become popular in the traditional infrastructure-centric world of virtual machines with proprietary vendors like Nutanix reaching prominence over the last several years.","content":"\nHyper convergence has a lot of benefits — which is one reason it has become popular in the traditional infrastructure-centric world of virtual machines with proprietary vendors like Nutanix reaching prominence over the last several years.\n\nKubernetes is nearly ready as a layer enabling hyper convergence, as the compute orchestration is extremely flexible and networking has moved to a largely containerized approach that leverages local resources in attached physical and virtual hosts.\n\nWhen it comes to storage, however, there are a few pieces that are missing. Once added to Kubernetes, these pieces will unlock a number of benefits to users of Kubernetes including better resource utilization, reduction of noisy neighbor phenomena, simpler management, isolation at the node level thereby reducing the potential blast radius of failures, and, perhaps most importantly, further ownership and management of relevant infrastructure per workload and per DevOps team.\n\nStorage management capabilities in Kubernetes have improved in the last couple of years. For example, there is now clarity around how to connect a stateful application to persistent storage. The constructs of persistent volume claim (PVC), persistent volume (PV), and storage class (SC) along with dynamic provisioners from vendors have clarified how to connect a pod to a storage volume. With these Kubernetes constructs, a large ecosystem of legacy storage found its way to be connected to application pods. Many vendors and open source projects are so excited about this connectivity to cloud native environments that they have taken to calling their traditional storage “[cloud native](https://blog.openebs.io/cloud-native-storage-vs-marketers-doing-cloud-washing-c936089c2b58)”.\n\nIn order to explain why new tools and constructs are needed to improve the management of storage media, let’s start by reviewing pod connectivity. Shown below is a pod connected to external storage through a dynamic provisioner interface.\n\n![Need for new tools and constructs in Kubernetes for managing disks](https://cdn-images-1.medium.com/max/800/1*zm4UFgEvTWesM2JoxQF9Cg.jpeg)\n\nIn addition, we show the Local PV construct connected to local disks whether spinning or solid state.\n\nCurrently the Local PV can manage just a single disk. In a typical hyper-converged solution, more disks would be involved for a given pod. In addition to this single disk limitation, the following are limitations or gaps in the local PV feature.\n\n- Add disks / detach disks to a pod currently requires the pod to be restarted\n- Control and access to the storage is itself is limited. There will be a number of benefits of enabling access at times to the level of NUMA and to allowing CPU cores to be attached to the storage pod; keep in mind that these days using all the cores itself can be a challenge and driving up utilization is one of the central attributes of hyper converged systems\n- Today there is no standard ability to share the underlying disk. This is particularly important as extremely fast, and relatively expensive, NVMe SSD devices are now readily available and if shared they could be used as a cache for multiple Persistent Volumes\n- Lack of any fault management capabilities. Kubernetes needs to be able to receive and manage storage faults such as failures of the underlying disk, changes to the latency of disk IO\n\nWith these limitations in mind, we summarize needed enhancements as:\n\n- Capability to pool the disks, and provide an interface to manage the pooling\n- Capability to monitor disks, identify faults, forward them to the appropriate receivers\n\nIn the drawing above, these requirements are loosely shown as “constructs and tools to manage local disks”. These disk related constructs and tools are largely meant to be managed by Kubernetes cluster administrators and DevOps administrators in a Kubernetes like way.\n\nIt may be easier to think about this using human personas. Let’s say a DevOps developer is interested in connecting a working storage volume to their workload. Meanwhile a DevOps admin wants to rely as much as possible on Kubernetes to deliver storage services.\n\nToday, DevOps admins are forced to turning to different storage solutions to create storage classes as opposed to having a generic way of writing solutions around creating storage classes in a k8s native way. The DevOps admin would love to have a native k8s way to create storage classes so that they can standardize on an approach irrespective of the underlying storage systems or even storage cloud services.\n\n![Using and constructing a storage class in Kubernetes](https://cdn-images-1.medium.com/max/800/1*17YT5-GR_JUXEq6qW2SD1A.jpeg)\n\n## Some thoughts on what these new disk related constructs and tools could be\n\nJust like storage connectivity issue is solved with a dynamic volume provisioner, we could introduce pool provisioners into Kubernetes.\n\n![Proposed disk related constructs and interfaces](https://cdn-images-1.medium.com/max/800/0*eM2LjKDvhbl62mjG.)\n\nAs shown above, DevOps administrators will have the required tools to design the storage policy decisions. A toolset called is created node-disk-manager to provision, monitor and manage disks on the node. The disks are then grouped into pools by an interface called pool provisioner. The pool provisioner gives a generic set of APIs to consume the kubernetes disk objects and create a storage technology specific pools such as OpenEBS cStorPool, OpenZFS zpool, GlusterPool etc.The advantage of representing the pools in native Kubernetes constructs is that Kubernetes native tools can be extended to manage these new constructs.\n\nWith these constructs, the end-to-end volume provisioning work flow could be depicted like below.\n\n![New proposed workflow for managing local disks and achieving true hyper convergence in Kubernetes](https://cdn-images-1.medium.com/max/800/1*9bAs7wOPNNGLxELpgP-4FA.jpeg)\n\n## Conclusion:\n\nKubernetes native constructs and tools to manage and monitor local disks will help move towards achieving true hyper-convergence. We have observed many users in the OpenEBS community are using OpenEBS dynamic provisioner seamlessly, and requesting tools to manage the disks and storage pools. We are thinking of adding such tools to Kubernetes itself so that they are available to the larger community. A draft design proposal is available at We are looking forward to proposing and discussing these thoughts with K8S SIG leadership.\n\nWe are cooking up some draft proposals in the OpenEBS project before we take the to K8S SIG. Your feedback is appreciated and needed.\n\n### Disk Manager design:\n\n[https://docs.google.com/presentation/d/11GLg21x7G-nMTNw8aNIOhhjW\\_-eK19zSI9Xm-0jYHKs/edit?usp=sharing](https://docs.google.com/presentation/d/11GLg21x7G-nMTNw8aNIOhhjW_-eK19zSI9Xm-0jYHKs/edit?usp=sharing)\n\n[https://github.com/kmova/node-bot/blob/3cb83976a5392003d02275f8a94d1860257915f0/design/node-storage-management.md](https://github.com/kmova/node-bot/blob/3cb83976a5392003d02275f8a94d1860257915f0/design/node-storage-management.md)\n\n### Pool Provisioner design:\n\n[https://github.com/kmova/openebs/blob/35fb65540b17ad3da3df270ccc425c4ec417ca12/contribute/design/proposal-cstor-orchestration.md](https://github.com/kmova/openebs/blob/35fb65540b17ad3da3df270ccc425c4ec417ca12/contribute/design/proposal-cstor-orchestration.md)\n","slug":"achieving-native-hyper-convergence-in-kubernetes"},{"id":37,"title":"The Mule and (the) Flash — going for a run?","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"26-02-2018","tags":["Kubernetes"," Cloud Storage"," Container"],"excerpt":"In this blog, I discuss why we are building an innovative approach to user IO for the purpose of containerized storage, in particular vhost. If you just want the code, take a look at https://github.com/openebs/vhost-user.","content":"\nIn this blog, I discuss why we are building an innovative approach to user IO for the purpose of containerized storage, in particular vhost. If you just want the code, take a look at [https://github.com/openebs/vhost-user](https://github.com/openebs/vhost-user).\n\nFirst off, as mentioned in previous blog articles, OpenEBS is not yet another distributed file system. Let’s reiterate the reasoning behind this:\n\n- As microservices typically require only a small (relatively) amount of storage, there is no need to build a scale-out storage system\n- As Direct-attached Storage (DAS), in particular, NVMe, is the fastest storage you can get, you want the workload and the controller to be local with respect to each other; this is true even with SSD cloud storage offerings like AWS EBS instances\n- As single NVMe devices can reach 450K IOPS per device or [more](https://www.prnewswire.com/news-releases/supermicro-delivers-groundbreaking-18-million-iops-of-storage-performance-in-new-2u-ultra-server-300508258.html) there is no longer any need to “scale out” to achieve high IOPS or low latency, in fact, scale-out adds latency as per the above argument\n\nFinally, distributed applications are complex by nature. When you are building microservices, you are in fact, developing a distributed application. It seems unwise to put one distributed application on top of the other (storage) and sleep well at night. All that work you’ve done limiting single points of failure in your application layer can be undone through the use of complex distributed storage.\n\nAnother fundamental aspect of OpenEBS is that it runs in user space. This too has, we like to believe, a significant advantage as it does not require you to [build a kernel module](https://github.com/portworx/px-fuse) and taint your kernel (in case of closed source) with out-of-tree code. But it does not stop there; if you want to move your data from cloud to cloud (c2c), you do not have to worry about kernel version mismatches or anything like that. User space is the new kernel — when it comes to IO.\n\nBut what about performance? Linus Torvals himself said some years ago that file systems in user space are nothing but [toys](https://www.phoronix.com/scan.php?page=news_item&px=OTYwMA). But, as it turns out, with these low latency SSDs and high-speed networking (100GbE) the kernel, in fact, has become the bottleneck!\n\n_“fuse works fine if the thing being exported is some random low-use interface to a fundamentally slow device.”_\n\nSo it seems that we have reached an impasse? The kernel appears to be the bottleneck, and user space implementations are just “toys.” Or have we? When you look into why IO in user space is slow, it’s mostly due to the inability to do DMA, the required context switches and the copying in and out of data. What if we could avoid this? Also, you as you may know, hardware is already causing a change in the way we do things — 3D XPoint™ next to NVMe. This can be seen by technologies applied in SPDK and others like FD.IO. As OpenEBS is storage in containers, we have started to work on what we call the IOC, or the IO Container using these technologies.\n\n**The IOC runs in user space and can do IO to the underlying hardware, bypassing the kernel altogether. It owns a set of resources (CPU, NICs, memory, and storage) and applies polling for IO instead of being interrupt driven.**\n\nWith 18-core desktop computers being available today, it’s hardly an issue to use a core or two dedicated for IO — in the user space.\n\nBecause the IOC exposes block devices, we need a way to connect these devices to the other containers. Luckily — the VM space solved that problem for us: v[host](http://www.spdk.io/doc/vhost.html). By reusing these approaches, we create high a speed connection between the IOC and the containerized storage controller without making a change to the applications.\n\n![IOC model with vhost user interface and VPP](/images/blog/ioc-model-with-vhost-user-interface-and-vpp.png)\n\nThe above picture tries to depict the situation on a single node. As the application sends its IO through a block protocol (the target), OpenEBS — through the shared vhost subsystem — sends the IO to the replica which applies storage logic to it. With storage logic, we mean things that allow OpenEBS to do Copy-on-write (COW), snapshots, clones, compression or whatever is required. Also, OpenEBS is starting to further leverage this architecture to alter data management parameters including replication and snapshot patterns and even lower level parameters as well as block size in those containers depending on the workload.\n\nThen finally, the IO is submitted again to the IOC where an adaptive polling algorithm waits for its completion. Note, that the target — replicates `n` copies to the other node(s) which is depicted with R(n).So instead of doing IO through the kernel, your application passes the IO to the IOC which takes care of completing the IO as fast as possible all from user space.\n\nWith this approach, we get the best of both worlds and are in fact capable of surpassing the performance you would get when doing the same in the kernel — hands down — while also providing per workload granularity of control.\n\n![User space outperforming the kernel](/images/blog/user-space-outperforming-the-kernel.png)\n\nAs you can see from the repository, the design is fairly straightforward and is intended to support both legacy workloads as well as those built for faster underlying storage. We welcome input and contributions from anyone.\n\nWhile the vHost work stands alone it is central to a new storage engine forthcoming in OpenEBS 0.6, code named ‘cStore’.\n\nWe would really like your input so please [open an issue](https://github.com/openebs/vhost-user/issues) or join us on Slack to discuss at [openebs-community.slack.com](http://openebs-community.slack.com/) or just contact me directly. I can be reached at Twitter at [@jeffrymolanus](https://twitter.com/jeffrymolanus)\n","slug":"the-mule-and-the-flash-going-for-a-run"},{"id":38,"title":"OpenEBS plus Red Hat OpenShift and StackPointCloud and IBM Cloud Private and….","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"05-02-2018","tags":["DevOps"," Docker"," Kubernetes"," Updates"," Openebs"],"excerpt":"This week we announced that our partnership with Red Hat is flourishing. We achieved their Primed level of certification for their OpenShift offerings and are seeing more and more users rely upon OpenShift and Kubernetes as a means to provide persistence to their workloads.","content":"\nThis week we [announced](https://www.prnewswire.com/news-releases/openebs-certified-with-red-hat-openshift-stackpointcloud-and-ibm-cloud-672729373.html) that our partnership with Red Hat is flourishing. We achieved their Primed level of certification for their OpenShift offerings and are seeing more and more users rely upon OpenShift and Kubernetes as a means to provide persistence to their workloads.\n\nThe alternative pattern, of course, is to connect to an external storage system. Solutions like Rook and others such as the CSI efforts of RexRay and many others enable the use of external storage.\n\nActually — so does OpenEBS :)\n\nOpenEBS can and often does use external storage underneath. With OpenEBS, however, every workload has its own storage controller(s) that themselves are easily orchestrated by Kubernetes and data is local by default. There are three main benefits to the OpenEBS containerized architecture that external only storage cannot address due to architectural limitations:\n\n- **The granularity of control** — with OpenEBS the storage controller interprets ever more individualized and extensive storage policies and makes them so for each workload. Because OpenEBS is a full system (or is becoming one :)), it offers far more control than centralized storage that itself has to address the sometimes competing needs of countless — hundreds — of workloads. Developer teams can take on storage knowing they are much less constrained than they are working with least common denominator external storage.\n- **No SPOF** — in an age in which chaos engineering is becoming more and more popular, the notion of a sacrosanct dependency that cannot itself be disrupted or the entire system crashes potentially into a non-recoverable state is anachronistic. Put more directly — shared scale-out storage is an anti-pattern for many. Blast Radius.\n- **Performance** — as storage heads, we too often likely focus on performance. However, OpenEBS does work with databases, and in some cases the speed at which you run those workloads directly translates into user experience and hence money. So the tax a scale out storage system puts on performance versus the insane and rapidly accelerating speed of direct attached is essential. Ironically, scale-out first arose in part to work around how slow local disk was; times have changed. If you are interested in performance, you’ll want to grab our cStore by the way which, as the name suggests, is written in C and does much else as well to build upon our inherently faster Container Attached Approach. Stay tuned…\n\nSo why Red Hat and why StackPointCloud?\n\nIn both cases, we see organizations that are doing an incredible job helping their target users adopt Kubernetes based orchestration. With Red Hat, we tend to see especially larger enterprises taking the approach. With StackPointCloud, there is a real mix of departmental level users at large organizations as well as countless start-ups. In both cases, our support of Helm charts for OpenEBS makes it trivial to spin OpenEBS up.\n\nWhile OpenEBS itself as not achieve 1.0 status, we are working hand in hand w/ partners to make sure users are succeeding in their use of OpenEBS for stateful workloads. There must now be at least hundreds of production proof of concept deployments ongoing. We will be making [MayaOnline](http://www.mayaonline.io/) freely available to help these and other users in the near future via no cost monitoring and control and ChatOps integrations.\n\nPlease get in touch via [Slack](https://join.slack.com/t/openebs-community/shared_invite/enQtMjQzMTg4NTcyNTY2LTJiMzVjYjA5ZDk3YmI4NjAxY2QyYmI3MTA1MmUxMTAzNTU0NTM5NTViOTIxMjA1NWQ4NzVmMTBiNjk0NDU1YzQ) or otherwise if you would like to spend a little time with us to discuss your use cases and, of course, if you are running OpenEBS and testing it out.\n","slug":"openebs-plus-red-hat-openshift-and-stackpointcloud-and-ibm-cloud-private-and"},{"id":39,"title":"How to install OpenEBS on OpenShift?","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"22-01-2018","tags":["Kubernetes"," Mongodb"," Openshift"," Percona"," Solutions"," Openebs"],"excerpt":"OpenShift Origin is the upstream community project used in all deployment models provided by Red Hat OpenShift such as OpenShift Online, OpenShift Dedicated, and OpenShift Container Platform.","content":"\n## What is OpenShift Origin?\n\n**OpenShift Origin** is the upstream community project used in all deployment models provided by Red Hat OpenShift such as **OpenShift Online**, **OpenShift Dedicated**, and **OpenShift Container Platform**. **Red Hat OpenShift** is an enterprise container application platform that is based on a core of **Docker** container packaging, **Kubernetes** container cluster management and the **OpenShift Origin** project itself.\n\nFirst, having more than one option sounds confusing, but they clearly differentiate from each other. Here is the summary of all available deployment models to start with OpenShift.\n\n- [**OpenShift Origin**](https://www.openshift.org/) is a distribution of Kubernetes optimized for continuous application development and multi-tenant deployment. Origin is open source and all source code for the Origin project is available under the Apache License v2.0 on GitHub. Website and documentation for the Origin project are under [www.openshift.org](https://www.openshift.org/). It is completely free, you can deploy Origin on baremetal, in a VM or on a cloud. This is the option I will focus on this article.\n- [**OpenShift Online**](https://manage.openshift.com/) is Red Hat’s public cloud application development and hosting service. Starter plan is free to use and includes 1 project, 1GiB memory, 1GiB terminating memory and 1GiB storage. Pro Plan costs $50/month and includes 10 projects, 2GiB memory, 2GiB terminating memory and 2GiB storage. Details are available [here](https://www.openshift.com/pricing/index.html).\n- [**OpenShift Dedicated**](https://www.openshift.com/dedicated/index.html) is Red Hat’s managed private cluster offering, built around a core of application containers powered by Docker, with orchestration and management provided by Kubernetes, on a foundation of Red Hat Enterprise Linux. It’s available on the Amazon Web Services (AWS) and Google Cloud Platform (GCP) marketplaces. A complete OpenShift 3 cluster, configured for high availability (HA) with a minimum of 5 masters, infrastructure nodes and 4 application nodes managed by Red Hat costs $48k. Details are available [here](https://www.openshift.com/dedicated/index.html#pricing).\n- [**OpenShift Container Platform**](https://www.openshift.com/container-platform/index.html) (formerly OpenShift Enterprise) is Red Hat’s on-premise private PaaS product.\n\nIn this blog post, I will focus on configuring **OpenEBS** as a **persistent storage** option on the open-source self-managed **OpenShift Origin** and deploy a stateful workload both from CLI and custom catalog template using OpenEBS storage classes.\n\n## Prerequisites\n\n### Hardware\n\n- Minimum two nodes. Recommended four or more (Baremetal, VMs or cloud instances)\n\n### Software components used\n\n- [CentOS 7.x](https://www.centos.org/download/)\n- [OpenShift Origin 3.7+](https://github.com/openshift/origin)\n- [OpenShift-Ansible](https://github.com/openshift/openshift-ansible) (master branch used for installation)\n- [OpenEBS 0.5.1](https://openebs.io/)\n\n**Note:** Make sure the following package dependencies are installed: python, wget, git, net-tools, bind-utils, iptables-services, bridge-utils, bash-completion, kexec-tools, sos, psacct, docker-1.12.6, ansible, pyOpenSS, httpd-tool\n\n### Install OpenShift Origin\n\nFollow instructions from [OpenShift Origin Latest Documentation](https://docs.openshift.org/latest/welcome/index.html) to deploy a multi-node Origin cluster. If you are deploying it for the first time it may be a bit complicated. I plan to post my notes, steps on getting minimum requirements satisfied and have a successful deployment after this post.\n\n### Verify OpenShift Origin deployment\n\nExecute the following commands to verify successful installation.\n\n```\n# oc get nodes\n```\n\nNumber of nodes you see maybe different in your case, but status should looks similar to below showing nodes ready.\n\n```\n# oc get nodes\n NAME STATUS AGE VERSION\n oonode1 Ready 2d v1.7.6+a08f5eeb62\n oonode2 Ready 2d v1.7.6+a08f5eeb62\n oonode3 Ready 2d v1.7.6+a08f5eeb62\n oonode4 Ready 2d v1.7.6+a08f5eeb62\n```\n\n### Configure access permissions\n\nCreate a new admin user with cluster-admin role/permissions and assing password using the following commands:\n\n```\n# oc adm policy add-cluster-role-to-user cluster-admin admin — as=system:admin\n# htpasswd /etc/origin/master/htpasswd admin\n```\n\nLogin as the `admin` user and you will be using default project.\n\n```\n# oc login -u admin\n```\n\nOutput:\n\n```\n# oc login -u admin\n Authentication required for https://oonode1:8443 (openshift)\n Username: admin\n Password:\n Login successful.\nYou have access to the following projects and can switch between them with ‘oc project <projectname>’:\n* default\n kube-public\n kube-service-catalog\n kube-system\n logging\n management-infra\n openshift\n openshift-ansible-service-broker\n openshift-infra\n openshift-node\n openshift-template-service-broker\n openshift-web-console\nUsing project “default”.\n```\n\nProvide access to the host volumes which is needed by the OpenEBS volume replicas by updating the default security context (scc). If you miss this step your replicas will fail to deploy.\n\n```\n# oc edit scc restricted\n```\n\nNow set `allowHostDirVolumePlugin: true` and save changes. The file should look like below:\n\n```\n# Please edit the object below. Lines beginning with a ‘#’ will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\nallowHostDirVolumePlugin: true\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegedContainer: false\nallowedCapabilities: []\nallowedFlexVolumes: []\napiVersion: v1\ndefaultAddCapabilities: []\nfsGroup:\ntype: MustRunAs\ngroups:\n— system:authenticated\nkind: SecurityContextConstraints\nmetadata:\nannotations:\nkubernetes.io/description: restricted denies access to all host features and requires\npods to be run with a UID, and SELinux context that are allocated to the namespace. This\nis the most restrictive SCC and it is used by default for authenticated users.\ncreationTimestamp: 2018–01–20T19:39:18Z\nname: restricted\nresourceVersion: “68274”\nselfLink: /api/v1/securitycontextconstraints/restricted\nuid: 9abddec5-fe19–11e7–8d06–005056873c08\npriority: null\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities:\n— KILL\n— MKNOD\n— SETUID\n— SETGID\nrunAsUser:\ntype: MustRunAsRange\nseLinuxContext:\ntype: MustRunAs\nsupplementalGroups:\ntype: RunAsAny\nusers: []\nvolumes:\n— configMap\n— downwardAPI\n— emptyDir\n— hostPath\n— persistentVolumeClaim\n— projected\n— secret\n```\n\nSave changes.\n\n### Install OpenEBS on Origin\n\nThere are few easy ways to install OpenEBS. You can either apply the operator and storageclasses direct from the URL or clone the repo and execute from the local copy. I prefer to clone a local copy, but i’ll also give you the other option if you prefer.\n\nClone the latest OpenEBS files and sample application specs using the below command on your OpenShift master node:\n\n```\n# git clone https://github.com/openebs/openebs.git\n# cd openebs/k8s\n```\n\nApply the file two yaml files below:\n\n```\n# oc apply -f openebs-operator.yaml\n# oc apply -f openebs-storageclasses.yaml\n```\n\nAlternative way — If you choose not to copy from the repo you can apply the yaml file direct from the URL below:\n\n```\noc apply -f https://openebs.github.io/charts/openebs-operator.yaml\n```\n\n### Verify OpenEBS deployment\n\nVerify that the OpenEBS provisioner and API server are created successfully and running.\n\n```\n# oc get deployments\nNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nmaya-apiserver 1 1 1 1 2d\nopenebs-provisioner 1 1 1 1 2d\n```\n\nCheck pods to confirm maya-apiserver and openebs-provisioner.\n\n```\n# oc get pods\nNAME READY STATUS RESTARTS AGE\ndocker-registry-1-b5r7t 1/1 Running 0 2d\nmaya-apiserver-3053842955-xbx8w 1/1 Running 0 2d\nopenebs-provisioner-2499455298–46brm 1/1 Running 0 2d\nregistry-console-1-mrpc9 1/1 Running 0 2d\nrouter-1-bf775 1/1 Running 3 2d\n```\n\nCheck services to confirm maya-apiserver exists.\n\n```\n# oc get service\nNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE\ndocker-registry 172.30.113.229 <none> 5000/TCP 2d\nkubernetes 172.30.0.1 <none> 443/TCP,53/UDP,53/TCP 2d\nmaya-apiserver-service 172.30.17.113 <none> 5656/TCP 2d\nregistry-console 172.30.148.98 <none> 9000/TCP 2d\nrouter 172.30.229.239 <none> 80/TCP,443/TCP,1936/TCP 2d\n```\n\nCheck service accounts for openebs-maya-operator:\n\n```\n# oc get sa\nNAME SECRETS AGE\nbuilder 2 2d\ndefault 3 2d\ndeployer 2 2d\nopenebs-maya-operator 2 2d\nregistry 3 2d\nrouter 2 2d\n# oc get clusterrole openebs-maya-operator\n\\NAME\nopenebs-maya-operator\n# oc get clusterrolebindings openebs-maya-operator\nNAME ROLE USERS GROUPS SERVICE ACCOUNTS SUBJECTS\nopenebs-maya-operator /openebs-maya-operator default/openebs-maya-operator, default/default\n```\n\nAnd finally verify OpenEBS default storage classes.\n\n```\n# oc get sc\nNAME TYPE\nopenebs-cassandra openebs.io/provisioner-iscsi\nopenebs-es-data-sc openebs.io/provisioner-iscsi\nopenebs-jupyter openebs.io/provisioner-iscsi\nopenebs-kafka openebs.io/provisioner-iscsi\nopenebs-mongodb openebs.io/provisioner-iscsi\nopenebs-percona openebs.io/provisioner-iscsi\nopenebs-redis openebs.io/provisioner-iscsi\nopenebs-standalone openebs.io/provisioner-iscsi\nopenebs-standard openebs.io/provisioner-iscsi\nopenebs-zk openebs.io/provisioner-iscsi\n```\n\nAfter few easy steps we are now ready to deploy workloads on persistent storage provided by OpenEBS. I’ll cover both CLI and Catalog installation through the OpenShift Web Console.\n\n### Install Percona on OpenEBS using OC CLI\n\nUse OpenEBS as persistent storage for a Percona DB deployment by selecting the `openebs-percona` storage class in the persistent volume claim. I will use the sample file available in the openebs repo which I cloned locally in the previous steps.\n\nView the Percona deployment yaml:\n\n```\n# cd openebs/k8s/demo/percona\n# cat demo-percona-mysql-pvc.yaml\n— -\napiVersion: v1\nkind: Pod\nmetadata:\nname: percona\nlabels:\nname: percona\nspec:\ncontainers:\n— resources:\nlimits:\ncpu: 0.5\nname: percona\nimage: percona\nargs:\n— “ — ignore-db-dir”\n— “lost+found”\nenv:\n— name: MYSQL_ROOT_PASSWORD\nvalue: k8sDem0\nports:\n— containerPort: 3306\nname: percona\nvolumeMounts:\n— mountPath: /var/lib/mysql\nname: demo-vol1\nvolumes:\n— name: demo-vol1\npersistentVolumeClaim:\nclaimName: demo-vol1-claim\n— -\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\nname: demo-vol1-claim\nspec:\nstorageClassName: openebs-percona\naccessModes:\n— ReadWriteOnce\nresources:\nrequests:\nstorage: 5G\n```\n\nAs you can see in the yaml file above, `storageClassName` is set to `openebs-percona` which has 2 replicas.\n\nNow, apply the file:\n\n```\n# oc apply -f demo-percona-mysql-pvc.yaml\n```\n\nFinally, verify that Percona is deployed and OpenEBS controller and replica are running:\n\n```\n# oc get pods\nNAME READY STATUS RESTARTS AGE\ndocker-registry-1-b5r7t 1/1 Running 0 2d\nmaya-apiserver-3053842955-xbx8w 1/1 Running 0 2d\nopenebs-provisioner-2499455298–46brm 1/1 Running 0 2d\npercona-1378140207–5q2gb 1/1 Running 0 15mh\npvc-c7a24dc8-ffc7–11e7-a7cd-005056873c08-ctrl-1719480235-xf4t5 2/2 Running 0 15m\npvc-c7a24dc8-ffc7–11e7-a7cd-005056873c08-rep-1550141838-ldm59 1/1 Running 0 15m\n```\n\n### Install MongoDB on OpenEBS using the OpenShift Web Console\n\nLogin to the OpenShift Web Console using the admin credentials we have created earlier.\n\n![OpenShift Origin](https://cdn-images-1.medium.com/max/800/0*-IbP4t-ZgYZx4qh6.png)\n\nClick on **Add to Project** button and select **Import YAML / JSON**.\n\n![Add to project](https://cdn-images-1.medium.com/max/800/0*FEwbuF146LMi7Zsx.png)\n\nCopy the content of [https://raw.githubusercontent.com/openebs/openebs/master/k8s/openshift/examples/v3.7/db-templates/openebs-mongodb-persistent-template.json](https://raw.githubusercontent.com/openebs/openebs/master/k8s/openshift/examples/v3.7/db-templates/openebs-mongodb-persistent-template.json) file and paste into **Import YAML / JSON** window.\n\n![Import Yaml/JSON](https://cdn-images-1.medium.com/max/800/0*d6b0iSD6JG83ad-N.png)\n\nClick on **Create** button, select **Save template** and click **Continue**.\n\n![Add template](https://cdn-images-1.medium.com/max/800/0*14UvCpI6Gf-Q5Pd2.png)\n\nOn the **Template Configuration** window make sure Storage Class is `openebs-standard` and click on **Create**.\n\n![Template configuration](https://cdn-images-1.medium.com/max/800/0*l_agQ7YUPJnqvKkq.png)\n\n![Add template configuration](https://cdn-images-1.medium.com/max/800/0*K8665fQzu2nIGNZh.png)\n\n![Result](https://cdn-images-1.medium.com/max/800/0*E6Vp2d7hqBWtJpzm.png)\n\nYou have successfully deployed MongoDB on a persistent storage provided by OpenEBS.\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/how-to-install-openebs-on-openshift/)_._\n","slug":"how-to-install-openebs-on-openshift"},{"id":40,"title":"Using OpenEBS as a Kubernetes persistent volume","author":"Jimmy Song","author_info":"Developer Advocate at Ant Financial, CNCF Ambassador, co-founder of ServiceMesher community, blog https://jimmysong.io","date":"10-01-2018","tags":["Kubernetes"," Openebs"," Docker"," Cloud Native"],"excerpt":"OpenEBS is a containerized block storage written in Go for cloud native and other environments which make the data workloads more reliable in Kubernetes.","content":"\n[OpenEBS](https://www.openebs.io/) is a containerized block storage written in Go for cloud native and other environments which make the data workloads more reliable in Kubernetes.\n\nOpenEBS is open sourced by [MayaData](http://www.mayadata.io/) who is a professional containerized storage company formerly known as CloudByte. Their vision is to make data workloads easy to use in Kubernetes across clouds or on premise.\n\nWe know that [EBS](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://amazonaws-china.com/cn/ebs/&usg=ALkJrhhv8rYmHkvvZS_bPmr_Ca1Wj24SnA) (Elastic Block Storage) is available in AWS, persistent block storage for Amazon EC2 to meet the functional and performance requirements of the most demanding applications, and OpenEBS is its open source implementation.\n\n## Introduction\n\nWith OpenEBS, you can treat containers that have persistent data as you would any other common container. OpenEBS itself is also deployed through containers that support Kubernetes, Swarm, Mesos, Rancher orchestration scheduling, and storage services can be assigned to each pod, application, cluster, or container level, including:\n\n- Data persistence across nodes\n- Synchronize data across available zones and cloud vendors\n- Use commercial hardware and container engines to provide highly scalable block storage\n- Integration with the container orchestration engine, the developer’s application can automatically configure OpenEBS\n- Based on CloudByte’s container-based experience in BSD, we provide users with OpenEBS QoS assurance\n\n## Architecture\n\nThe OpenEBS storage controller itself runs in a container. OpenEBS Volume consists of one or more containers that run microservices. This storage controller function is based on a microservices architecture — the data for each volume is provided by its own set of containers, not by a single monolithic storage controller that provides control for multiple volumes at the same time To provide. This is the essential difference between OpenEBS and traditional storage devices.\n\nThe OpenEBS architecture can be divided into Data Plane (Data Plane) and Control Plane (Control Plane) in two parts:\n\n- Data Plane: Provides data storage for applications\n- Control Plane: Managing OpenEBS Volume Containers, which typically uses the functionality of container layout software\n\n## Data plane\n\nThe following figure shows the architecture of OpenEBS deployed on Kubernetes cluster. Among them, the yellow or orange part is the OpenEBS persistent storage volume, created by Kubernetes’ PVs, implemented using iSCSI, and stored on host nodes or in the cloud (such as EBS, GPD, etc.) depending on where your cluster is deployed. The OpenEBS volume is completely independent of the user’s application life cycle to manage, which is Kuberentes PV in the basic idea.\n\n![OpenEBS Cluster - Data Pane](/images/blog/openebs-data-plane.png)\n\nOpenEBS volumes provide persistent storage for containers with resiliency to system failures and faster access to storage, snapshots and backups. In addition, it provides mechanisms for monitoring usage and enforcing QoS policies.\n\nThe disk that stores the data is called the storage backend and can be a host directory, an attached block device, or a remote disk. Each OpenEBS volume contains an iSCSI target container (represented as openebs-vol1 in the previous figure) and one or more replica containers (openebs-vol1-R1 and openebs-vol1-R2).\n\nThe application pod accesses the storage through the iSCSI target container, which copies the data to all of its replicas. In the event of a node failure, the iSCSI target container starts from one of the remaining online nodes and provides data by connecting to the available replica containers.\n\n**Source**\n\nThe implementation of this section consists of two containers:\n\n- [openebs/jiva](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/jiva&usg=ALkJrhhhCfHb4LkQReHbpayqLJwjwdctgw) : storage control functions, including copy logic\n\n- [openebs/gotgt](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/gotgt&usg=ALkJrhgoXb10SL2TVf8_urB_TIfEVSDBxg) : iSCSI target features used by openebs/jiva\n\n## Control plane\n\nThe OpenEBS control plane is also known as maya. The purpose is to create a hyper-converged OpenEBS that is mounted on a container scheduling engine such as Kubernetes, Swarm, Nomad, etc. to extend the storage capabilities provided by a particular container orchestration system.\n\n![OpenEBS Cluster - Control Plane](/images/blog/openebs-control-plane.png)\n\nOpenEBS’s control plane is also based on microservices, and its services can be divided into the following sections:\n\nContainer layout plug-in, used to enhance the function of the strong container layout framework:\n\n- **Kubernetes Dynamic Configuration** : [openebs-provisioner](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/external-storage/tree/master/openebs&usg=ALkJrhjuOf_IBvwR0NC-g734l_p4Ia14hg)\n- **Kubernetes-dashboard** : [openebs-dashboard](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/dashboard&usg=ALkJrhigRmJSDzmVT_NRMupygPwAM5EX9g)\n- **Extended schema** : Kubernetes-based CRDs (custom resource defination) that store OpenEBS-related configuration data\n\nCluster services provide OpenEBS-specific storage intelligence such as:\n\n- **maya-apiserver** : Contains APIs for performing volume operations that translate requests into container-specific system-specific operations\n- **maya-mulebot** : Use the information collected to suggest optimized layout and event handling tips\n- **maya-connect** : Allows monitoring data to be uploaded to `maya-cloud` for further storage access mode analysis\n\nNode Services, which provide OpenEBS-specific storage intelligence that runs with kubelet, such as:\n\n- **maya-agent** : Includes storage management features\n\nBy using prometheus, heapster, grafana and jaegar for these services, you can add monitoring and tracking capabilities.\n\n**Source**\n\n- [openebs / maya](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/maya&usg=ALkJrhgksSLVDOSt9WRSnCdGdaf4nezkyQ) : All of the specific binary code (non-plugins) is stored in this repository, such as `maya-apiserver` , `maya-agent` , `maya-mulebot` , `maya-connect` , `mayactl` and more.\n- [openebs-dashboard](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/dashboard&usg=ALkJrhigRmJSDzmVT_NRMupygPwAM5EX9g) : A branch of the kubernetes-dashboard project that extends storage capabilities.\n- [openebs-provisioner](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/external-storage/tree/master/openebs&usg=ALkJrhjuOf_IBvwR0NC-g734l_p4Ia14hg) : The OpenEBS K8s Provisioner from the Kubernetes incubator project.\n\n## Install OpenEBS on Kubernetes\n\nBelow we will use the way to install OpenEBS operator, you need to make sure you have already installed iSCSI on your node before installation.\n\n## Prerequisites\n\nOpenEBS relies on iSCSI for storage management, so you need to make sure that you have OpenEBS installed on your cluster.\n\n**Note** : If you are using kubeadm, container-mounted kublet, it comes with iSCSI and does not need to be manually installed. For a kubelet installed directly on the bare metal in binary form, you need to install iSCSI yourself.\n\nThe iSCSI (Internet Small Computer System Interface) is a TCP / IP-based protocol used to establish and manage interconnections between IP storage devices, hosts and clients, and to create storage area networks (SANs ). The SAN makes it possible for the SCSI protocol to be used in high-speed data transmission networks, with block-level data transfer between multiple data storage networks. The SCSI architecture is based on C/S mode and is typically used in environments where devices are close to each other and these devices are connected by a SCSI bus.\n\nOpenEBS needs to use iSCSI as a storage protocol, and CentOS default does not have iSCSI installed, so we need to manually install.\n\nThere are two types of roles in iSCSI:\n\n- **target** : used to provide storage (server)\n- **initiator** : use the stored client (client)\n\nThe following figure in Kubernetes uses iSCSI architecture (Source: [http://rootfs.github.io/iSCSI-Kubernetes/)](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=http://rootfs.github.io/iSCSI-Kubernetes/%25EF%25BC%2589&usg=ALkJrhgk4iuBd1pHB1zGq6XKLwffkSGZew)\n![](/content/images/2020/01/iscsi-kubernetes.png)iSCSI-Kubernetes\nInstalling the iSCSI service is very simple, you do not need additional configuration, just start the service after installation.\n\nExecute the following command on each node node:\n\n```\nyum -y install iscsi-initiator-utils systemctl enable iscsid systemctl start iscsid\n```\n\n## Quick start\n\nRun the OpenEBS service using Operator:\n\n```\nwget https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-operator.yaml kubectl apply -f openebs-operator.yaml\n```\n\nUse the default or custom storageclass:\n\n```\nwget https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml kubectl apply -f openebs-storageclasses.yaml\n```\n\nMirror used are:\n\n- openebs/m-apiserver: 0.5.1-RC1\n- openebs/openebs-k8s-provisioner: 0.5.1-RC2\n- openebs/jiva: 0.5.1-RC1\n- openebs/m-exporter: 0.5.0\n\n## Test\n\nLet’s use the Example from the official OpenEBS documentation to install the Jenkins test:\n\n```\nwget https://raw.githubusercontent.com/openebs/openebs/master/k8s/demo/jenkins/jenkins.yml kubectl apply -f jenkins.yml\n```\n\nCheck PV and PVC\n\n```\n$ kubectl get pv\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\npvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0 5G RWO Delete Bound default/jenkins-claim openebs-standard 1h\n$ kubectl get pvc kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\njenkins-claim Bound pvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0 5G RWO openebs-standard 1h\n```\n\nView Jenkins pod:\n\n```\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 29m (x2 over 29m) default-scheduler PersistentVolumeClaim is not bound: \"jenkins-claim\" (repeated 3 times) Normal Scheduled 29m default-scheduler Successfully assigned jenkins-668dfbd847-vhg4c to 172.20.0.115 Normal SuccessfulMountVolume 29m kubelet, 172.20.0.115 MountVolume.SetUp succeeded for volume \"default-token-3l9f0\" Warning FailedMount 27m kubelet, 172.20.0.115 Unable to mount volumes for pod \"jenkins-668dfbd847-vhg4c_default(8e2ad467-f1e5-11e7-aa47-f4e9d49f8ed0)\": timeout expired waiting for volumes to attach/mount for pod \"default\"/\"jenkins-668dfbd847-vhg4c\". list of unattached/unmounted volumes=[jenkins-home] Warning FailedSync 27m kubelet, 172.20.0.115 Error syncing pod Normal SuccessfulMountVolume 26m kubelet, 172.20.0.115 MountVolume.SetUp succeeded for volume \"pvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0\" Normal Pulling 26m kubelet, 172.20.0.115 pulling image \"sz-pg-oam-docker-hub-001.tendcloud.com/library/jenkins:lts\" Normal Pulled 26m kubelet, 172.20.0.115 Successfully pulled image \"sz-pg-oam-docker-hub-001.tendcloud.com/library/jenkins:lts\" Normal Created 26m kubelet, 172.20.0.115 Created container Normal Started 26m kubelet, 172.20.0.115 Started container\n```\n\nStart up successful. The Jenkins configuration uses **NodePort** mode access and now accesses the NodePort of Jenkins service for any node in the cluster.\n\n## Reference\n\n- [OpenEBS Documentation](http://openebs.readthedocs.io/)\n- [CentOS 7.x 下配置 iSCSI 网络存储](http://blog.csdn.net/wh211212/article/details/52981305)\n- [Configure iSCSI Initiator](https://www.server-world.info/en/note?os=CentOS_7&p=iscsi&f=2)\n- [https://www.openebs.io/](https://www.openebs.io/)\n- [https://github.com/openebs/openebs](https://github.com/openebs/openebs)\n- [Data Scientists adopting tools and solutions that allow them to focus more on Data Science and less on the infrastructure around them](https://blog.openebs.io/data-scientists-adopting-tools-and-solutions-that-allow-them-to-focus-more-on-data-science-and-less-db9654063bd5)\n- [RHEL7: Configure a system as either an iSCSI target or initiator that persistently mounts an iSCSI target.](https://www.certdepot.net/rhel7-configure-iscsi-target-initiator-persistently/)\n\nOriginal page: [https://jimmysong.io/posts/using-openebs-as-kubernetes-persistent-volume/](https://jimmysong.io/posts/using-openebs-as-kubernetes-persistent-volume/)\n\nTranslated from Chinese to English by Google Translate\n","slug":"using-openebs-as-a-kubernetes-persistent-volume"},{"id":41,"title":"In 2018 - IT dreams deferred finally achieved?","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"09-01-2018","tags":["Containerization"," Docker"," Kubernetes"," Openebs"," Storage"],"excerpt":"At MayaData, we believe we, and others are building the foundation for a much longer cycle of software-centric innovation thanks to proactively eliminating sources of lock-in.","content":"\n# **_…..Dreams deferred_**\n\nMany of us in the infrastructure business have been forced by experience to lower our expectations of what is possible. While we’ve all dreamed for decades of a world in which software just works — and delivers value where and how it is needed — we’ve been disappointed again and again.\n\nWe have seen open systems that, over time, became increasingly proprietary with Unix diverging into proprietary camps.\n\nWe’ve seen SQL go from a fascinating research project to a broadly deployed standard to, with the help of stored procedures and truly nefarious licensing, a source of lock-in dominated by one company and one eccentric multi-billionaire.\n\nWe’ve seen a vision of Java as a cross infrastructure abstraction layer bloom and wither.\n\nAnd of course, we’ve seen virtual machines offer the promise of cross infrastructure mobility only to fall prey to the rest of the stack and proprietary business models and incorrect levels of abstraction.\n\nOver time the result has been infrastructure by silos, with each silo — security, storage, networking and compute — dominated by proprietary solution providers that over time sought to provide the entire stack to drive up their sales, even if doing so meant increasing the friction for users seeking to combine best of breed solutions.\n\n# **_On the other hand…._**\n\nAll along technological progress has continued. Allowing for new possibilities.\n\nWe’ve even seen — finally — broadband make its way into the United States so that more and more we can cost effectively access the cloud (yes, the loss of net neutrality seems to put this at risk for at least consumers and new entrants).\n\nAnd intra data center networking has gotten insanely fast — which is crucial if we are to run workloads in a flexible manner.\n\nAnd arguably the best example of innovation at scale in modern business — Amazon — focusing on the right persona — the developer — and raising the bar massively for all of us in infrastructure.\n\nAnd perhaps most importantly, the Open Source community, which as Richard Stallman and others have pointed out predates the commercial software world and which some have called the world’s first social network, grew to become an undeniable force.\n\nAnd pulling all the positive forces together — DevOps and microservices. DevOps as a cultural movement and approach to building and running software at scale PLUS an emerging understanding of how to run systems via microservices as explained by the [12 factor approach](https://www.12factor.net/) and elsewhere led to countless examples of “software eating the world.”\n\n# **But …. What about lock-in?**\n\nSo as the above suggests, one theme in the story of innovation in IT over the years has been breakthrough technologies, and business models, enabling fundamentally better software delivered more easily to users. And as one approach came to predominate, proprietary approaches over time led to more “rent seeking”, where leading vendors extracted more value from their users and slowed their innovation. And this stagnation leads to pent up demand for better approaches — triggering the next cycle.\n\nWell — what about this time?\n\nKubernetes has emerged in part because it promises a world more free from lock-in to AWS and other clouds. Could it be that we have collectively learned enough from all the boom and bust cycles to know what is good for us?\n\nCould be — the signs are incredibly promising as all the cloud vendors and RedHat and Cloud Foundry and Docker and Mesos have all embraced Kubernetes as the standard control plane. This means that you are no longer locked-in by the control plane logic and should be able to move your applications from cloud to cloud and from on premise to off. Crucially — Kubernetes itself is open source and all the major vendors have pledged to not fork it; so it shouldn’t be _too_ bad to move from one vendor supporting Kubernetes to another.\n\n_…. but what about data?_ Without data mobility all you can move is the stateless components of your applications — provided you address having those components able to access your store of state.\n\n# **And your data remains largely locked-in**\n\n_Locked into_ proprietary vendors.\n\n_Locked into_ underlying systems that are sources of risk and that themselves are resolutely monolithic.\n\nI harken back to a speech Randy Bias gave at one of the OpenStorage summits I helped host back in 2010 about `blast radius`. The basic idea is that microservices dramatically reduce the blast radius of any single outage; conversely putting all your state in a shared storage system is, by comparison, an anti-pattern. When your shared storage dies or slows down unexpectedly perhaps due to a rebalancing, so does your entire environment. So much for being built for failure!\n\nS3 for non performant data and EBS for performant data have become defacto standards. They are easy, they “just work”, and — crucially — they put the responsibility for the configuration, care and feeding of state in the hands of the teams that also control the microservices.\n\nThe only problem is that it is _hard_ to move your data from these AWS services to other solutions without a lot of work that frankly software development teams don’t have the time or inclination to invest. I see the lock-in that results as the TBs pile up treated much as technical debt is treated — it is annoying and yet it is much less important than getting valuable capabilities in the hands of end users.\n\nAnd putting all your data in a scale-out software solution running on these clouds only makes the issue worse. Now you have the blast radius issue and you have your data stored in a solution that cannot be stretched across clouds. Two sources of lock-in and at least twice the effort!\n\nIt might be worth remembering that networking, security and compute are all becoming both infrastructure services delivered as services **to** today’s microservice environments and **are themselves also microservice based services**. Take a look at Project Calico for instance. Or at Kubernetes itself.\n\n**Nobody says — hey, Kubernetes is just a black box that sits to the side and so it needn’t be a bunch of microservices. But not storage. Storage somehow gets a pass. It gets to live with aged architectures and typically aged business models.**\n\n## Which raises the question: What if storage was itself delivered as microservices and orchestrated by Kubernetes?\n\nFor the purpose of this exercise, **assume** it were possible to make storage a set of capabilities delivered as microservices with the controller running on containers.\n\nYou’d probably agree that such an approach would have some benefits including:\n\n**Familiarity:**\n\n- If storage is delivered as microservices within Kubernetes then if you know how to run Kubernetes then you know how to run the storage.\n- Perhaps more importantly, you are familiar with the failure domain. You lose a storage controller — well, you just lost a stateless container that itself simply provides services and pointers towards the underlying data. Your data is always safe in multiple locations and your storage system itself is resilient (at least the way OpenEBS is architected with the use of atomic transactions).\n\n**Granularity:**\n\n- As mentioned above, the defacto standard approach to delivering storage is to use AWS itself with each team organized around one or more microservices having their own approach to EBS for performant storage and S3 for blobs of data.\n- Using a shared storage system runs counter to this approach and cuts these teams out of the loop. They are back to lobbying central IT as one of hundreds or even thousands of workloads with particular desires as to how storage should be configured. And, yes, those configurations matter. And, actually, they are impossible to get right. We’ve talked about that in the past including at Meet-ups: [https://www.slideshare.net/MattBaldwin3/containerized-storage-for-containers-why-what-and-how-openebs-works](https://www.slideshare.net/MattBaldwin3/containerized-storage-for-containers-why-what-and-how-openebs-works)\n\n![What move the data and configs next to the app](/images/blog/what-move-the-data-and-configs-next-to-the-app.png)\n\n**Performant:**\n\n- This being a storage blog, it is worth reiterating the point that shared storage is inherently less performant these days than direct attached or DAS. That is a fairly new reality. It used to be that DAS was really slow disk and the way to get IOPS was to stripe across a bunch of faster disks. That was a primary driver for shared storage. Imagine that — at one time CEPH would have been faster than the underlying hardware! How times have changed.\n- Our CTO, Jeffry Molanus does a good job walking through how the landscape of performance has changed why this and other changes now favor what we call “container attached storage”:\n- [https://blog.openebs.io/not-yet-another-distributed-storage-system-57ee9220c409](https://blog.openebs.io/not-yet-another-distributed-storage-system-57ee9220c409)\n\n**Natively cross cloud — with the help of metadata and routing services:**\n\n- What is perhaps least well appreciated about the potential of treating storage as a service delivered via microservices is that, correctly engineered, this means that data itself can be served as a service in the background across underlying clouds.\n- The first prerequisite is that the controller itself runs in a container or set of containers.\n- The second prerequisite is that the controller performs its magic in the user space so that the container does not need to be a special build and so that the system can perform.\n- Third, there needs to be the management of metadata to see where the data is versus the workloads. Kubernetes can help here as it expands however in addition a solution such as MayaOnline.io — as it matures — is needed. This service acts as an air traffic controller, helping the data to get to where it is needed. Such a service can also become more intelligent over time, for example suggesting improvements to Kubernetes storage policies based on success in running similar workloads.\n\n# **TL;DR:**\n\nSo, in short, this time perhaps it really _is_ different.\n\nThis time we “won’t get fooled again” (gratuitous old guy music reference :)).\n\nThis time we _will_ address the sources of lock-in not just at the controller plane via Kubernetes but also at the data layer. And in so doing we will avoid ending the the cycle of innovation prematurely. Perhaps it goes without saying — only an open source solution like OpenEBS that is widely accepted and easy to fork if needed can help free us from the risk of cloud lock-in without adding yet another source of lock-in.\n\nAnd we can address lock-in while respecting and extending the patterns we know are working including: every team controlling their infrastructure themselves, the elimination of single points of failure (aka “storage blast radius”), and allowing Kubernetes to control more and more of the environment, leaving the developers to focus on capabilities that add value to their end users.\n\nIn short, at MayaData we believe we and others are building the foundation for a much longer cycle of software-centric innovation thanks to proactively eliminating sources of lock-in.\n\nPlease help this reality come true by providing us feedback on [OpenEBS](http://www.openebs.io/) and [MayaData](http://www.mayadata.io/) or see us on the Kubernetes storage SIG where we are trying to be helpful as well.\n","slug":"in-2018-it-dreams-deferred-finally-achieved"},{"id":42,"title":"Austin KubeCon — Persistent Storage Round-up and Looking beyond!","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"08-01-2018","tags":["Kubecon"," Kubernetes"," Persistence"," Storage Containers"," Updates"],"excerpt":"Kubernetes Clusters are up and running at the push of a button or even better by talking to your favorite bot.","content":"\nTL;DR\n\nThis rather has become a long post as I drafted it and incorporated feedback from community members. So, in short:\n\n- 2017 saw Kubernetes being crowned as the de-facto container orchestration engine. And from the storage perspective, containerized storage makes its presence felt.\n- 2018 — The reign of Kubernetes continues. Containerized Storage gains momentum with renewed focus on manageability of persistence workloads\n\n—\n\nKubernetes Clusters are up and running at the [push of a button](https://twitter.com/muratkarslioglu/status/941399154714066944) or even better by [talking to your favorite bot](https://www.youtube.com/watch?v=07jq-5VbBVQ).\n\n![](https://cdn-images-1.medium.com/max/800/1*oz5esyJvsb5zBIaoyDKUeQ.png)\n\nsource: Containerized Storage for Containers — session at Kubernetes Meetup [https://t.co/tdQaOue5w8](https://t.co/tdQaOue5w8)\n\nBut just about a year ago when we started envisioning OpenEBS — Containerized Storage for Containers — to be orchestrated by Kubernetes, setting up a cluster took a good three days. Phenomenal progress by the Kubernetes Community in 2017 — from Kubernetes — the Hard-Way to making it Child’s play!\n\nIf you were at KubeCon, you would have definitely been caught up in or at least glimpsed the Euphoria around Kubernetes. Kubernetes, almost feels like Noah’s Ark right now — you are either in or wait to perish. A little exaggerated, I know, but only a little.\n\n_Every Technology and Cloud Service Provider are now providing or planning to provide a container service using Kubernetes and almost every infrastructure provider is looking at putting themselves on the map of Kubernetes._\n\n![](https://cdn-images-1.medium.com/max/800/1*YJIF6xBEPL1WpVgOK4VV0Q.png)[https://raw.githubusercontent.com/cncf/landscape/master/landscape/CloudNativeLandscape_latest.png](https://raw.githubusercontent.com/cncf/landscape/master/landscape/CloudNativeLandscape_latest.png)\n\nAnd why not!\n\nKubernetes has reached the level of maturity that can be used with ease in controlled environments and at the same time, has gained tremendous strength from a community that is not afraid to re-engineer or re-architect the core components. The popularity of Kubernetes is enabling many meta-kubernetes projects like — kubespray, stackpointcloud, kubeless, heptio ksonnet, heptio ark,etc. And with these new projects and possibilities, many _Kubernetes — blue ocean — companies are on the rise!_\n\n—\n\nI am very bullish that Kubernetes is that magical ingredient that will renew the focus on HumanOps!\n\nOne inevitable aspect of being an infrastructure operations admin is to be prepared for smooth operations, scaling, maintaining and recovering from faults and disasters — which usually tend to put a lot of unwarranted pressure on the admins when dealing with their own management (business impact) and the vendors whose technology they used to build a “black-box” infrastructures. A “black-box” infrastructure that doesn’t comply to what they were told and assumed would do — and involves talking to people building those black-boxes often crossing company borders, leading into non-technical calls about blaming who is at fault. Such stressful conditions also exist within an organizations where there is crunch for resources.\n\nKubernetes and the meta-kubernetes projects are helping administrators build — what I call “white-box” infrastructures. Often professed and hardly-prevailed aspect of Infrastructure is the [_HumanOps_](https://blog.serverdensity.com/humanops/) _— \"_ technology affects the well being of humans just as humans affect the reliable operation of technology *\"* — which can be achieved by building “white-box” infrastructures that are easy to operate and reduce the dependency on specialists that tend to be over-worked in an organization. _The “white-box” infrastructures are built with API-driven Open Source Micro-Services._\n\nThe key to the widespread adoption of Kubernetes in such a short time is the inclusive nature of it, which was well captured by this slide from the KubeCon:\n\n![Extensibility](https://cdn-images-1.medium.com/max/800/1*IXods_RnXRco2z7UcngePw.png)\n\n[https://schd.ws/hosted_files/kccncna17/ac/KubeCon_2017\\_-_Kernels_and_Distros.pdf](https://schd.ws/hosted_files/kccncna17/ac/KubeCon_2017_-_Kernels_and_Distros.pdf)\n\n### **_Kubernetes is more than an orchestration engine → It is the new kernel for building clustered infrastructures._**\n\nI consider this shift towards making Kubernetes a Kernel that can be extended by custom solutions that can be downloaded and installed as a true enabler for driving innovation — which is inline with the Psyche of keeping “Community First and Company Next!”.\n\n—\n\nThis past year, saw the rise in user awareness for securing Containers. Different teams started tackling this issue from different perspectives — from providing secure container runtime like Kata Containers to using different types of Service Meshes to better access control and more.\n\nService Mesh was definitely a buzzword in 2017! The options — linkerd, envoy, istio and conduit — all of which are (or will be) accepted into CNCF sooner or later, provide a glimpse of interesting trend. For instance, [conduit](https://buoyant.io/2017/12/05/introducing-conduit/) is from the same team that built Linkerd. Conduit provides similar capabilities like Linkerd for managing the communication between micro-services, but seems better suited for Kubernetes environment that can run across clouds and with low resource constraints.\n\nLike Service Mesh, the other infrastructure components — logging, monitoring, tracing, and networking are all being containerized (re-engineered) to work well with Kubernetes primitives (resources, pods, policies, federations, labels, taints, tolerations, affinity and anti-affinity, CR, CRDs, Custom Controllers, etc.)\n\n### **_Kubernetes has become a powerful set of nuts and bolts, that is changing the way people should think about infrastructures and how systems are built._**\n\n—\n\nStorage is no different. How data is stored and managed is also being transformed by the possibilities afforded by Kubernetes. Like Service Mesh of initial days, a lot of incumbent storage vendors are providing a patched (which some view as cloud washed or container plugged) solutions that will result in operations and developers spending endless hours firefighting to make them work with cloud native environments.\n\nThe key for any infrastructure component to be called container native will be characterized by being hardware agnostic and usable at scale! The past few months, there is an active workgroup team grappling with defining — [_Cloud Native Storage (WIP White Paper by CNCF Storage Workgroup)_](https://docs.google.com/document/d/1cJLgOAIWbi-Ya27BY7mjH61yoO3oWcO5tOZYteaDVgI/edit#heading=h.ik4inq9mv6b4)\n\nWhile deliberations are ongoing about what Cloud Native Storage is, which I think will finally be about users adoption, the talks at KubeCon suggest the community sees three distinct storage options for Kubernetes:\n\n- Persistence Volumes from External Storage Providers\n- Local/Ephemeral Storage for Containers\n- Containerized Storage for Containers\n\n—\n\n**Persistence Storage from External Storage Providers**\n\nMost of the cloud providers and incumbent storage vendors want the users to opt for this option where storage is connected via in-tree or out-of-tree dynamic volume provisioners. Many vendors are coming together in helping shape the CSI [(Container Storage Interface)](https://github.com/container-storage-interface/spec), and the initial implementation are slated to get into beta stage in early 2018. There are constant improvements — or strides — being made in storage workflow automation via controllers and `kubectl` — dynamically provisioning volumes, resizing, and snapshots.\n\nI spoke to a number of storage users at KubeCon, including the team at GitHub who are at the forefront of putting Kubernetes in production. The users are still very wary with the state of storage w.r.t using the PVs to connected storage and the amount of work involved in rewriting their operational scripts and playbooks.\n\nAnother issue I heard users talk about that puts them off NAS or SAN — and this was a little surprising as I’ve spent years building a unified storage system that in some environments is really fundamental to the architectures of private clouds and hosting environments — is that they think shared underlying storage does not fit a microservices architecture. Of course if you read the 12 Factor definition it talks about storage if at all as an attached resource. However — it also is clear from 12 Factor approaches that _dev should be the same as possible as production and that the same people should be doing coding and deploys._ That’s just not the world of external arrays with special teams running storage and different arrays for dev, test, staging and production.\n\nIt is also worth noting and taking time to understand that these options of connecting to network storage have been around for more than couple of years, and the fact that Stateful workloads on Kubernetes aren’t yet as prevalent says something about user acceptance of the approach! _Users are waiting for better options to be made available — like the support for local storage or something else — but not NAS!_\n\nLearning from the HBO team that was streaming GoT using Kubernetes, it is interesting to see a solution like Rook being used on top of EBS, while EBS is provided as PVs themselves.\n\n![Telemetry](https://cdn-images-1.medium.com/max/800/1*Zl5PPYzJpDZoXrK7DCL_0w.png)\n\n[https://www.youtube.com/watch?v=7skInj_vqN0](https://www.youtube.com/watch?v=7skInj_vqN0)\n\nRook also presented a pretty interesting study against using PVs from external storage to Pods in their talk [here](https://schd.ws/hosted_files/kccncna17/b3/Cloud%20storage-2.pdf). This is inline with what the teams at [PortWorx](https://portworx.com/ebs-stuck-attaching-state-docker-containers/), [StorageOS ](https://schd.ws/hosted_files/kccncna17/ca/2017-12-8-persistent-storage.pdf)and OpenEBS have been advocating as well.\n\n- Make static assignments of disks (physical or virtual) to nodes and use them as local storage — avoid detaching/attaching disks from nodes\n- As long as the applications can take care of replication and sustain longer downtime for nodes and cluster rebuilding times — use local PVs with the storage provisioned in the previous steps.\n- For workloads that don’t inherently support replication, snapshots, etc. use a containerized storage option.\n\n_I am a firm believer in CSI and what it was set to achieve and has already accomplished— Open Standard for interfacing with Storage. Something which SNIA should have done and couldn’t do in past two decades of my experience. OpenSDS seems to be an effort in that direction by SNIA, but is being received with the same cold response from vendors and in turn the community. FWIW, REX-Ray is also playing in the same space._\n\nAt the moment, the focus for CSI is on (simplifying a bit) provisioning and de-provisioning volume, but albeit a good start. But is it enough for the users to start using it? There was an interesting observation made in the F2F storage workgroup meeting at KubeCon that CSI discussions are mostly driven by vendors. Where are the users? Can we say that vendors represent the users, because they interact with their users?\n\nComing from a operational background, for me to consider using CSI to connect with external storage systems, CSI requires to evolve and include API for Day 2+ Operational Usecases that involve — ease of debugging, snapshots, backups, migration and most importantly, a unified monitoring system of the Kubernetes Clusters and the Storage Systems.\n\nDon;t get me wrong. We need storage, lots and lots of it and it will be served from external storage systems — cloud (EBS, GPD, etc., ) or on-premise SAN/NAS products. But these external storage systems weren’t designed to be used for micro-services environment but rather to provide volumes to Nodes (physical or virtual) that are long running and are not subject to rapid connects, disconnects and migrations.\n\n_I believe in the long run we will be using CSI with these external storage for what they were designed for — mainly to provision storage to the nodes rather than Pods._\n\n—\n\n**Local/Ephemeral Storage for containers (aka Direct Attached Storage — DAS)**\n\nKubernetes keeps improving the capabilities for managing the local/ephemeral storage. The recent advancements include:\n\n- Support for attaching [block devices](https://schd.ws/hosted_files/kccncna17/8e/Mitsuhiro_Tanino_Block_Volume_KC_CNC_NA17.pdf) to pods\n- Support for enforcing policies or [resource limits for ephemeral storage](https://schd.ws/hosted_files/kccncna17/3e/Kubecon_localstorage.pdf)\n- Enhance the UX for using [local storage for PVs](https://schd.ws/hosted_files/kccncna17/3c/2017%20Kubecon%20Storage%20-%20FINAL.pdf) — dynamic provisioning, hook into the scheduler for pods requiring local storage PVs etc.,\n\n_When using local storage for PVs, the applications using these PVs need to also own up some of the features like — data consistency, replication, snapshots, etc., that are typically taken care of by the storage controllers._\n\n_One of the ongoing issue with using the local storage in clouds are the quirks of disconnecting and connecting the disks to different instances. The local storage is really meant for using storage that is tied to the node — either physically inserted or hardwired to a VM instance._\n\n—\n\n**Containerized Storage for Containers (aka Container Attached Storage — CAS)**\n\nThe appeal for fully containerized storage for containers is in the possibilities that it opens up to the DevOps administrators who are interested in building on-demand programmable infrastructures, which include:\n\n- storage can be observed down to the bit using the same set of tools they use to monitor their compute and network.\n- storage can also be secured using the same tools used to secure application pods\n- storage can be made policy driven similar to networks\n- storage can be programmed and versioned — made an integral part of the work flows for developers and operations administrators\n- storage can also use federation features for cloud migration similar to application pods.\n\n_StorageOS presented at KubeCon on what we call Container Attached Storage — and on how to select which storage approach for which workload and environment. It was a good talk — slides are here: _[talk](https://schd.ws/hosted_files/kccncna17/ca/2017-12-8-persistent-storage.pdf)\n\n_Kubernetes can provide an unified infrastructure layer to the applications by pooling together nodes with compute, network, and **storage as well**._\n\nKubeCon showcased a demo of launching [glusterfs in containers](https://schd.ws/hosted_files/kccncna17/7b/KubeRunningYourStorage1208.pdf). While this is feasible, it might put some hard requirements on the amount of RAM and CPU required for running the software optimized for running in the nodes in containers.\n\nTo be container native storage, the storage software needs to be broken down into micro-services, just like how Kubernetes runs using micro-services. There has to be greater flexibility provided to the developers and operations to run seamlessly on their choice of hardware!\n\nOpenEBS does just that! OpenEBS provides all the enterprise grade storage features by its open-source containers that can run anywhere. _No kernel dependencies and vendor lock-in._ A typical data path using the OpenEBS Containers is as follows:\n![](https://cdn-images-1.medium.com/max/800/1*Ifsa-k-q4EnO7Fpg7E6jLA.png)\n\n[https://github.com/openebs/openebs/blob/master/contribute/design/OpenEBS%20Architecture%20and%20Design.pdf](https://github.com/openebs/openebs/blob/master/contribute/design/OpenEBS%20Architecture%20and%20Design.pdf)\n\nOpenEBS can consume any storage connected to the node and provide enterprise grade storage features (like snapshots, replication, data-consistency, cross-cloud migration, etc.) to Stateful workloads.\n\n2017 saw a steep rise in the community for building OpenEBS with users evaluating it for different types of storage workloads from Cassandra, Minio to MySQL and some users also rolling out services to their customers using Kubernetes and OpenEBS. _I am looking forward to more application work-flow focused automation of Stateful workloads using OpenEBS in 2018._\n\n—\n\nManaging Storage in an enterprise environment — whether it is cloud or on-premise has to be as seamless as interacting with your favorite bot! I know it is a bit far fetched, but it is definitely going to happen in 2018 with companies like MayaData leading from the front!\n\n2017 saw some major improvements to storage in Kubernetes, but there is a lot more to look forward to in 2018!\n\n- CSI spec will mature to encompass all the storage API and will be adopted by a large percentage of storage vendors.\n- Improved debuggability/observability of PV — Metrics and Alerts etc.\n- Make PVs accessible via namespaces and RBAC and extend the Policies to involve HumanOps!\n- Further improvements to resource constraints from the IOPS perspective\n- Support for host-supported file system types to be used on top of local storage\n\n_Programmable and Predictable Infrastructures are what the developers need while the administrators are looking for building infrastructures that can be easily versioned, built, and deployed anywhere — where the economics makes sense._\n\n—\n\nI take tremendous pride in having been associated with MayaData team that is at the forefront of making Storage Operations fade away by extending Kubernetes with containerized storage for containers.\n\nYour participation will shape and accelerate the movement of Stateful Workloads on Kubernetes. Do join us on Slack on either [Kubernetes sig-storage](http://slack.k8s.io/) or [OpenEBS users](http://slack.openebs.io/) or join the [CNCF storage events](https://calendar.google.com/calendar/embed?src=linuxfoundation.org_o5avjlvt2cae9bq7a95emc4740%40group.calendar.google.com)!\n\nLooking forward to an exciting 2018 for the Stateful Workloads on Kubernetes!\n","slug":"austin-kubecon-persistent-storage-roundup-and-looking-beyond"},{"id":43,"title":"Install OpenEBS using StackPointCloud Trusted Charts?","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"07-01-2018","tags":["Digital Ocean"," Helm"," Kubernetes"," Solutions"," Stackpointcloud"],"excerpt":"What is StackPointCloud Trusted Charts?","content":"\n#### What is StackPointCloud Trusted Charts?\n\n[StackPointCloud](https://stackpoint.io/) (SPC) introduced a concept of Trusted Charts, a list of validated [Helm](https://helm.sh/) Charts provided by its partners to quickly spin up a solution in a [Kubernetes](https://kubernetes.io/) cluster. Helm Charts helps you define, install, and upgrade even the most complex Kubernetes application.\n\nPreviously, I wrote about few different ways of getting OpenEBS up and running on different cloud vendors. Using Helm Chart is one of the available options to deploy OpenEBS. OpenEBS Helm Charts were available since v.5.0 both on [Github](https://github.com/openebs/openebs/tree/master/k8s/charts/openebs) and as a [packaged chart](https://openebs.github.io/charts/). Recently SPC included OpenEBS into their Trusted Charts repo and made it one-click easy for its customers.\n\nSPC Trusted Charts currently offer 23 solutions including databases, CI/CD, monitoring, storage and ingress solutions. Here is the list of Trusted Charts:\n\n### CI/CD\n\n- [Jenkins](https://jenkins-ci.org/)\n- [Gitlab Runner](https://docs.gitlab.com/runner/)\n- [Spinnaker](https://www.spinnaker.io/)\n\n### Databases\n\n- [CockroachDB](https://www.cockroachlabs.com/)\n- [Crunchy PostgreSQL Operator](https://github.com/CrunchyData/postgres-operator)\n- [Patroni](https://github.com/turbonomic/kubeturbo)\n- [Redis](https://redis.io)\n- [RethinkDB](https://www.rethinkdb.com/)\n- [MongoDB Replica Set](https://docs.mongodb.com/manual/replication/)\n\n### Ingress/Proxy/Load Balancer\n\n- [Nginx Ingress](https://github.com/kubernetes/ingress-nginx)\n- [Traefik](https://traefik.io/)\n\n### Messaging\n\n- [Kafka](https://kafka.apache.org/)\n- [Rabbitmq](https://www.rabbitmq.com)\n\n### Storage\n\n- [OpenEBS](https://openebs.io/)\n- [Minio](https://www.minio.io/)\n- [Etcd-operator](https://github.com/kubernetes/charts/tree/master/stable/etcd-operator)\n\n### Others\n\n- [Grafana](https://grafana.com/)\n- [Keel](https://keel.sh/)\n- [Kube-lego](https://github.com/jetstack/kube-lego)\n- [Kubeturbo](https://github.com/turbonomic/kubeturbo)\n- [Memcached](https://memcached.org/)\n- [Tensorflow Inception](https://github.com/tensorflow/models/tree/master/research/inception)\n\nI’ll go through the quick steps of deploying OpenEBS.\n\n### Prerequisites\n\nMinimum requirements for deploying your Kubernetes clusters on StackPointCloud:\n\n### Cloud Provider Account\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) or\n- [DigitalOcean](https://www.digitalocean.com)\n\n### Deploy a New Kubernetes Cluster\n\nFirst, go to [stackpoint.io](https://stackpoint.io/) and click on **Launch a Cluster** button to start your free trial.\n\n![Universal control plane for managed Kubernetes](https://cdn-images-1.medium.com/max/800/0*0cB3ttYmslFZgH1h.png)\n\nThen choose your cloud provider. In this example, I will use **Digital Ocean**.\n\n![Choose cloud provider](https://cdn-images-1.medium.com/max/800/0*21G24JgfuqlR6snZ.png)\n\n### Configure Access to Digital Ocean\n\nOn the next screen, we need to configure our provider. You need to provide Digital Ocean API Token and optionally your SSH Key.\n\n![Configure your provider](https://cdn-images-1.medium.com/max/800/0*wDcMg-_HTjIOFvgb.png)\n\nClick on **Add API Token** button.\n\n![Add API token](https://cdn-images-1.medium.com/max/800/0*53wGtQ7eUt18u6pS.png)\n\nAfter you add your credentials, click on **Submit**.\n\n### Configure K8s Cluster\n\nOn “Configure your cluster” page click the edit button on **Distribution** and choose **Ubuntu 16.04 LTS**.\n\n![Configure your cluster](https://cdn-images-1.medium.com/max/800/0*NvtnryAA8GNi-fyN.png)\n\nChange the **Cluster Name** something meaningful like **OpenEBS Demo**.\n\n![Enter cluster name](https://cdn-images-1.medium.com/max/800/0*LTa6zBooJdTsyqss.png)\n\nLeave everything else as default and click on **Submit**.\n\nIn about 10–15 minutes you will get your new cluster deployed.\n\n### Adding OpenEBS to Your Kubernetes Cluster\n\nFirst, make sure your cluster and all nodes are up.\n\nOn the **Control Plane** tab click on your recently created cluster.\n\n![Control plane](https://cdn-images-1.medium.com/max/800/0*RHQ9LbyxydjHkJSk.png)\n\nOnce the Kubernetes cluster is up on Digital Ocean with functional Helm, scroll down to the **Solutions** tab and click on **Add Solution** button.\n\n![Add Solution](https://cdn-images-1.medium.com/max/800/0*sH0lzv23vHonV5Zk.png)\n\nClick on **Add Solutions**, and select **Trusted Charts**.\n\n![Select charts](https://cdn-images-1.medium.com/max/800/0*V6iP5PzNAzFk4sME.png)\n\nFrom the list above select **OpenEBS**.\n\n![OpenEBS namespace](https://cdn-images-1.medium.com/max/800/0*CJkPrkJCS9Fp_GXu.png)\n\n**Release Name** is randomly generated every time. If you want to use OpenEBS example workloads provided in OpenEBS repos without any modification then use `default`as **NameSpace**. Otherwise, you need to modify the namespace for workloads you deploy and make sure to use the same name.\n\nClick on **Install** to deploy OpenEBS on your cluster.\n\n**Note:** Default settings assume that RBAC is enabled. If you disabled RBAC while you are configuring your provider previously then set `rbacEnable: false` otherwise use default values.\n\nState field should be green after OpenEBS is successfully added.\n\n![OpenEBS successfully added](https://cdn-images-1.medium.com/max/800/0*HzCZp3Z5LbT3Hsrh.png)\n\nNow your cluster is ready; you can run your workloads on `openebs-standard` and other predefined storage classes.\n\nTo confirm, click on **Kubernetes Dashboard**. This will bring up your Kubernetes Dashboard UI in a new window. You will find all predefined OpenEBS **Storage Classes** here under **Storage Classes** section.\n\n![Kubernetes Storage Classes](https://cdn-images-1.medium.com/max/800/0*mNU-nhwvNy9UB0W5.png)\n\nNow you are ready to deploy your stateful workloads.\n\nTake a look at my previous articles on step-by-step instructions for deploying few popular stateful workloads such as [Cassandra](http://containerized.me/how-to-deploy-a-cassandra-cluster-ring-on-kubernetes-openebs/), [Jenkins](http://containerized.me/how-to-deploy-jenkins-on-kubernetes-openebs/), and [Postgres](http://containerized.me/how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs/) on OpenEBS persistent storage.\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/install-openebs-using-stackpointcloud-trusted-charts/)_._\n","slug":"install-openebs-using-stackpointcloud-trusted-charts"},{"id":44,"title":"How we built multi-tenant ChatOps.. for MayaOnline!","author":"Satyam Zode","author_info":"Go Developer @openebs | Open Source Contributor | Avid Learner","date":"31-12-2017","tags":["Kubernetes"," Slack"," Chatbots"," ChatOps"," Chatbot Design"],"excerpt":"Maya-ChatOps is one of the core areas of MayaOnline, covering the storage operational support of kubernetes clusters.","content":"\n## What is Maya ChatOps?\n\nMaya-ChatOps is one of the core areas of [MayaOnline](https://mayaonline.io/), covering the storage operational support of kubernetes clusters. DevOps developers and admins get the alerts and analytics of their OpenEBS volumes deployed across multi-cloud kubernetes clusters right into their [slack](https://slack.com/) channels. Our vision of ChatOps extend beyond just simply providing alerts and providing a way to query any configuration and status from slack. It goes all the way to interact with DevOps developers and admins to manage the yaml config files in their CI/CD system.\n\n## What is MuleBot ?\n\n![MuleBot](/images/blog/mule-bot.png)\n\nMuleBot is the name of the bot or slack application from Maya. MuleBot is a distributed slack application. MuleBot responds to user’s queries about configuration and status of the OpenEBS volumes. Sometimes, MuleBot tries to surprise you with smart alerts prior to a real situation happens.\n\n## How to use Maya ChatOps?\n\nYou can start using ChatOps by adding Slack integration in MayaOnline. The MuleBot slack application will be installed in your workspace. Subsequent steps involve configuration a single or multiple clusters to the desired slack channel. This mapping is maintained in the MO in the form of a “slack-card”.\n\nYou can add as many slack cards as you want for your clusters. Through this channel you will be able to interact with clusters imported in the MayaOnline.\n\n## What are we using underneath for powering our ChatOps?\n\nWell, this is why I am writing this blog, to tell you the various choices we had and why we ended up with a particular choice. Some of the design goals we kept while choosing the bot framework are:\n\n- Users of MayaOnline will be in thousands to begin with, so, the bot framework has to be multi-tenant\n- The bot has to be a micro service and suitable to run seamlessly on kubernetes\n- The bot framework has to have the NLP AI support for us to get that capability out to the users in the near future\n\nSo, we looked at [Hubot](https://hubot.github.com/), [StackStorm](https://github.com/StackStorm)/errBot and [BotMan](https://botman.io/)\n\nEach one of them had their benefits but none of them were multi-tenant. Then we looked at which is easiest to add the multi-tenant support to, BotMan came surprisingly easy to add this support to. BotMan is thin, and is written as a stateless application. The preliminary approach involved passing the user configuration in environment variables. All it needed was a thin shim to get user-config details dynamically and we had achieved multi-tenancy ! It is that simple.\n\nWe kept a combination of slack **team_id**, **channel-id** as the key of the mulebot to manage the link between the slack user config and MayaOnline user config.\n\n![Chat Ops Architecture](/images/blog/bot-architecture.jpeg)\n\nWith the above design Maya ChatOps allows users to configure different slack channels for different kuberenetes clusters at MayaOline.\n\nNext steps:\n\n- In the coming weeks, we will try to post some example scenarios suggesting how smart our MuleBot can be 😄\n- We plan to extend the BotMan framework to provide Maya ChatOps API. A DevOps developer/admin can use these APIs to integrate better into their CI/CD\n- Currently it is integrated with Slack. PagerDuty is on our horizon.\n","slug":"how-we-built-multitenant-chatops-for-mayaonline"}]