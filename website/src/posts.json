[{"id":1,"title":"Deploying YugabyteDB on Google Kubernetes Engine with OpenEBS","author":"OPENEBS","author_info":"No author information","date":"05-04-2021","tags":["Openebs","OpenSource","Yugabyte","Cloud","Native","Gke"],"content":"\n[OpenEBS](https://www.openebs.io/) is a CNCF project backed by [MayaData](https://mayadata.io/) that provides cloud-native, open source container attached storage (CAS). OpenEBS delivers persistent block storage and other capabilities such as integrated back-up, management of local and cloud disks, and more. For enterprise cloud-native applications, OpenEBS provides storage functionality that is idiomatic with cloud-native development environments, with granular storage policies and isolation that enable cloud developers and architects to optimize storage for specific workloads.\n\nBecause [YugabyteDB](https://www.yugabyte.com/) is a cloud-native, distributed SQL database that runs in Kubernetes environments, it can interoperate with OpenEBS and many other CNCF projects.\n\n***Wait, what is YugabyteDB?** It is an open source, and high-performance distributed SQL database built on a scalable and fault-tolerant design inspired by Google Spanner. Yugabyte’s YSQL API is PostgreSQL wire compatible.*\n\nIn this blog post we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\n\n**Why OpenEBS and YugabyteDB?**\nBecause YugabyteDB is a transactional database often used as a system of record, it needs to be deployed as a StatefulSet on Kubernetes and requires persistent storage. OpenEBS can be used for backing YugabyteDB local disks, allowing the provisioning of large-scale persistent volumes. \n\nHere are a few of the advantages of using OpenEBS in conjunction with a YugabyteDB database cluster:\n\n- There’s no need to manage the local disks as OpenEBS manages them.\n- OpenEBS and YugabyteDB can provision large size persistent volumes.\n- With OpenEBS persistent volumes, capacity can be thin provisioned, and disks can be added to OpenEBS on the fly without disruption of service. When this capability is combined with YugabyteDB, which already supports multi-TB data density per node, this can prove to be[ massive cost savings on storage.](https://docs.openebs.io/features.html#reduced-storage-tco-upto-50)\n- Both OpenEBS and YugabyteDB support multi-cloud deployments [helping organizations avoid cloud lock-in.](https://docs.openebs.io/docs/next/features.html#truely-cloud-native-storage-for-kubernetes)\n- Both OpenEBS and YugabyteDB integrate with another CNCF project, [Prometheus](https://prometheus.io/). This makes it easy to [monitor both storage and the database](https://docs.openebs.io/docs/next/features.html#prometheus-metrics-for-workload-tuning) from a single system.\n\nAdditionally, OpenEBS can do [synchronous replication](https://docs.openebs.io/docs/next/features.html#synchronous-replication) inside a geographic region. In a scenario where YugabyteDB is deployed across regions, and a node in any one region fails, YugaByteDB would have to rebuild this node with data from another region. This would incur cross-region traffic, which is more expensive and lower in performance. But, with OpenEBS, this rebuilding of a node can be done seamlessly because OpenEBS is replicating locally inside the region. This means YugabyteDB does not end up having to copy data from another region, which ends up being less expensive and higher in performance. In this deployment setup, only if the entire region failed, YugabyteDB would need to do a cross-region node rebuild. Additional detailed descriptions of OpenEBS enabled use cases can be found [here.](https://docs.openebs.io/docs/next/usecases.html)\n\nOk, let’s get started!\n\n**Prerequisites**\n![](/images/blog/yugabyte-work-flow.png)\n\n\nUsing the latest and greatest versions of the available software (as of this blog’s writing), below is the environment which we’ll use to run a YugabyteDB cluster on top of a Google Kubernetes Engine (GKE) cluster backed by OpenEBS\n\n1. YugabyteDB - [Version 2.5.3.1](https://docs.yugabyte.com/latest/quick-start/install/)\n2. OpenEBS - [Version 2.7.0](https://github.com/openebs/openebs)\n3. A [Google Cloud Platform](https://cloud.google.com/gcp/) account\n\n**Step 1: Setting Up a Cluster on GKE**\nTo deploy YugabyteDB on the Google Cloud Platform (GCP), we first have to set up a cluster using Ubuntu as our base node image.\n\n***Note**: GKE’s Container-Optimized OS does not come with an iSCSI client pre-installed and does not allow the installation of an iSCSI client. Therefore, we’ll be using the Ubuntu with Docker image type for our nodes.*\n\nFor the purposes of this demo, I used the Google Cloud Console to configure my Kubernetes cluster. Aside from the typical defaults, here’s the options under the* Node Pools > default-pool > Nodes*  I selected\n\n- **Image Type:** Ubuntu with Docker\n- **Series:** N1\n- **Machine Type: **n1-standard-4 (4 vCPU, 15 GB memory)\n\n![](/images/blog/yugabyte-nodes.png)\n\n\nClick *Create* and wait for the Kubernetes cluster to come online.\n\n**Step 2: Configure iSCSI**\nThe iSCSI client is a prerequisite for provisioning cStor and Jiva volumes. However, it is recommended that the iSCSI client is setup and* iscsid* service is running on worker nodes before proceeding with the OpenEBS installation. In order to set up iSCSI, we’ll first need to determine the names of the nodes in our cluster\n\n    $ kubectl get nodes\n    \n    NAME                                       \tSTATUS   ROLES    \tAGE   \tVERSION\n    gke-cluster-1-default-pool-be95f6dd-5x65  \tReady    <none>   \t18h   \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-rs6c  \tReady    <none>   \t18h \tv1.18.15-gke.1501\n    gke-cluster-1-default-pool-be95f6dd-t4cp  \tReady    <none> \t18h  \tv1.18.15-gke.1501\n    \n    Now that we have the names of our nodes, we’ll want to log into each node and enable the iSCSI service.\n    \n    $ gcloud compute ssh <node name>\n    $ sudo systemctl enable iscsid && sudo systemctl start iscsid\n    \n    You can check the status of the iSCSI service using the following command:\n    \n    $ systemctl status iscsid\n    \n    iscsid.service - iSCSI initiator daemon (iscsid)\n       Loaded: loaded (/lib/systemd/system/iscsid.service; enabled; vendor preset: enabled)\n       Active: active (running) since Fri 2021-03-26 02:25:42 UTC; 18h ago\n         Docs: man:iscsid(8)\n      Process: 10052 ExecStart=/sbin/iscsid (code=exited, status=0/SUCCESS)\n      Process: 10038 ExecStartPre=/lib/open-iscsi/startup-checks.sh (code=exited, status=0/SUCCESS)\n     Main PID: 10059 (iscsid)\n        Tasks: 2 (limit: 4915)\n       CGroup: /system.slice/iscsid.service\n               ├─10057 /sbin/iscsid\n               └─10059 /sbin/iscsid\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Starting iSCSI initiator daemon (iscsid)...\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 iscsid[10052]: iSCSI logger with pid=10057 started!\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Started iSCSI initiator daemon (iscsid).\n    \n\n**Step 3: Install OpenEBS**\nNext, let’s install OpenEBS. I’ve found that the OpenEBS Operator is one of the simplest ways to get the software up and running.\n\n    $ kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml\n\nOnce the installation is completed, check and verify the status of the pods. You should something similar to this:\n\n    $ kubectl get pods -n openebs\n    \n    NAME                                            READY   STATUS    \n    maya-apiserver-dd655ff87-rbgmd                  1/1     Running  \n    openebs-admission-server-5965c94767-4h8rc       1/1     Running   \n    openebs-localpv-provisioner-5495669c66-z46lr    1/1     Running   \n    openebs-ndm-dss64                               1/1     Running  \n    openebs-ndm-gnv75                               1/1     Running   \n    openebs-ndm-operator-68949644b9-mqvlx           1/1     Running  \n    openebs-ndm-r5pws                               1/1     Running  \n    openebs-provisioner-544cb85449-w9spl            1/1     Running   \n    openebs-snapshot-operator-6d65b778dd-79zcn      2/2     Running \n\n**Step 4: Create and Attach Disks to Nodes**\nOur worker nodes need to have disks attached. These disks need to be unmounted and not have a filesystem on them. To accomplish this we’ll need to execute the following commands on each node.\n\n    $ gcloud compute disks create disk1 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-5x65 --disk disk1\n    \n    $ gcloud compute disks create disk2 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-rs6c --disk disk2\n    \n    $ gcloud compute disks create disk3 --size=10GB\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-t4cp --disk disk3\n    \n    Next let’s verify that our block devices are indeed attached.\n    \n    $ kubectl get blockdevice -n openebs\n    \n    NAME              NODENAME                           SIZE          CLAIMSTATE   STATUS   \n    blockdevice-03... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    blockdevice-85... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active   \n    blockdevice-b0... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\n    \n\n**Step 5: Create a Storage Pool Claim**\nNow that we have the names of our block devices and have verified that they are active, the next step is to create a Storage Pool Claim. We’ll use this to then create a Storage Class, and finally use that for our Persistent Volume Claims. The first step in this chain of steps is to configure our Storage Pool Claim YAML file. In this demo, I’ve named it “cstor-pool1-config.yaml”.\n\n    $ vim cstor-pool1-config.yaml\n    \n    #Use the following YAMLs to create a cStor Storage Pool.\n    apiVersion: openebs.io/v1alpha1\n    kind: StoragePoolClaim\n    metadata:\n      name: cstor-disk-pool\n      annotations:\n        cas.openebs.io/config: |\n          - name: PoolResourceRequests\n            value: |-\n                memory: 2Gi\n          - name: PoolResourceLimits\n            value: |-\n                memory: 4Gi\n    spec:\n      name: cstor-disk-pool\n      type: disk\n      poolSpec:\n        poolType: striped\n      blockDevices:\n        blockDeviceList:\n    - blockdevice-03e93d010db5169322eb16f3e18e33ed   \n    - blockdevice-22591882979084d0fe580fe229e0d84f   \n    - blockdevice-4d1b4bacbeec1650b337c2cfda7e3a48   \n    ---\n\n    Once you’ve figured out how to exit vim, the next step is to create the resource.\n    $ kubectl create -f cstor-pool1-config.yaml\n    \n    \n\nWe can verify our storage pool with the following command:\n\n    $ kubectl get csp\n    \n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE   \n    cstor-disk-pool-6cmf   1.85M       9.94G   9.94G      Healthy   false      striped\n    cstor-disk-pool-jql6   40.6M       9.90G   9.94G      Healthy   false      striped\n    cstor-disk-pool-vbz5   68.2M       9.87G   9.94G      Healthy   false      striped\n    \n\n**Step 6: Create a Storage Class**\nNow that we have a storage pool, let’s configure the YAML file for our storage class.  In this demo, I’ve named it “openebs-sc-rep1.yaml”.\n\n    $ vim openebs-sc-rep1.yaml\n    \n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: openebs-sc-rep1\n      annotations:\n        openebs.io/cas-type: cstor\n        cas.openebs.io/config: |\n          - name: StoragePoolClaim\n            value: \"cstor-disk-pool\"\n          - name: ReplicaCount\n            value: \"1\"\n    provisioner: openebs.io/provisioner-iscsi\n\nAssuming you have remembered how to exit vim from the previous step, we now need to create the storage class.\n\n    $ kubectl create -f openebs-sc-rep1.yaml\n\nFinally, let’s verify the storage class.\n\n    $ kubectl get sc\n    \n    NAME                  PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE \n    openebs-device        openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-hostpath      openebs.io/local             Delete          WaitForFirstConsumer\n    openebs-jiva-default  openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-sc-rep1       openebs.io/provisioner-iscsi Delete          Immediate\n    openebs-snapshot...   volumesnapshot.external...   Delete          Immediate\n    premium-rwo           pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n    standard (default)    kubernetes.io/gce-pd         Delete          Immediate\n    standard-rwo          pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\n\nAt this point, we are now set up for Persistent Volume Claims.\n\n**Step 7: Install YugabyteDB**\n\nIn this final step we’ll install a 3 node YugabyteDB cluster running on top of GKE that will be backed by the OpenEBS deployment we just completed.\n\nThe first step is to create a namespace.\n\n*$ kubectl create namespace yb-demo*\n\nNext, let’s install the cluster using Helm.\n\n    $ helm install yb-demo yugabytedb/yugabyte --set resource.master.requests.cpu=1,resource.master.requests.memory=1Gi,\\\n    resource.tserver.requests.cpu=1,resource.tserver.requests.memory=1Gi,\\\n    enableLoadBalancer=True --namespace yb-demo  --set storage.master.storageClass=openebs-sc-rep1,storage.tserver.storageClass=openebs-sc-rep1 --set persistence.storageClass=openebs-cstor-disk --wait\n    \n\nNote that in the command above we are specifying the following so that YugabyteDB makes explicit use of OpenEBS:\n\n- *storage.master.storageClass=openebs-sc-rep1*\n- *storage.tserver.storageClass=openebs-sc-rep1*\n- *persistence.storageClass=openebs-cstor-disk*\n\nOnce the installation is complete you should be able log into the PostgreSQL compatible YSQL shell on port 5433 with the following command:\n\n    $ kubectl --namespace yb-demo exec -it yb-tserver-0 -- sh -c \"cd /home/yugabyte && ysqlsh -h yb-tserver-0\"\n    \n    ysqlsh (11.2-YB-2.5.3.1-b0)\n    Type \"help\" for help.\n    yugabyte=#\n    \n\nYou can also access the basic YugabyteDB web admin portal at:\n\n*http://<yb-master-ui-endpoint>:7000*\n\n![](/images/blog/yugabyte-master.png)\n\n**Viewing Services and Ingress**\nA quick and visual way to check out all the services and ingress is to go to the “Services and Ingress” view in the Google Cloud Console. If you’ve made it this far you should see something like this:\n\n![](/images/blog/yugabyte-ingress.png)\n\nNote: I have omitted the “Endpoints” column from the screenshot above, but in your view you’ll be able to see the IPs and ports of the various endpoints.\n\nThat’s it! You now have a 3 node YugabyteDB cluster running on GKE with OpenEBS storage.\n\n**Next Steps**\nAs mentioned, MayData is the chief sponsor of the OpenEBS project. It offers an enterprise-grade OpenEBS platform that makes it easier to run stateful applications on Kubernetes by helping get your workloads provisioned, backed-up, monitored, logged, managed, tested, and even migrated across clusters and clouds. You can learn more about MayaData [here.](https://mayadata.io/)\n\n- Learn more about OpenEBS by visiting the [GitHub](https://github.com/openebs/openebs) and [official Docs](https://docs.openebs.io/) pages.\n- Learn more about YugabyteDB by visiting the [GitHub](https://github.com/yugabyte/yugabyte-db) and [official Docs](https://docs.yugabyte.com/) pages.\n\n****About the author:****\n\n![Jimmy Guerrero](/images/blog/authors/jimmy-guerrero.png)\n\nJimmy Guerrero, VP Marketing, and Community at YugaByte.\n","slug":"deploying-yugabytedb-on-google-kubernetes-engine-with-openebs"},{"id":2,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks\r","author":"OPENEBS\r","author_info":"\r","date":"22-03-2021\r","tags":["tutorials","openebs"],"content":"\r\n## Introduction\r\n\r\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\r\n\r\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\r\n\r\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\r\n\r\n\r\n## OpenEBS\r\n\r\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\r\n\r\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\r\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\r\n\r\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\r\n\r\n\r\n## OpenEBS Mayastor\r\n\r\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\r\n\r\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\r\n\r\n\r\n## Introducing: the Automation Playground\r\n\r\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\r\n\r\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\r\n\r\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\r\n\r\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\r\n\r\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars\r\n\r\n\r\n## Stages\r\n\r\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\r\n\r\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\r\n\r\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\r\n\r\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\r\n\r\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\r\n\r\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\r\n\r\n\r\n#### Stage 1: Provisioning\r\n\r\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\r\n\r\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\r\n\r\nThe nodes provisioned are of three varieties\r\n\r\n* Master nodes (for Kubernetes Masters)\r\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\r\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\r\n\r\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\r\n\r\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\r\n\r\n#### Stage 2: Start VPN\r\n\r\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\r\n\r\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\r\n\r\n#### Stage 3: Kubernetes setup\r\n\r\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\r\n\r\nCurrently two installation types are supported with more planned:\r\n\r\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\r\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\r\n\r\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\r\n\r\n#### Stage 4: Node preparation\r\n\r\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\r\n\r\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\r\n\r\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\r\n\r\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\r\n\r\n## Playbooks\r\n\r\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\r\n\r\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\r\n\r\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\r\n\r\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\r\n\r\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\r\n\r\n## Conclusion\r\n\r\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\r\n\r\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\r\n\r\nPlease visit us at https://mayadata.io and give the Demo Playground a spin at https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground.\r\n\r\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":3,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes\r","author":"Kiran Mova\r","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.\r","date":"12-03-2021\r","tags":["solutions","tutorials","chaosengineering"],"content":"\r\n**How to select the right local volume for your workloads?**\r\n\r\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\r\n\r\n![kg-image](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\r\n\r\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: https://github.com/openebs/openebs/blob/master/ADOPTERS.md.\r\n\r\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\r\n\r\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\r\n\r\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\r\n\r\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\r\n\r\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\r\n\r\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\r\n\r\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\r\n\r\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:\r\n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\r\n\r\n## Limitations of Kubernetes LocalPV\r\n\r\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\r\n\r\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\r\n\r\nWe have seen that cluster administrators are challenged by the following aspects:\r\n\r\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\r\n\r\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\r\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\r\n* Nodes have 8 to 16 high-performing NVMe SSDs.\r\n\r\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\r\n\r\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\r\n\r\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\r\n\r\n* Enforcing Capacity Limits/Thresholds\r\n* Securing the Volumes\r\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\r\n* Encrypting the Volumes\r\n* Enforce compliance with BCP by taking regular snapshots and full backups\r\n\r\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\r\n\r\n## Selecting your LocalPV\r\n\r\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\r\n\r\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\r\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\r\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\r\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\r\n\r\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\r\n\r\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\r\n\r\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\r\n\r\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\r\n\r\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: https://github.com/openebs/openebs/blob/master/ADOPTERS.md","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":4,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage\r","author":"Akhil Mohan\r","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.\r","date":"13-01-2021\r","tags":["openebs"],"content":"\r\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\r\n\r\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\r\n\r\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\r\n\r\n## Key Storage Problems solved by NDM\r\n\r\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\r\n* Cluster-wide storage visibility\r\n* Detect the movement of storage devices across nodes\r\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\r\n\r\n## Getting Started with NDM\r\n\r\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\r\n\r\nMaster: 2 virtual disks\r\n\r\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\r\n\r\nWorker 2: 4 physical disks\r\n\r\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\r\n\r\n```kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml```\r\n\r\n(The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\r\n\r\n* Once deployed, check the blockdevices present in the cluster using\r\n\r\n```kubectl get bd -n openebs -o wide```\r\n\r\nSome block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\r\n\r\n* Deploy a sample application to use the block device\r\n\r\nDownload the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\r\n\r\nkubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\r\n\r\nNow check the status of block devices again\r\n\r\nWe can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\r\n\r\n* Pool movement across nodes\r\n\r\nNDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\r\n\r\n* Reserving storage for workloads\r\n\r\nNDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\r\n\r\n## Future Roadmap\r\n\r\n* Southbound provisioning\r\n* Metrics (currently in alpha)\r\n* API Service to interact with NDM\r\n* Ability to create partitions or LVM volume groups - preparing storage in general.\r\n\r\n## Interested in Contributing to NDM?\r\n\r\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":5,"title":"Storage is Evolving!\r","author":"Nick Connolly\r","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.\r","date":"11-12-2020\r","tags":["openebs"],"content":"\r\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\r\n\r\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\r\n\r\n## The hardware environment is changing!\r\n\r\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\r\n\r\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\r\n\r\n## Application development is changing!\r\n\r\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\r\n\r\n## A New Era\r\n\r\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\r\n\r\n## Container Attached Storage\r\n\r\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\r\n\r\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\r\n\r\n## Microsoft Windows\r\n\r\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not supported on Windows’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\r\n\r\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\r\n\r\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\r\n\r\n## Windows Platform Development Kit\r\n\r\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\r\n\r\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\r\n\r\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\r\n\r\n1. Enable high-performance access to NVMe storage directly from applications.\r\n2. Native software defined storage stacks, including OpenEBS Mayastor.\r\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\r\n\r\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to https://wpdk.github.io or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":6,"title":"OpenEBS on DigitalOcean Marketplace\r","author":"Abhishek\r","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.\r","date":"3-12-2020\r","tags":["openebs","chaosengineering","tutorials"],"content":"\r\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\r\n\r\nWORKFLOW:\r\n\r\nSTEP 1: Getting started\r\nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\r\n\r\nSTEP 2: Creation of cluster\r\nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\r\n\r\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\r\n\r\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\r\n\r\nSTEP 3: Connecting your cluster\r\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\r\n\r\nTo verify, execute the following command:\r\n\r\n```$ kubectl get ns```\r\n\r\nOutput:\r\n```\r\nNAME     STATUS    AGE\r\ndefault  Active    13m\r\nopenebs  Active    13m\r\n```\r\nThe output must contain openebs ns in an Active state.\r\n\r\nNext, execute:\r\n\r\n```$ kubectl get pods -n openebs```\r\n\r\nOutput:\r\n```\r\nNAME                                                 READY     STATUS    RESTARTS AGE\r\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\r\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\r\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\r\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\r\nopenebs-ndm-74njq                                    1/1       Running   0        13m\r\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\r\nopenebs-ndm-spttv                                    1/1       Running   0        13m\r\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\r\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\r\n```\r\nAll the pods must be in a running state.\r\n\r\nSTEP 4: Attaching BlockDevices\r\nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\r\n\r\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\r\n\r\nNOTE:\r\n\r\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\r\n\r\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\r\n\r\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\r\n\r\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":7,"title":"Atlassian Jira Deployment on OpenEBS\r","author":"Abhishek\r","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.\r","date":"20-11-2020\r","tags":["openebs"],"content":"\r\n**Jira** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, Jira has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\r\n\r\n## Requirements\r\n\r\n#### Install OpenEBS\r\n\r\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\r\n\r\n#### Configure cStor Pool\r\n\r\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\r\n\r\n```\r\n#Use the following YAMLs to create a cStor Storage Pool.\r\n# and associated storage class.\r\napiVersion: openebs.io/v1alpha1\r\nkind: StoragePoolClaim\r\nmetadata:\r\n  name: cstor-disk\r\nspec:\r\n  name: cstor-disk\r\n  type: disk\r\n  poolSpec:\r\n    poolType: striped\r\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\r\n  #\r\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\r\n  # as the disk operator\r\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\r\n# Uncomment the below lines after updating the actual disk names.\r\n  blockDevices:\r\n    blockDeviceList:\r\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n\r\n---\r\n```\r\n\r\n#### Create Storage Class\r\n\r\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\r\n\r\n```\r\napiVersion: storage.k8s.io/v1\r\nkind: StorageClass\r\nmetadata:\r\n  name: openebs-cstor-disk\r\n  annotations:\r\n    openebs.io/cas-type: cstor\r\n    cas.openebs.io/config: |\r\n      - name: StoragePoolClaim\r\n        value: \"cstor-disk\"\r\n      - name: ReplicaCount\r\n        value: \"3\"       \r\nprovisioner: openebs.io/provisioner-iscsi\r\nreclaimPolicy: Delete\r\n```\r\n\r\n### Deployment of Jira\r\n\r\nSample Jira Yaml:\r\n\r\n```\r\napiVersion: extensions/v1beta1\r\nkind: Deployment\r\nmetadata:\r\n  labels:\r\n    app: jira\r\n  name: jira\r\nspec:\r\n  replicas: 1\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: jira\r\n      name: jira\r\n    spec:\r\n      containers:\r\n        - name: jira\r\n          image: \"doriftoshoes/jira:7.3.6\"\r\n          resources:\r\n            requests:\r\n              cpu: \"2\"\r\n              memory: \"2G\"\r\n          volumeMounts:\r\n            - name: \"jira-home\"\r\n              mountPath: /opt/jira-home\r\n      volumes:\r\n        - name: jira-home\r\n          persistentVolumeClaim:\r\n            claimName: demo-vol1-claim\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  labels:\r\n    app: jira\r\n  name: jira\r\nspec:\r\n  ports:\r\n    - port: 8080\r\n      targetPort: 8080\r\n  selector:\r\n    app: jira\r\n  type: LoadBalancer\r\n---\r\nkind: PersistentVolumeClaim\r\napiVersion: v1\r\nmetadata:\r\n  name: demo-vol1-claim\r\nspec:\r\n  storageClassName: openebs-cstor-disk\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 10G\r\n```\r\n\r\nNext, apply both the **Jira deployment** and service to your Kubernetes cluster.\r\n\r\n```kubectl apply -f jira.yaml```\r\n\r\n#### Verify Jira Pods:\r\n\r\n#### Run the following to get the status of Jira pods:\r\n\r\n```kubectl get pods```\r\n\r\nFollowing is an example output:\r\n\r\n```\r\nNAME                    READY   STATUS    RESTARTS   AGE\r\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\r\n```\r\n\r\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":8,"title":"Mayastor NVMe-oF TCP performance","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"19-11-2020","tags":["Mayastor"],"content":"\nFor a while now, we have been saying that OpenEBS Mayastor is “high” performance and community members have written [blogs](https://medium.com/volterra-io/kubernetes-storage-performance-comparison-v2-2020-updated-1c0b69f0dcf4) showing that the performance of OpenEBS Mayastor indeed is much better or on par with others even when running on relatively slow cloud volumes. However, is Mayastor high performance or just “as fast” as the other things out there? \n\nIt used to be the case that CPUs were much faster than the storage systems they served. With modern NVMe, this does not ***have*** to be the case anymore. NVMe is a ***protocol ***that can go fast but does not have to be fast. What this means is that you can use NVMe as your transport protocol for any block device, not just flash. Yes, this is what Mayastor does. It is really useful to keep in mind the distinction between NVMe as a protocol and NVMe devices - you don’t need to use them together but, when you do, additional performance can be unlocked.\n\nIn this blog, we will be using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known.  We will show what happens when you marry NVMe as a protocol (embedded within Mayastor) and fast NVMe devices from our friends at Intel.  \n\nBefore we get started, you might wonder how we came to this point that a new project like OpenEBS Mayastor was able to deliver amongst the fastest storage available today. Richard Elling of Viking / Sanmina recently wrote an excellent blog on the trends in hardware design that puts NVMe and OpenEBS Mayastor into context:  [https://richardelling.substack.com/p/the-pendulum-swings-hard-towards](https://richardelling.substack.com/p/the-pendulum-swings-hard-towards)\n\n## Hardware setup\n\nLet’s get to it.  We will be using three machines which will run kernel version 5.8. The hardware configuration of each host is as follows:\n\n- Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz\n- Intel Corporation NVMe Datacenter SSD [Optane]\n- Mellanox Technologies MT28908 Family [ConnectX-6]\n\n## Baseline performance\n\nTo understand the performance of the device we will be using throughout the test, we run the following Fio workload:\n\n    [global]\n    ioengine=linuxaio\n    thread=1\n    group_reporting=1\n    direct=1\n    norandommap=1\n    bs=4k\n    numjobs=8\n    time_based=1\n    ramp_time=0\n    runtime=300\n    iodepth=64\n    \n    \n    [random-read-QD64]\n    filename=/dev/nvme1n1\n    rw=randread\n    stonewall\n    \n    \n    [random-write-QD64]\n    filename=/dev/nvme1n1\n    rw=randwrite\n    stonewall\n    \n    \n    [random-rw-QD64]\n    filename=/dev/nvme1n1\n    rw=randrw\n    stonewall\n\n![](/images/blog/mayastor-nvme1.png)\nThese numbers are incredibly high and are provided by a ***single*** device. Note that the benchmark itself is rather synthetic in the sense that, in practice, no workload is 100% random.\n\n## High-level overview of the experiments\n\nMy approach in this benchmarking is very much OpenEBS Mayastor “the hard way”.  If you want an easier to use solution that for example automates pool creation and device selection and so on - we call that offering Kubera Propel (also open source btw). You can learn more about Kubera Propel on the [MayaData.io](https://mayadata.io/) web site.  \n\nOn two of the nodes, we create a pool (MSP CRD) which we use in the control plane to determine replica placement. To construct pools, we must have what we call a persistence layer. We support several ways to access this persistence layer. To select a particular scheme we use URIs. In this case we will be using today the pcie:/// scheme. This means that Mayastor will directly write into the NVMe devices listed above. The nice thing is that from the user perspective, things do not change that much. We simply replace disks: [‘/dev/nvme0n1’] with disks: [‘pcie:///80:00.0’]. Note that this persistence layer is used to store the replicas of the PVC. Once we have this layer up and running, we will create storage classes and select that we want to use nvmf (NVMe-oF) as the transport layer between the replicas, resulting in NVMe all the way through. \n\nAfter we have deployed mayastor we applied to following two storage classes:\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf\n    parameters:\n      repl: '1'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n    ---\n\n    kind: StorageClass\n    apiVersion: storage.k8s.io/v1\n    metadata:\n      name: nvmf-mirror\n    parameters:\n      repl: '2'\n      protocol: 'nvmf'\n    provisioner: io.openebs.csi-mayastor\n\nNote that `protocol: `nvmf` is just a shorthand for the NVMe-oF format mentioned above. We will be using both storage classes to run a single replica followed by a two way replica AKA mirror.  We use the following YAML to create the volume.\n\n    apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: ms-volume-claim\n    spec:\n      accessModes:\n       - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100G\n      storageClassName: nvmf\n\nAfter creating the PVC, Mayastor’s control plane creates a CRD, “Mayastor Volume” (MSV), that contains additional information about the corresponding volume.  Using kubectl describe msv -n mayastor we get:\n\n    Name:         ba081dc3-46db-445b-969c-7e5245aba146\n    Namespace:    mayastor\n    Labels:       <none>\n    Annotations:  <none>\n    API Version:  openebs.io/v1alpha1\n    Kind:         MayastorVolume\n    Metadata:\n      Creation Timestamp:  2020-09-11T08:49:30Z\n      Generation:          1\n      Managed Fields:\n        API Version:  openebs.io/v1alpha1\n        Fields Type:  FieldsV1\n        fieldsV1:\n          f:spec:\n            .:\n            f:limitBytes:\n            f:preferredNodes:\n            f:replicaCount:\n            f:requiredBytes:\n            f:requiredNodes:\n          f:status:\n            .:\n            f:nexus:\n              .:\n              f:children:\n              f:deviceUri:\n              f:state:\n            f:node:\n            f:reason:\n            f:replicas:\n            f:size:\n            f:state:\n        Manager:         unknown\n        Operation:       Update\n        Time:            2020-09-11T08:51:18Z\n      Resource Version:  56571\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/mayastor/mayastorvolumes/ba081dc3-46db-445b-969c-7e5245aba146\n      UID:               94e11d58-fed9-44c9-9368-95b6f0712ddf\n    Spec:\n      Limit Bytes:  0\n      Preferred Nodes:\n      Replica Count:   1\n      Required Bytes:  100000000000\n      Required Nodes:\n    Status:\n      Nexus:\n        Children:\n          State:     CHILD_ONLINE\n          Uri:       bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n        Device Uri:  nvmf://x.y.z.y:8420/nqn.2019-05.io.openebs:nexus-ba081dc3-46db-445b-969c-7e5245aba146\n        State:       NEXUS_ONLINE\n      Node:          atsnode3\n      Reason:\n      Replicas:\n        Node:     node3\n        Offline:  false\n        Pool:     pool-atsnode3\n        Uri:      bdev:///ba081dc3-46db-445b-969c-7e5245aba146\n      Size:       100000000000\n      State:      healthy\n    Events:       <none>\n\n## Results single replica\n![](/images/blog/mayastor-nvme2.png)![Chart](https://lh5.googleusercontent.com/whpgDl_Id_oo4tUdl7RZDv-C1Uq2ZfvM6Eh7KXbwNkNTu5Mki14meunBgF1PMWMnWLoccSGgHqCfRKXgQpJTfQG42NaS0GkwWRCuNpWGh7znOhqQ94aJXiCODJkzNUs9-G2ucqMJ)\nFrom the results we can see that we are very close to the performance of the local device. To be sure we can put it in the right perspective, the difference between the experiments here is that with the baseline, the workload was local. With repl=1 we use the same NVMe device but export it through our pool layer (and thus provide volume management), but also go over the network.\n\n## Results 2 replicas (mirror)\n\nWe are going to repeat the same test, this time, we will use two replicas. As we now have double the disks bandwidth, we expect to see that the read performance will go up. For writes, however, we actually expect a drop in performance, because we must do each write to both disks before we can acknowledge the IO.  Note that Mayastor does not cache - if you read the blog referenced above from Richard Elling you can learn why caching seems to be falling out of favor for use cases in which millions of IOPS are desired.\n![](/images/blog/mayastor-nvme3.png)![Chart](https://lh4.googleusercontent.com/GJ7c_cZ6vuDxd9-jAnU3XxAc8L0idA9sscz2JB5XVa0taj8v56H6MSIFB56XqPQzQsy_p49-yHlwhCB8SVjZ05YfT0oRdlFt0EMBze1IDrCioqWgtWypidK9fBpb9p3ULI19Dhfa)\n## Wrapup\n\nWith the above experiments, we have demonstrated that with OpenEBS Mayastor we have built a foundational layer that allows us to abstract storage in a way that Kubernetes abstracts compute. While doing so, the user can focus on what's important -- deploying and operating stateful workloads. \n\nIf you’re interested in trying out Mayastor for yourself, instructions for how to setup your own cluster, and run a benchmark like **fio** may be found at [mayastor.gitbook.io/](https://mayastor.gitbook.io/introduction/).\n\nAnd if you are a Kubera Propel user, you’ll find that we’ve productized some of the benchmarking above so that platform teams and other users can programmatically use benchmarks in their decisions about workload placement. We are working with a number of users about operating OpenEBS Mayastor / Kubera Propel at scale. Please get in touch if you have suggestions, feedback, ideas for interesting use cases and so on. Contributions of all kinds are welcome!\n","slug":"mayastor-nvmeof-tcp-performance"},{"id":9,"title":"Mayastor Engine Reaches Beta","author":"Glenn Bullingham","author_info":"Director of Solution Architecture","date":"19-11-2020","tags":["Openebs"],"content":"\ntitle: Mayastor Engine Reaches Beta\nAs I write this, it is early November, and the winds of change are blowing. The United States has a new president. Here in the United Kingdom, Keats' days of mists and mellow fruitfulness are departing, replaced by a low sun and the first morning frosts. And at MayaData, we see the Mayastor project carefully but tenaciously emerging from alpha/pre-release into its beta phase. In fact, Mayastor now undergirds MayaData’s commercial offering for performance sensitive containerized workloads, called [Kubera Propel](https://mayadata.io/product).\n\n> ***“Beta Software: Software considered to be feature complete and substantially free of known major defects”***\n\nSignificant contributions over the past 18 months have seen the project raised from concept to working software. A major requirement of our MVP specification is that it should carry minimal performance overhead; Mayastor is intended to satisfy demands for performance at all levels of scale. At the beginning of Autumn, working in conjunction with Intel’s labs in the UK, we were able to validate that assertion; deployed in conjunction with the latest generation of Optane NVMe devices, the Mayastor data plane was found to introduce less than 6% overhead; you can read more about that benchmarking [here](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/). Having addressed that performance criteria and the other principle MVP requirements, the Mayastor team at MayaData has begun to focus its contributions to the project on QA as we approach Beta and GA releases.\n\nIn particular, we’ve greatly increased end-to-end test coverage on Kubernetes. How MayaData tests Mayastor is something that I’ll elaborate upon in a forthcoming post.  However, suffice it to say customary suspects feature (Jenkins, mocha, nix, cargo test), whilst we’re also collaborating with our colleagues who maintain the [Litmus Chaos](https://litmuschaos.io/) project. By the time that you’re likely reading this, Mayastor-specific chaos tests should be available to all on [ChaosHub](https://hub.litmuschaos.io/).\n\n## Ease of Use, Perf, and Availability\n\nMayastor MVP requirements center on ease of use, performance, and availability. In the Beta phase and subsequent GA release, these will be realized as a CAS platform with full NVMe data path semantics, declarative configuration via CSI compliant dynamic provisioning, and N+1 synchronous mirroring of data at the persistent layer. This closely approaches functional parity with the current OpenEBS storage engines (cStor, Jiva, and Local PV), with snapshot and cloning functionality to be added in Q1 2021. Mayastor will also very soon be the recipient of a streamlined deployment and configuration experience, which is exclusive to this engine.\n\n## Try it Yourself\n\nIf you’re a member of the Kubernetes community looking to implement a platform-native storage solution in the new year, now is an ideal time to start evaluating Mayastor. The other venerable and respected engines of OpenEBS won’t be retiring overnight, but as full feature parity emerges, MayaData’s commercial products and services will on Mayastor as their default storage engine; we do recognize that some users will continue to prefer various flavors of Dynamic Local PV from OpenEBS - as a recent [blog](https://www.percona.com/blog/2020/10/01/deploying-percona-kubernetes-operators-with-openebs-local-storage/) from the CTO of Percona attests as do countless [Adopter.md case studies](https://github.com/openebs/openebs/blob/master/ADOPTERS.md) including that of the SaaS company Optoro, also a CNCF case study. Mayastor’s roadmap includes provisions for the inward migration of existing OpenEBS users. It’s an equally opportune moment to [consider becoming a contributor](https://github.com/openebs/Mayastor/issues/new/choose) to the project yourself.\n\nTo help with Mayastor onboarding as we prepare to go to full steam, we’re putting together a new documentation site over at[ GitBook](https://mayastor.gitbook.io/introduction/), which includes a comprehensive quick-start deployment guide (developer docs will remain, at least for now, with the OpenEBS/Mayastor GitHub repository). We’re also holding [Office Hours at Kubecon NA 2020 this month](https://kccncna20.sched.com/?searchstring=OpenEBS&amp;iframe=no&amp;w=&amp;sidebar=&amp;bg=), and we’d love to see you there.\n\nIf you’d like to try Mayastor from the source - you can do so, of course, from the GitHub repositories. If you’d like to also try out management utilities, including a cool management interface and available 24x7 support - please take a look at [Kubera Propel](https://go.mayadata.io/register-for-kubera-chaos-and-propel-technical-preview). A free forever for individual use tier is available.\n\n## Conclusion\n\nIt is a propitious time for MayaData and Mayastor - and for data on Kubernetes more broadly. If you have always wanted to run workloads on Kubernetes but were put off by the stories of performance challenges, you can now move forward with confidence. Kubernetes enabled storage with the help of Mayastor performs faster than that of traditional shared everything storage while retaining the ease of use, open source community, and Kubernetes semantics for which OpenEBS has become famous.\n","slug":"mayastor-engine-reaches-beta"},{"id":10,"title":"Migrate CSPIs to a different node by moving the disks","author":"Sai Chaithanya","author_info":"A developer whos is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate towards Data Science. Enjoys playing kabaddi and traveling.","date":"04-11-2020","tags":["Openebs"],"content":"\n\nThis blog describes steps to migrate CStorPoolInstances from one node to different nodes by **moving the set of underlying disks to a new node that participates in the pool provisioning**. There were a couple of use cases where this feature can be helpful:\n\n1. Scaling down and scaling up nodes in the cluster(in a cloud environment) by retaining external volumes(for cost savings).\n2. Replacing failed storage nodes with new nodes by attaching the same old disks to the new node.\n\n**Steps to migrate the CSPI to different node:**\n\n1. Detach the disks belonging to the CSPI that you wish to migrate from the node and attach it to the new node. If you are using a cloud platform, check on their documentation, or ask the administrator about the steps to do this.\n2. Change the node selector in the CSPC YAML (next section describes how to do this).\n\n![](https://lh4.googleusercontent.com/XTwKu6lE3lyoZ3cHRO9HNJGUaTOoGfE-OWGuscrmukbxEKJNPSaEqxUPbbNnnc3dcD-Aybc2_AF0y2Scf0QBxSDG_f9QZWRu67sXZjoMKO6nymhgelEWfDzPjfGKi4D9UwLBaN0D)\n\n**Existing setup**:\n\nI have a three-node cluster with CSPC and CSI volumes already provisioned(To create CSPC pools and CSI volume click [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md#quickstart)). Here is detailed information:\n\n**Cluster details**:\n\n    Kubernetes Cluster: AWS\n    Kubernetes Version: v1.15.9\n    OpenEBS Version: 2.2.0 \n\n****Node and BlockDevice details**: **Attached three disks to three nodes(each node has one disk)\n\n    Kubectl get nodes\n    \n    NAME                STATUS   ROLES    AGE   VERSION\n    ip-192-168-29-151   Ready    <none>   16m   v1.15.9\n    ip-192-168-36-89    Ready    <none>   8h    v1.15.9\n    ip-192-168-74-129   Ready    <none>   8h    v1.15.9\n    \n    Kubectl get bd -n openebs\n    NAME                                           NODENAME          SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-36-89  10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-74-129 10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-29-151 10737418240   Claimed      Active\n\n****CSPC Manifest**: **Applied following CSPC manifest to provision cStor pools\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-74-129\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-36-89\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-29-151\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nAfter applying the above CSPC manifest, the following three CStorPoolInstances(CSPI) were created.\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-74-129 24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-36-89  24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-29-151   24100M   24113200k   false     ONLINE   8h\n\nNow everything looks good. After some time, the cluster has been scaled down **0** nodes and scaled back to **3 **nodes. So after scaling operations following are new nodes in the cluster.\n\n    Kubectl get nodes\n    \n    NAME               STATUS   ROLES    AGE     VERSION\n    ip-192-168-14-90   Ready    <none>   118s    v1.15.9\n    ip-192-168-49-43   Ready    <none>   5m55s   v1.15.9\n    ip-192-168-94-113  Ready    <none>   4m6s    v1.15.9\n\nAttached old disks that participated in pool creation to new nodes, and the following is blockdevice output.\n\n    Kubectl get bd -n openebs\n    \n    NAME                                           NODENAME            SIZE          CLAIMSTATE   STATUS  \n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-49-43    10737418240   Claimed      Active   \n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-94-113   10737418240   Claimed      Active   \n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-14-90    10737418240   Claimed      Active\n\nFrom the above and previous output following are blockdevice mappings with zn old node and new node:\n\n    Blockdevice  Name                                    Old Node            New Node \n    blockdevice-7d311a98255a454a717427b5c2d38426    ip-192-168-36-89        ip-192-168-49-43\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b    ip-192-168-74-129       ip-192-168-94-113\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3    ip-192-168-29-151       ip-192-168-14-90\n\nOpenEBS **NodeDiskManager**(NDM) will automatically update the details in blockdevice CRs when the disks migrate to a new node. Based on the above output, update the CSPC manifest with new **nodeSelector **values.\n\n****Updated CSPC Manifest**:**\n\n    apiVersion: cstor.openebs.io/v1\n    kind: CStorPoolCluster\n    metadata:\n      name: cstor-disk-cspc\n      namespace: openebs\n    spec:\n      pools:\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-94-113\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-49-43\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n        - nodeSelector:\n            kubernetes.io/hostname: \"ip-192-168-14-90\"\n          dataRaidGroups:\n          - blockDevices:\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\n          poolConfig:\n            dataRaidGroupType: \"stripe\"\n\nOnce the CSPC manifest is updated then CSPIs will automatically migrate to the new node (which can be verified using ****kubectl get cspi -n openebs****).\n\n    kubectl get cspi -n openebs\n    \n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\n    cstor-disk-cspc-dvc2  ip-192-168-94-113   24100M   24111M      false     ONLINE   8h\n    cstor-disk-cspc-f56z  ip-192-168-49-43    24100M   24113200k   false     ONLINE   8h\n    cstor-disk-cspc-q9yt  ip-192-168-14-90    24100M   24113200k   false     ONLINE   8h\n\n**Note:** Along with CStorPoolInstance migration, CStorVolumeReplicas belongs to CSPI will also migrate automatically.\n","slug":"migrate-cspis-to-a-different-node-by-moving-the-disks"},{"id":11,"title":"OpenEBS Backup/Restore for ZFS-LocalPV","author":"Pawan Prakash Sharma","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series","date":"27-10-2020","tags":["Openebs"],"content":"\n## Overview: OpenEBS Backup/Restore for ZFS-LocalPV\n\n**Backup **is the process of copying the data to a different/remote location to protect against accidental or corruption or any other type of data loss. Restore is the process of getting back the data from the backup. In this blog, I will discuss how we can use *Velero Backup/Restore* plugin for ***ZFS-LocalPV*** to protect it against data loss.\n\n### Pre-requisites\n\nWe should have installed the ZFS-LocalPV 1.0.0 or later version for Backup and Restore, see my previous[ blog](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d) for the steps to install the ZFS-LocalPV driver.\n\n### Setup\n\n**1.Install Velero CLI**\n\nDownload the 1.5 or later binary for ZFS-LocalPV. For Linux on amd64, we need to download below\n\n    wget\n    https://github.com/vmware-tanzu/velero/releases/download/v1.5.1/velero-v1.5.1-linux-amd64.tar.gz\n\nExtract the tarball:\n\n    tar -xvf velero-v1.5.1-linux-amd64.tar.gz\n\nMove the extracted velero binary to somewhere in your $PATH (/usr/local/bin for most users).\n\nSee the detailed steps[ here](https://velero.io/docs/v1.5/basic-install/).\n\n**2.Deploy Velero**\n\nWe will be using minio for storage purpose in this blog, we need to setup the credential file first\n\n    $ cat /home/pawan/velero/credentials-minio\n    [default]\n    aws_access_key_id = minio\n    aws_secret_access_key = minio123\n\nWe can install Velero by using below command\n\n    $ velero install --provider aws --bucket velero --secret-file /home/pawan/velero/credentials-minio --plugins velero/velero-plugin-for-aws:v1.0.0-beta.1 --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://minio.velero.svc:9000 --use-volume-snapshots=true --use-restic\n\nWe have to install the velero 1.5 or later version of velero for ZFS-LocalPV.\n\n**3.Deploy MinIO**\n\nDeploy the MinIO for storing the backup:-\n\n    $ kubectl apply -f\n    https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/sample/minio.yaml\n\nThe above MinIO uses tmp directory inside the pod to store the data for the demonstration purpose, so when restart happens, the backed up data will be gone. We should change the above YAML to use persistence storage to store the data when deploying it for the production.\n\nCheck the Velero Pods are UP and Running\n\n    $ kubectl get po -n velero\n    NAME                      READY   STATUS      RESTARTS   AGE\n    minio-d787f4bf7-xqmq5     1/1     Running     0          8s\n    minio-setup-prln8         0/1     Completed   0          8s\n    restic-4kx8l              1/1     Running     0          69s\n    restic-g5zq9              1/1     Running     0          69s\n    restic-k7k4s              1/1     Running     0          69s\n    velero-7d9c448bc5-j424s   1/1     Running     3          69s\n\n**4.Setup OpenEBS Plugin**\n\nWe can Install the Velero Plugin for ZFS-LocalPV using the below command\n\n    velero plugin add openebs/velero-plugin:2.2.0\n\nWe have to install the velero-plugin 2.2.0 or later version, which has the support for ZFS-LocalPV. Once the setup is done, we can go ahead and create the backup/restore.\n\n**5.Create the VSL**\n\nThe VSL(Volume Snapshot Location) has information about where the snapshot should be stored. To create the Backup/Restore, we can create the Volume Snapshot Location by applying the below YAML:\n\n    apiVersion: velero.io/v1\n    kind: VolumeSnapshotLocation\n    metadata:\n     name: default\n     namespace: velero\n    spec:\n     provider: openebs.io/zfspv-blockstore\n     config:\n       bucket: velero\n       prefix: zfs\n       namespace: openebs # this is the namespace where ZFS-LocalPV creates all the CRs, passed as OPENEBS_NAMESPACE env in the ZFS-LocalPV deployment\n       provider: aws\n       region: minio\n       s3ForcePathStyle: \"true\"\n       s3Url: http://minio.velero.svc:9000\n\nHere, we have to provide the namespace, which we have used as OPENEBS_NAMESPACE env while deploying the ZFS-LocalPV. The ZFS-LocalPV Operator yamls uses “openebs” as the default value for OPENEBS_NAMESPACE env. Verify the volumesnapshot location:\n\n    kubectl get volumesnapshotlocations.velero.io -n velero\n\n### Create Backup\n\nWe can use the below Velero command to create the backup:\n\n    velero backup create my-backup --snapshot-volumes --include-namespaces=<backup-namespace> --volume-snapshot-locations=default --storage-location=default\n\nwe can add all the namespaces we want to be backed up in a comma-separated format in --include-namespaces parameter. We have to provide the VSL that we have created in --volume-snapshot-locations parameter.\n\nWe can check the backup status using the velero backup get command:\n\n    $ velero backup get\n    NAME        STATUS       CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR\n    my-backup   InProgress   2020-09-14 21:09:06 +0530 IST   29d       default            <none>\n\nThe status InProgress means that the backup is in progress. Wait for it to be Completed.\n\nWe can also create a scheduled backup which will take the backup periodically. For example, to take the full backup at every 5 min, we can create the below schedule :\n\n    velero create schedule schd --schedule=\"*/5 * * * *\" --snapshot-volumes --include-namespaces=<backup-namespace1>,<backup-namespace2> --volume-snapshot-locations=default --storage-location=default\n\n### Restore\n\nIf the application and its PVC has been deployed in a namespace, then we can use the below Velero command to create the backup of the entire namespace:\n\n    velero restore create --from-backup my-backup --restore-volumes=true --namespace-mappings <source-ns>:<dest-ns>\n\nThe above command will create the backup of everything that is there in the namespace provided as --include-namespaces argument. We can provide the namespace mapping if we want to restore in a different namespace as --namespace-mappings parameter. If namespace mappings are not provided, it will restore in the source namespace only where the original pod and pvc was present. Now we can check the restore status:\n\n    $ velero restore get\n    NAME                       BACKUP      STATUS       WARNINGS   ERRORS   CREATED                         SELECTOR\n    my-backup-20200914211331   my-backup   InProgress   0          0        2020-09-14 21:13:31 +0530 IST   <none>\n\nOnce the Status is Completed, we can check the pods in the destination namespace and verify that everything is up and running. We can also verify that the data has been restored.\n\n### Summary\n\nAs demonstrated in this blog, OpenEBS makes it easy to take the backup of the Kubernetes applications, which we can use to Restore as part of disaster recovery. In my next blog, I will talk about how we can take the incremental backup of the volumes, which is space optimized backup for ZFS-LocalPV\n\n## Important links\n\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n[https://velero.io/docs/](https://velero.io/docs/v1.5/basic-install/)\n","slug":"openebs-backuprestore-for-zfslocalpv"},{"id":12,"title":"OpenEBS 2.2.0 - Enhancements And New Storage Capabilities","author":"Ashutosh Kumar","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut","date":"20-10-2020","tags":["Openebs"],"content":"\n### **OpenEBS 2.2.0 is here**\n\nWe are excited to announce yet another ***OpenEBS ***release that comes with new storage capabilities, control plane enhancements, bug fixes, and new APIs for the world’s fastest storage engine built on RUST, also known as Mayastor.\n\nOpenEBS has seen a wider adoption among the users, thanks to the vibrant and growing community. Like in most of the OpenEBS releases, this release responds to the feedback received in the community. If you want to learn more about the project roadmap, please browse the following link:\n[https://github.com/openebs/openebs/blob/master/ROADMAP.md](https://github.com/openebs/openebs/blob/master/ROADMAP.md)\n\nIncremental Backup and Restore in ZFS local PV and pool and volume migration in cStor are the major release milestones made into the release. The pool migration in cStor solves the use-case of replacing a bad node with a new node or sending a node for maintenance on on-premise clusters. The migration feature provides great value in cloud-managed Kubernetes clusters, too, e.g., GKE, where node reboots or voluntary scale down of nodes can cause the disks to get removed. \n\nThis release is also special due to the [*Hacktoberfest*](https://hacktoberfest.digitalocean.com/)festival, and would like to give a shout out to first-time contributors [@didier-durand](https://github.com/didier-durand), [@zlymeda](https://github.com/zlymeda), [@avats-dev](https://github.com/avats-dev), and many more.\n\n### **Key Highlights of OpenEBS 2.2.0 Release:**\n\n- Mayastor aims to be the world’s fastest container attached storage and is currently in alpha. The release introduced block device enumeration feature via the gRPC API and enhancement around storage pool finalizers.\n- ZFS local PV has become a popular storage engine built on local storage design and provides powerful storage features like snapshots and clones, raw block volume, etc. It also supports day two operations like volume resize and backup and restore via the pluggable Velero interface.\nSupport for Incremental Backup and Restore by enhancing the OpenEBS Velero Plugin has been a significant highlight for ZFS local PV release. \nTo learn more about this, please refer to the document [here](https://github.com/openebs/zfs-localpv/blob/master/docs/backup-restore.md).\n- OpenEBS Velero plugin connects the Velero interface to the OpenEBS storage engines to deliver backup/restore functionality. Velero Plugin has been enhanced to restore ZFS Local PV into a different cluster or a different node in the cluster and use custom certificates for S3 object storage.\n- CStor went into beta in 2.0 and has been enhanced to migrate the storage pool from one node to another node. This will help with scenarios where a Kubernetes node can be replaced with a new node but can be attached with the block devices from the old node that contain cStor Pool and the volume data.\n- OpenEBS node disk manager helps in block device discovery and management in a Kubernetes cluster and powers storage engines like cStor. Support to exclude multiple devices that could be mounted as host filesystem directories has been added.\nAn issue where NDM could cause data loss by creating a partition table on an uninitialized iSCSI volume has also been fixed.\n\n### **Useful Links and Summary:**\n\nIf you are interested in knowing more details regarding the changes that made to this release, please visit the release note [link](https://github.com/openebs/openebs/releases/tag/v2.2.0). To try out OpenEBS, you can visit [https://docs.openebs.io/](https://docs.openebs.io/) and follow the user guides.\n\nYou can visit the following link to learn more or experiment with Mayastor\n[https://github.com/openebs/mayastor](https://github.com/openebs/mayastor)\n\nYou can visit the following link to learn more or experiment with ZFS local PV\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\n\nTo learn more about the new cStor CSPC API, please visit the following link:\n[https://github.com/openebs/cstor-operators](https://github.com/openebs/cstor-operators)\n\nIf you have any feedback, questions, or suggestions — please reach out to the community on the #openebs channel in the Kubernetes workspace or consider opening a relevant issue at [Github](https://github.com/openebs/openebs).\n","slug":"openebs-220-enhancements-and-new-storage-capabilities"},{"id":13,"title":"Scaling up cStor Volume Replica","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"07-10-2020","tags":["Openebs"],"content":"\nEven if a cluster is reliable, nodes can and do fail. Rebooting a node does not simulate a crash. There can be many reasons, such as catastrophic hardware failure, Operating System failure, or communication failure among the nodes. To overcome this hazardous situation, the Replication of volume becomes necessary.\n\nReplication is the process by which one or more volumes can be copied to maintain the significance of a cluster and to avoid data loss. OpenEBS provides volume replication through different storage engines. One of them is cStor Volume Replication.\n![Synchronous replication of data](https://lh5.googleusercontent.com/ijS24Ywabw-QkWWYbSLoOshGTi2SHZhdEFATaHIYbkNGK8lUq5SJrct6fNHfPjWcPTHGyvByS7uD1vYct2m5D6-HdRC2ZoMpS_c4Crw-9sREhPU-tXE8KAt-nWj7vYw99Ee_s1pE)\n#### Prerequisite for scaling up the replicas of cStor volume:\n\n- A cStor pool should be available, and replicas of this cStor volume should not be present on this cStor pool.\n- The OpenEBS version should be 1.3.0 or more.\n\n### Please follow the below steps for cStor Volume Replication:\n\nGet the StorageClass name using the following command:\n\n    kubectl get sc\n\nExample Output:\n![](https://lh5.googleusercontent.com/lTma7ZqsAavmXEzGG_b4BXDMUEYXjFXf0xxnWgE70znfR_EzP3IorVFp0evkKoLMsBQ0D7gwOQxivB_bZxEcv2vhYZOe17k7mNyDBaPewTgiUdusrd3ow12ClBeQvZVmVzjDrdsI)\nThe storage class for cStor is ***openebs-sc-cstor***. Perform the following command to get the details of the corresponding StorageClass, which is used for creating the cStor volume :\n\n    Kubectl get sc openebs-sc-cstor\n\nWe will get the Yaml file of the corresponding StorageClass ***openebs-sc-cstor***.\n![](https://lh5.googleusercontent.com/81DQJ-DhT3AKseMRfCZ4NpkmOPl2Tckm76jrUxE2eECY7lrejvNz3OjomFWmNiCRwm0L2seAWzmJJhe-8xcqFirBsEUedf2xzPN4NHq2RM2YYEZZv-iKpsE03j06EQi_D5kqnDCi)\nIn the Yaml above, We can see the Replica count Value is 1.\n\nGet the volume name using the following command:\n\n    Kubectl get pvc\n\nGet the VOLUME name and use it in the following command to get the details of corresponding cStor volume. All commands are performed by considering the above PVC.\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=<Vol-name>\n\nExample output:\n![](https://lh4.googleusercontent.com/FIOJchscq3lm7UJLwnk7i1oNne_RxhjIJzI3FMANxxkRhz4yWZAue-Wu1jD03ii2aMjtdDu3zr9C-0ZGaeazkvxb_JkGnxBBDza605w_p-v9BY1ER40f6DityHwimJvhvuAR8FcT)\nGet the details of existing cStor Volume Replica details using the following command:\n\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nExample output:\n![](https://lh3.googleusercontent.com/68NvgkfD7audTNZN1QLt6SVw4OvN_B3MIlnFnWm8MfgDziiexFX2qeI3tX6H1TCJJgrCA8b-nZQJoM6hx1QoYWOv4q74tKwB7nrZLc9xdluXRCvWTpj-sU6sIv7aJ0AMgL3rr1AR)\nPerform the following command to get complete details of the existing cStor volume replica:\n\n    kubectl get cvr -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\n\nGet the available cStor Pools for creating new cStor volume replica. The following command will get the other associated cStor pools details:\n\n    kubectl get csp -l openebs.io/storage-pool-claim=cstor-disk-pool | grep -v cstor-disk-pool-hgt4\n\nExample Output:\n![](https://lh6.googleusercontent.com/lcbO830nSZgValr-I4ci7FHRa6Qvqf3eG-bycWHHAniRD8mb8dwRHOwxeVObFqj4FqvXbNkb_oZUdWhMgAQuHvU1pYDecvWXhDetYGdJADBQhWfzMuwJm4d9Ywgg6bAKkj-Sd79a)\nFrom the above example output, there are 2 cStor pools available, i.e., ***cstor-disk-pool-2phf*** and ***cstor-disk-pool-zm8l***. So it is possible to scale up the current volume replica count to 3 from 1. If there are no cStor pools available to perform volume replica scale-up, then follow the [steps](https://docs.openebs.io/docs/next/ugcstor.html#expanding-cStor-pool-to-a-new-node) to create a new cStor pool by updating existing SPC configuration.\n\nPerform the following command to get the details of the cStor Pool where new replica will be created:\n\n    kubectl get csp -n openebs cstor-disk-pool-2phf -oyaml\n\nNote down following parameters from the output:\n\n- metadata.labels.cstorpool.openebs.io/name\n- metadata.labels.cstorpool.cstorpool.openebs.io/uid\n- metadata.annotations.cstorpool.openebs.io/hostname\n\nThe sample CVR Yaml is provided below:\n![](https://lh3.googleusercontent.com/JePqVqyIryf396SEkCf9NoS3kmPDXM0huqehkN3kX5f-eE7nX3-mCr42xriJeDKSNRgfVxSeQG_SUHkbqEZS4ktIzzcJ8VKCsFXuz4VhtdXpikLADE3eJdkgwH3zFd5PXRPfYc70)\nApply the updated CVR YAML spec to create the new replica of cStor volume using the following command:\n\n    kubectl apply -f cvr.yaml\n\nExample Output:\n![](https://lh5.googleusercontent.com/JElB0d8zFXHoUh6wM0QpAshOmYbVXOvH5RIR9UjJ_svM67ZR2pq6cQ4ckrq0Qw6ACpRnOqO-6nUbvLUrDhFKvgZxjrh-ke0VHnKW-pR2oyzkgXdQuRATSwy9EVN19G458ZyR_9Xd)\nVerify if new CVR is created successfully using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh4.googleusercontent.com/ql9j6Zcod6DT1vKhJrlJJaxk4YUN8Mf_o7LT3e-fBjjoybINByEwwDS5fln6K5BEJGW6vFfE8h2JA_2tFvQY5PQKo62eJvQfTE5j5JwECIz2oO3u_ypKHWRylL3gmU4KYlo4axtU)\nFrom the above output, a new replica of the cStor volume is created, and STATUS is showing as Offline.\n\nUpdate Desired Replication Factor in cStor volume with a new replica count. This can be updated by editing corresponding cStor volume CR YAML.\n\n    kubectl edit cstorvolume pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8 -n openebs\n\nThe following is the snippet of updated cStor volume CR YAML:\n![](https://lh3.googleusercontent.com/lAisXwgequP2MyeCw1cVuwUYFG9G9L5U88olJ2CjbjIOpHjlMwn-K8p11ktaCjQfxK-u5EL-ebpZofD0W_LOKmfFa-wW3eTLtBpqSt7EPYvz5rQciYeaFdT6_7PCsJkdxPVHZCVg)\n\nIn the above snippet, the desiredReplicationFactor is updated to 2 from 1. Example output:\n![](https://lh6.googleusercontent.com/uBkJft958gfjATk070ZFZOMXaq7Sb1xnd5lBVMa2sKuXo-nxwrRxQS58TPgdpoLjMuMHvT4LwPscxPdT6kgwpaDVSraLmsNwWhfanMUrNVO72K8WgxwT3_or4EdzqQkWBgI-Ka84)\nVerify if the rebuilding has started on the new replica of the cStor volume. Once rebuilding has been completed, it will update its STATUS as Healthy. Get the latest status of the CVRs using the following command:\n\n    kubectl get cvr -n openebs\n\nExample output:\n![](https://lh6.googleusercontent.com/1KjmeLgtvoFcBh0vVmB0iwj_gjo-Tkd3vVTTmaw3OaREY9KbvDUQLqyEu0Hj_aYKDpTIRSDVG2sOrTPMczJAPASlzFitSHDyocPV4Bb6IgajW-ArUpDKhi8StFesnHYZrUc3X9DJ)\n","slug":"scaling-up-cstor-volume-replica"},{"id":14,"title":"\"Hacktoberfest 2020 - Contribute to OpenEBS\"","author":"MayaData Marketing","author_info":"Mayadata Marketing Team","date":"30-09-2020","tags":["Openebs"],"content":"\n### Hacktoberfest returns! Contribute to OpenEBS and win exciting swag\n\nThe seventh annual [***Hacktoberfest ***](https://hacktoberfest.digitalocean.com/)celebration is almost here, and we at *OpenEBS *are happy to be participating in the contest once again. In August 2017, the OpenEBS community began growing and building a strong foundation for an open source project.\n\nWe were first introduced to *Hacktoberfest *by friends and peers at the DigitalOcean Bangalore Meetup and were immediately interested in participating. We enlisted OpenEBS as one of the projects participating in Hacktoberfest 2017. We were pleasantly surprised by the participation and enthusiasm that Hacktoberfest attracts from developers around the world. The PRs have been at their peak during Hacktoberfest.\n![](https://lh4.googleusercontent.com/Og_t8KLCiRni_LS66bpJsonSXMjcoAX671c8a2LD7ZjbkVdYZgZCRFq47sDC7hsEZt6qcaoCJPZi_gm2FnKmuzMvlg4UZAQKofU0agH2Z11TRmw6vBCQ8u3ssGfre75BN9OV-vOO)\n### Get started with OpenEBS this Hacktoberfest\n\nFollowing the smashing success we had when we participated in the event last few years, we’re going to do the same this year! MayaData makes it more exciting to participate in **Hacktoberfest **by running multiple Meetups through-out the month, and helping contributors to get started with their favorite areas (in any of the programming languages) like website development and documentation enhancements. \n\nTo top it all, there are exciting prizes to be won and every contribution deserves an additional swag from MayaData. Read [this blog](https://blog.mayadata.io/openebs/experience-with-openebs-in-this-hacktoberfest) by Aswath K, one of last year’s weekly winners, who writes about his experience with OpenEBS in Hacktoberfest 2019.\n![](https://lh6.googleusercontent.com/2POqPppb7pyGM0OWwl_LlkHzwz-DSWXMMggxIeNCXvsU6EVVmNHdiIzIoTw23-ceK9R5iBleFMGiK-lw9JLtCP5VVjFGQS1QhIOXbpQhtvku5Gp5aCw4Eul_r6JcM-o0WuVZRZmj)\n### How do I contribute to OpenEBS?\n\nThat is an excellent question! OpenEBS is a Kubernetes native Container Attached Storage (CAS) that simplifies running Stateful workloads on Kubernetes. It is built on Microservices architectural patterns, fully automated development, and build pipelines.\n\nOpenEBS has several components that need your help from simple fixes like adding GitHub issue templates, to enhancing the components. These are developed using Go, Rust, Python, Javascript, Ansible, and many more interesting tools. OpenEBS is also a great way to start your journey into the exciting world of storage, containers, and Kubernetes.\n\nThe [architecture overview document ](https://github.com/openebs/openebs/blob/master/contribute/design/README.md)is a great place to start learning and picking up a component that speaks to your passion. You could start your first contribution by enhancing that document itself for providing more clarity.\n\nThere are many other [good first issues](https://github.com/search?q=org%3Aopenebs+is%3Aissue+label%3A%22good+first+issue%22) to pick from.\n\nContributions can be anything from creating issues, improving user and contributor documents, enhancing build and docker tools, fixing and enhancing code, or unit tests and e2e tests. If you are unsure where to start, begin a discussion with the contributors on [GitHub Discussions](https://github.com/openebs/openebs/discussions) or by joining [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).\n\n### Will there be swag?\n\nYes. A big fat YES!\n\nThe official [Hacktoberfest](https://hacktoberfest.digitalocean.com/) will be giving away free t-shirts to every person making four pull requests to open source repositories during October, as well as limited-edition Hacktoberfest stickers to everyone who participates.\n\nOn top of this, you will also be able to get some exclusive and limited OpenEBS swag. When your PR to any OpenEBS repository is merged, we will contact you to fill out a form to send a special edition swag designed for Hacktoberfest.\n\nNot only this but by becoming a top weekly contributor, you’ll be able to grab even more swag.\n\nPrizes will be sent to quality contributions. The best PR will win a grand prize. Stay tuned to find out more.\n\nSo, what are you waiting for! Go get your git on and start contributing - we can’t wait to receive your PR.\n\nHappy hacking!\n\n### Getting Started:\n\n1. [https://hacktoberfest.digitalocean.com/](https://hacktoberfest.digitalocean.com/)\n2. Join [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F)\n3. Checkout the [OpenEBS Contributing guide](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md)\n4. Learn about the [architecture and components](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) of OpenEBS\n5. Create new issues for your contribution or pick one of the existing issues from [https://github.com/openebs/openebs/issues](https://github.com/openebs/openebs/issues)\n","slug":"hacktoberfest-2020-contribute-to-openebs"}]