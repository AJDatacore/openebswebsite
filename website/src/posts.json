[{"id":1,"title":"Deploying YugabyteDB on Google Kubernetes Engine with OpenEBS\r","author":"OPENEBS\r","author_info":"No author information","date":"05-04-2021\r","tags":["OpenEBS"," OpenSource"," Yugabyte"," Cloud Native Gke"],"excerpt":"In this blog post, we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\r","content":"\r\n[OpenEBS](https://www.openebs.io/) is a CNCF project backed by [MayaData](https://mayadata.io/) that provides cloud-native, open source container attached storage (CAS). OpenEBS delivers persistent block storage and other capabilities such as integrated back-up, management of local and cloud disks, and more. For enterprise cloud-native applications, OpenEBS provides storage functionality that is idiomatic with cloud-native development environments, with granular storage policies and isolation that enable cloud developers and architects to optimize storage for specific workloads.\r\n\r\nBecause [YugabyteDB](https://www.yugabyte.com/) is a cloud-native, distributed SQL database that runs in Kubernetes environments, it can interoperate with OpenEBS and many other CNCF projects.\r\n\r\n***Wait, what is YugabyteDB?** It is an open source, and high-performance distributed SQL database built on a scalable and fault-tolerant design inspired by Google Spanner. Yugabyte’s YSQL API is PostgreSQL wire compatible.*\r\n\r\nIn this blog post we’ll walk you through the necessary steps to get a 3 node YugabyteDB cluster running on top of GKE, backed by OpenEBS.\r\n\r\n**Why OpenEBS and YugabyteDB?**\r\nBecause YugabyteDB is a transactional database often used as a system of record, it needs to be deployed as a StatefulSet on Kubernetes and requires persistent storage. OpenEBS can be used for backing YugabyteDB local disks, allowing the provisioning of large-scale persistent volumes. \r\n\r\nHere are a few of the advantages of using OpenEBS in conjunction with a YugabyteDB database cluster:\r\n\r\n- There’s no need to manage the local disks as OpenEBS manages them.\r\n- OpenEBS and YugabyteDB can provision large size persistent volumes.\r\n- With OpenEBS persistent volumes, capacity can be thin provisioned, and disks can be added to OpenEBS on the fly without disruption of service. When this capability is combined with YugabyteDB, which already supports multi-TB data density per node, this can prove to be[ massive cost savings on storage.](https://docs.openebs.io/features.html#reduced-storage-tco-upto-50)\r\n- Both OpenEBS and YugabyteDB support multi-cloud deployments [helping organizations avoid cloud lock-in.](https://docs.openebs.io/docs/next/features.html#truely-cloud-native-storage-for-kubernetes)\r\n- Both OpenEBS and YugabyteDB integrate with another CNCF project, [Prometheus](https://prometheus.io/). This makes it easy to [monitor both storage and the database](https://docs.openebs.io/docs/next/features.html#prometheus-metrics-for-workload-tuning) from a single system.\r\n\r\nAdditionally, OpenEBS can do [synchronous replication](https://docs.openebs.io/docs/next/features.html#synchronous-replication) inside a geographic region. In a scenario where YugabyteDB is deployed across regions, and a node in any one region fails, YugaByteDB would have to rebuild this node with data from another region. This would incur cross-region traffic, which is more expensive and lower in performance. But, with OpenEBS, this rebuilding of a node can be done seamlessly because OpenEBS is replicating locally inside the region. This means YugabyteDB does not end up having to copy data from another region, which ends up being less expensive and higher in performance. In this deployment setup, only if the entire region failed, YugabyteDB would need to do a cross-region node rebuild. Additional detailed descriptions of OpenEBS enabled use cases can be found [here.](https://docs.openebs.io/docs/next/usecases.html)\r\n\r\nOk, let’s get started!\r\n\r\n**Prerequisites**\r\n![Yugabyte work flow](/images/blog/yugabyte-work-flow.png)\r\n\r\n\r\nUsing the latest and greatest versions of the available software (as of this blog’s writing), below is the environment which we’ll use to run a YugabyteDB cluster on top of a Google Kubernetes Engine (GKE) cluster backed by OpenEBS\r\n\r\n1. YugabyteDB - [Version 2.5.3.1](https://docs.yugabyte.com/latest/quick-start/install/)\r\n2. OpenEBS - [Version 2.7.0](https://github.com/openebs/openebs)\r\n3. A [Google Cloud Platform](https://cloud.google.com/gcp/) account\r\n\r\n**Step 1: Setting Up a Cluster on GKE**\r\nTo deploy YugabyteDB on the Google Cloud Platform (GCP), we first have to set up a cluster using Ubuntu as our base node image.\r\n\r\n***Note**: GKE’s Container-Optimized OS does not come with an iSCSI client pre-installed and does not allow the installation of an iSCSI client. Therefore, we’ll be using the Ubuntu with Docker image type for our nodes.*\r\n\r\nFor the purposes of this demo, I used the Google Cloud Console to configure my Kubernetes cluster. Aside from the typical defaults, here’s the options under the* Node Pools > default-pool > Nodes*  I selected\r\n\r\n- **Image Type:** Ubuntu with Docker\r\n- **Series:** N1\r\n- **Machine Type: **n1-standard-4 (4 vCPU, 15 GB memory)\r\n\r\n![Yugabyte nodes](/images/blog/yugabyte-nodes.png)\r\n\r\n\r\nClick *Create* and wait for the Kubernetes cluster to come online.\r\n\r\n**Step 2: Configure iSCSI**\r\nThe iSCSI client is a prerequisite for provisioning cStor and Jiva volumes. However, it is recommended that the iSCSI client is setup and* iscsid* service is running on worker nodes before proceeding with the OpenEBS installation. In order to set up iSCSI, we’ll first need to determine the names of the nodes in our cluster\r\n\r\n    $ kubectl get nodes\r\n    \r\n    NAME                                       \tSTATUS   ROLES    \tAGE   \tVERSION\r\n    gke-cluster-1-default-pool-be95f6dd-5x65  \tReady    <none>   \t18h   \tv1.18.15-gke.1501\r\n    gke-cluster-1-default-pool-be95f6dd-rs6c  \tReady    <none>   \t18h \tv1.18.15-gke.1501\r\n    gke-cluster-1-default-pool-be95f6dd-t4cp  \tReady    <none> \t18h  \tv1.18.15-gke.1501\r\n    \r\n    Now that we have the names of our nodes, we’ll want to log into each node and enable the iSCSI service.\r\n    \r\n    $ gcloud compute ssh <node name>\r\n    $ sudo systemctl enable iscsid && sudo systemctl start iscsid\r\n    \r\n    You can check the status of the iSCSI service using the following command:\r\n    \r\n    $ systemctl status iscsid\r\n    \r\n    iscsid.service - iSCSI initiator daemon (iscsid)\r\n       Loaded: loaded (/lib/systemd/system/iscsid.service; enabled; vendor preset: enabled)\r\n       Active: active (running) since Fri 2021-03-26 02:25:42 UTC; 18h ago\r\n         Docs: man:iscsid(8)\r\n      Process: 10052 ExecStart=/sbin/iscsid (code=exited, status=0/SUCCESS)\r\n      Process: 10038 ExecStartPre=/lib/open-iscsi/startup-checks.sh (code=exited, status=0/SUCCESS)\r\n     Main PID: 10059 (iscsid)\r\n        Tasks: 2 (limit: 4915)\r\n       CGroup: /system.slice/iscsid.service\r\n               ├─10057 /sbin/iscsid\r\n               └─10059 /sbin/iscsid\r\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Starting iSCSI initiator daemon (iscsid)...\r\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 iscsid[10052]: iSCSI logger with pid=10057 started!\r\n    Mar 26 02:25:42 gke-cluster-1-default-pool-be95f6dd-5x65 systemd[1]: Started iSCSI initiator daemon (iscsid).\r\n    \r\n\r\n**Step 3: Install OpenEBS**\r\nNext, let’s install OpenEBS. I’ve found that the OpenEBS Operator is one of the simplest ways to get the software up and running.\r\n\r\n    $ kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml\r\n\r\nOnce the installation is completed, check and verify the status of the pods. You should something similar to this:\r\n\r\n    $ kubectl get pods -n openebs\r\n    \r\n    NAME                                            READY   STATUS    \r\n    maya-apiserver-dd655ff87-rbgmd                  1/1     Running  \r\n    openebs-admission-server-5965c94767-4h8rc       1/1     Running   \r\n    openebs-localpv-provisioner-5495669c66-z46lr    1/1     Running   \r\n    openebs-ndm-dss64                               1/1     Running  \r\n    openebs-ndm-gnv75                               1/1     Running   \r\n    openebs-ndm-operator-68949644b9-mqvlx           1/1     Running  \r\n    openebs-ndm-r5pws                               1/1     Running  \r\n    openebs-provisioner-544cb85449-w9spl            1/1     Running   \r\n    openebs-snapshot-operator-6d65b778dd-79zcn      2/2     Running \r\n\r\n**Step 4: Create and Attach Disks to Nodes**\r\nOur worker nodes need to have disks attached. These disks need to be unmounted and not have a filesystem on them. To accomplish this we’ll need to execute the following commands on each node.\r\n\r\n    $ gcloud compute disks create disk1 --size=10GB\r\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-5x65 --disk disk1\r\n    \r\n    $ gcloud compute disks create disk2 --size=10GB\r\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-rs6c --disk disk2\r\n    \r\n    $ gcloud compute disks create disk3 --size=10GB\r\n    $ gcloud compute instances attach-disk gke-cluster-1-default-pool-be95f6dd-t4cp --disk disk3\r\n    \r\n    Next let’s verify that our block devices are indeed attached.\r\n    \r\n    $ kubectl get blockdevice -n openebs\r\n    \r\n    NAME              NODENAME                           SIZE          CLAIMSTATE   STATUS   \r\n    blockdevice-03... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\r\n    blockdevice-85... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active   \r\n    blockdevice-b0... gke-cluster-1-default-pool-be9...  10736352768   Claimed      Active\r\n    \r\n\r\n**Step 5: Create a Storage Pool Claim**\r\nNow that we have the names of our block devices and have verified that they are active, the next step is to create a Storage Pool Claim. We’ll use this to then create a Storage Class, and finally use that for our Persistent Volume Claims. The first step in this chain of steps is to configure our Storage Pool Claim YAML file. In this demo, I’ve named it “cstor-pool1-config.yaml”.\r\n\r\n    $ vim cstor-pool1-config.yaml\r\n    \r\n    #Use the following YAMLs to create a cStor Storage Pool.\r\n    apiVersion: openebs.io/v1alpha1\r\n    kind: StoragePoolClaim\r\n    metadata:\r\n      name: cstor-disk-pool\r\n      annotations:\r\n        cas.openebs.io/config: |\r\n          - name: PoolResourceRequests\r\n            value: |-\r\n                memory: 2Gi\r\n          - name: PoolResourceLimits\r\n            value: |-\r\n                memory: 4Gi\r\n    spec:\r\n      name: cstor-disk-pool\r\n      type: disk\r\n      poolSpec:\r\n        poolType: striped\r\n      blockDevices:\r\n        blockDeviceList:\r\n    - blockdevice-03e93d010db5169322eb16f3e18e33ed   \r\n    - blockdevice-22591882979084d0fe580fe229e0d84f   \r\n    - blockdevice-4d1b4bacbeec1650b337c2cfda7e3a48   \r\n    ---\r\n\r\n    Once you’ve figured out how to exit vim, the next step is to create the resource.\r\n    $ kubectl create -f cstor-pool1-config.yaml\r\n    \r\n    \r\n\r\nWe can verify our storage pool with the following command:\r\n\r\n    $ kubectl get csp\r\n    \r\n    NAME                   ALLOCATED   FREE    CAPACITY   STATUS    READONLY   TYPE   \r\n    cstor-disk-pool-6cmf   1.85M       9.94G   9.94G      Healthy   false      striped\r\n    cstor-disk-pool-jql6   40.6M       9.90G   9.94G      Healthy   false      striped\r\n    cstor-disk-pool-vbz5   68.2M       9.87G   9.94G      Healthy   false      striped\r\n    \r\n\r\n**Step 6: Create a Storage Class**\r\nNow that we have a storage pool, let’s configure the YAML file for our storage class.  In this demo, I’ve named it “openebs-sc-rep1.yaml”.\r\n\r\n    $ vim openebs-sc-rep1.yaml\r\n    \r\n    apiVersion: storage.k8s.io/v1\r\n    kind: StorageClass\r\n    metadata:\r\n      name: openebs-sc-rep1\r\n      annotations:\r\n        openebs.io/cas-type: cstor\r\n        cas.openebs.io/config: |\r\n          - name: StoragePoolClaim\r\n            value: \"cstor-disk-pool\"\r\n          - name: ReplicaCount\r\n            value: \"1\"\r\n    provisioner: openebs.io/provisioner-iscsi\r\n\r\nAssuming you have remembered how to exit vim from the previous step, we now need to create the storage class.\r\n\r\n    $ kubectl create -f openebs-sc-rep1.yaml\r\n\r\nFinally, let’s verify the storage class.\r\n\r\n    $ kubectl get sc\r\n    \r\n    NAME                  PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE \r\n    openebs-device        openebs.io/local             Delete          WaitForFirstConsumer\r\n    openebs-hostpath      openebs.io/local             Delete          WaitForFirstConsumer\r\n    openebs-jiva-default  openebs.io/provisioner-iscsi Delete          Immediate\r\n    openebs-sc-rep1       openebs.io/provisioner-iscsi Delete          Immediate\r\n    openebs-snapshot...   volumesnapshot.external...   Delete          Immediate\r\n    premium-rwo           pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\r\n    standard (default)    kubernetes.io/gce-pd         Delete          Immediate\r\n    standard-rwo          pd.csi.storage.gke.io        Delete          WaitForFirstConsumer\r\n\r\nAt this point, we are now set up for Persistent Volume Claims.\r\n\r\n**Step 7: Install YugabyteDB**\r\n\r\nIn this final step we’ll install a 3 node YugabyteDB cluster running on top of GKE that will be backed by the OpenEBS deployment we just completed.\r\n\r\nThe first step is to create a namespace.\r\n\r\n*$ kubectl create namespace yb-demo*\r\n\r\nNext, let’s install the cluster using Helm.\r\n\r\n    $ helm install yb-demo yugabytedb/yugabyte --set resource.master.requests.cpu=1,resource.master.requests.memory=1Gi,\\\r\n    resource.tserver.requests.cpu=1,resource.tserver.requests.memory=1Gi,\\\r\n    enableLoadBalancer=True --namespace yb-demo  --set storage.master.storageClass=openebs-sc-rep1,storage.tserver.storageClass=openebs-sc-rep1 --set persistence.storageClass=openebs-cstor-disk --wait\r\n    \r\n\r\nNote that in the command above we are specifying the following so that YugabyteDB makes explicit use of OpenEBS:\r\n\r\n- *storage.master.storageClass=openebs-sc-rep1*\r\n- *storage.tserver.storageClass=openebs-sc-rep1*\r\n- *persistence.storageClass=openebs-cstor-disk*\r\n\r\nOnce the installation is complete you should be able log into the PostgreSQL compatible YSQL shell on port 5433 with the following command:\r\n\r\n    $ kubectl --namespace yb-demo exec -it yb-tserver-0 -- sh -c \"cd /home/yugabyte && ysqlsh -h yb-tserver-0\"\r\n    \r\n    ysqlsh (11.2-YB-2.5.3.1-b0)\r\n    Type \"help\" for help.\r\n    yugabyte=#\r\n    \r\n\r\nYou can also access the basic YugabyteDB web admin portal at:\r\n\r\n*http://<yb-master-ui-endpoint>:7000*\r\n\r\n![Yugabyte master](/images/blog/yugabyte-master.png)\r\n\r\n**Viewing Services and Ingress**\r\nA quick and visual way to check out all the services and ingress is to go to the “Services and Ingress” view in the Google Cloud Console. If you’ve made it this far you should see something like this:\r\n\r\n![Yugabyte ingress](/images/blog/yugabyte-ingress.png)\r\n\r\nNote: I have omitted the “Endpoints” column from the screenshot above, but in your view you’ll be able to see the IPs and ports of the various endpoints.\r\n\r\nThat’s it! You now have a 3 node YugabyteDB cluster running on GKE with OpenEBS storage.\r\n\r\n**Next Steps**\r\nAs mentioned, MayData is the chief sponsor of the OpenEBS project. It offers an enterprise-grade OpenEBS platform that makes it easier to run stateful applications on Kubernetes by helping get your workloads provisioned, backed-up, monitored, logged, managed, tested, and even migrated across clusters and clouds. You can learn more about MayaData [here.](https://mayadata.io/)\r\n\r\n- Learn more about OpenEBS by visiting the [GitHub](https://github.com/openebs/openebs) and [official Docs](https://docs.openebs.io/) pages.\r\n- Learn more about YugabyteDB by visiting the [GitHub](https://github.com/yugabyte/yugabyte-db) and [official Docs](https://docs.yugabyte.com/) pages.\r\n\r\n****About the author:****\r\n\r\n![Jimmy Guerrero](/images/blog/authors/jimmy-guerrero.png)\r\n\r\nJimmy Guerrero, VP Marketing, and Community at YugaByte.\r\n","slug":"deploying-yugabytedb-on-google-kubernetes-engine-with-openebs"},{"id":2,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks\r","author":"OPENEBS\r","author_info":"\r","date":"22-03-2021\r","tags":["Mayastor","OpenEBS"],"excerpt":"Learn about Repeatable OpenEBS Mayastor deployments and benchmarks\r","content":"\r\n## Introduction\r\n\r\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\r\n\r\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\r\n\r\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\r\n\r\n\r\n## OpenEBS\r\n\r\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\r\n\r\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\r\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\r\n\r\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\r\n\r\n\r\n## OpenEBS Mayastor\r\n\r\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\r\n\r\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\r\n\r\n\r\n## Introducing: the Automation Playground\r\n\r\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\r\n\r\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\r\n\r\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\r\n\r\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\r\n\r\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars\r\n\r\n\r\n## Stages\r\n\r\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\r\n\r\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\r\n\r\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\r\n\r\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\r\n\r\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\r\n\r\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\r\n\r\n\r\n#### Stage 1: Provisioning\r\n\r\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\r\n\r\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\r\n\r\nThe nodes provisioned are of three varieties\r\n\r\n* Master nodes (for Kubernetes Masters)\r\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\r\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\r\n\r\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\r\n\r\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\r\n\r\n#### Stage 2: Start VPN\r\n\r\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\r\n\r\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\r\n\r\n#### Stage 3: Kubernetes setup\r\n\r\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\r\n\r\nCurrently two installation types are supported with more planned:\r\n\r\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\r\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\r\n\r\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\r\n\r\n#### Stage 4: Node preparation\r\n\r\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\r\n\r\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\r\n\r\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\r\n\r\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\r\n\r\n## Playbooks\r\n\r\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\r\n\r\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\r\n\r\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\r\n\r\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\r\n\r\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\r\n\r\n## Conclusion\r\n\r\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\r\n\r\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\r\n\r\nPlease visit us at https://mayadata.io and give the Demo Playground a spin at https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground.\r\n\r\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":3,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes\r","author":"Kiran Mova\r","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.\r","date":"12-03-2021\r","tags":["Localpv"," OpenEBS"," Flipkart"," TikTok"," Kubernetes"," Mayastor"," MayaData"],"excerpt":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes\r","content":"\r\n**How to select the right local volume for your workloads?**\r\n\r\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\r\n\r\n![kg-image](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\r\n\r\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: https://github.com/openebs/openebs/blob/master/ADOPTERS.md.\r\n\r\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\r\n\r\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\r\n\r\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\r\n\r\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\r\n\r\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\r\n\r\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\r\n\r\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\r\n\r\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:\r\n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\r\n\r\n## Limitations of Kubernetes LocalPV\r\n\r\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\r\n\r\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\r\n\r\nWe have seen that cluster administrators are challenged by the following aspects:\r\n\r\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\r\n\r\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\r\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\r\n* Nodes have 8 to 16 high-performing NVMe SSDs.\r\n\r\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\r\n\r\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\r\n\r\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\r\n\r\n* Enforcing Capacity Limits/Thresholds\r\n* Securing the Volumes\r\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\r\n* Encrypting the Volumes\r\n* Enforce compliance with BCP by taking regular snapshots and full backups\r\n\r\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\r\n\r\n## Selecting your LocalPV\r\n\r\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\r\n\r\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\r\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\r\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\r\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\r\n\r\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\r\n\r\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\r\n\r\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\r\n\r\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\r\n\r\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: https://github.com/openebs/openebs/blob/master/ADOPTERS.md","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":4,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage\r","author":"Akhil Mohan\r","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.\r","date":"13-01-2021\r","tags":["OpenEBS"],"excerpt":"Read about OpenEBS NDM, the go-to solution for managing Kubernetes Local Storage.\r","content":"\r\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\r\n\r\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\r\n\r\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\r\n\r\n## Key Storage Problems solved by NDM\r\n\r\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\r\n* Cluster-wide storage visibility\r\n* Detect the movement of storage devices across nodes\r\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\r\n\r\n## Getting Started with NDM\r\n\r\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\r\n\r\nMaster: 2 virtual disks\r\n\r\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\r\n\r\nWorker 2: 4 physical disks\r\n\r\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\r\n    ```\r\n    kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml\r\n    ```\r\n    (The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\r\n\r\n* Once deployed, check the blockdevices present in the cluster using\r\n    ```\r\n    kubectl get bd -n openebs -o wide\r\n    ```\r\n    Some block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\r\n\r\n* Deploy a sample application to use the block device\r\n\r\n    Download the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\r\n    ```\r\n    kubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\r\n    ```\r\n    Now check the status of block devices again\r\n\r\n    We can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\r\n\r\n* Pool movement across nodes\r\n\r\n  NDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\r\n\r\n* Reserving storage for workloads\r\n\r\n  NDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\r\n\r\n## Future Roadmap\r\n\r\n* Southbound provisioning\r\n* Metrics (currently in alpha)\r\n* API Service to interact with NDM\r\n* Ability to create partitions or LVM volume groups - preparing storage in general.\r\n\r\n## Interested in Contributing to NDM?\r\n\r\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":5,"title":"Storage is Evolving!\r","author":"Nick Connolly\r","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.\r","date":"11-12-2020\r","tags":["OpenEBS"],"excerpt":"Learn how storage has evolved over the years. \r","content":"\r\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\r\n\r\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\r\n\r\n## The hardware environment is changing!\r\n\r\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\r\n\r\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\r\n\r\n## Application development is changing!\r\n\r\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\r\n\r\n## A New Era\r\n\r\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\r\n\r\n## Container Attached Storage\r\n\r\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\r\n\r\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\r\n\r\n## Microsoft Windows\r\n\r\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not supported on Windows’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\r\n\r\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\r\n\r\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\r\n\r\n## Windows Platform Development Kit\r\n\r\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\r\n\r\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\r\n\r\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\r\n\r\n1. Enable high-performance access to NVMe storage directly from applications.\r\n2. Native software defined storage stacks, including OpenEBS Mayastor.\r\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\r\n\r\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to https://wpdk.github.io or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":6,"title":"OpenEBS on DigitalOcean Marketplace\r","author":"Abhishek\r","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.\r","date":"3-12-2020\r","tags":["OpenEBS","chaosengineering","tutorials"],"excerpt":"Learn how to deploy OpenEBS on the DigitalOcean marketplace\r","content":"\r\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\r\n\r\nWORKFLOW:\r\n\r\nSTEP 1: Getting started\r\nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\r\n\r\nSTEP 2: Creation of cluster\r\nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\r\n\r\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\r\n\r\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\r\n\r\nSTEP 3: Connecting your cluster\r\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\r\n\r\nTo verify, execute the following command:\r\n\r\n```$ kubectl get ns```\r\n\r\nOutput:\r\n```\r\nNAME     STATUS    AGE\r\ndefault  Active    13m\r\nopenebs  Active    13m\r\n```\r\nThe output must contain openebs ns in an Active state.\r\n\r\nNext, execute:\r\n\r\n```$ kubectl get pods -n openebs```\r\n\r\nOutput:\r\n```\r\nNAME                                                 READY     STATUS    RESTARTS AGE\r\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\r\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\r\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\r\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\r\nopenebs-ndm-74njq                                    1/1       Running   0        13m\r\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\r\nopenebs-ndm-spttv                                    1/1       Running   0        13m\r\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\r\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\r\n```\r\nAll the pods must be in a running state.\r\n\r\nSTEP 4: Attaching BlockDevices\r\nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\r\n\r\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\r\n\r\nNOTE:\r\n\r\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\r\n\r\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\r\n\r\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\r\n\r\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":7,"title":"Atlassian Jira Deployment on OpenEBS\r","author":"Abhishek\r","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.\r","date":"20-11-2020\r","tags":["OpenEBS"],"excerpt":"Learn how to deploy Atlassian Jira on OpenEBS in this short post.\r","content":"\r\n**Jira** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, Jira has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\r\n\r\n## Requirements\r\n\r\n#### Install OpenEBS\r\n\r\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\r\n\r\n#### Configure cStor Pool\r\n\r\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\r\n\r\n```\r\n#Use the following YAMLs to create a cStor Storage Pool.\r\n# and associated storage class.\r\napiVersion: openebs.io/v1alpha1\r\nkind: StoragePoolClaim\r\nmetadata:\r\n  name: cstor-disk\r\nspec:\r\n  name: cstor-disk\r\n  type: disk\r\n  poolSpec:\r\n    poolType: striped\r\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\r\n  #\r\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\r\n  # as the disk operator\r\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\r\n# Uncomment the below lines after updating the actual disk names.\r\n  blockDevices:\r\n    blockDeviceList:\r\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n\r\n---\r\n```\r\n\r\n#### Create Storage Class\r\n\r\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\r\n\r\n```\r\napiVersion: storage.k8s.io/v1\r\nkind: StorageClass\r\nmetadata:\r\n  name: openebs-cstor-disk\r\n  annotations:\r\n    openebs.io/cas-type: cstor\r\n    cas.openebs.io/config: |\r\n      - name: StoragePoolClaim\r\n        value: \"cstor-disk\"\r\n      - name: ReplicaCount\r\n        value: \"3\"       \r\nprovisioner: openebs.io/provisioner-iscsi\r\nreclaimPolicy: Delete\r\n```\r\n\r\n### Deployment of Jira\r\n\r\nSample Jira Yaml:\r\n\r\n```\r\napiVersion: extensions/v1beta1\r\nkind: Deployment\r\nmetadata:\r\n  labels:\r\n    app: jira\r\n  name: jira\r\nspec:\r\n  replicas: 1\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: jira\r\n      name: jira\r\n    spec:\r\n      containers:\r\n        - name: jira\r\n          image: \"doriftoshoes/jira:7.3.6\"\r\n          resources:\r\n            requests:\r\n              cpu: \"2\"\r\n              memory: \"2G\"\r\n          volumeMounts:\r\n            - name: \"jira-home\"\r\n              mountPath: /opt/jira-home\r\n      volumes:\r\n        - name: jira-home\r\n          persistentVolumeClaim:\r\n            claimName: demo-vol1-claim\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  labels:\r\n    app: jira\r\n  name: jira\r\nspec:\r\n  ports:\r\n    - port: 8080\r\n      targetPort: 8080\r\n  selector:\r\n    app: jira\r\n  type: LoadBalancer\r\n---\r\nkind: PersistentVolumeClaim\r\napiVersion: v1\r\nmetadata:\r\n  name: demo-vol1-claim\r\nspec:\r\n  storageClassName: openebs-cstor-disk\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 10G\r\n```\r\n\r\nNext, apply both the **Jira deployment** and service to your Kubernetes cluster.\r\n\r\n```kubectl apply -f jira.yaml```\r\n\r\n#### Verify Jira Pods:\r\n\r\n#### Run the following to get the status of Jira pods:\r\n\r\n```kubectl get pods```\r\n\r\nFollowing is an example output:\r\n\r\n```\r\nNAME                    READY   STATUS    RESTARTS   AGE\r\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\r\n```\r\n\r\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":8,"title":"Mayastor NVMe-oF TCP performance\r","author":"Jeffry Molanus\r","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.\r","date":"19-11-2020\r","tags":["Mayastor"],"excerpt":"Overview of using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known.\r","content":"\r\nFor a while now, we have been saying that OpenEBS Mayastor is “high” performance and community members have written [blogs](https://medium.com/volterra-io/kubernetes-storage-performance-comparison-v2-2020-updated-1c0b69f0dcf4) showing that the performance of OpenEBS Mayastor indeed is much better or on par with others even when running on relatively slow cloud volumes. However, is Mayastor high performance or just “as fast” as the other things out there? \r\n\r\nIt used to be the case that CPUs were much faster than the storage systems they served. With modern NVMe, this does not ***have*** to be the case anymore. NVMe is a ***protocol*** that can go fast but does not have to be fast. What this means is that you can use NVMe as your transport protocol for any block device, not just flash. Yes, this is what Mayastor does. It is really useful to keep in mind the distinction between NVMe as a protocol and NVMe devices - you don’t need to use them together but, when you do, additional performance can be unlocked.\r\n\r\nIn this blog, we will be using Mayastor to try out some of the fastest NVMe devices currently available on the market and see how we perform on top of these devices within k8s, using the container attached storage approach for which OpenEBS is well known. We will show what happens when you marry NVMe as a protocol (embedded within Mayastor) and fast NVMe devices from our friends at Intel.\r\n\r\nBefore we get started, you might wonder how we came to this point that a new project like OpenEBS Mayastor was able to deliver amongst the fastest storage available today. Richard Elling of Viking / Sanmina recently wrote an excellent blog on the trends in hardware design that puts NVMe and OpenEBS Mayastor into context:  [https://richardelling.substack.com/p/the-pendulum-swings-hard-towards](https://richardelling.substack.com/p/the-pendulum-swings-hard-towards)\r\n\r\n## Hardware setup\r\n\r\nLet’s get to it. We will be using three machines that will run kernel version 5.8. The hardware configuration of each host is as follows:\r\n\r\n- Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz\r\n- Intel Corporation NVMe Datacenter SSD [Optane]\r\n- Mellanox Technologies MT28908 Family [ConnectX-6]\r\n\r\n## Baseline performance\r\n\r\nTo understand the performance of the device we will be using throughout the test, we run the following Fio workload:\r\n\r\n    [global]\r\n    ioengine=linuxaio\r\n    thread=1\r\n    group_reporting=1\r\n    direct=1\r\n    norandommap=1\r\n    bs=4k\r\n    numjobs=8\r\n    time_based=1\r\n    ramp_time=0\r\n    runtime=300\r\n    iodepth=64\r\n    \r\n    \r\n    [random-read-QD64]\r\n    filename=/dev/nvme1n1\r\n    rw=randread\r\n    stonewall\r\n    \r\n    \r\n    [random-write-QD64]\r\n    filename=/dev/nvme1n1\r\n    rw=randwrite\r\n    stonewall\r\n    \r\n    \r\n    [random-rw-QD64]\r\n    filename=/dev/nvme1n1\r\n    rw=randrw\r\n    stonewall\r\n\r\n![Mayastor NVME](/images/blog/mayastor-nvme1.png)\r\nThese numbers are incredibly high and are provided by a ***single*** device. Note that the benchmark itself is rather synthetic in the sense that, in practice, no workload is 100% random.\r\n\r\n## High-level overview of the experiments\r\n\r\nMy approach in this benchmarking is very much OpenEBS Mayastor “the hard way”.  If you want an easier to use solution that for example automates pool creation and device selection and so on - we call that offering Kubera Propel (also open source btw). You can learn more about Kubera Propel on the [MayaData.io](https://mayadata.io/) website.    \r\n\r\nOn two of the nodes, we create a pool (MSP CRD) which we use in the control plane to determine replica placement. To construct pools, we must have what we call a persistence layer. We support several ways to access this persistence layer. To select a particular scheme we use URIs. In this case we will be using today the pcie:/// scheme. This means that Mayastor will directly write into the NVMe devices listed above. The nice thing is that from the user perspective, things do not change that much. We simply replace disks: [‘/dev/nvme0n1’] with disks: [‘pcie:///80:00.0’]. Note that this persistence layer is used to store the replicas of the PVC. Once we have this layer up and running, we will create storage classes and select that we want to use nvmf (NVMe-oF) as the transport layer between the replicas, resulting in NVMe all the way through. \r\n\r\nAfter we have deployed mayastor we applied to following two storage classes:\r\n\r\n    kind: StorageClass\r\n    apiVersion: storage.k8s.io/v1\r\n    metadata:\r\n      name: nvmf\r\n    parameters:\r\n      repl: '1'\r\n      protocol: 'nvmf'\r\n    provisioner: io.openebs.csi-mayastor\r\n    ---\r\n\r\n    kind: StorageClass\r\n    apiVersion: storage.k8s.io/v1\r\n    metadata:\r\n      name: nvmf-mirror\r\n    parameters:\r\n      repl: '2'\r\n      protocol: 'nvmf'\r\n    provisioner: io.openebs.csi-mayastor\r\n\r\nNote that `protocol: `nvmf` is just a shorthand for the NVMe-oF format mentioned above. We will be using both storage classes to run a single replica followed by a two way replica AKA mirror.  We use the following YAML to create the volume.\r\n\r\n    apiVersion: v1\r\n    kind: PersistentVolumeClaim\r\n    metadata:\r\n      name: ms-volume-claim\r\n    spec:\r\n      accessModes:\r\n       - ReadWriteOnce\r\n      resources:\r\n        requests:\r\n          storage: 100G\r\n      storageClassName: nvmf\r\n\r\nAfter creating the PVC, Mayastor’s control plane creates a CRD, “Mayastor Volume” (MSV), that contains additional information about the corresponding volume.  Using kubectl describe msv -n mayastor we get:\r\n\r\n    Name:         ba081dc3-46db-445b-969c-7e5245aba146\r\n    Namespace:    mayastor\r\n    Labels:       <none>\r\n    Annotations:  <none>\r\n    API Version:  openebs.io/v1alpha1\r\n    Kind:         MayastorVolume\r\n    Metadata:\r\n      Creation Timestamp:  2020-09-11T08:49:30Z\r\n      Generation:          1\r\n      Managed Fields:\r\n        API Version:  openebs.io/v1alpha1\r\n        Fields Type:  FieldsV1\r\n        fieldsV1:\r\n          f:spec:\r\n            .:\r\n            f:limitBytes:\r\n            f:preferredNodes:\r\n            f:replicaCount:\r\n            f:requiredBytes:\r\n            f:requiredNodes:\r\n          f:status:\r\n            .:\r\n            f:nexus:\r\n              .:\r\n              f:children:\r\n              f:deviceUri:\r\n              f:state:\r\n            f:node:\r\n            f:reason:\r\n            f:replicas:\r\n            f:size:\r\n            f:state:\r\n        Manager:         unknown\r\n        Operation:       Update\r\n        Time:            2020-09-11T08:51:18Z\r\n      Resource Version:  56571\r\n      Self Link:         /apis/openebs.io/v1alpha1/namespaces/mayastor/mayastorvolumes/ba081dc3-46db-445b-969c-7e5245aba146\r\n      UID:               94e11d58-fed9-44c9-9368-95b6f0712ddf\r\n    Spec:\r\n      Limit Bytes:  0\r\n      Preferred Nodes:\r\n      Replica Count:   1\r\n      Required Bytes:  100000000000\r\n      Required Nodes:\r\n    Status:\r\n      Nexus:\r\n        Children:\r\n          State:     CHILD_ONLINE\r\n          Uri:       bdev:///ba081dc3-46db-445b-969c-7e5245aba146\r\n        Device Uri:  nvmf://x.y.z.y:8420/nqn.2019-05.io.openebs:nexus-ba081dc3-46db-445b-969c-7e5245aba146\r\n        State:       NEXUS_ONLINE\r\n      Node:          atsnode3\r\n      Reason:\r\n      Replicas:\r\n        Node:     node3\r\n        Offline:  false\r\n        Pool:     pool-atsnode3\r\n        Uri:      bdev:///ba081dc3-46db-445b-969c-7e5245aba146\r\n      Size:       100000000000\r\n      State:      healthy\r\n    Events:       <none>\r\n\r\n## Results single replica\r\n![Mayastor NVME](/images/blog/mayastor-nvme2.png)![Chart](https://lh5.googleusercontent.com/whpgDl_Id_oo4tUdl7RZDv-C1Uq2ZfvM6Eh7KXbwNkNTu5Mki14meunBgF1PMWMnWLoccSGgHqCfRKXgQpJTfQG42NaS0GkwWRCuNpWGh7znOhqQ94aJXiCODJkzNUs9-G2ucqMJ)\r\nFrom the results we can see that we are very close to the performance of the local device. To be sure we can put it in the right perspective, the difference between the experiments here is that with the baseline, the workload was local. With repl=1 we use the same NVMe device but export it through our pool layer (and thus provide volume management), but also go over the network.\r\n\r\n## Results 2 replicas (mirror)\r\n\r\nWe are going to repeat the same test, this time, we will use two replicas. As we now have double the disks bandwidth, we expect to see that the read performance will go up. For writes, however, we actually expect a drop in performance, because we must do each write to both disks before we can acknowledge the IO.  Note that Mayastor does not cache - if you read the blog referenced above from Richard Elling you can learn why caching seems to be falling out of favor for use cases in which millions of IOPS are desired.\r\n![Mayastor NVME](/images/blog/mayastor-nvme3.png)![Chart](https://lh4.googleusercontent.com/GJ7c_cZ6vuDxd9-jAnU3XxAc8L0idA9sscz2JB5XVa0taj8v56H6MSIFB56XqPQzQsy_p49-yHlwhCB8SVjZ05YfT0oRdlFt0EMBze1IDrCioqWgtWypidK9fBpb9p3ULI19Dhfa)\r\n## Wrapup\r\n\r\nWith the above experiments, we have demonstrated that with OpenEBS Mayastor we have built a foundational layer that allows us to abstract storage in a way that Kubernetes abstracts compute. While doing so, the user can focus on what's important -- deploying and operating stateful workloads. \r\n\r\nIf you’re interested in trying out Mayastor for yourself, instructions for how to setup your own cluster, and run a benchmark like **fio** may be found at [mayastor.gitbook.io/](https://mayastor.gitbook.io/introduction/).\r\n\r\nAnd if you are a Kubera Propel user, you’ll find that we’ve productized some of the benchmarking above so that platform teams and other users can programmatically use benchmarks in their decisions about workload placement. We are working with a number of users about operating OpenEBS Mayastor / Kubera Propel at scale. Please get in touch if you have suggestions, feedback, ideas for interesting use cases and so on. Contributions of all kinds are welcome!\r\n","slug":"mayastor-nvmeof-tcp-performance"},{"id":9,"title":"Mayastor Engine Reaches Beta\r","author":"Glenn Bullingham\r","author_info":"Director of Solution Architecture\r","date":"19-11-2020\r","tags":["OpenEBS"],"excerpt":"Mayastor, the storage engine by OpenEBS has reached the beta stage. Read the blog to know more.\r","content":"\r\ntitle: Mayastor Engine Reaches Beta\r\nAs I write this, it is early November, and the winds of change are blowing. The United States has a new president. Here in the United Kingdom, Keats' days of mists and mellow fruitfulness are departing, replaced by a low sun and the first morning frosts. And at MayaData, we see the Mayastor project carefully but tenaciously emerging from alpha/pre-release into its beta phase. In fact, Mayastor now undergirds MayaData’s commercial offering for performance sensitive containerized workloads, called [Kubera Propel](https://mayadata.io/product).\r\n\r\n> ***“Beta Software: Software considered to be feature complete and substantially free of known major defects”***\r\n\r\nSignificant contributions over the past 18 months have seen the project raised from concept to working software. A major requirement of our MVP specification is that it should carry minimal performance overhead; Mayastor is intended to satisfy demands for performance at all levels of scale. At the beginning of Autumn, working in conjunction with Intel’s labs in the UK, we were able to validate that assertion; deployed in conjunction with the latest generation of Optane NVMe devices, the Mayastor data plane was found to introduce less than 6% overhead; you can read more about that benchmarking [here](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/). Having addressed that performance criteria and the other principle MVP requirements, the Mayastor team at MayaData has begun to focus its contributions to the project on QA as we approach Beta and GA releases.\r\n\r\nIn particular, we’ve greatly increased end-to-end test coverage on Kubernetes. How MayaData tests Mayastor is something that I’ll elaborate upon in a forthcoming post.  However, suffice it to say customary suspects feature (Jenkins, mocha, nix, cargo test), whilst we’re also collaborating with our colleagues who maintain the [Litmus Chaos](https://litmuschaos.io/) project. By the time that you’re likely reading this, Mayastor-specific chaos tests should be available to all on [ChaosHub](https://hub.litmuschaos.io/).\r\n\r\n## Ease of Use, Perf, and Availability\r\n\r\nMayastor MVP requirements center on ease of use, performance, and availability. In the Beta phase and subsequent GA release, these will be realized as a CAS platform with full NVMe data path semantics, declarative configuration via CSI compliant dynamic provisioning, and N+1 synchronous mirroring of data at the persistent layer. This closely approaches functional parity with the current OpenEBS storage engines (cStor, Jiva, and Local PV), with snapshot and cloning functionality to be added in Q1 2021. Mayastor will also very soon be the recipient of a streamlined deployment and configuration experience, which is exclusive to this engine.\r\n\r\n## Try it Yourself\r\n\r\nIf you’re a member of the Kubernetes community looking to implement a platform-native storage solution in the new year, now is an ideal time to start evaluating Mayastor. The other venerable and respected engines of OpenEBS won’t be retiring overnight, but as full feature parity emerges, MayaData’s commercial products and services will on Mayastor as their default storage engine; we do recognize that some users will continue to prefer various flavors of Dynamic Local PV from OpenEBS - as a recent [blog](https://www.percona.com/blog/2020/10/01/deploying-percona-kubernetes-operators-with-openebs-local-storage/) from the CTO of Percona attests as do countless [Adopter.md case studies](https://github.com/openebs/openebs/blob/master/ADOPTERS.md) including that of the SaaS company Optoro, also a CNCF case study. Mayastor’s roadmap includes provisions for the inward migration of existing OpenEBS users. It’s an equally opportune moment to [consider becoming a contributor](https://github.com/openebs/Mayastor/issues/new/choose) to the project yourself.\r\n\r\nTo help with Mayastor onboarding as we prepare to go to full steam, we’re putting together a new documentation site over at[ GitBook](https://mayastor.gitbook.io/introduction/), which includes a comprehensive quick-start deployment guide (developer docs will remain, at least for now, with the OpenEBS/Mayastor GitHub repository). We’re also holding [Office Hours at Kubecon NA 2020 this month](https://kccncna20.sched.com/?searchstring=OpenEBS&amp;iframe=no&amp;w=&amp;sidebar=&amp;bg=), and we’d love to see you there.\r\n\r\nIf you’d like to try Mayastor from the source - you can do so, of course, from the GitHub repositories. If you’d like to also try out management utilities, including a cool management interface and available 24x7 support - please take a look at [Kubera Propel](https://go.mayadata.io/register-for-kubera-chaos-and-propel-technical-preview). A free forever for individual use tier is available.\r\n\r\n## Conclusion\r\n\r\nIt is a propitious time for MayaData and Mayastor - and for data on Kubernetes more broadly. If you have always wanted to run workloads on Kubernetes but were put off by the stories of performance challenges, you can now move forward with confidence. Kubernetes enabled storage with the help of Mayastor performs faster than that of traditional shared everything storage while retaining the ease of use, open source community, and Kubernetes semantics for which OpenEBS has become famous.\r\n","slug":"mayastor-engine-reaches-beta"},{"id":10,"title":"Migrate CSPIs to a different node by moving the disks\r","author":"Sai Chaithanya\r","author_info":"A developer who is always eager to learn, loves algorithms, maths, Kubernetes, and programming, Passionate about Data Science. Enjoys playing kabaddi and traveling.\r","date":"04-11-2020\r","tags":["OpenEBS"],"excerpt":"Step by step guide to migrate CStorPoolInstances from one node to different nodes by moving the set of underlying disks\r","content":"\r\n\r\nThis blog describes steps to migrate CStorPoolInstances from one node to different nodes by **moving the set of underlying disks to a new node that participates in the pool provisioning**. There were a couple of use cases where this feature can be helpful:\r\n\r\n1. Scaling down and scaling up nodes in the cluster(in a cloud environment) by retaining external volumes(for cost savings).\r\n2. Replacing failed storage nodes with new nodes by attaching the same old disks to the new node.\r\n\r\n**Steps to migrate the CSPI to different node:**\r\n\r\n1. Detach the disks belonging to the CSPI that you wish to migrate from the node and attach it to the new node. If you are using a cloud platform, check on their documentation, or ask the administrator about the steps to do this.\r\n2. Change the node selector in the CSPC YAML (next section describes how to do this).\r\n\r\n![](https://lh4.googleusercontent.com/XTwKu6lE3lyoZ3cHRO9HNJGUaTOoGfE-OWGuscrmukbxEKJNPSaEqxUPbbNnnc3dcD-Aybc2_AF0y2Scf0QBxSDG_f9QZWRu67sXZjoMKO6nymhgelEWfDzPjfGKi4D9UwLBaN0D)\r\n\r\n**Existing setup**:\r\n\r\nI have a three-node cluster with CSPC and CSI volumes already provisioned(To create CSPC pools and CSI volume click [here](https://github.com/openebs/cstor-operators/blob/master/docs/quick.md#quickstart)). Here is detailed information:\r\n\r\n**Cluster details**:\r\n\r\n    Kubernetes Cluster: AWS\r\n    Kubernetes Version: v1.15.9\r\n    OpenEBS Version: 2.2.0 \r\n\r\n****Node and BlockDevice details**: **Attached three disks to three nodes(each node has one disk)\r\n\r\n    Kubectl get nodes\r\n    \r\n    NAME                STATUS   ROLES    AGE   VERSION\r\n    ip-192-168-29-151   Ready    <none>   16m   v1.15.9\r\n    ip-192-168-36-89    Ready    <none>   8h    v1.15.9\r\n    ip-192-168-74-129   Ready    <none>   8h    v1.15.9\r\n    \r\n    Kubectl get bd -n openebs\r\n    NAME                                           NODENAME          SIZE          CLAIMSTATE   STATUS  \r\n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-36-89  10737418240   Claimed      Active   \r\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-74-129 10737418240   Claimed      Active   \r\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-29-151 10737418240   Claimed      Active\r\n\r\n****CSPC Manifest**: **Applied following CSPC manifest to provision cStor pools\r\n\r\n    apiVersion: cstor.openebs.io/v1\r\n    kind: CStorPoolCluster\r\n    metadata:\r\n      name: cstor-disk-cspc\r\n      namespace: openebs\r\n    spec:\r\n      pools:\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-74-129\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-36-89\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-29-151\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n\r\nAfter applying the above CSPC manifest, the following three CStorPoolInstances(CSPI) were created.\r\n\r\n    kubectl get cspi -n openebs\r\n    \r\n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\r\n    cstor-disk-cspc-dvc2  ip-192-168-74-129 24100M   24111M      false     ONLINE   8h\r\n    cstor-disk-cspc-f56z  ip-192-168-36-89  24100M   24113200k   false     ONLINE   8h\r\n    cstor-disk-cspc-q9yt  ip-192-168-29-151   24100M   24113200k   false     ONLINE   8h\r\n\r\nNow everything looks good. After some time, the cluster has been scaled down **0** nodes and scaled back to **3** nodes. So after scaling operations following are new nodes in the cluster.\r\n\r\n    Kubectl get nodes\r\n    \r\n    NAME               STATUS   ROLES    AGE     VERSION\r\n    ip-192-168-14-90   Ready    <none>   118s    v1.15.9\r\n    ip-192-168-49-43   Ready    <none>   5m55s   v1.15.9\r\n    ip-192-168-94-113  Ready    <none>   4m6s    v1.15.9\r\n\r\nAttached old disks that participated in pool creation to new nodes, and the following is blockdevice output.\r\n\r\n    Kubectl get bd -n openebs\r\n    \r\n    NAME                                           NODENAME            SIZE          CLAIMSTATE   STATUS  \r\n    blockdevice-7d311a98255a454a717427b5c2d38426   ip-192-168-49-43    10737418240   Claimed      Active   \r\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b   ip-192-168-94-113   10737418240   Claimed      Active   \r\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3   ip-192-168-14-90    10737418240   Claimed      Active\r\n\r\nFrom the above and previous output following are blockdevice mappings with zn old node and new node:\r\n\r\n    Blockdevice  Name                                    Old Node            New Node \r\n    blockdevice-7d311a98255a454a717427b5c2d38426    ip-192-168-36-89        ip-192-168-49-43\r\n    blockdevice-c2c846cce1befec7fbdcbae254329b0b    ip-192-168-74-129       ip-192-168-94-113\r\n    blockdevice-c608881cd3edbeab674a1aee7e0a1fc3    ip-192-168-29-151       ip-192-168-14-90\r\n\r\nOpenEBS **NodeDiskManager**(NDM) will automatically update the details in blockdevice CRs when the disks migrate to a new node. Based on the above output, update the CSPC manifest with new **nodeSelector** values.\r\n\r\n****Updated CSPC Manifest**:**\r\n\r\n    apiVersion: cstor.openebs.io/v1\r\n    kind: CStorPoolCluster\r\n    metadata:\r\n      name: cstor-disk-cspc\r\n      namespace: openebs\r\n    spec:\r\n      pools:\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-94-113\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-c2c846cce1befec7fbdcbae254329b0b\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-49-43\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-7d311a98255a454a717427b5c2d38426\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n        - nodeSelector:\r\n            kubernetes.io/hostname: \"ip-192-168-14-90\"\r\n          dataRaidGroups:\r\n          - blockDevices:\r\n              - blockDeviceName: \"blockdevice-c608881cd3edbeab674a1aee7e0a1fc3\"\r\n          poolConfig:\r\n            dataRaidGroupType: \"stripe\"\r\n\r\nOnce the CSPC manifest is updated then CSPIs will automatically migrate to the new node (which can be verified using ****kubectl get cspi -n openebs****).\r\n\r\n    kubectl get cspi -n openebs\r\n    \r\n    NAME                  HOSTNAME          FREE     CAPACITY    READONLY  STATUS   AGE\r\n    cstor-disk-cspc-dvc2  ip-192-168-94-113   24100M   24111M      false     ONLINE   8h\r\n    cstor-disk-cspc-f56z  ip-192-168-49-43    24100M   24113200k   false     ONLINE   8h\r\n    cstor-disk-cspc-q9yt  ip-192-168-14-90    24100M   24113200k   false     ONLINE   8h\r\n\r\n**Note:** Along with CStorPoolInstance migration, CStorVolumeReplicas belongs to CSPI will also migrate automatically.\r\n","slug":"migrate-cspis-to-a-different-node-by-moving-the-disks"},{"id":11,"title":"OpenEBS Backup/Restore for ZFS-LocalPV\r","author":"Pawan Prakash Sharma\r","author_info":"It's been an amazing experience in Software Engineering because of my love for coding. In my free time, I read books, play table tennis and watch tv series\r","date":"27-10-2020\r","tags":["OpenEBS"],"excerpt":"Overview of how to use Velero Backup/Restore plugin for ZFS-LocalPV to protect it against data loss.\r","content":"\r\n## Overview: OpenEBS Backup/Restore for ZFS-LocalPV\r\n\r\n**Backup** is the process of copying the data to a different/remote location to protect against accidental or corruption or any other type of data loss. Restore is the process of getting back the data from the backup. In this blog, I will discuss how we can use *Velero Backup/Restore* plugin for ***ZFS-LocalPV*** to protect it against data loss.\r\n\r\n### Pre-requisites\r\n\r\nWe should have installed the ZFS-LocalPV 1.0.0 or later version for Backup and Restore, see my previous[ blog](https://blog.openebs.io/openebs-dynamic-volume-provisioning-on-zfs-d8670720181d) for the steps to install the ZFS-LocalPV driver.\r\n\r\n### Setup\r\n\r\n**1.Install Velero CLI**\r\n\r\nDownload the 1.5 or later binary for ZFS-LocalPV. For Linux on amd64, we need to download below\r\n\r\n    wget\r\n    https://github.com/vmware-tanzu/velero/releases/download/v1.5.1/velero-v1.5.1-linux-amd64.tar.gz\r\n\r\nExtract the tarball:\r\n\r\n    tar -xvf velero-v1.5.1-linux-amd64.tar.gz\r\n\r\nMove the extracted velero binary to somewhere in your $PATH (/usr/local/bin for most users).\r\n\r\nSee the detailed steps[ here](https://velero.io/docs/v1.5/basic-install/).\r\n\r\n**2.Deploy Velero**\r\n\r\nWe will be using minio for storage purpose in this blog, we need to setup the credential file first\r\n\r\n    $ cat /home/pawan/velero/credentials-minio\r\n    [default]\r\n    aws_access_key_id = minio\r\n    aws_secret_access_key = minio123\r\n\r\nWe can install Velero by using below command\r\n\r\n    $ velero install --provider aws --bucket velero --secret-file /home/pawan/velero/credentials-minio --plugins velero/velero-plugin-for-aws:v1.0.0-beta.1 --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://minio.velero.svc:9000 --use-volume-snapshots=true --use-restic\r\n\r\nWe have to install the velero 1.5 or later version of velero for ZFS-LocalPV.\r\n\r\n**3.Deploy MinIO**\r\n\r\nDeploy the MinIO for storing the backup:-\r\n\r\n    $ kubectl apply -f\r\n    https://raw.githubusercontent.com/openebs/zfs-localpv/master/deploy/sample/minio.yaml\r\n\r\nThe above MinIO uses tmp directory inside the pod to store the data for the demonstration purpose, so when restart happens, the backed up data will be gone. We should change the above YAML to use persistence storage to store the data when deploying it for the production.\r\n\r\nCheck the Velero Pods are UP and Running\r\n\r\n    $ kubectl get po -n velero\r\n    NAME                      READY   STATUS      RESTARTS   AGE\r\n    minio-d787f4bf7-xqmq5     1/1     Running     0          8s\r\n    minio-setup-prln8         0/1     Completed   0          8s\r\n    restic-4kx8l              1/1     Running     0          69s\r\n    restic-g5zq9              1/1     Running     0          69s\r\n    restic-k7k4s              1/1     Running     0          69s\r\n    velero-7d9c448bc5-j424s   1/1     Running     3          69s\r\n\r\n**4.Setup OpenEBS Plugin**\r\n\r\nWe can Install the Velero Plugin for ZFS-LocalPV using the below command\r\n\r\n    velero plugin add openebs/velero-plugin:2.2.0\r\n\r\nWe have to install the velero-plugin 2.2.0 or later version, which has the support for ZFS-LocalPV. Once the setup is done, we can go ahead and create the backup/restore.\r\n\r\n**5.Create the VSL**\r\n\r\nThe VSL(Volume Snapshot Location) has information about where the snapshot should be stored. To create the Backup/Restore, we can create the Volume Snapshot Location by applying the below YAML:\r\n\r\n    apiVersion: velero.io/v1\r\n    kind: VolumeSnapshotLocation\r\n    metadata:\r\n     name: default\r\n     namespace: velero\r\n    spec:\r\n     provider: openebs.io/zfspv-blockstore\r\n     config:\r\n       bucket: velero\r\n       prefix: zfs\r\n       namespace: openebs # this is the namespace where ZFS-LocalPV creates all the CRs, passed as OPENEBS_NAMESPACE env in the ZFS-LocalPV deployment\r\n       provider: aws\r\n       region: minio\r\n       s3ForcePathStyle: \"true\"\r\n       s3Url: http://minio.velero.svc:9000\r\n\r\nHere, we have to provide the namespace, which we have used as OPENEBS_NAMESPACE env while deploying the ZFS-LocalPV. The ZFS-LocalPV Operator yamls uses “openebs” as the default value for OPENEBS_NAMESPACE env. Verify the volumesnapshot location:\r\n\r\n    kubectl get volumesnapshotlocations.velero.io -n velero\r\n\r\n### Create Backup\r\n\r\nWe can use the below Velero command to create the backup:\r\n\r\n    velero backup create my-backup --snapshot-volumes --include-namespaces=<backup-namespace> --volume-snapshot-locations=default --storage-location=default\r\n\r\nwe can add all the namespaces we want to be backed up in a comma-separated format in --include-namespaces parameter. We have to provide the VSL that we have created in --volume-snapshot-locations parameter.\r\n\r\nWe can check the backup status using the velero backup get command:\r\n\r\n    $ velero backup get\r\n    NAME        STATUS       CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR\r\n    my-backup   InProgress   2020-09-14 21:09:06 +0530 IST   29d       default            <none>\r\n\r\nThe status InProgress means that the backup is in progress. Wait for it to be Completed.\r\n\r\nWe can also create a scheduled backup which will take the backup periodically. For example, to take the full backup at every 5 min, we can create the below schedule :\r\n\r\n    velero create schedule schd --schedule=\"*/5 * * * *\" --snapshot-volumes --include-namespaces=<backup-namespace1>,<backup-namespace2> --volume-snapshot-locations=default --storage-location=default\r\n\r\n### Restore\r\n\r\nIf the application and its PVC has been deployed in a namespace, then we can use the below Velero command to create the backup of the entire namespace:\r\n\r\n    velero restore create --from-backup my-backup --restore-volumes=true --namespace-mappings <source-ns>:<dest-ns>\r\n\r\nThe above command will create the backup of everything that is there in the namespace provided as --include-namespaces argument. We can provide the namespace mapping if we want to restore in a different namespace as --namespace-mappings parameter. If namespace mappings are not provided, it will restore in the source namespace only where the original pod and pvc was present. Now we can check the restore status:\r\n\r\n    $ velero restore get\r\n    NAME                       BACKUP      STATUS       WARNINGS   ERRORS   CREATED                         SELECTOR\r\n    my-backup-20200914211331   my-backup   InProgress   0          0        2020-09-14 21:13:31 +0530 IST   <none>\r\n\r\nOnce the Status is Completed, we can check the pods in the destination namespace and verify that everything is up and running. We can also verify that the data has been restored.\r\n\r\n### Summary\r\n\r\nAs demonstrated in this blog, OpenEBS makes it easy to take the backup of the Kubernetes applications, which we can use to Restore as part of disaster recovery. In my next blog, I will talk about how we can take the incremental backup of the volumes, which is space optimized backup for ZFS-LocalPV\r\n\r\n## Important links\r\n\r\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\r\n[https://velero.io/docs/](https://velero.io/docs/v1.5/basic-install/)\r\n","slug":"openebs-backuprestore-for-zfslocalpv"},{"id":12,"title":"OpenEBS 2.2.0 - Enhancements And New Storage Capabilities\r","author":"Ashutosh Kumar\r","author_info":"Software Engineer at MayaData | OpenEBS Reviewer and Contributor | CKA | Gopher | Kubernaut\r","date":"20-10-2020\r","tags":["OpenEBS"],"excerpt":"OpenEBS 2.2.0 is here! Read this post to learn about the new updates.\r","content":"\r\n### **OpenEBS 2.2.0 is here**\r\n\r\nWe are excited to announce yet another ***OpenEBS*** release that comes with new storage capabilities, control plane enhancements, bug fixes, and new APIs for the world’s fastest storage engine built on RUST, also known as Mayastor.\r\n\r\nOpenEBS has seen a wider adoption among the users, thanks to the vibrant and growing community. Like in most of the OpenEBS releases, this release responds to the feedback received in the community. If you want to learn more about the project roadmap, please browse the following link:\r\n[https://github.com/openebs/openebs/blob/master/ROADMAP.md](https://github.com/openebs/openebs/blob/master/ROADMAP.md)\r\n\r\nIncremental Backup and Restore in ZFS local PV and pool and volume migration in cStor are the major release milestones made into the release. The pool migration in cStor solves the use-case of replacing a bad node with a new node or sending a node for maintenance on on-premise clusters. The migration feature provides great value in cloud-managed Kubernetes clusters, too, e.g., GKE, where node reboots or voluntary scale down of nodes can cause the disks to get removed. \r\n\r\nThis release is also special due to the [*Hacktoberfest*](https://hacktoberfest.digitalocean.com/) festival and would like to give a shout out to first-time contributors [@didier-durand](https://github.com/didier-durand), [@zlymeda](https://github.com/zlymeda), [@avats-dev](https://github.com/avats-dev), and many more.\r\n\r\n### **Key Highlights of OpenEBS 2.2.0 Release:**\r\n\r\n- Mayastor aims to be the world’s fastest container attached storage and is currently in alpha. The release introduced block device enumeration feature via the gRPC API and enhancement around storage pool finalizers.\r\n- ZFS local PV has become a popular storage engine built on local storage design and provides powerful storage features like snapshots and clones, raw block volume, etc. It also supports day two operations like volume resize and backup and restore via the pluggable Velero interface.\r\nSupport for Incremental Backup and Restore by enhancing the OpenEBS Velero Plugin has been a significant highlight for ZFS local PV release. \r\nTo learn more about this, please refer to the document [here](https://github.com/openebs/zfs-localpv/blob/master/docs/backup-restore.md).\r\n- OpenEBS Velero plugin connects the Velero interface to the OpenEBS storage engines to deliver backup/restore functionality. Velero Plugin has been enhanced to restore ZFS Local PV into a different cluster or a different node in the cluster and use custom certificates for S3 object storage.\r\n- CStor went into beta in 2.0 and has been enhanced to migrate the storage pool from one node to another node. This will help with scenarios where a Kubernetes node can be replaced with a new node but can be attached with the block devices from the old node that contain cStor Pool and the volume data.\r\n- OpenEBS node disk manager helps in block device discovery and management in a Kubernetes cluster and powers storage engines like cStor. Support to exclude multiple devices that could be mounted as host filesystem directories has been added.\r\nAn issue where NDM could cause data loss by creating a partition table on an uninitialized iSCSI volume has also been fixed.\r\n\r\n### **Useful Links and Summary:**\r\n\r\nIf you are interested in knowing more details regarding the changes that made to this release, please visit the release note [link](https://github.com/openebs/openebs/releases/tag/v2.2.0). To try out OpenEBS, you can visit [https://docs.openebs.io/](https://docs.openebs.io/) and follow the user guides.\r\n\r\nYou can visit the following link to learn more or experiment with Mayastor\r\n[https://github.com/openebs/mayastor](https://github.com/openebs/mayastor)\r\n\r\nYou can visit the following link to learn more or experiment with ZFS local PV\r\n[https://github.com/openebs/zfs-localpv](https://github.com/openebs/zfs-localpv)\r\n\r\nTo learn more about the new cStor CSPC API, please visit the following link:\r\n[https://github.com/openebs/cstor-operators](https://github.com/openebs/cstor-operators)\r\n\r\nIf you have any feedback, questions, or suggestions — please reach out to the community on the #openebs channel in the Kubernetes workspace or consider opening a relevant issue at [Github](https://github.com/openebs/openebs).\r\n","slug":"openebs-220-enhancements-and-new-storage-capabilities"},{"id":13,"title":"Scaling up cStor Volume Replica\r","author":"Abhishek\r","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.\r","date":"07-10-2020\r","tags":["OpenEBS"],"excerpt":"OpenEBS provides volume replication through different storage engines. Learn how to scale up cStor Volume Replica.\r","content":"\r\nEven if a cluster is reliable, nodes can and do fail. Rebooting a node does not simulate a crash. There can be many reasons, such as catastrophic hardware failure, Operating System failure, or communication failure among the nodes. To overcome this hazardous situation, the Replication of volume becomes necessary.\r\n\r\nReplication is the process by which one or more volumes can be copied to maintain the significance of a cluster and to avoid data loss. OpenEBS provides volume replication through different storage engines. One of them is cStor Volume Replication.\r\n![Synchronous replication of data](https://lh5.googleusercontent.com/ijS24Ywabw-QkWWYbSLoOshGTi2SHZhdEFATaHIYbkNGK8lUq5SJrct6fNHfPjWcPTHGyvByS7uD1vYct2m5D6-HdRC2ZoMpS_c4Crw-9sREhPU-tXE8KAt-nWj7vYw99Ee_s1pE)\r\n#### Prerequisite for scaling up the replicas of cStor volume:\r\n\r\n- A cStor pool should be available, and replicas of this cStor volume should not be present on this cStor pool.\r\n- The OpenEBS version should be 1.3.0 or more.\r\n\r\n### Please follow the below steps for cStor Volume Replication:\r\n\r\nGet the StorageClass name using the following command:\r\n\r\n    kubectl get sc\r\n\r\nExample Output:\r\n![](https://lh5.googleusercontent.com/lTma7ZqsAavmXEzGG_b4BXDMUEYXjFXf0xxnWgE70znfR_EzP3IorVFp0evkKoLMsBQ0D7gwOQxivB_bZxEcv2vhYZOe17k7mNyDBaPewTgiUdusrd3ow12ClBeQvZVmVzjDrdsI)\r\nThe storage class for cStor is ***openebs-sc-cstor***. Perform the following command to get the details of the corresponding StorageClass, which is used for creating the cStor volume :\r\n\r\n    Kubectl get sc openebs-sc-cstor\r\n\r\nWe will get the Yaml file of the corresponding StorageClass ***openebs-sc-cstor***.\r\n![](https://lh5.googleusercontent.com/81DQJ-DhT3AKseMRfCZ4NpkmOPl2Tckm76jrUxE2eECY7lrejvNz3OjomFWmNiCRwm0L2seAWzmJJhe-8xcqFirBsEUedf2xzPN4NHq2RM2YYEZZv-iKpsE03j06EQi_D5kqnDCi)\r\nIn the Yaml above, We can see the Replica count Value is 1.\r\n\r\nGet the volume name using the following command:\r\n\r\n    Kubectl get pvc\r\n\r\nGet the VOLUME name and use it in the following command to get the details of corresponding cStor volume. All commands are performed by considering the above PVC.\r\n\r\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=<Vol-name>\r\n\r\nExample output:\r\n![](https://lh4.googleusercontent.com/FIOJchscq3lm7UJLwnk7i1oNne_RxhjIJzI3FMANxxkRhz4yWZAue-Wu1jD03ii2aMjtdDu3zr9C-0ZGaeazkvxb_JkGnxBBDza605w_p-v9BY1ER40f6DityHwimJvhvuAR8FcT)\r\nGet the details of existing cStor Volume Replica details using the following command:\r\n\r\n    kubectl get cstorvolume -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\r\n\r\nExample output:\r\n![](https://lh3.googleusercontent.com/68NvgkfD7audTNZN1QLt6SVw4OvN_B3MIlnFnWm8MfgDziiexFX2qeI3tX6H1TCJJgrCA8b-nZQJoM6hx1QoYWOv4q74tKwB7nrZLc9xdluXRCvWTpj-sU6sIv7aJ0AMgL3rr1AR)\r\nPerform the following command to get complete details of the existing cStor volume replica:\r\n\r\n    kubectl get cvr -n openebs -l openebs.io/persistent-volume=pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8\r\n\r\nGet the available cStor Pools for creating new cStor volume replica. The following command will get the other associated cStor pools details:\r\n\r\n    kubectl get csp -l openebs.io/storage-pool-claim=cstor-disk-pool | grep -v cstor-disk-pool-hgt4\r\n\r\nExample Output:\r\n![](https://lh6.googleusercontent.com/lcbO830nSZgValr-I4ci7FHRa6Qvqf3eG-bycWHHAniRD8mb8dwRHOwxeVObFqj4FqvXbNkb_oZUdWhMgAQuHvU1pYDecvWXhDetYGdJADBQhWfzMuwJm4d9Ywgg6bAKkj-Sd79a)\r\nFrom the above example output, there are 2 cStor pools available, i.e., ***cstor-disk-pool-2phf*** and ***cstor-disk-pool-zm8l***. So it is possible to scale up the current volume replica count to 3 from 1. If there are no cStor pools available to perform volume replica scale-up, then follow the [steps](https://docs.openebs.io/docs/next/ugcstor.html#expanding-cStor-pool-to-a-new-node) to create a new cStor pool by updating existing SPC configuration.\r\n\r\nPerform the following command to get the details of the cStor Pool where new replica will be created:\r\n\r\n    kubectl get csp -n openebs cstor-disk-pool-2phf -oyaml\r\n\r\nNote down following parameters from the output:\r\n\r\n- metadata.labels.cstorpool.openebs.io/name\r\n- metadata.labels.cstorpool.cstorpool.openebs.io/uid\r\n- metadata.annotations.cstorpool.openebs.io/hostname\r\n\r\nThe sample CVR Yaml is provided below:\r\n![](https://lh3.googleusercontent.com/JePqVqyIryf396SEkCf9NoS3kmPDXM0huqehkN3kX5f-eE7nX3-mCr42xriJeDKSNRgfVxSeQG_SUHkbqEZS4ktIzzcJ8VKCsFXuz4VhtdXpikLADE3eJdkgwH3zFd5PXRPfYc70)\r\nApply the updated CVR YAML spec to create the new replica of cStor volume using the following command:\r\n\r\n    kubectl apply -f cvr.yaml\r\n\r\nExample Output:\r\n![](https://lh5.googleusercontent.com/JElB0d8zFXHoUh6wM0QpAshOmYbVXOvH5RIR9UjJ_svM67ZR2pq6cQ4ckrq0Qw6ACpRnOqO-6nUbvLUrDhFKvgZxjrh-ke0VHnKW-pR2oyzkgXdQuRATSwy9EVN19G458ZyR_9Xd)\r\nVerify if new CVR is created successfully using the following command:\r\n\r\n    kubectl get cvr -n openebs\r\n\r\nExample output:\r\n![](https://lh4.googleusercontent.com/ql9j6Zcod6DT1vKhJrlJJaxk4YUN8Mf_o7LT3e-fBjjoybINByEwwDS5fln6K5BEJGW6vFfE8h2JA_2tFvQY5PQKo62eJvQfTE5j5JwECIz2oO3u_ypKHWRylL3gmU4KYlo4axtU)\r\nFrom the above output, a new replica of the cStor volume is created, and STATUS is showing as Offline.\r\n\r\nUpdate Desired Replication Factor in cStor volume with a new replica count. This can be updated by editing corresponding cStor volume CR YAML.\r\n\r\n    kubectl edit cstorvolume pvc-3f86fcdf-02f6-11ea-b0f6-42010a8000f8 -n openebs\r\n\r\nThe following is the snippet of updated cStor volume CR YAML:\r\n![](https://lh3.googleusercontent.com/lAisXwgequP2MyeCw1cVuwUYFG9G9L5U88olJ2CjbjIOpHjlMwn-K8p11ktaCjQfxK-u5EL-ebpZofD0W_LOKmfFa-wW3eTLtBpqSt7EPYvz5rQciYeaFdT6_7PCsJkdxPVHZCVg)\r\n\r\nIn the above snippet, the desiredReplicationFactor is updated to 2 from 1. Example output:\r\n![](https://lh6.googleusercontent.com/uBkJft958gfjATk070ZFZOMXaq7Sb1xnd5lBVMa2sKuXo-nxwrRxQS58TPgdpoLjMuMHvT4LwPscxPdT6kgwpaDVSraLmsNwWhfanMUrNVO72K8WgxwT3_or4EdzqQkWBgI-Ka84)\r\nVerify if the rebuilding has started on the new replica of the cStor volume. Once rebuilding has been completed, it will update its STATUS as Healthy. Get the latest status of the CVRs using the following command:\r\n\r\n    kubectl get cvr -n openebs\r\n\r\nExample output:\r\n![](https://lh6.googleusercontent.com/1KjmeLgtvoFcBh0vVmB0iwj_gjo-Tkd3vVTTmaw3OaREY9KbvDUQLqyEu0Hj_aYKDpTIRSDVG2sOrTPMczJAPASlzFitSHDyocPV4Bb6IgajW-ArUpDKhi8StFesnHYZrUc3X9DJ)\r\n","slug":"scaling-up-cstor-volume-replica"},{"id":14,"title":"\"Hacktoberfest 2020 - Contribute to OpenEBS\"\r","author":"MayaData Marketing\r","author_info":"Mayadata Marketing Team\r","date":"30-09-2020\r","tags":["OpenEBS"],"excerpt":"Hacktoberfest 2020 is almost here. Contribute to open source project, OpenEBS, to win exciting swag.\r","content":"\r\n### Hacktoberfest returns! Contribute to OpenEBS and win exciting swag\r\n\r\nThe seventh annual [***Hacktoberfest ***](https://hacktoberfest.digitalocean.com/) celebration is almost here, and we at *OpenEBS* are happy to be participating in the contest once again. In August 2017, the OpenEBS community began growing and building a strong foundation for an open source project.\r\n\r\nWe were first introduced to *Hacktoberfest* by friends and peers at the DigitalOcean Bangalore Meetup and were immediately interested in participating. We enlisted OpenEBS as one of the projects participating in Hacktoberfest 2017. We were pleasantly surprised by the participation and enthusiasm that Hacktoberfest attracts from developers around the world. The PRs have been at their peak during Hacktoberfest.\r\n![](https://lh4.googleusercontent.com/Og_t8KLCiRni_LS66bpJsonSXMjcoAX671c8a2LD7ZjbkVdYZgZCRFq47sDC7hsEZt6qcaoCJPZi_gm2FnKmuzMvlg4UZAQKofU0agH2Z11TRmw6vBCQ8u3ssGfre75BN9OV-vOO)\r\n### Get started with OpenEBS this Hacktoberfest\r\n\r\nFollowing the smashing success we had when we participated in the event last few years, we’re going to do the same this year! MayaData makes it more exciting to participate in **Hacktoberfest **by running multiple Meetups throughout the month and helping contributors to get started with their favorite areas (in any of the programming languages) like website development and documentation enhancements. \r\n\r\nTo top it all, there are exciting prizes to be won and every contribution deserves an additional swag from MayaData. Read [this blog](https://blog.mayadata.io/openebs/experience-with-openebs-in-this-hacktoberfest) by Aswath K, one of last year’s weekly winners, who writes about his experience with OpenEBS in Hacktoberfest 2019.\r\n![](https://lh6.googleusercontent.com/2POqPppb7pyGM0OWwl_LlkHzwz-DSWXMMggxIeNCXvsU6EVVmNHdiIzIoTw23-ceK9R5iBleFMGiK-lw9JLtCP5VVjFGQS1QhIOXbpQhtvku5Gp5aCw4Eul_r6JcM-o0WuVZRZmj)\r\n### How do I contribute to OpenEBS?\r\n\r\nThat is an excellent question! OpenEBS is a Kubernetes native Container Attached Storage (CAS) that simplifies running Stateful workloads on Kubernetes. It is built on Microservices architectural patterns, fully automated development, and build pipelines.\r\n\r\nOpenEBS has several components that need your help from simple fixes like adding GitHub issue templates, to enhancing the components. These are developed using Go, Rust, Python, Javascript, Ansible, and many more interesting tools. OpenEBS is also a great way to start your journey into the exciting world of storage, containers, and Kubernetes.\r\n\r\nThe [architecture overview document ](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) is a great place to start learning and picking up a component that speaks to your passion. You could start your first contribution by enhancing that document itself for providing more clarity.\r\n\r\nThere are many other [good first issues](https://github.com/search?q=org%3Aopenebs+is%3Aissue+label%3A%22good+first+issue%22) to pick from.\r\n\r\nContributions can be anything from creating issues, improving user and contributor documents, enhancing build and docker tools, fixing and enhancing code, or unit tests and e2e tests. If you are unsure where to start, begin a discussion with the contributors on [GitHub Discussions](https://github.com/openebs/openebs/discussions) or by joining [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).\r\n\r\n### Will there be swag?\r\n\r\nYes. A big fat YES!\r\n\r\nThe official [Hacktoberfest](https://hacktoberfest.digitalocean.com/) will be giving away free t-shirts to every person making four pull requests to open source repositories during October, as well as limited-edition Hacktoberfest stickers to everyone who participates.\r\n\r\nOn top of this, you will also be able to get some exclusive and limited OpenEBS swag. When your PR to any OpenEBS repository is merged, we will contact you to fill out a form to send a special edition swag designed for Hacktoberfest.\r\n\r\nNot only this but by becoming a top weekly contributor, you’ll be able to grab even more swag.\r\n\r\nPrizes will be sent to quality contributions. The best PR will win a grand prize. Stay tuned to find out more.\r\n\r\nSo, what are you waiting for! Go get your git on and start contributing - we can’t wait to receive your PR.\r\n\r\nHappy hacking!\r\n\r\n### Getting Started:\r\n\r\n1. [https://hacktoberfest.digitalocean.com/](https://hacktoberfest.digitalocean.com/)\r\n2. Join [OpenEBS Community on Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F)\r\n3. Checkout the [OpenEBS Contributing guide](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md)\r\n4. Learn about the [architecture and components](https://github.com/openebs/openebs/blob/master/contribute/design/README.md) of OpenEBS\r\n5. Create new issues for your contribution or pick one of the existing issues from [https://github.com/openebs/openebs/issues](https://github.com/openebs/openebs/issues)\r\n","slug":"hacktoberfest-2020-contribute-to-openebs"},{"id":15,"title":"OpenEBS 0.5 enables Storage Policies for Kubernetes Persistent Volumes","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"30-11-2017","tags":["Container"," Open Source"," Storage Containers"," Kubernetes"," Updates"],"excerpt":"Personally, it is very exciting and enriching to see the growth of the OpenEBS project — from its capabilities, contributors and community perspective!","content":"\n\nPersonally, it is very exciting and enriching to see the growth of the OpenEBS project — from its capabilities, contributors and community perspective!\n\nI believe the metric to measure the success of OpenSource Projects is determined by the number of users and the conversion ratio of users turning into contributors. The past couple of months (thanks to campaigns like Hacktoberfest and the ongoing OpenEBS Hackfest), we have seen a steep rise in the number of contributors and contributions to the OpenEBS project.\n![OpenEBS contributors](https://cdn-images-1.medium.com/max/800/1*BMOr9ULh_7KnM6k8aUj9hw.png)\n\nIn almost all the interactions we had with the user community, we are seeing a clear resonance of the value proposition that OpenEBS brings to the [DevOps teams managing systems with large number of micro-services](https://twitter.com/muratkarslioglu/status/921072858628997121). The best part is that the users are independently evaluating OpenEBS and finding ways to automate their Compute, Network, Storage, and Data related Operations.\n![Towards Kubernetes](https://cdn-images-1.medium.com/max/800/0*XilwHl_ucs5K5fcK.jpg)\n\nToday, I can look back on our decision to use Kubernetes as a framework to build OpenEBS is one of the best decisions we have made. While the core of the Kubernetes community is helping DevOps teams treat Compute and Network as Code — we at OpenEBS are focused at extending Kubernetes to enable treating Storage and Data also as Code.\n\nI am delighted to announce that OpenEBS 0.5 is released with 300+ PRs coming from 50+ new community contributors, with several new features and bug fixes. Summary of changes are available in the [Release Notes](https://github.com/openebs/openebs/releases/tag/v0.5.0).\n\nSome notable changes include:\n\n- Storage Policy Enforcement Framework that allows DevOps teams to deploy a customized storage\n- Extend OpenEBS API Server to expose volume snapshot api\n- Support for deploying OpenEBS via helm charts\n- Support for monitor and get insights into OpenEBS volumes via Prometheus and Grafana\n- Sample Deployment YAMLs and corresponding Policy enabled Storage Classes for several stateful applications\n- Sample Deployment YAMLs for launching Kubernetes Dashboard for a preview of the changes done by OpenEBS Team to Kubernetes Dashboard\n\n***My favorite capability is the Storage Policy Framework that will enable each DevOps team to have their own storage controller — with their own storage policies. And the possibilities it will open-up!***\n\nImagine as a Developer I want to test my service against MySQL database with different datasets. On my staging PV (mysqldata), I can create multiple snapshots containing different datasets — say snaps like *sandy* and *wendy*. Now I can extend OpenEBS to support a new policy “o*penebs.io/jiva-replica-snap”,* that can launch a new volume using snapshot for seed data.\n\nThe policy can be defined for snap — *sandy* as follows:\n\n    # Define a SC referring to snapshot sandy \n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: mysvc-mysqldata-kiran-ds-sandy\n    provisioner: openebs.io/provisioner-iscsi\n    parameters:\n      openebs.io/jiva-replica-count: \"1\"\n      openebs.io/jiva-source-pv: \"mysqldata\"      \n      openebs.io/jiva-replica-snap: \"mysqldata-ds-sandy\"\n\nand another one for *wendy*:\n\n    # Define a storage classes supported by OpenEBS\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: mysvc-mysqldata-kiran-ds-wendy\n    provisioner: openebs.io/provisioner-iscsi\n    parameters:\n      openebs.io/jiva-replica-count: \"1\"\n      openebs.io/jiva-source-pv: \"mysqldata\"\n      openebs.io/jiva-replica-snap: \"mysqldata-ds-wendy\"\n\nIn my PVC, I can now use the above StorageClasses(augmented with OpenEBS Storage Policies) to point to different dataset and independently test my service.\n\nAll this from ***kubectl***.\n\nIn the background, OpenEBS will create a separate Containerized Storage Engine/Controller for my test database — by sourcing the data from the specified snapshot.\n\nAnd btw, we are on the [CNCF LandScape](https://github.com/cncf/landscape) under the Cloud Native Storage options, and decidedly leading the niche market for Containerized Storage Controller. You will hear more on this in the coming days at the KubeCon, Austin.\n\n![CNCF](https://cdn-images-1.medium.com/max/800/1*rdKFLGyf0hRDB_zcgGlywA.png)\n\nYou will hear more on OpenEBS 0.5 in the coming days at `KubeCon 2017`, Austin, Texas.\n\nI will be at the OpenEBS booths with my team and look forward to catching up with some of you in person.\n","slug":"openebs-05-enables-storage-policies-for-kubernetes-persistent-volumes"},{"id":16,"title":"Storage Policies — It’s different this time","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"29-11-2017","tags":["Container"," DevOps"," Kubernetes"," Storage Policy"," Updates"],"excerpt":"One of the most common disbelief at the operator’s end would be the reports of an application’s (that consumed this storage) sudden death after introducing a much awaited shiny new storage feature.","content":"\n\n### Need for Storage Policy\n\nOne of the most common disbelief at the operator’s end would be the reports of an application’s (*that consumed this storage*) sudden death after introducing a much awaited shiny new storage feature. To make things worse the same surprise would be reciprocated from the storage provider as well. Neither the operator nor the storage fellow have any clues to this sudden strangeness.\n\nHaving gone through many such cycles of frustrations building storage features that satisfy the needs of every operator as well does not break stuff that are outside its control; I knew there was clearly a gap in storage design that needs to be talked about openly and bridged. In this article, I present storage policy as the solution to this pressing problem.\n\nThe moment I think about conceptualizing storage policy, my mind tries to battle against many odds. *Is this not what everyone (read storage vendors) has accomplished?*\n\n**Think again!!!** The chances are, it works for a specific storage **“A”** and needs a radically different approach for the other storage **“B”**; assuming both of these provide the infrastructure for the operator’s storage needs. So the operator goes ahead and does some plumbings if lucky enough to get these infrastructures as white-box components. *At the end of the day the operator is ready with a new bespoke program and feels so lucky*. Whatsoever, this does not last long due the very behaviour of infra components. *This operator needs to be ready all the time for the next upgrade to above crafted program,**since little can be expected from the monolith storage fellas*. *Poor operator is left to fend for self, building all possible defence mechanisms*.\n\nGetting back to the need for a storage policy; *what is the edge in this incarnation of storage policy then*? Well, it is all about capitalising the essential features that being native to cloud and being operated from within a container provides *(I can only hope and pray for those storage controllers who cannot operate from the cloud(s) or can not be run from within the container(s))*.\n\nHaving said that, there is no innate need to design storage policy that is drastically different just to prove its greatness. Instead there is a need to design, build, and apply policies that is agnostic to a storage implementation and is conducive to storage operations that are never ever meant to be interrupted.\n\n1. A Storage Policy should be simple to setup on Day 0\n2. It should be simple to expect the obvious on Day 1\n3. It should be simple enough to build an update whenever desired.\n\n### Is it that simple?\n\nAll this time, I have been describing the storage policy and its operations \nas simple. *Well, they can be described as simple, but not easy*. What was your feelings when you created one last time? *Have you ever felt creating a storage snapshot policy is easy?* How about a policy that does periodic restore\nof some randomly picked snapshots and marks them as *PASSED* or *FAILED* after verifying its data integrity. How did that failure alert you? Was it a slack notification? To make it further interesting, can you think of a snapshot policy that hooks into its consuming application’s life cycle events before trying out the snapshot (*Yes!!! I am suggesting those ‘freeze’ and ‘thaw’ exploits before and after a snapshot*).\n\n**Policies can be described as simple, but not easy.**\n\nRemember, these are not the only policies that can be thought of with respect to storage (*we have not even scratched the storage surface*). While all of these are achievable in a cloud and container native way, they may not be termed as easy.\n\nApplying storage policies is like a dangerous yet interesting sport. Like rock climbing, building a suitable policy can be learnt and then adapted based on the needs, workloads, environment, and so on. However, these policies if applied incorrectly can create a ripple-effect that can lead to increased costs and SLA misses which in turn leads to more support personnel on duty, and so on. As we read further, this new design of storage policies helps in eliminating the aforementioned impacts.\n\n### Bring your own YAML\n\nDid I just say YAML ? Yes I did and I shall explain it in a moment. Let us first explore the possible design angles of a storage policy. *Will it not be great to design a policy that fits well within an enterprise’s existing processes, its employees, its culture, its tools?* Is this too much to ask for?\n\nNo!!! *These are no more a set of good to have features but a must have checklist.* I believe expressing storage policy intents as YAMLs can pass all possible checks in an enterprise’s checklist. These current generation declarative intents are now fluent enough to be understood by APIs. In addition, one of YAML’s greatest strengths is its ability to abstract the entire logic that most of us understand as programmable code. This code now becomes truly yours since you have full control of these YAMLs. In other words, it is the operators who have the controlling rights.\n\nTo reiterate, there are few but really solid facts that makes this approach towards policy design a much better one than that of all its predecessors.\n\n***Here are my bets that makes this design different****:*\n\n***Fact #1*** — To put things into perspective, the unassuming reader needs to look at the storage policies along with the current trends in cloud infrastructure as well as the trends in container engine. The cloud has of late become seamless. Thanks to Kubernetes which has been continuously bridging the impedance mismatch between different cloud providers. In addition, the communities involved in Container Storage Initiative, Container Runtime Interface, etc. are making intents as first class citizens. These declarative code pieces are thought of in a bottoms-up approach in each of these implementations which are then placed together coherently by the likes of Kubernetes. Now this is what is definitely more effective than just a tool that parses YAML and runs in isolation.\n\n***Fact #2*** — These intents are precise and parsed with appropriate validation checks to state with decisive control on the exact outcome. In other words they control the actual execution logic in addition to accepting input values via its declarative specifications. This grounds-up approach coupled with the nativity towards cloud as well as container engine is more suited to design storage policies that align with modern day DevOps’ practices.\n\n***Fact #3*** — Let us not forget the containers and the critical role they play in this age of cloud and orchestrators. Perhaps containers have become so ubiquitous and hence are easy to miss. I truly feel there are umpteen number of cool things that are yet to be discovered when we run a storage controller inside a container.\n\n**Fact #4** — All these also mean the intents that were once the sole prerogative of humans can now be built and operated by machines as well. This too with the same ease that the humans used to enjoy. After all, the ingredients *(#1, #2 and #3)* to make this possibility are all in place. This has come of age and is really an advancement in my opinion.\n\n***Bringing your own YAML really means setting your own policies and having complete control over their execution as well.***\n\n### Use the tool(s) you always loved\n\nA policy alone cannot justify its existence unless it is complimented with simple tools and automated processes. The careful reader might have already guessed it. Yes, I am talking of aligning storage policies with DevOps to realise its full potential.\n\n*Making storage policies more visible, more obvious, and enabling them to the enterprise’s established processes will make them simple to be believed and instil the faith to operate*. *Once again, there is a learning involved but the curve is not steep*.\n\nThese policies should offer finest levels of control to the operators’ tools, their bots and of-course operators themselves when such a need arises. *For example finer granularity is craved for during rollbacks, automated downgrades or blue green deployments which are not uncommon in the world of storage infrastructures.*\n\nTo complete the DevOps cycle, these policies which can be hand crafted or system generated can be submitted to the approver(s) (*which again can be a combination of humans as well as their loved tools*) as Pull Requests before being installed and applied against the storage.\n\n### Storage was the proverbial “Missing Cog”\n\nWe are seeing users finally achieving what many have dreamt of for so long — ***storage****(and the rest of the infrastructure)* truly being driven by the needs of the application and in a way that remains understandable and for a variety of reasons *(take infra as code for example)* trusted by humans. And now increasingly we see the recognition that containerised storage itself is another important ingredient.\n\nThanks to [OpenEBS](http://openebs.io) and more broadly containerised storage. *For the first time every team and workload can have its ****own fully functional storage controller***, with capabilities that have always been required by enterprise storage systems and that are still useful in taking care of *stateful workloads*. Our users do not want to give up the tools they used for the care and feeding of MySQL for example just because it now runs in a container. *This is possible by enabling capabilities like snapshots, versioning, encryption and more ****as knobs**** to be able to be turned on/off for each workload.*\n\nThis incarnation of storage policies make it easy for many procedures for these workloads to be recorded as YAML; *the run book is truly code and so can easily be shared, versioned, and executed without humans having to play a role in the ugly details of managing storage system ****A**** or ****B**** or even ****C***. *Storage fades into the background.**Time is ripe for the operators to rule.*\n","slug":"storage-policies-its-different-this-time"},{"id":17,"title":"How to deploy a Cassandra Cluster/Ring on Kubernetes + OpenEBS","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"25-11-2017","tags":["Cassandra"," Kubernetes"," NoSQL"," Solutions"],"excerpt":"Apache Cassandra is a distributed key-value store intended to run in a data center and also across multiple data centers. Initially it was designed as Facebook as an infrastructure for their messaging platform.","content":"\n\nApache Cassandra is a **distributed key-value store** intended to run in a data center and also across multiple data centers. Initially it was designed as Facebook as an infrastructure for their messaging platform. Later it is open sourced, and today it’s one of the most active Apache projects.\n\nIf you are using eBay, Twitter, Spotify or Netflix you are consuming data provided by Cassandra. For example, Netflix uses Cassandra to keep track of your current place in a streaming video, as well as movie ratings, bookmarks and user history of 90+ million users.\n\nAmazing to see how much of this technology we consume in our day-to-day life. The feature that allowed me and my wife to start watching Stranger Things on our long trip on a tablet and continued on TV was depending on Cassandra. To give you an idea of its size, according to a [recent presentation](https://www.youtube.com/watch?v=2l0_onmQsPI), Cassandra serving Netflix has 250+ Clusters, 10,000+ Nodes and 3+ PB of data.\n\nIn summary, Cassandra solves the problem of mapping the key-value pair to a server/node, in our case to a container. This mapping is called as the **partitioner**. There are two common placement strategies used by Cassandra: **SimpleStrategy** or **NetworkTopologyStrategy**. SimpleStrategy uses partitioner Murmur3Partitioner by default. Both **Murmur3Partitioner** and **RandomPartitioner** partitioners uniformly distribute data to nodes across the cluster. Read and write requests to the cluster are evenly distributed while using these partitioners. Load balancing is simplified as each part of the hash range receives an equal number of rows on average. **Byte-Order Partitioner **is not recommended other than key range queries.\n\nFor development work, the SimpleStrategy class is acceptable. For production work, the NetworkTopologyStrategy class must be set. In production, you will end up with multiple rings using mostly NetworkTopology placement which is by-itself extremely complex to plan.\n\nIf you want to learn the architecture of Cassandra, the University of Illinois has a great course on [Cloud Computing Concepts](https://www.coursera.org/learn/cloud-computing/home/welcome) and [Key-Value Stores](https://www.coursera.org/learn/cloud-computing/home/week/4) which covers internals of Cassandra. You can also find more about custom SeedProvider and Snitches [here](https://github.com/kubernetes/kubernetes/issues/24286).\n\nCassandra doesn’t like shared storage, therefore use of NFS or GlusterFS not recommended for Cassandra rings. It’s also recommended to use SSD or NVMe, since it’s essential to have low latency random reads and good sequential writes at the same time. This kind of requirements can be only satisfied with OpenEBS like local and persistent storage solution.\n\nTo achieve the best fault tolerance with Cassandra, you need to have an excellent understanding of the [**snitch**](http://cassandra.apache.org/doc/latest/operating/snitch.html)and placement strategies. There is a big debate on whether if Cassandra or the storage should handle the placement of data. My suggestion would be to have a balanced approach and have both. OpenEBS can help you to place your persistent volumes across the datacenter, multiple cloud vendors and fault domains against Cassandra replica failures. First, you can **avoid rebalancing** your cluster in case of a datacenter failure. Second, in case of node failures in a rack, you can bring up the same node from a snapshot and **minimize the time needed to rebalance**.\n\nI will use Cassandra custom Kubernetes SeedProvider that allows discovery within Kubernetes clusters as they join the cluster and deploy using `gcr.io/google-samples/cassandra:v11` image from Google’s container registry.\n\nLet’s deploy our first three replica Cassandra cluster on our existing AWS K8s cluster with OpenEBS. If you are using on local minikube or datacenter, you can keep the default **SimpleStrategy **and **Murmur3Partitioner **in `cassandra.yaml` file.\n\n#### **Prerequisites**\n\n**Software**\n\n- [Docker ](https://docs.docker.com/engine/installation/)installed\n- Kubernetes 1.8.3+ RBAC enabled cluster\n- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) installed\n- [OpenEBS](https://github.com/openebs/openebs) installed\n- Cassandra 3.x\n\n**Cloud Provider**\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) account\n\n#### **Deploy Cassandra Stateful with Persistent Storage in one Region**\n\nOnce you have OpenEBS storage classes created on your K8s cluster, you can use the following steps to launch a Cassandra service with any number of nodes you like.\n\nBy using environment variables, you can change values that are inserted into `cassandra.yaml`. Default **endpoint_snitch** is set to SimpleSnitch. I will change the Snitch to Ec2Snitch and also increase the replicas from 3 to 4 later.\n\nBefore getting started, check the status of the cluster using the following command.\n\n    kubectl get nodes\n\nOn my setup, I have one master and four worker nodes on AWS in the same US West (Oregon) region and availability zone (us-west-2a).\n\n    ubuntu@ip-172–23–1–236:~$ kubectl get nodes\n     NAME STATUS ROLES AGE VERSION\n     ip-172–23–1–225.us-west-2.compute.internal Ready <none> 21h v1.8.3\n     ip-172–23–1–236.us-west-2.compute.internal Ready master 21h v1.8.3\n     ip-172–23–1–32.us-west-2.compute.internal Ready <none> 21h v1.8.3\n     ip-172–23–1–35.us-west-2.compute.internal Ready <none> 21h v1.8.3\n     ip-172–23–1–46.us-west-2.compute.internal Ready <none> 21h v1.8.3\n\nDownload openebs github repo to your host, where sample yaml files are stored.\n\n    git clone [https://github.com/openebs/openebs.git](https://github.com/openebs/openebs.git)\n\nFirst list predefined OpenEBS storage classes available to you.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get storageclasses\n    NAME PROVISIONER\n    default kubernetes.io/aws-ebs\n    etcd-backup-gce-pd kubernetes.io/gce-pd\n    gp2 (default) kubernetes.io/aws-ebs\n    openebs-cassandra openebs.io/provisioner-iscsi\n    openebs-es-data-sc openebs.io/provisioner-iscsi\n    openebs-jupyter openebs.io/provisioner-iscsi\n    openebs-kafka openebs.io/provisioner-iscsi\n    openebs-mongodb openebs.io/provisioner-iscsi\n    openebs-percona openebs.io/provisioner-iscsi\n    openebs-redis openebs.io/provisioner-iscsi\n    openebs-standalone openebs.io/provisioner-iscsi\n    openebs-standard openebs.io/provisioner-iscsi\n    openebs-zk openebs.io/provisioner-iscsi\n\nGo to `openebs/k8s/demo/cassandra/` folder and edit `cassandra-statefulset.yaml` file.\n\n    vi cassandra-statefulset.yaml\n\nThis file should look like below. You can edit and specify number of replicas preferred and your own OpenEBS storage class before applying.\n\n    apiVersion: apps/v1beta1\n     kind: StatefulSet\n     metadata:\n     name: cassandra\n     labels:\n     app: cassandra\n     spec:\n     serviceName: cassandra\n     replicas: 3\n     selector:\n     matchLabels:\n     app: cassandra\n     template:\n     metadata:\n     labels:\n     app: cassandra\n     spec:\n     containers:\n     — name: cassandra\n     image: gcr.io/google-samples/cassandra:v11\n     imagePullPolicy: Always\n     ports:\n     — containerPort: 7000\n     name: intra-node\n     — containerPort: 7001\n     name: tls-intra-node\n     — containerPort: 7199\n     name: jmx\n     — containerPort: 9042\n     name: cql\n     resources:\n     limits:\n     cpu: “500m”\n     memory: 1Gi\n     requests:\n     cpu: “500m”\n     memory: 1Gi\n     securityContext:\n     capabilities:\n     add:\n     — IPC_LOCK\n     lifecycle:\n     preStop:\n     exec:\n     command: [“/bin/sh”, “-c”, “PID=$(pidof java) && kill $PID && while ps -p $PID > /dev/null; do sleep 1; done”]\n     env:\n     — name: MAX_HEAP_SIZE\n     value: 512M\n     — name: HEAP_NEWSIZE\n     value: 100M\n     — name: CASSANDRA_SEEDS\n     value: “cassandra-0.cassandra.default.svc.cluster.local”\n     — name: CASSANDRA_CLUSTER_NAME\n     value: “K8Demo”\n     — name: CASSANDRA_DC\n     value: “DC1-K8Demo”\n     — name: CASSANDRA_RACK\n     value: “Rack1-K8Demo”\n     — name: CASSANDRA_AUTO_BOOTSTRAP\n     value: “false”\n     — name: POD_IP\n     valueFrom:\n     fieldRef:\n     fieldPath: status.podIP\n     readinessProbe:\n     exec:\n     command:\n     — /bin/bash\n     — -c\n     — /ready-probe.sh\n     initialDelaySeconds: 15\n     timeoutSeconds: 5\n     # These volume mounts are persistent. They are like inline claims,\n     # but not exactly because the names need to match exactly one of\n     # the stateful pod volumes.\n     volumeMounts:\n     — name: cassandra-data\n     mountPath: /cassandra_data\n     volumeClaimTemplates:\n     — metadata:\n     name: cassandra-data\n     annotations:\n     volume.beta.kubernetes.io/storage-class: openebs-cassandra\n     spec:\n     accessModes: [ “ReadWriteOnce” ]\n     resources:\n     requests:\n     storage: 5G\n\nNote: There are few parameters you may want to modify.\n\n`apiVersion: apps/v1beta2` API group and version is introduced 1.8 release.\n\n`replicas: 3`, i’m starting with 3 replicas and will increase later.\n\n`image: gcr.io/google-samples/cassandra:v12` is the latest image available at the time I&#8217;ve tested.\n\n`volume.beta.kubernetes.io/storage-class: openebs-cassandra` i’m using a predefined OpenEBS storage class. You can modify it separately.\n\n#### Create a Cassandra Headless Service\n\nTo be able to have a simple discovery of the Cassandra seed node we need to create a “headless” service. If you view the `cassandra-service.yaml`file, you will notice that `clusterIP` is set to None. This will allows us to use KubeDNS for the Pods to discover the IP address of the Cassandra seed.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ cat cassandra-service.yaml\n     apiVersion: v1\n     kind: Service\n     metadata:\n     labels:\n     app: cassandra\n     name: cassandra\n     spec:\n     clusterIP: None\n     ports:\n     — port: 9042\n     selector:\n     app: cassandra\n\nNow apply `cassandra-service.yaml` file to create headless service.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl apply -f cassandra-service.yaml\n     service “cassandra” created\n\n#### Create a Cassandra StatefulSet\n\nMost applications deployed on Kubernetes should be **cloud-native** and rely on external resources for their data and state. However, stateful application and databases like Cassandra require stateful sets and persistent volumes to ensure resiliency. In this case, OpenEBS will provide us our persistent volume.\n\nThe StatefulSet is responsible for creating the Pods. Run the following command to start our Cassandra replicas.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl apply -f cassandra-statefulset.yaml\n     statefulset “cassandra” created\n\n#### Validate the StatefulSet\n\nCheck if your StatefulSet has deployed using the command below. Time may take around 4–5 minutes to complete.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get statefulsets\n     NAME DESIRED CURRENT AGE\n     cassandra 3 3 5m\n\nIf you don’t see all 3 replicas ready, you can check status of pods to watch progress. For example, i ran `kubectl get pods` after 2 minutes below. First node was ready and second was still creating. All three pods were ready after around 5 minutes.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get pods\n     NAME READY STATUS RESTARTS AGE\n     cassandra-0 1/1 Running 0 2m\n     cassandra-1 0/1 ContainerCreating 0 12s\n     maya-apiserver-5994b58bbb-ss7mr 1/1 Running 0 13m\n     openebs-provisioner-6f45dcf459-hqldl 1/1 Running 0 13m\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-ctrl-9c7dcdcfc-bgmrp 1/1 Running 0 12s\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–572j8 0/1 ContainerCreating 0 12s\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–66qtf 1/1 Running 0 12s\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-ctrl-584956b667-n88mv 1/1 Running 0 2m\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84–5m8nz 1/1 Running 0 2m\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84-c4t9c 1/1 Running 0\n\nVerify that all the OpenEBS persistent volumes are created, the Cassandra headless service and replicas are running.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get pods -o wide\n     NAME READY STATUS RESTARTS AGE IP NODE\n     cassandra-0 1/1 Running 0 6m 10.2.2.4 ip-172–23–1–32.us-west-2.compute.internal\n     cassandra-1 1/1 Running 0 4m 10.2.4.6 ip-172–23–1–46.us-west-2.compute.internal\n     cassandra-2 1/1 Running 0 2m 10.2.1.6 ip-172–23–1–35.us-west-2.compute.internal\n     maya-apiserver-5994b58bbb-ss7mr 1/1 Running 0 17m 10.2.4.3 ip-172–23–1–46.us-west-2.compute.internal\n     openebs-provisioner-6f45dcf459-hqldl 1/1 Running 0 17m 10.2.3.2 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-ctrl-9c7dcdcfc-bgmrp 1/1 Running 0 4m 10.2.3.4 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–572j8 1/1 Running 0 4m 10.2.4.5 ip-172–23–1–46.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–66qtf 1/1 Running 0 4m 10.2.3.5 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-ctrl-9c4bfcd6–4ss2r 1/1 Running 0 2m 10.2.1.4 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-rep-5bbbd9ff45–7tss8 1/1 Running 0 2m 10.2.3.6 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-rep-5bbbd9ff45-vfkrn 1/1 Running 0 2m 10.2.1.5 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-ctrl-584956b667-n88mv 1/1 Running 0 6m 10.2.1.3 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84–5m8nz 1/1 Running 0 6m 10.2.3.3 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84-c4t9c 1/1 Running 0 6m 10.2.4.4 ip-172–23–1–46.us-west-2.compute.internal\n\nOn the list of the Pods above, you see 3 Pods running. Your Pod names should be cassandra-0, cassandra-1, cassandra-2 and the next pods would follow the ordinal number (cassandra-3, cassandra-4,..) Use this command to view the Pods created by the StatefulSet:\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get svc\n     NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n     cassandra ClusterIP None <none> 9042/TCP 7m\n     kubernetes ClusterIP 10.3.0.1 <none> 443/TCP 22h\n     maya-apiserver-service ClusterIP 10.3.0.204 <none> 5656/TCP 18m\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-ctrl-svc ClusterIP 10.3.0.188 <none> 3260/TCP,9501/TCP 5m\n     pvc-5383da78-d226–11e7–955b-062af127ae24-ctrl-svc ClusterIP 10.3.0.23 <none> 3260/TCP,9501/TCP 3m\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-ctrl-svc ClusterIP 10.3.0.187 <none> 3260/TCP,9501/TCP 7m\n\n#### Verifying Successful Cassandra Deployment\n\nCheck if the Cassandra nodes are up, perform a `**nodetool status**`on cassandra-0 node**:**\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl exec -ti cassandra-0 — nodetool status\n     Datacenter: DC1-K8Demo\n     ======================\n     Status=Up/Down\n     |/ State=Normal/Leaving/Joining/Moving\n     — Address Load Tokens Owns (effective) Host ID Rack\n     UN 10.2.4.6 83.17 KiB 32 75.6% 3c93c7b7–61a7–4cf1-a407-cb47b1de0763 Rack1-K8Demo\n     UN 10.2.1.6 65.65 KiB 32 59.5% 552569fe-c6df-4edb-a553–9efdcf682fb3 Rack1-K8Demo\n     UN 10.2.2.4 83.12 KiB 32 64.9% 92060271-d8cd-48be-a489-c830a8553462 Rack1-K8Demo\n\nUN means node is **up **and in **normal **state. You will also notice that each node has 32 tokens. This is the default value, in production workloads a good default value for this is 256. See more information [here](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/architecture/architectureDataDistributeVnodesUsing_c.html).\n\nThe **Owns** column suggests the data distribution percentage for the content placed into the Cassandra keyspaces.\n\n#### Create a Test Keyspace with Tables\n\nIdentify the IP Address of any of the Cassandra replicas, for example, Cassandra-0. This is available from the output of the `nodetool status` command executed above (10.2.4.6, 10.2.1.6, 10.2.2.4).\n\n**Cqlsh** is a Python-based utility that enables you to execute Cassandra Query Language (CQL). **CQL** is a declarative language that allows users to query Cassandra using semantics similar to SQL.\n\nInstall the python-minimal and python-pip apt packages and perform a pip install of Csqlsh using the following commands.\n\n    sudo apt-get install -y python-minimal python-pip\n     pip install cqlsh\n\nLogin to the CQL shell using the Cqlsh utility using the following command.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ cqlsh 10.2.4.6 9042 — cqlversion=”3.4.2\"\n     Connected to K8Demo at 10.2.4.6:9042.\n     [cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]\n     Use HELP for help.\n     cqlsh>\n\nAs I mentioned earlier, you have two placement options while creating a keyspace. You can either use SimpleStrategy or NetworkTopologyStrategy.\n\nYou can create a keyspace using SimpleStrategy with replication factor 2 by running the following commands.\n\n    cqlsh> create keyspace ssks with replication = { ‘class’ : ‘SimpleStrategy’ , ‘replication_factor’ : 2 };\n\nI will create a keyspace using NetworkTopologyStrategy by running the following commands.\n\n    cqlsh> create keyspace ntsks with replication = { ‘class’ : NetworkTopologyStrategy’, ‘DC1-K8Demo’ : 1 };\n\n    cqlsh> describe keyspaces;\n\n    ntsks system_schema system_auth system system_distributed system_traces\n\nTo use NetworkTopologyStrategy with data centers in a production environment, you need to change the default snitch, **SimpleSnitch** to a network-aware **Ec2Snitch.** You need to define one or more data center names in the snitch properties file, and use those data center names to define the keyspace; otherwise, Cassandra will fail to find a node. You can find the instructions to change the default Snitch [here](https://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_switch_snitch.html).\n\nCreate a table with test content and view the data using the following commands.\n\n    cqlsh> use ntsks;\n\n    cqlsh:ntsks> create table inventory (id uuid,Username text,Email text,Age int,PRIMARY KEY ((id), Username));\n\n    cqlsh:ntsks> insert into inventory (id, Username, Email, Age) values (1234b130-ae79–11e4-ab27–0700500c9a24, ‘Murat’, ‘murat@cloudbyte.com’, 40);\n\n    cqlsh:ntsks> select * from inventory;\n\n    id | username | age | email\n     — — — — — — — — — — — — — — — — — — — + — — — — — + — — -+ — — — — — — — — — — -\n     1234b130-ae79–11e4-ab27–0700500c9a24 | Murat | 37 | murat@cloudbyte.com\n\n    (1 rows)\n\nFlush the data to ensure it is written to a disk from the memtable (memory) using the following command.\n\n    kubectl exec cassandra-0 — nodetool flush ntsks\n\n#### Delete the Test Keyspace\n\nVerify the masterless nature of Cassandra StatefulSet by deleting the keyspace from another replica, in this example, Cassandra-1.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ cqlsh 10.2.1.6 9042 — cqlversion=”3.4.2\"\n     Connected to K8Demo at 10.2.1.6:9042.\n     [cqlsh 5.0.1 | Cassandra 3.9 | CQL spec 3.4.2 | Native protocol v4]\n     Use HELP for help.\n     cqlsh> use ntsks;\n\n    cqlsh:ssks> select * from Inventory;\n\n    id | username | age | email\n     — — — — — — — — — — — — — — — — — — — + — — — — — + — — -+ — — — — — — — — — — -\n     1234b130-ae79–11e4-ab27–0700500c9a24 | Murat | 37 | murat@cloudbyte.com\n\n    (1 rows)\n\n    cqlsh> drop keyspace ntsks;\n\nVerify that the keyspace is deleted successfully using the following command.\n\n    cqlsh> describe keyspaces\n\n    system_traces system_schema system_auth system system_distributed\n\n#### Scale the StatefulSet\n\nTo increase or decrease the size of your StatefulSet you can use the scale command:\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl scale — replicas=4 statefulset/cassandra\n     statefulset “cassandra” scaled\n\nWait a minute or two and check if it worked:\n\n    $ kubectl get statefulsets\n     NAME DESIRED CURRENT AGE\n     cassandra 4 4 1h\n\nIf you watch the Cassandra pods deploy, they should be created sequentially.\n\nYou can view the list of the Pods again to confirm that your Pods are up and running.\n\n    ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get statefulsets\n     NAME DESIRED CURRENT AGE\n     cassandra 4 4 1h\n     ubuntu@ip-172–23–1–236:~/openebs/k8s/demo/cassandra$ kubectl get pods -o wide\n     NAME READY STATUS RESTARTS AGE IP NODE\n     cassandra-0 1/1 Running 0 1h 10.2.2.4 ip-172–23–1–32.us-west-2.compute.internal\n     cassandra-1 1/1 Running 0 1h 10.2.4.6 ip-172–23–1–46.us-west-2.compute.internal\n     cassandra-2 1/1 Running 0 1h 10.2.1.6 ip-172–23–1–35.us-west-2.compute.internal\n     cassandra-3 0/1 Running 0 1m 10.2.3.9 ip-172–23–1–225.us-west-2.compute.internal\n     maya-apiserver-5994b58bbb-ss7mr 1/1 Running 0 1h 10.2.4.3 ip-172–23–1–46.us-west-2.compute.internal\n     openebs-provisioner-6f45dcf459-hqldl 1/1 Running 0 1h 10.2.3.2 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-ctrl-9c7dcdcfc-bgmrp 1/1 Running 0 1h 10.2.3.4 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–572j8 1/1 Running 0 1h 10.2.4.5 ip-172–23–1–46.us-west-2.compute.internal\n     pvc-13a2ebce-d226–11e7–955b-062af127ae24-rep-78bf89ff99–66qtf 1/1 Running 0 1h 10.2.3.5 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-ctrl-9c4bfcd6–4ss2r 1/1 Running 0 1h 10.2.1.4 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-rep-5bbbd9ff45–7tss8 1/1 Running 0 1h 10.2.3.6 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-5383da78-d226–11e7–955b-062af127ae24-rep-5bbbd9ff45-vfkrn 1/1 Running 0 1h 10.2.1.5 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-5c9e5136-d22f-11e7–955b-062af127ae24-ctrl-5b6d99869–7gxv5 1/1 Running 0 1m 10.2.3.7 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-5c9e5136-d22f-11e7–955b-062af127ae24-rep-5fc8b95cd-6vfbt 1/1 Running 0 1m 10.2.2.5 ip-172–23–1–32.us-west-2.compute.internal\n     pvc-5c9e5136-d22f-11e7–955b-062af127ae24-rep-5fc8b95cd-h22qz 1/1 Running 0 1m 10.2.3.8 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-ctrl-584956b667-n88mv 1/1 Running 0 1h 10.2.1.3 ip-172–23–1–35.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84–5m8nz 1/1 Running 0 1h 10.2.3.3 ip-172–23–1–225.us-west-2.compute.internal\n     pvc-d13bf437-d225–11e7–955b-062af127ae24-rep-74d4cf4b84-c4t9c 1/1 Running 0 1h 10.2.4.4 ip-172–23–1–46.us-west-2.compute.internal\n\nYou can perform a `nodetool status` to check if the other Cassandra nodes have joined and formed a Cassandra cluster.\n\n    $ kubectl exec -ti cassandra-0 — nodetool status\n     Datacenter: DC1-K8Demo\n     ======================\n     Status=Up/Down\n     |/ State=Normal/Leaving/Joining/Moving\n     — Address Load Tokens Owns (effective) Host ID Rack\n     UN 10.2.4.6 174.97 KiB 32 59.7% 3c93c7b7–61a7–4cf1-a407-cb47b1de0763 Rack1-K8Demo\n     UN 10.2.1.6 182.32 KiB 32 43.8% 552569fe-c6df-4edb-a553–9efdcf682fb3 Rack1-K8Demo\n     UN 10.2.2.4 169.7 KiB 32 42.5% 92060271-d8cd-48be-a489-c830a8553462 Rack1-K8Demo\n     UN 10.2.3.9 90.81 KiB 32 54.1% 47e8c9e2-a6d9–4276–88ae-6fe2256ca2af Rack1-K8Demo\n\nYou will need to wait for the status of the nodes to be Up and Normal (UN) to execute the commands in the next steps.\n\n#### Troubleshooting\n\nIf your Cassandra instance is not running properly, you may check the logs using the command below. Replace <your-pod-name> with your pod name. For example, `cassandra-0`:\n\n    kubectl logs <your-pod-name>\n\nIf your Cassandra nodes are not joining, delete your controller/statefulset then delete your Cassandra service:\n\n    kubectl delete statefulset cassandra\n\nif you created the Cassandra StatefulSet:\n\n    kubectl delete svc cassandra\n\nTo delete everything:\n\n    kubectl delete statefulset,pvc,pv,svc -l app=cassandra\n\n---\n\n*Originally published at *[*Containerized Me*](http://containerized.me/how-to-deploy-a-cassandra-cluster-ring-on-kubernetes-openebs/)*.*\n","slug":"how-to-deploy-a-cassandra-clusterring-on-kubernetes-openebs"},{"id":18,"title":"How to install OpenEBS on IBM Cloud Private","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"19-11-2017","tags":["Helm Charts"," Openebs"," Solutions"," Icp"],"excerpt":"What is IBM Cloud Private? IBM Cloud Private (ICP) is a new application platform that is based on Kubernetes and provides services for developing and managing on-premises containerized applications. ","content":"\n## What is IBM Cloud Private?\n\n**IBM Cloud Private (ICP)** is a new application platform that is based on **Kubernetes** and provides services for developing and managing **on-premises** containerized applications. ICP Community Edition (ICP-CE) is distributed free of charge for non-production use and is available on Docker Hub. For commercial use, you would need the Enterprise package.\n\nIn my previous blog post, [Introduction to IBM Cloud Private](http://containerized.me/introduction-to-ibm-cloud-private/), I have covered step-by-step installation of ICP 2.1. This time I will focus on configuring **OpenEBS** as a **persistent storage** option and deploying a stateful workload (MongoDB) using OpenEBS storage classes.\n\n## Prerequisites\n\n### Hardware\n\n- Minimum three x64 servers\n\n### Software\n\n- [Ubuntu Server 16.04 LTS](https://www.ubuntu.com/download/server)\n- IBM Cloud Private 2.1\n- [OpenEBS](https://github.com/openebs/openebs)\n\n### Install IBM Cloud Private\n\nFollow instructions from [Introduction to IBM Cloud Private](http://containerized.me/introduction-to-ibm-cloud-private/) to deploy a multi-node ICP cluster.\n\n### Install OpenEBS on ICP\n\n1. Log in to the ICP console and go to the **Admin/Repositories** menu.\n\n![OpenEBS on ICP](https://cdn-images-1.medium.com/max/800/0*PPZPNSr9_mW_9AZq.png)\n1. Click **Add repository**.\n\n![Add repository](https://cdn-images-1.medium.com/max/800/0*ZNaLIkk1gxFLWUJK.png)\n1. Add a chart repository with the following parameters:\n — **Name:** openebs-charts\n — **URL:**[https://openebs.github.io/charts/](https://openebs.github.io/charts/)\n\n![Confirm charts](https://cdn-images-1.medium.com/max/800/0*2m2J6V9YhnYk5_Cx.png)\n1. After you click **Add**, confirm that **openebs-charts** is listed under Repositories.\n\n![Catalog menu](https://cdn-images-1.medium.com/max/800/0*wkPxIB_Q2DevkgWh.png)\n1. Go to the **Catalog** menu, select **openebs** from the list.\n\n![Configure](https://cdn-images-1.medium.com/max/800/0*7Lt6IE4f_da0jZEB.png)\n1. On OpenEBS chart instructions page, click **Configure**.\n2. Configure OpenEBS deployment with the following parameters:\n — **Release name:** openebs-<your-release-name> (you need to pick a unique name)\n — **Target Namespace:** default (namespace should be the same as your workload)\n — **rbacEnable:** true\n — **image pullPolicy:** IfNotPresent\n — **apiserver image:** openebs/m-apiserver\n — **apiserver tag:** 0.4.0\n — **provisione image:** openebs/openebs-k8s-provisioner\n — **provisioner tag:** 0.4.0\n — **jiva image:** openebs/jiva:0.4.0\n — **replicas:** 2 (Number of Jiva Volume replicas)\n\n![Installation](https://cdn-images-1.medium.com/max/800/0*qfLs4pg_3TE1PbCB.png)\n1. Click **Install**. When finished click **View Helm Release.**\n\n![Storage classes](https://cdn-images-1.medium.com/max/800/0*raLyHiJeZ0hC_BAk.png)\n1. On the Helm Release page, you can see the status of OpenEBS, deployment, and available **Storage Classes**.\n\n![Deploy stateful application](https://cdn-images-1.medium.com/max/800/0*-gCAd374s2jXY3AP.jpg)\n1. Now, let’s try to deploy a stateful app on OpenEBS.\n\n### Install MongoDB on OpenEBS\n\n1. Under **Catalog**, select **ibm-mongodb-dev** and click **Configure**.\n2. Configure MongoDB deployment with the following parameters:\n — **Release name:** mongodb-<your-release-name> (you need to pick a unique name here)\n — **Target Namespace:** default (same as OpenEBS)\n — **persistence enabled:** true\n — **persistence useDynamicProvisioning:** true\n — **dataVolume storageClassName:** openebs-mongodb\n — **dataVolume size:** 2G (default is 20Gi, remove “i” — in current version it is not supported)\n — **database password:** mongo\n Accept the license agreements, keep all the other values as default and click **Install**.\n\n![Workloads release](https://cdn-images-1.medium.com/max/800/0*UTiLWk3zOy5bw_Wh.png)\n1. Go to **Workloads/Helm Releases** and select your MongoDB release. Under the **PersistentVolumeClaim** table you are going to see the volume claim and OpenEBS storage class.\n\n![Workloads deployment](https://cdn-images-1.medium.com/max/800/0*PNNp0nDxsZXzYwIH.png)\n1. If you go to the **Workloads/Deployments** page, you can find the storage controller and two volume replicas (as configured) running.\n\n![Repository](https://cdn-images-1.medium.com/max/800/0*uaEIPO8n2vY0yUet.png)\n1. Confirm that replicas are running on separate nodes. Click on the PVC name ending with **rep** (Example:pvc-23025190-c516–11e7-b45e-e8fd90000064-rep). Scroll down, and you will see that pods are running on separate hosts.\n\n![DEployment successful](https://cdn-images-1.medium.com/max/800/0*pD7rHAX_D8_cxcfl.png)\nYou have successfully deployed a stateful application on a persistent block storage presented by OpenEBS.\n\n### How does storage HA work for stateful workloads?\n\nHigh Availability storage (HA storage) is a storage system that is continuously operational. Redundancy is the key feature of HA storage as it allows data to be kept in more than one place while ensuring data protection and consistency.\n\nAn **OpenEBS Jiva Volume** is a controller deployed during the OpenEBS installation. Volume replicas are defined by the parameter we set above. The controller is an **iSCSI target** while the replicas play the role of a disk. The controller exposes the iSCSI target while the actual data is written. The controller and each replica run inside a dedicated container.\n\nAn OpenEBS Jiva Volume controller exists as a single instance, but there can be multiple instances of OpenEBS Jiva volume replicas. Persistent data is synchronized between replicas.\n\nOpenEBS Jiva Volume HA is based on various scenarios as explained in the following sections.\n\nNOTE: Each replica is scheduled in a unique K8s node, and a K8s node never has two replicas of one OpenEBS volume.\n\n### What happens when an OpenEBS volume controller pod crashes?\n\nKubernetes automatically re-schedules the controller as a new Kubernetes pod.\n Policies are in place that ensures faster rescheduling.\n\n### What happens when a K8s node that hosts OpenEBS volume controller goes offline?\n\nThe controller is automatically re-scheduled as a new Kubernetes pod.\n Policies are in place that ensures faster rescheduling.\n If Kubernetes node is unavailable, the controller gets scheduled on one of the available nodes.\n\n### What happens when an OpenEBS volume replica pod crashes for reasons other than node not-ready and node unreachable?\n\nThe replica is autoamtically re-scheduled as a new Kubernetes pod.\n The replica may or may not be re-scheduled on the same K8s node.\n There is data loss with this newly scheduled replica if it gets re-scheduled on a different K8s node.\n\n### What happens when a K8s node that hosts OpenEBS volume replica goes offline?\n\nThere is no storage downtime as the other available replica displays inputs/outputs.\n Policies are in place that does not allow re-scheduling of crashed replica (as the replica is tied to a node’s resources) to any other node.\n\n---\n\n*Originally published at *[*Containerized Me*](http://containerized.me/how-to-install-openebs-on-ibm-cloud-private/)*.*\n","slug":"how-to-install-openebs-on-ibm-cloud-private"},{"id":19,"title":"How to deploy Jenkins on Kubernetes + OpenEBS","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"16-11-2017","tags":["Jenkins"," Kubernetes"," Open Source"," Solutions"," Openebs"],"excerpt":"Modern development requires Continuous Integration / Continuous Delivery (CI/CD) and it means building and validating your software on every commit to make sure your development & test environments are always up-to-date. ","content":"\nModern development requires [Continuous Integration](https://aws.amazon.com/devops/continuous-integration/) / [Continuous Delivery](https://aws.amazon.com/devops/continuous-delivery/) (**CI/CD**) and it means building and validating your software on every commit to make sure your development & test environments are always up-to-date. This level of automation is a combination of cultural philosophies (aka **DevOps**) and practices. CI/CD increases an organization’s ability to deliver applications and services at high velocity. Jenkins serves as the **workflow engine** to manage this **CI/CD pipeline** from source to delivery.\n\nDeploying Jenkins on Kubernetes provides the following benefits:\n\n- Isolates different jobs from one another\n- Quickly clean a job’s workspace\n- Dynamically deploy or schedule jobs with Kubernetes pods\n- Allows increased resource utilization and efficiency\n- Dynamically scale up Jenkins slaves on demand\n\nEspecially, running dynamic slaves in a Kubernetes/Docker environment and automating the scaling of Jenkins slaves running in Kubernetes on top of OpenEBS can **minimize the deployment time and cost**. With OpenEBS, you can build extremely scalable test cycles. You will be able to create instant snapshots (thanks to the [**CoW**](https://en.wikipedia.org/wiki/Copy-on-write)) from the master and **deploy new slaves faster and dynamically on demand**. This process will eliminate the need to perform container-to-container copies.\n\nIn Jenkins, slaves are optional. OpenEBS can also help when you have a smaller environment and running a **monolithic master**. In that model, state on the master would be lost when you shut down the Jenkins master service. When using monolithic master on OpenEBS, your volume is persistent and replicated over to n nodes (defined in your OpenEBS storage class). In that case, the master can exit, even if your node fails it can start on other nodes, migrate from private to public cloud, vice-versa when needed and your data will follow you.\n\nLet’s deploy Jenkins on our existing K8s cluster with OpenEBS. You will notice that it’s not much different than deploying on local storage, except your data will be protected with OpenEBS.\n\n## Prerequisites\n\n### Software\n\n- [Docker ](https://docs.docker.com/engine/installation/)installed\n- Kubernetes 1.7.3+ RBAC enabled cluster\n- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) installed\n- [OpenEBS](https://github.com/openebs/openebs) installed\n\n### Cloud Provider\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) account\n\n## Deploy Jenkins Pod with Persistent Storage\n\nOnce you have OpenEBS storage classes created on your K8s cluster, you can use the following simple steps to launch Jenkins service with a monolithic master.\n\nBefore getting started, check the status of the cluster using the following command.\n\n    kubectl get nodes\n\nIn my environment, i have one master and two worker nodes.\n\n    ubuntu@ip-172–23–1–115:~$ kubectl get nodes\n    NAME STATUS ROLES AGE VERSION\n    ip-172–23–1–115.us-west-2.compute.internal Ready master 2h v1.8.3\n    ip-172–23–1–144.us-west-2.compute.internal Ready <none> 2h v1.8.3\n    ip-172–23–1–244.us-west-2.compute.internal Ready <none> 2h v1.8.3\n\nDownload the `Jenkins.yml` file to your host, which has access to kubectl.\n\n    wget https://raw.githubusercontent.com/openebs/openebs/master/k8s/demo/jenkins/jenkins.yml\n\nThis file looks like below. You can edit and specify a different OpenEBS storage class before you apply.\n\n    kind: PersistentVolumeClaim\n     apiVersion: v1\n     metadata:\n     name: jenkins-claim\n     annotations:\n     volume.beta.kubernetes.io/storage-class: openebs-standard\n     spec:\n     accessModes:\n     — ReadWriteOnce\n     resources:\n     requests:\n     storage: 5G\n     — -\n     apiVersion: extensions/v1beta1\n     kind: Deployment\n     metadata:\n     name: jenkins\n     spec:\n     replicas: 1\n     template:\n     metadata:\n     labels:\n     app: jenkins-app\n     spec:\n     securityContext:\n     fsGroup: 1000\n     containers:\n     — name: jenkins\n     imagePullPolicy: IfNotPresent\n     image: jenkins/jenkins:lts\n     ports:\n     — containerPort: 8080\n     volumeMounts:\n     — mountPath: /var/jenkins_home\n     name: jenkins-home\n     volumes:\n     — name: jenkins-home\n     persistentVolumeClaim:\n     claimName: jenkins-claim\n     — -\n     apiVersion: v1\n     kind: Service\n     metadata:\n     name: jenkins-svc\n     spec:\n     ports:\n     — port: 80\n     targetPort: 8080\n     selector:\n     app: jenkins-app\n     type: NodePort\n\nNow apply `jenkins.yml` file.\n\n    kubectl apply -f jenkins.yml\n\n![results](/images/blog/results.png)\n\nGet the status of running pods using the following command.\n\n    kubectl get pods\n\nResult should like similar to below, and the Jenkins pod running.\n\n    ubuntu@ip-172–23–1–115:~$ kubectl get pods\n     NAME READY STATUS RESTARTS AGE\n     jenkins-797b888448-pfx8x 1/1 Running 0 11m\n     maya-apiserver-5994b58bbb-ck2tv 1/1 Running 0 2h\n     openebs-provisioner-6f45dcf459-qjdlx 1/1 Running 0 2h\n     pvc-94586807-cb09–11e7-b125–064dff6dc2a2-ctrl-864fcb6f74–2phfw 1/1 Running 0 11m\n     pvc-94586807-cb09–11e7-b125–064dff6dc2a2-rep-575d85d96c-dk4dq 1/1 Running 0 11m\n     pvc-94586807-cb09–11e7-b125–064dff6dc2a2-rep-575d85d96c-pzrgn 1/1 Running 0 11m\n\nAs you noticed, your OpenEBS controller `pvc-…-ctrl-…` and two copies of persistent volumes `pvc-…-rep-…` are also deployed and running.\n\nGet the status of underlying persistent volumes used by Jenkins deployment using the following command.\n\n    kubectl get pvc\n\nExample output below:\n\n    ubuntu@ip-172–23–1–115:~$ kubectl get pvc\n     NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\n     jenkins-claim Bound pvc-94586807-cb09–11e7-b125–064dff6dc2a2 5G RWO openebs-standard 22m\n\nGet the status of Jenkins service using the following command:\n\n    kubectl get svc\n\nExample output below:\n\n    ubuntu@ip-172–23–1–115:~$ kubectl get svc\n    NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n    jenkins-svc NodePort 10.3.0.17 <none> 80:31705/TCP 25m\n    kubernetes ClusterIP 10.3.0.1 <none> 443/TCP 3h\n    maya-apiserver-service ClusterIP 10.3.0.34 <none> 5656/TCP 3h\n    pvc-94586807-cb09–11e7-b125–064dff6dc2a2-ctrl-svc ClusterIP 10.3.0.100 <none> 3260/TCP,9501/TCP 25m\n\n### Launching Jenkins\n\nThe Jenkins deployment YAML file `jenkins.yaml` we have used above creates a NodePort service type to make Jenkins available outside the cluster.\n\nGet the node IP Address that is running the Jenkins pod using the following command.\n\nNote: Replace your pod name with your the pod name returned when you ran `kubectl get pods` command.\n\n    kubectl describe pod jenkins-797b888448-pfx8x | grep Node:\n\nExample output below:\n\n    kubectl describe pod jenkins-797b888448-pfx8x | grep Node:\n     Node: ip-172–23–1–144.us-west-2.compute.internal/172.23.1.144\n\nGet the port number from the Jenkins service using the following command:\n\n    kubectl describe svc jenkins-svc | grep NodePort:\n\nExample output below:\n\n    ubuntu@ip-172–23–1–115:~$ kubectl describe svc jenkins-svc | grep NodePort:\n     NodePort: <unset> 31705/TCP\n\nIP above is your private IP on AWS, can be used if you are accesing through another instance on AWS. To access it remotely, you also need to open that port on E2C instance’s security group.\n\nGo to the Network & Security -> Security Group settings in the left hand navigation\n Find the **Security Group** that your instance is apart of. Click on **Inbound Rules. **Click on **Edit** and **Add Rule** button. Then add HTTP (port 31705). Click **Save**.\n\nNow, combine your public IP and port number and open that in your browser. In my case it is [https://34.223.235.50:31705.](https://34.223.235.50:31705.)\n\nOnce you access the URL the Getting Started page is displayed. Follow the procedure below to setup Jenkins.\n\nProvide the [cci]initialAdminPassword[/cci] in the Unlock Jenkins screen and copy the password in the [cci]Administrator password[/cci] field. Click **Continue**.\n\n![unclock jenkins](/images/blog/unlock-jenkins.png)\n\nGet the password using the following command:\n\n    kubectl exec -it jenkins-797b888448-pfx8x cat /var/jenkins_home/secrets/initialAdminPassword\n\nExample output below:\n\n    ubuntu@ip-172–23–1–115:~$ kubectl exec -it jenkins-797b888448-pfx8x cat /var/jenkins_home/secrets/initialAdminPassword\n     5aa044d226d1466eb84621e75e369c64\n\nOn the **Customize Jenkins** screen click on **Install suggested plugins**.\n\n![customize jenkins](/images/blog/customize-jenkins.png)\n\nConfigure the Administrator user in the **Create First Admin User** screen. Fill in the following fields.\n\n**Username:** — Key in the administrator username.\n**Password:** — Key in the password for the administrator.\n**Confirm password:** — Key in the password again and confirm.\n**Full name:** — Key in the administrator’s full name.\n\nClick **Continue as admin** if you want to perform further administrator tasks or click **Save and Finish**.\n You can now start using Jenkins!\n\n![jenkins-is-ready](/images/blog/jenkins-is-ready.png)\n\n\n*Originally published at *[*Containerized Me*](http://containerized.me/how-to-deploy-jenkins-on-kubernetes-openebs/)*.*\n","slug":"how-to-deploy-jenkins-on-kubernetes-openebs"},{"id":20,"title":"Deployment modes of OpenEBS\r","author":"Uma Mukkara\r","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).\r","date":"13-02-2017\r","tags":["Container"," Docker"," Kubernetes"," Openebs"," Storage For Containers"],"excerpt":"OpenEBS supports two modes — Hyper-converged and dedicated. The deployment mode really depends on where and how you want to use OpenEBS.\r","content":"\r\nOpenEBS supports two modes — Hyper-converged and dedicated. The deployment mode really depends on where and how you want to use OpenEBS. If you are adding block storage capability to existing kubernetes minions, hyper-converged mode is most desired, so that you can use the existing hardware as is. If the desire is to get a full fledged EBS type functionality to your on-premise cloud or container needs, then dedicated storage servers for OpenEBS is a better choice.\r\n\r\nIn the hyper-converged mode, OpenEBS Maya hooks into the K8s master and minions, hooking into scheduling algorithms for creating OpenEBS VSMs. When used in dedicated mode, the provisioning API are exposed via the OpenEBS Maya master. Dynamic Provisioning of the storage can be enabled using the volume plugin drivers or use the EBS volume plugin as in the case with K8s.\r\n\r\n![OpenEBS — Hyper-converged mode](https://cdn-images-1.medium.com/max/800/1*MxM5MmWCB_5mmy7A5bor6Q.png)*(OpenEBS — Hyper-converged mode)*\r\n\r\n\r\n![OpenEBS — Dedicated mode](https://cdn-images-1.medium.com/max/800/1*MAbRf5rJfv8w_OvZz02q7g.png)*(OpenEBS — Dedicated mode)*\r\n\r\nIn both modes, Flannel plays an important role in OpenEBS deployment for storage networking. A lot of issues are yet to be discovered in this area.. yes, this is just a start.","slug":"deployment-modes-of-openebs"},{"id":21,"title":"Containerization meetup - Containers for storage too\r","author":"Uma Mukkara\r","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).\r","date":"15-01-2017\r","tags":["Containerized Storage"," Docker"," Kubernetes"," Openebs"," Storage Containerization"],"excerpt":"I had the opportunity to talk to a very good group of technologists, DevOPs users in the Digital Ocean Containerization Meetup . Docker 1.13 details and Kubernetes deployment tips were fantastics.\r","content":"\r\nI had the opportunity to talk to a very good group of technologists, DevOPs users in the [Digital Ocean Containerization Meetup](https://www.meetup.com/DigitalOceanBangalore/events/236353004/) . Docker 1.13 details and Kubernetes deployment tips were fantastics.\r\n\r\nI talked about the containerization for storage. The presentation slides are published [here](http://www.slideshare.net/UmasankarMukkara/openebs-containerized-storage-for-containers). Slide #6 talks about the advantages when the storage volumes are containerized, just like the advantages when the applications are containerized. In the storage containerization, the storage software becomes a micro service. Storage protocol (iSCSI in this case), replication, QoS, Encryption are micro services that are better managed and served when containerized. This form of containerization leads to a true non-disruptive storage upgrade possibility in production.\r\n\r\nImagine, there are thousands of storage volumes in production serving thousands of containerized applications. If a storage upgrade has to happen that actually is needed only few volumes, such as a special snapshot or encryption feature or bug fix, then only those containers need to be upgraded. The maintenance window scheduling will be the simplest in such scenarios. To make this possible, OpenEBS abstracts the storage functionality into the user space (slide #7) and each volume is dedicated with a separate storage process in the form of containers… Micro services architecture to the storage, delivered.\r\n\r\nI also talked about the building blocks of OpenEBS.\r\n\r\nOpenEBS uses or builds on:\r\n\r\n- Docker — for achieving containerization. [Jiva](https://hub.docker.com/r/openebs/jiva/) is the docker image\r\n- Longhorn Rancher — For basic storage replication and distributed scale-out needs. QoS, encryption comes from here.\r\n- Nomad — Clustering capability among storage hosts as well as storage pods or VSMs is served by Nomad\r\n- Consul — for the cluster db\r\n- Flannel — for the container networking needs. We use the flannel’s intelligence for picking up the IP addresses for VSMs automatically, VLANS and other networking stuff. The database portion of flannel is not needed as OpenEBS has the centralized config db for Maya (consul implementation)\r\n\r\n![OpenEBS Building Blocks and Integration](/images/blog/containerization-meetup-building-blocks.png)\r\nAs far as the integration points of OpenEBS are concerned, the provisioning in integrated into k8s. The provisioning of the OpenEBS can be done through the [K8s iSCSI volume interface](https://kubernetes.io/docs/user-guide/volumes/#iscsi) or through the [K8s AWS EBS interface](https://kubernetes.io/docs/user-guide/volumes/#awselasticblockstore). Yes, OpenEBS exposes AWS EBS API. Any orchestration layer or application that knows to connect to and use AWS EBS, will work with OpenEBS.\r\n\r\nAs we progress from this early stage, we look forward to work closely with the Docker and k8s user communities.\r\n","slug":"containerization-meetup-containers-for-storage-too"},{"id":22,"title":"Emerging Storage Trends for Containers\r","author":"Kiran Mova\r","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.\r","date":"11-01-2017\r","tags":["DevOps"," Docker"," Openebs"," Startup"," Storage"],"excerpt":"The smiling docker whale is everywhere these days. You either have ridden on it or you want to know how to ride on it. As far as operations teams are concerned the docker whale is just teasing them.\r","content":"\r\nThe smiling docker whale is everywhere these days. You either have ridden on it or you want to know how to ride on it. As far as operations teams are concerned the docker whale is just teasing them. In the recent meetups and conferences I attended here, very few hands rise when asked if they have deployed containers in production.\r\n\r\nWell, it has taken over a decade and half at least for the shift from servers to virtual machines. And even now, I see a lot of caution in the enterprises to move completely into the public cloud. Though the technology around virtualization is well established, the real return$$ of moving onto public cloud aren’t as great as initially expected.\r\n\r\nA similar transitional trend, but at a much faster pace is being seen around the containers. Docker has done a phenomenal job in breaking the entry barrier for playing with containers, by addressing the Container Eco-System components for Developers to quickly build, test and package the applications via containers.\r\n\r\n\r\n![Interest over time](https://cdn-images-1.medium.com/max/800/1*c8cxwXMmU93xXAiK4Rs0BA.png)\r\n\r\nWhile it is very easy to setup and run containers, are dockers really ready for the production work load? The following diagram pretty much sums it up.\r\n\r\n(Credit: [http://bicarait.com/2016/11/01/running-your-docker-using-vsphere-integrated-container/](http://bicarait.com/2016/11/01/running-your-docker-using-vsphere-integrated-container/))\r\n\r\n![Containers in development & production](https://cdn-images-1.medium.com/max/800/0*nDL6ATRys2vPH8m9.png)\r\n\r\nLearning from the recent past, the cloud was led by the compute virtualization, but it wasn’t a true cloud until the network and storage also were fully virtualized, giving way to Software Defined Storage and Software Defined Networking. These days it is about SDDC, which involves significant improvement in the orchestration of infrastructure and the services running on them. For those of us that have contributed and implemented the cloud, and operated them in production — the journey was exciting and in some instances nail biting!!\r\n\r\nI keep hearing developers say, I don’t care about the infrastructure. That’s great, but it just means that someone else is taking care of it, usually the operations team! I wonder if the DevOps is bringing developers closer to operations or Operations closer to Developers? I bet it is the Operations Team getting closer to Developers and making the life of Developers much easier.\r\n\r\nThe Developers are excited about the stateless containers or server-less architectures or lambda services. All of these are great architectural patterns, but all these eventually depend in some form on some stateful containers or servers that are running over robust infrastructure with extremely low latency.\r\n\r\nThe Operations Teams are the one that need to define this robust infrastructure for running the containers. Unlike VMs that were provisioned (or self provisioned on designated infrastructure) for specific use-cases, the container infrastructure must come with a brain of its own, where the containers are provisioned and moved depending on the load and performance parameters.\r\n\r\nAn application or service in the container world, will be a set of interconnected containers (stateful or stateless — much like a K8s Pod), that will require compute, network and storage. And for these Application Pods to be portable, the infrastructure also needs to move along with them. It is time for programmable infrastructure to go mainstream. Just as virtualization paved way for software defined networks and software defined storage, we are now seeing the need for container defined network and container defined storage.\r\n\r\nFor a recent [Bangalore Docker meetup](http://neependra.net/?p=2141), I took a shot at looking through the various storage startups that are trying to build storage for the containers. The slides are available here : [Emerging Storage Trends for Containers](http://www.slideshare.net/kiranmova/emerging-storagetrendsforcontainers)\r\n\r\nThe storage trends can be summarized as follows:\r\n\r\n(1) (Slide#22) **Elastic Storage Infrastructure** — The storage can be horizontally scaled, much like the docker hosts in docker swarm. The technology to implement the Elastic Storage is already in production with many vendors supplying ***Software Defined Scale-out/Distributed Storage*** in the cloud environments.\r\n\r\n(2) (Slide #23) **Ease of Accessing the Storage**— The volume of volumes required by the containerized applications will be manyfold compared to volumes used in the VM storage. And the volumes will be more portable. Operations team should be shielded from having to mount/unmount volumes or datastores. ***The integration into the orchestration layers for mounting the storage and providing access to the volumes, without requiring additional software changes will be paramount.*** The TCMU/iSCSI, NBD/NFS interfaces are two different approaches with each coming with its own nuances w.r.t isolation vs ease.\r\n\r\n(3) (Slide #24) **Hyper Converged Storage** — For storage to be hardened, the developer setups need to be and ***avoid managing silos of infrastructure for compute, network, and storage.*** The concept of lightweight storage software will emerge which will mount distributed external storage or cloud storage onto the local machines (with caching).\r\n\r\n(4) (Slide #25) **Hybrid Clouds / Storage** — Put the storage in the right place and move it around depending on the demands of the application and economics. A first in this place would be to move the snapshots into S3 when the persistent disks are used for stateful containers. The industry has established that to save money, a mix of clouds is going to be used with the apps moving into different container environments. The storage platform should be able to run alongside different clouds or have the ability to inter-operate. ***Seamless Storage Migration within and across clouds is a must.***\r\n\r\n(5) (Slide #26) **Containerized Storage** — One of the best innovations is the way the containers are defined and deployed. The storage software also will reap these benefits by containerizing the storage. ***Version of the storage being used will become another parameter to be defined in the intent specs along with capacity and performance (QoS).*** Containerization also helps with isolation and ease of upgrades in shared environments.\r\n\r\n(6) (Slide #27) **Keep up with the core storage innovations** — Flash is already mainstream, with CIOs questioning if they still really need the SAS Tiers. With NVMe, cache is becoming more accessible both in terms of $$ and the performance boost it can provide to the Storage Software. ***The low latency demands from the containerized applications will be guaranteed via the use of NVMe Flash for read/write caching of data that is possibly stored on disks or remote cloud storage.***\r\n\r\n\r\nIt is euphoric to see the new developments being made in the opensource for the storage, networking, and orchestration layers, apart from the container runtime itself!\r\n\r\n\r\n2017 may well be year where we will start seeing containers in production as the infrastructure pieces for Containers mature.\r\n","slug":"emerging-storage-trends-for-containers"},{"id":23,"title":"I’ve become a Chairman — of CloudByte / OpenEBS\r","author":"Evan Powell\r","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!\r","date":"04-01-2017\r","tags":["DevOps"," Docker"],"excerpt":"I’m excited to announce that I recently joined CloudByte, a developer of storage solutions for enterprises and service providers and the originator of the new OpenEBS project.\r","content":"\r\nI’m excited to announce that I recently joined CloudByte, a developer of storage solutions for enterprises and service providers and the originator of the new OpenEBS project. While my role is Chairman of the Board of Directors, I’ll be rolling up my sleeves and doing whatever I can to help.\r\n\r\nYou might ask — why? And so what?\r\n\r\n## 1. **YAML = truth**\r\n\r\nWhen I helped popularize the notion of software **defined** open storage years ago as founding CEO of Nexenta — one of the concerns was “who sets the definition?” At the time VMware was pushing themselves for that role. It was a bottoms up — infrastructure up — approach that never fully caught hold.\r\n\r\nIt was a pre DevOps approach of doing things that often ended in the old familiar:\r\n\r\nThese days the intent of the developer and the requirements of the application are being expressed via flavors of YAML that Kubernetes, Docker Swarm, Mesos, StackStorm, Rancher and others leverage.\r\n\r\nCloudByte, via the OpenEBS community that builds on many of the technologies that CloudByte has been building and selling for years, is well positioned to be the preferred solution for containerized storage for containers not just because of the underlying QoS isolation bits — though that heritage is important — but also because we and the OpenEBS community are 100% focused on manifesting the intent and latent requirements of the application.\r\n\r\nTake a look at OpenEBS here: [www.OpenEBS.io](http://www.openebs.io/). It is early however already gathering some great contributors and users. Please let us know what you think.\r\n\r\n## 2. **I like money**\r\n\r\nNo, it isn’t that I’m joining the board for the money. News flash — early stage start-ups don’t have money lying around to pay board members, actually the cash flows the other way :) Rather, CloudByte’s technologies have been proven by demanding enterprises and service providers.\r\n\r\nThis existing customer set — and their increasing commitments as confirmed by a far and away record quarter of sales last quarter — gives us a foundation to build upon. We intend to extend our success in the scale up storage space via our flexible business model and superior technology — especially for use cases where our per volume QoS management matters to users.\r\n\r\n## 3. **Team time!**\r\n\r\nMost importantly, as I’ve come to know the CloudByte team I’ve formed a commitment to them and their vision for the kind of company we can build. I feel honored to support our CEO and co-founder Uma — he’s brilliant, he is stubborn, and he is relentlessly making real a vision for what storage can be — as an **enabler** of the shift towards cloud native and DevOps as opposed to an **inhibitor**. It didn’t hurt that the new board hit it off immediately and that Raj from Fidelity / EightRoads and Sandeep from Nexus have great entrepreneur-friendly reputations as well as massive funds supporting them.\r\n\r\nThere will be much more to come as we share our thoughts about strategy and, maybe more importantly, as [OpenEBS](http://www.openebs.io/) community members lay out what they’d like to see in containerized storage.\r\n\r\nUntil then — please get in touch. Hang out with us on [the community](http://www.openebs.io/) or just ping me via twitter @epowell101 or otherwise. Let’s work together to make storage — finally — something that does what it is supposed to do despite all the challenges inherent to providing persistence to today’s ever more dynamic environments.\r\n","slug":"ive-become-a-chairman-of-cloudbyte-openebs"},{"id":24,"title":"OpenEBS — The containerized storage\r","author":"Uma Mukkara\r","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).\r","date":"01-01-2017\r","tags":["DevOps"," Docker"," Kubernetes"," Rancher"," Golang"," Openebs"],"excerpt":"In the infrastructure space, the compute environment is always the first to lead the change. Docker has brought in the new thinking into every DevOPs administrator and application developer.\r","content":"\r\n\r\nIn the infrastructure space, the compute environment is always the first to lead the change. Docker has brought in the new thinking into every DevOps administrator and application developer. CIOs across the spectrum are beginning to include Docker into their policies. As the IT environment begins to adopt containerization into mainstream, there are holes that still need to be plugged in, specifically in the storage space.\r\n\r\nI am excited to write the first details on OpenEBS ([www.openebs.io](http://www.openebs.io/)) project.\r\n\r\nAfter 4 amazing years of building commercial storage products, I recently took a giant leap into the open source model of building infrastructure software. We recently launched OpenEBS project with the goal of building the developer friendly storage using coolest available infrastructure pieces underneath .. be it Docker, k8s, Rancher LongHorn, Nomad, Terraform, etc.\r\n\r\n## So, what is OpenEBS, in short ?\r\n\r\nOpenEBS offers persistent block storage with the following features:\r\n\r\n- Containerized block storage using Docker containers. We call them VSMs or Virtual Storage Machines, a concept similar to k8s PODs.\r\n- A highly scalable storage orchestration platform that spins the storage volumes seamlessly and manages them effortlessly\r\n- A simple, yet high performing distributed block storage designed with best caching via the NVMe optimizations\r\n\r\n## Why containerized storage?\r\n\r\nSimple answer is that even the storage volumes have software associated with them for their regular functions and this software needs to be managed at volume level.\r\n\r\n![Monolithic vs Containerized Storage](https://cdn-images-1.medium.com/max/800/1*OoQnpEsGf_ovb5BFnGI8hA.jpeg)\r\n\r\nWhen software upgrades happen at storage host level, all volumes' behavior will change simultaneously, which may not be the desired result. Similarly, upgrade maintenance windows may not be the same for all applications or storage volumes. We often observe that it is very difficult to get a convenient window that satisfies all storage volumes or associated applications.\r\n\r\nWith containerized storage, storage upgrades becomes simple and easy, just like application upgrades with Docker containers.\r\n\r\n## Maya, our new storage orchestration platform\r\n\r\nKubernetes, Docker swarm, Rancher cattle, Nomad and other orchestration platforms do a good job of managing the lifecycle of compute containers and initial provisioning of network and storage. However, the storage infrastructure management, when scaled is a big beast in itself. Storage volumes need to be persistent to the application but they need to be volatile in the backend. Storage volumes need to be scheduled on various hosts based on the capacity and IOPS availability and these volumes may need to be moved on the fly as the usage goes up.\r\n\r\n*Maya in Sanskrit language means “****Magic****”. Maya will seamlessly integrate storage management functionality into existing container orchestration layers for provisioning, scheduling, reporting, rolling upgrades etc., and provide storage specific capabilities like data protection capabilities, migrating storage etc.,*\r\n\r\n## The building blocks of high performing, distributed block storage:\r\n\r\n***Rancher longhorn:*** We chose to adopt and enhance Rancher longhorn as the basic building block of storage block intelligence in OpenEBS. I will write a separate blog about what is longhorn, it’s features and why we chose longhorn, but in short, longhorn employs a clever and simple approach to container data connectivity, data availability (replication), data protection (snapshot). And longhorn is written in GoLang.\r\n\r\n***Gostor gotgt:*** One of the initial front ends for OpenEBS is of course the iSCSI. We chose gostor/gotgt as a good starting point. OpenEBS plans to add many new capabilities to gotgt like clustering support, performance optimizations etc.\r\n\r\n***Bulk Caching layer through NVMe:*** The caching layer that we see in traditional storage systems is usually small in size. The recent advancements in flash technology made it possible to offer large capacities of flash at affordable prices. Now cost is not a deterrent to have terabytes of low latency flash storage. OpenEBS provides an intelligent caching technology which keeps the hot data in the large NVMe flash layer. Intel’s 3d XPoint is a good fit for this technology.\r\n\r\n## Community:\r\n\r\nCommunity is paramount. We hope to embrace a lot of friends, advisers, experts in this journey and successfully deliver the OpenEBS promise. Drop by at our [gitter channel](https://gitter.im/openebs/Lobby) and say Hi !\r\n","slug":"openebs-the-containerized-storage"},{"id":25,"title":"Running through the mud looking skywards\r","author":"Amit Kumar Das\r","author_info":"Engineer the DAO\r","date":"2017-02-11\r","tags":["Education"," Industry"," Storage"," Openebs"],"excerpt":"I always believe, bridging the minds of academia & industry has to go beyond the nuances of theory vs. practical.\r","content":"\r\nI knew we would be running through the mud looking skywards for those brightest stars. We were not at all disappointed with our first attempt at *Kuppam Engineering College*, India.\r\n\r\nI always believe, bridging the minds of academia & industry has to go beyond the nuances of theory vs. practical. We call ourselves the industry’s core and form the industry’s grey cells. What we need to do is make our problems open to the public. These problems becomes the new practice that needs to be picked up by our *alma mater*. Once selected, it will take no time for these problems to go viral among the students of these institutions. Let these young minds chart their own course; love, enjoy & live every moment when they traverse through this meandering amazon of practical problems. This becomes the fodder for the future theory allowing the current one to rest in peace.\r\n\r\nAbove sounds like a grand planning that resembles more like a trickle down effect. Well, the answer is a big ‘No’. Team at [**OpenEBS**](http://openebs.io/) believes there are many faster ways to achieve above in a time bound manner. Hence the formation of various internship programs where [**OpenEBS**](http://openebs.io/) approaches the Universities to get the latter on same plane that the former is passionate about.\r\n\r\n**At Kuppam, we could feel the freshness in the air, the disruptions that yearn to come out of the closet. We are all geared to lighten up this brilliance that is currently lying dishevelled.**\r\n\r\nOn a closing note, I challenge the myriad number of B.E projects & Ph.D. programs that are purposeless versus the likes of problems that the world wants us to solve. Join me in my effort to solve the problems that matter.\r\n","slug":"running-through-the-mud-looking-skywards"},{"id":26,"title":"OpenEBS Building blocks — Rancher Longhorn\r","author":"Uma Mukkara\r","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).\r","date":"2017-01-06\r","tags":["Container"," DevOps"," Longhorn"," Openebs"," Docker"],"excerpt":"In the previous blog post, I shared the initial details of OpenEBS. In this post, I will continue to discuss the OpenEBS technology building blocks and touch upon the details of Rancher longhorn and why we chose longhorn .\r","content":"\r\nIn the [previous ](https://blog.openebs.io/openebs-the-containerized-storage-f76e394a9543#.vaquo22zw)blog post, I shared the initial details of OpenEBS. In this post, I will continue to discuss the OpenEBS technology building blocks and touch upon the details of Rancher longhorn and why we chose [longhorn ](https://github.com/rancher/longhorn).\r\n\r\nOpenEBS platform contains three core building blocks:\r\n\r\n- An orchestration platform, Maya, that works with Kubernetes and manages thousands of volumes with ease.\r\n- Containerized storage volumes called Virtual Storage Machines or VSMs and\r\n- Maya managed backing stores or data stores residing either locally on OpenEBS hosts or remotely over network\r\n\r\n***Just to recap, why storage containerization?*** With storage containerization, the storage upgrades are flexible, easy, and effective. The containerization of storage means that the core functionality of storage (like front end protocol ISCSI, snapshotting, replication, backup) is abstracted into a Docker container and managed outside the kernel. A software patch to correct or enhance the replication behavior of a volume does not affect the other volume in the same host. Each of these Docker containers do a specific job of either running [gotgt ](https://github.com/gostor/gotgt)iSCSI or running a [longhorn ](https://github.com/rancher/longhorn)replica. The storage software is built as [Docker image](https://hub.docker.com/r/openebs/jiva/) and is the core/essence of OpenEBS technology. Hence, we named it “Jiva” (meaning “life”, [Wikipedia](https://en.wikipedia.org/wiki/Jiva)).\r\n\r\n***About VSM:*** Virtual Storage Machine is the logical set of storage pods that encapsulates the entire functionality of the life cycle of a volume. The components of an OpenEBS VSM is shown in the below picture.\r\n\r\n![Fig: OpenEBS VSM components](https://cdn-images-1.medium.com/max/800/1*-Bl0JyjyNdVe_bp6YI-n6w.png)\r\n\r\nA VSM contains as many storage pods as the number of data copies of the volume. Each storage pod has at least one container for replica and optionally has a container for exposing the storage access protocol (iSCSI, NBD etc). We are using a fork of rancher/longhorn software to manage the replication among the storage pods and a fork of gostor/gotgt software to provide iSCSI interface.\r\n\r\n## What is longhorn ?\r\n\r\nLonghorn is a simplified block storage software, implemented in golang, that stores the entire volume as a single linux sparse file. The sparse files provide thin provisioning behavior. Formatting with QCow2 adds the CoW feature to the data. It is lean and provides an AWS EBS style snapshot functionality. Longhorn has two subcomponents, longhorn controller (LHC) and longhorn replica (LHR). LHC takes care of storage connectivity, replication, rebuild, encryption, etc while LHR does snapshotting, backup, QoS, etc.\r\n\r\nLHC and LHR can be deployed in two modes.\r\n\r\n- *Hyper-converged container model,* where LHC and LHR are on the same host as that of compute or Docker Host. TCMU is used for block storage volume drive emulation on Docker Host.\r\n- *Remote storage model,* where LHC and LHR are on separate storage host. The compute Docker Host connects to LHC using iSCSI. iSCSI client is used for block storage volume drive emulation on Docker Host.\r\n\r\nThese two models are shown below\r\n\r\n#### LHC and LHR are on the Docker Host\r\n![Fig. Longhorn deployment mode : Hyper-converged](https://cdn-images-1.medium.com/max/800/1*nlswAfJqgqaWRJpKYLr_jA.png)\r\n\r\n*Note: Minimum linux kernel version required for hyper-converged mode is 4.4*\r\n\r\n## LHC and LHR are on the remote Storage\r\n![Fig: Longhorn deployment mode : Network storage](https://cdn-images-1.medium.com/max/800/1*wB_PG-Y_jZm8lMmSzKJAww.png)\r\n\r\nA third mode is also possible, where LHC runs on the Docker Host and LHR runs on the remote storage host, the discussion about this is for a later day.\r\n\r\nLonghorn replica uses 4K as the underlying block size and is a chain of differencing disks among the live data and snapshot data. The backup is done in a AWS-EBS style, where only the changed blocks are copied to the remote location (like S3) using 2M block size.\r\n\r\n## Why we chose longhorn for OpenEBS?\r\n\r\nWe wanted to implement a simple block storage engine, in user space, that can be containerized. Rancher had spent quite an amount of effort in just doing that. It is written in golang too. We found it to be thin, working, and fit. We integrated gotgt and longhorn for the basic use case of OpenEBS. We are thrilled to find great support from longhorn team in this journey. Thank you, Rancher. Though [openebs longhorn](https://github.com/openebs/longhorn) is forked at the moment from Rancher longhorn, we intend to push back the changes to the mainstream longhorn and contribute there. We plan to add the functionality of flash caching, S3 integration, RDMA support, cache tier-ing to remote storage, etc to longhorn in the days and months to come.\r\n\r\nThe next blog post will discuss the deployment modes of OpenEBS with containerized longhorn or jiva.\r\n","slug":"openebs-building-blocks-rancher-longhorn"}]